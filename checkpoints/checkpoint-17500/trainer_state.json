{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9352566252935257,
  "eval_steps": 500,
  "global_step": 17500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0033545790003354577,
      "grad_norm": 1.602724552154541,
      "learning_rate": 4.9949681314994973e-05,
      "logits/chosen": 2.584540605545044,
      "logits/rejected": 2.648106813430786,
      "logps/chosen": -207.41378784179688,
      "logps/rejected": -194.99993896484375,
      "loss": 0.6938,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0018768550362437963,
      "rewards/margins": -0.0011345961829647422,
      "rewards/rejected": 0.0030114506371319294,
      "step": 20
    },
    {
      "epoch": 0.006709158000670915,
      "grad_norm": 0.822058379650116,
      "learning_rate": 4.989377166498938e-05,
      "logits/chosen": 2.64306640625,
      "logits/rejected": 2.8245513439178467,
      "logps/chosen": -179.55459594726562,
      "logps/rejected": -158.52877807617188,
      "loss": 0.6893,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.002008786890655756,
      "rewards/margins": 0.00877046026289463,
      "rewards/rejected": -0.010779248550534248,
      "step": 40
    },
    {
      "epoch": 0.010063737001006373,
      "grad_norm": 1.298406958580017,
      "learning_rate": 4.983786201498379e-05,
      "logits/chosen": 2.660907745361328,
      "logits/rejected": 2.800337553024292,
      "logps/chosen": -190.09117126464844,
      "logps/rejected": -164.3841552734375,
      "loss": 0.6888,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.0103604756295681,
      "rewards/margins": 0.010530196130275726,
      "rewards/rejected": -0.00016972031153272837,
      "step": 60
    },
    {
      "epoch": 0.01341831600134183,
      "grad_norm": 1.4033902883529663,
      "learning_rate": 4.97819523649782e-05,
      "logits/chosen": 2.71637225151062,
      "logits/rejected": 2.8875248432159424,
      "logps/chosen": -197.58761596679688,
      "logps/rejected": -175.32131958007812,
      "loss": 0.6784,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.13588854670524597,
      "rewards/margins": 0.03354645520448685,
      "rewards/rejected": 0.10234208405017853,
      "step": 80
    },
    {
      "epoch": 0.01677289500167729,
      "grad_norm": 1.7522106170654297,
      "learning_rate": 4.972604271497261e-05,
      "logits/chosen": 2.581108570098877,
      "logits/rejected": 2.7964675426483154,
      "logps/chosen": -194.477783203125,
      "logps/rejected": -181.4481964111328,
      "loss": 0.6782,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.26609355211257935,
      "rewards/margins": 0.04479866474866867,
      "rewards/rejected": 0.22129487991333008,
      "step": 100
    },
    {
      "epoch": 0.020127474002012747,
      "grad_norm": 1.3791552782058716,
      "learning_rate": 4.96729285474673e-05,
      "logits/chosen": 2.5870723724365234,
      "logits/rejected": 2.737656831741333,
      "logps/chosen": -194.0970916748047,
      "logps/rejected": -184.80667114257812,
      "loss": 0.6953,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.3349589705467224,
      "rewards/margins": 0.020339634269475937,
      "rewards/rejected": 0.31461936235427856,
      "step": 120
    },
    {
      "epoch": 0.023482053002348204,
      "grad_norm": 1.99814772605896,
      "learning_rate": 4.96170188974617e-05,
      "logits/chosen": 2.653226137161255,
      "logits/rejected": 2.8298397064208984,
      "logps/chosen": -190.706787109375,
      "logps/rejected": -165.88998413085938,
      "loss": 0.6691,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.37015634775161743,
      "rewards/margins": 0.08400025218725204,
      "rewards/rejected": 0.2861561179161072,
      "step": 140
    },
    {
      "epoch": 0.02683663200268366,
      "grad_norm": 1.9201322793960571,
      "learning_rate": 4.956110924745611e-05,
      "logits/chosen": 2.827000617980957,
      "logits/rejected": 2.998521327972412,
      "logps/chosen": -199.27365112304688,
      "logps/rejected": -150.91238403320312,
      "loss": 0.6501,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.35622286796569824,
      "rewards/margins": 0.11978491395711899,
      "rewards/rejected": 0.23643796145915985,
      "step": 160
    },
    {
      "epoch": 0.030191211003019122,
      "grad_norm": 1.4467636346817017,
      "learning_rate": 4.950519959745053e-05,
      "logits/chosen": 2.5714874267578125,
      "logits/rejected": 2.609849452972412,
      "logps/chosen": -202.20370483398438,
      "logps/rejected": -181.92697143554688,
      "loss": 0.7084,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.3090362548828125,
      "rewards/margins": 0.03062998689711094,
      "rewards/rejected": 0.2784062623977661,
      "step": 180
    },
    {
      "epoch": 0.03354579000335458,
      "grad_norm": 1.5280402898788452,
      "learning_rate": 4.944928994744493e-05,
      "logits/chosen": 2.4856960773468018,
      "logits/rejected": 2.680724620819092,
      "logps/chosen": -209.8896484375,
      "logps/rejected": -179.07391357421875,
      "loss": 0.6279,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.08453953266143799,
      "rewards/margins": 0.19429557025432587,
      "rewards/rejected": -0.10975603759288788,
      "step": 200
    },
    {
      "epoch": 0.03690036900369004,
      "grad_norm": 1.9600063562393188,
      "learning_rate": 4.939338029743934e-05,
      "logits/chosen": 2.745112657546997,
      "logits/rejected": 2.8542609214782715,
      "logps/chosen": -197.17190551757812,
      "logps/rejected": -172.19386291503906,
      "loss": 0.6352,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.03249914199113846,
      "rewards/margins": 0.15978357195854187,
      "rewards/rejected": -0.19228270649909973,
      "step": 220
    },
    {
      "epoch": 0.040254948004025494,
      "grad_norm": 1.594118356704712,
      "learning_rate": 4.933747064743375e-05,
      "logits/chosen": 2.7287380695343018,
      "logits/rejected": 2.8446273803710938,
      "logps/chosen": -200.82257080078125,
      "logps/rejected": -182.18446350097656,
      "loss": 0.6376,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.049980126321315765,
      "rewards/margins": 0.2141311913728714,
      "rewards/rejected": -0.26411134004592896,
      "step": 240
    },
    {
      "epoch": 0.04360952700436095,
      "grad_norm": 2.4538261890411377,
      "learning_rate": 4.928156099742816e-05,
      "logits/chosen": 2.6944594383239746,
      "logits/rejected": 2.838416576385498,
      "logps/chosen": -188.24264526367188,
      "logps/rejected": -175.0318145751953,
      "loss": 0.6482,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.036345068365335464,
      "rewards/margins": 0.18594205379486084,
      "rewards/rejected": -0.14959698915481567,
      "step": 260
    },
    {
      "epoch": 0.04696410600469641,
      "grad_norm": 2.244781255722046,
      "learning_rate": 4.922565134742257e-05,
      "logits/chosen": 2.787468671798706,
      "logits/rejected": 2.8272247314453125,
      "logps/chosen": -190.1040496826172,
      "logps/rejected": -179.19688415527344,
      "loss": 0.7254,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.14179019629955292,
      "rewards/margins": 0.05520351976156235,
      "rewards/rejected": 0.08658669143915176,
      "step": 280
    },
    {
      "epoch": 0.050318685005031866,
      "grad_norm": 1.8590843677520752,
      "learning_rate": 4.9169741697416974e-05,
      "logits/chosen": 2.7020180225372314,
      "logits/rejected": 2.916081666946411,
      "logps/chosen": -185.01405334472656,
      "logps/rejected": -155.96914672851562,
      "loss": 0.583,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.3117392361164093,
      "rewards/margins": 0.35567641258239746,
      "rewards/rejected": -0.04393719136714935,
      "step": 300
    },
    {
      "epoch": 0.05367326400536732,
      "grad_norm": 1.0284286737442017,
      "learning_rate": 4.911383204741139e-05,
      "logits/chosen": 2.8492138385772705,
      "logits/rejected": 3.0119926929473877,
      "logps/chosen": -203.4135284423828,
      "logps/rejected": -175.13589477539062,
      "loss": 0.5882,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.4050019681453705,
      "rewards/margins": 0.4646264910697937,
      "rewards/rejected": -0.05962458252906799,
      "step": 320
    },
    {
      "epoch": 0.05702784300570279,
      "grad_norm": 1.8600730895996094,
      "learning_rate": 4.905792239740579e-05,
      "logits/chosen": 2.805264472961426,
      "logits/rejected": 2.8737521171569824,
      "logps/chosen": -186.3101806640625,
      "logps/rejected": -179.34396362304688,
      "loss": 0.6821,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.13716962933540344,
      "rewards/margins": 0.2539389133453369,
      "rewards/rejected": -0.39110854268074036,
      "step": 340
    },
    {
      "epoch": 0.060382422006038244,
      "grad_norm": 4.413689613342285,
      "learning_rate": 4.9002012747400204e-05,
      "logits/chosen": 2.712430953979492,
      "logits/rejected": 2.8295750617980957,
      "logps/chosen": -197.01803588867188,
      "logps/rejected": -177.54815673828125,
      "loss": 0.6803,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.1469690203666687,
      "rewards/margins": 0.29998165369033813,
      "rewards/rejected": -0.15301264822483063,
      "step": 360
    },
    {
      "epoch": 0.0637370010063737,
      "grad_norm": 1.7531015872955322,
      "learning_rate": 4.894610309739461e-05,
      "logits/chosen": 2.578063488006592,
      "logits/rejected": 2.7475666999816895,
      "logps/chosen": -182.25509643554688,
      "logps/rejected": -170.70492553710938,
      "loss": 0.6801,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.223423033952713,
      "rewards/margins": 0.23077479004859924,
      "rewards/rejected": -0.007351764477789402,
      "step": 380
    },
    {
      "epoch": 0.06709158000670916,
      "grad_norm": 1.5515999794006348,
      "learning_rate": 4.889019344738902e-05,
      "logits/chosen": 2.687506675720215,
      "logits/rejected": 2.8248488903045654,
      "logps/chosen": -185.68133544921875,
      "logps/rejected": -180.8264923095703,
      "loss": 0.7046,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.3056235909461975,
      "rewards/margins": 0.19127964973449707,
      "rewards/rejected": 0.11434390395879745,
      "step": 400
    },
    {
      "epoch": 0.07044615900704461,
      "grad_norm": 3.28035831451416,
      "learning_rate": 4.883428379738343e-05,
      "logits/chosen": 2.720445156097412,
      "logits/rejected": 2.862623453140259,
      "logps/chosen": -194.13819885253906,
      "logps/rejected": -166.2915496826172,
      "loss": 0.6674,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.49423113465309143,
      "rewards/margins": 0.324152410030365,
      "rewards/rejected": 0.17007872462272644,
      "step": 420
    },
    {
      "epoch": 0.07380073800738007,
      "grad_norm": 2.5757436752319336,
      "learning_rate": 4.877837414737784e-05,
      "logits/chosen": 2.62019681930542,
      "logits/rejected": 2.7858386039733887,
      "logps/chosen": -199.19468688964844,
      "logps/rejected": -175.82748413085938,
      "loss": 0.6835,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.43695634603500366,
      "rewards/margins": 0.26093825697898865,
      "rewards/rejected": 0.1760181486606598,
      "step": 440
    },
    {
      "epoch": 0.07715531700771554,
      "grad_norm": 1.4799219369888306,
      "learning_rate": 4.872246449737225e-05,
      "logits/chosen": 2.705759048461914,
      "logits/rejected": 2.926384449005127,
      "logps/chosen": -184.95916748046875,
      "logps/rejected": -171.65679931640625,
      "loss": 0.6296,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.3884405195713043,
      "rewards/margins": 0.2816200852394104,
      "rewards/rejected": 0.10682036727666855,
      "step": 460
    },
    {
      "epoch": 0.08050989600805099,
      "grad_norm": 2.2538890838623047,
      "learning_rate": 4.866655484736666e-05,
      "logits/chosen": 2.656360626220703,
      "logits/rejected": 2.7498726844787598,
      "logps/chosen": -197.10684204101562,
      "logps/rejected": -181.97125244140625,
      "loss": 0.6737,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.3534371554851532,
      "rewards/margins": 0.2404661923646927,
      "rewards/rejected": 0.1129709854722023,
      "step": 480
    },
    {
      "epoch": 0.08386447500838645,
      "grad_norm": 1.6163979768753052,
      "learning_rate": 4.8610645197361063e-05,
      "logits/chosen": 2.7523012161254883,
      "logits/rejected": 2.8701601028442383,
      "logps/chosen": -181.13412475585938,
      "logps/rejected": -155.65750122070312,
      "loss": 0.6162,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.4370195269584656,
      "rewards/margins": 0.4019792675971985,
      "rewards/rejected": 0.03504032641649246,
      "step": 500
    },
    {
      "epoch": 0.0872190540087219,
      "grad_norm": 1.6377232074737549,
      "learning_rate": 4.8554735547355476e-05,
      "logits/chosen": 2.750011920928955,
      "logits/rejected": 2.911612033843994,
      "logps/chosen": -200.753662109375,
      "logps/rejected": -186.97689819335938,
      "loss": 0.6357,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.8186728358268738,
      "rewards/margins": 0.36579927802085876,
      "rewards/rejected": 0.452873557806015,
      "step": 520
    },
    {
      "epoch": 0.09057363300905737,
      "grad_norm": 1.3733251094818115,
      "learning_rate": 4.849882589734989e-05,
      "logits/chosen": 2.687201976776123,
      "logits/rejected": 2.8382108211517334,
      "logps/chosen": -166.59603881835938,
      "logps/rejected": -155.63446044921875,
      "loss": 0.7069,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.7261150479316711,
      "rewards/margins": 0.26846322417259216,
      "rewards/rejected": 0.45765185356140137,
      "step": 540
    },
    {
      "epoch": 0.09392821200939282,
      "grad_norm": 1.781256914138794,
      "learning_rate": 4.8442916247344294e-05,
      "logits/chosen": 2.884967803955078,
      "logits/rejected": 3.0561461448669434,
      "logps/chosen": -182.9031524658203,
      "logps/rejected": -167.23818969726562,
      "loss": 0.6137,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.8070894479751587,
      "rewards/margins": 0.34782275557518005,
      "rewards/rejected": 0.459266722202301,
      "step": 560
    },
    {
      "epoch": 0.09728279100972828,
      "grad_norm": 1.9700040817260742,
      "learning_rate": 4.83870065973387e-05,
      "logits/chosen": 2.627573013305664,
      "logits/rejected": 2.8138582706451416,
      "logps/chosen": -191.10543823242188,
      "logps/rejected": -178.4449462890625,
      "loss": 0.7093,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.7040919661521912,
      "rewards/margins": 0.2175290286540985,
      "rewards/rejected": 0.48656290769577026,
      "step": 580
    },
    {
      "epoch": 0.10063737001006373,
      "grad_norm": 2.229964017868042,
      "learning_rate": 4.833109694733311e-05,
      "logits/chosen": 2.894744634628296,
      "logits/rejected": 3.036550760269165,
      "logps/chosen": -190.37191772460938,
      "logps/rejected": -169.0396728515625,
      "loss": 0.7319,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.30000609159469604,
      "rewards/margins": 0.1409134566783905,
      "rewards/rejected": 0.15909263491630554,
      "step": 600
    },
    {
      "epoch": 0.1039919490103992,
      "grad_norm": 2.2222349643707275,
      "learning_rate": 4.8275187297327524e-05,
      "logits/chosen": 2.828425168991089,
      "logits/rejected": 2.9710237979888916,
      "logps/chosen": -183.89700317382812,
      "logps/rejected": -168.99974060058594,
      "loss": 0.7003,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.24736475944519043,
      "rewards/margins": 0.16280364990234375,
      "rewards/rejected": 0.08456110209226608,
      "step": 620
    },
    {
      "epoch": 0.10734652801073465,
      "grad_norm": 1.5560461282730103,
      "learning_rate": 4.821927764732193e-05,
      "logits/chosen": 2.826017141342163,
      "logits/rejected": 2.928398370742798,
      "logps/chosen": -173.701416015625,
      "logps/rejected": -157.26026916503906,
      "loss": 0.5732,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.21229028701782227,
      "rewards/margins": 0.3823976516723633,
      "rewards/rejected": -0.1701073795557022,
      "step": 640
    },
    {
      "epoch": 0.11070110701107011,
      "grad_norm": 1.62636137008667,
      "learning_rate": 4.816336799731634e-05,
      "logits/chosen": 2.925287961959839,
      "logits/rejected": 3.0563528537750244,
      "logps/chosen": -193.1484375,
      "logps/rejected": -161.12820434570312,
      "loss": 0.6506,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.18798048794269562,
      "rewards/margins": 0.2646636664867401,
      "rewards/rejected": -0.0766831785440445,
      "step": 660
    },
    {
      "epoch": 0.11405568601140557,
      "grad_norm": 2.6393964290618896,
      "learning_rate": 4.810745834731075e-05,
      "logits/chosen": 2.9391510486602783,
      "logits/rejected": 2.9662623405456543,
      "logps/chosen": -192.41793823242188,
      "logps/rejected": -180.6452178955078,
      "loss": 0.786,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.18901625275611877,
      "rewards/margins": 0.05349850654602051,
      "rewards/rejected": 0.13551774621009827,
      "step": 680
    },
    {
      "epoch": 0.11741026501174102,
      "grad_norm": 1.1556322574615479,
      "learning_rate": 4.805154869730516e-05,
      "logits/chosen": 2.966348171234131,
      "logits/rejected": 3.090938091278076,
      "logps/chosen": -200.29428100585938,
      "logps/rejected": -192.7462158203125,
      "loss": 0.6586,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.2138155996799469,
      "rewards/margins": 0.24773132801055908,
      "rewards/rejected": -0.03391571715474129,
      "step": 700
    },
    {
      "epoch": 0.12076484401207649,
      "grad_norm": 2.5406384468078613,
      "learning_rate": 4.7995639047299565e-05,
      "logits/chosen": 2.925494909286499,
      "logits/rejected": 2.971353054046631,
      "logps/chosen": -193.40084838867188,
      "logps/rejected": -175.58221435546875,
      "loss": 0.6298,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.18600112199783325,
      "rewards/margins": 0.3104361891746521,
      "rewards/rejected": -0.12443510442972183,
      "step": 720
    },
    {
      "epoch": 0.12411942301241194,
      "grad_norm": 1.5424267053604126,
      "learning_rate": 4.793972939729398e-05,
      "logits/chosen": 2.8012442588806152,
      "logits/rejected": 3.1270668506622314,
      "logps/chosen": -186.70223999023438,
      "logps/rejected": -178.58177185058594,
      "loss": 0.6381,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.526451051235199,
      "rewards/margins": 0.36801987886428833,
      "rewards/rejected": 0.15843120217323303,
      "step": 740
    },
    {
      "epoch": 0.1274740020127474,
      "grad_norm": 1.3221197128295898,
      "learning_rate": 4.788661522978866e-05,
      "logits/chosen": 3.0007405281066895,
      "logits/rejected": 3.0635764598846436,
      "logps/chosen": -171.98904418945312,
      "logps/rejected": -161.07537841796875,
      "loss": 0.7042,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.019228558987379074,
      "rewards/margins": 0.2107965499162674,
      "rewards/rejected": -0.19156798720359802,
      "step": 760
    },
    {
      "epoch": 0.13082858101308287,
      "grad_norm": 1.983131766319275,
      "learning_rate": 4.783070557978308e-05,
      "logits/chosen": 2.8450636863708496,
      "logits/rejected": 3.1365017890930176,
      "logps/chosen": -209.9490203857422,
      "logps/rejected": -180.17922973632812,
      "loss": 0.6055,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.13648101687431335,
      "rewards/margins": 0.3995557427406311,
      "rewards/rejected": -0.26307469606399536,
      "step": 780
    },
    {
      "epoch": 0.13418316001341832,
      "grad_norm": 1.1809452772140503,
      "learning_rate": 4.7774795929777483e-05,
      "logits/chosen": 2.922135829925537,
      "logits/rejected": 3.052471160888672,
      "logps/chosen": -186.95108032226562,
      "logps/rejected": -183.69454956054688,
      "loss": 0.6437,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.020729612559080124,
      "rewards/margins": 0.371796190738678,
      "rewards/rejected": -0.35106658935546875,
      "step": 800
    },
    {
      "epoch": 0.13753773901375377,
      "grad_norm": 1.4757938385009766,
      "learning_rate": 4.771888627977189e-05,
      "logits/chosen": 2.7792062759399414,
      "logits/rejected": 2.90997052192688,
      "logps/chosen": -187.05982971191406,
      "logps/rejected": -176.2550506591797,
      "loss": 0.6516,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.09122493118047714,
      "rewards/margins": 0.30644768476486206,
      "rewards/rejected": -0.21522274613380432,
      "step": 820
    },
    {
      "epoch": 0.14089231801408922,
      "grad_norm": 1.4381840229034424,
      "learning_rate": 4.76629766297663e-05,
      "logits/chosen": 2.8002848625183105,
      "logits/rejected": 2.8951892852783203,
      "logps/chosen": -187.6775360107422,
      "logps/rejected": -170.6439971923828,
      "loss": 0.6556,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.07518098503351212,
      "rewards/margins": 0.3044685125350952,
      "rewards/rejected": -0.2292875051498413,
      "step": 840
    },
    {
      "epoch": 0.1442468970144247,
      "grad_norm": 1.6586754322052002,
      "learning_rate": 4.7607066979760714e-05,
      "logits/chosen": 2.8216636180877686,
      "logits/rejected": 2.9623467922210693,
      "logps/chosen": -179.23150634765625,
      "logps/rejected": -170.54818725585938,
      "loss": 0.6542,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.05519567057490349,
      "rewards/margins": 0.3383621275424957,
      "rewards/rejected": -0.28316646814346313,
      "step": 860
    },
    {
      "epoch": 0.14760147601476015,
      "grad_norm": 1.3766905069351196,
      "learning_rate": 4.755115732975512e-05,
      "logits/chosen": 2.8877272605895996,
      "logits/rejected": 3.0582103729248047,
      "logps/chosen": -199.90480041503906,
      "logps/rejected": -170.79478454589844,
      "loss": 0.5399,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.19757162034511566,
      "rewards/margins": 0.7071629166603088,
      "rewards/rejected": -0.5095912218093872,
      "step": 880
    },
    {
      "epoch": 0.1509560550150956,
      "grad_norm": 1.3494194746017456,
      "learning_rate": 4.7495247679749525e-05,
      "logits/chosen": 2.9472274780273438,
      "logits/rejected": 3.1897287368774414,
      "logps/chosen": -192.53236389160156,
      "logps/rejected": -175.42601013183594,
      "loss": 0.5423,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.2570987343788147,
      "rewards/margins": 0.6730427145957947,
      "rewards/rejected": -0.41594401001930237,
      "step": 900
    },
    {
      "epoch": 0.15431063401543108,
      "grad_norm": 1.7766634225845337,
      "learning_rate": 4.744213351224421e-05,
      "logits/chosen": 2.7011590003967285,
      "logits/rejected": 2.8573341369628906,
      "logps/chosen": -195.2232666015625,
      "logps/rejected": -173.0470428466797,
      "loss": 0.6596,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.2520155906677246,
      "rewards/margins": 0.40665706992149353,
      "rewards/rejected": -0.15464147925376892,
      "step": 920
    },
    {
      "epoch": 0.15766521301576653,
      "grad_norm": 2.1810479164123535,
      "learning_rate": 4.7386223862238625e-05,
      "logits/chosen": 2.881800889968872,
      "logits/rejected": 3.050449848175049,
      "logps/chosen": -176.50875854492188,
      "logps/rejected": -162.96401977539062,
      "loss": 0.7545,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.01159515418112278,
      "rewards/margins": 0.3376583158969879,
      "rewards/rejected": -0.34925344586372375,
      "step": 940
    },
    {
      "epoch": 0.16101979201610198,
      "grad_norm": 1.278371810913086,
      "learning_rate": 4.733031421223304e-05,
      "logits/chosen": 2.817946434020996,
      "logits/rejected": 2.9713451862335205,
      "logps/chosen": -186.7019500732422,
      "logps/rejected": -169.97171020507812,
      "loss": 0.5421,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.18108291923999786,
      "rewards/margins": 0.6093229651451111,
      "rewards/rejected": -0.42824000120162964,
      "step": 960
    },
    {
      "epoch": 0.16437437101643743,
      "grad_norm": 3.0879578590393066,
      "learning_rate": 4.727440456222744e-05,
      "logits/chosen": 2.676305055618286,
      "logits/rejected": 2.868317127227783,
      "logps/chosen": -186.0510711669922,
      "logps/rejected": -177.23313903808594,
      "loss": 0.6195,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.3193758726119995,
      "rewards/margins": 0.4445417821407318,
      "rewards/rejected": -0.7639176845550537,
      "step": 980
    },
    {
      "epoch": 0.1677289500167729,
      "grad_norm": 1.4042954444885254,
      "learning_rate": 4.721849491222185e-05,
      "logits/chosen": 2.5450291633605957,
      "logits/rejected": 2.663907766342163,
      "logps/chosen": -194.75509643554688,
      "logps/rejected": -189.8476104736328,
      "loss": 0.6796,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.2829144597053528,
      "rewards/margins": 0.29289180040359497,
      "rewards/rejected": -0.5758062601089478,
      "step": 1000
    },
    {
      "epoch": 0.17108352901710835,
      "grad_norm": 1.510348916053772,
      "learning_rate": 4.716258526221626e-05,
      "logits/chosen": 2.608144998550415,
      "logits/rejected": 2.7832062244415283,
      "logps/chosen": -198.17437744140625,
      "logps/rejected": -185.3258056640625,
      "loss": 0.5695,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5131916403770447,
      "rewards/margins": 0.6919979453086853,
      "rewards/rejected": -1.2051897048950195,
      "step": 1020
    },
    {
      "epoch": 0.1744381080174438,
      "grad_norm": 1.195935606956482,
      "learning_rate": 4.710667561221067e-05,
      "logits/chosen": 2.714430809020996,
      "logits/rejected": 2.8799030780792236,
      "logps/chosen": -195.82083129882812,
      "logps/rejected": -180.4180908203125,
      "loss": 0.7129,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.2558618485927582,
      "rewards/margins": 0.5078341960906982,
      "rewards/rejected": -0.763696014881134,
      "step": 1040
    },
    {
      "epoch": 0.17779268701777926,
      "grad_norm": 5.63440465927124,
      "learning_rate": 4.705076596220508e-05,
      "logits/chosen": 2.906184434890747,
      "logits/rejected": 3.015427350997925,
      "logps/chosen": -219.47457885742188,
      "logps/rejected": -194.84056091308594,
      "loss": 0.5766,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.17895542085170746,
      "rewards/margins": 0.6975582838058472,
      "rewards/rejected": -0.876513659954071,
      "step": 1060
    },
    {
      "epoch": 0.18114726601811473,
      "grad_norm": 1.7138466835021973,
      "learning_rate": 4.6994856312199484e-05,
      "logits/chosen": 2.7671022415161133,
      "logits/rejected": 2.8890833854675293,
      "logps/chosen": -193.4934844970703,
      "logps/rejected": -182.71044921875,
      "loss": 0.5642,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.23098742961883545,
      "rewards/margins": 0.6849770545959473,
      "rewards/rejected": -0.9159644246101379,
      "step": 1080
    },
    {
      "epoch": 0.18450184501845018,
      "grad_norm": 1.5120080709457397,
      "learning_rate": 4.6938946662193897e-05,
      "logits/chosen": 2.8592026233673096,
      "logits/rejected": 2.9855265617370605,
      "logps/chosen": -201.37977600097656,
      "logps/rejected": -186.12660217285156,
      "loss": 0.5557,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.05313235521316528,
      "rewards/margins": 0.653859555721283,
      "rewards/rejected": -0.7069919109344482,
      "step": 1100
    },
    {
      "epoch": 0.18785642401878563,
      "grad_norm": 2.956414222717285,
      "learning_rate": 4.688303701218831e-05,
      "logits/chosen": 2.7503952980041504,
      "logits/rejected": 2.871364116668701,
      "logps/chosen": -189.4630584716797,
      "logps/rejected": -170.01211547851562,
      "loss": 0.6818,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.04631885141134262,
      "rewards/margins": 0.547034740447998,
      "rewards/rejected": -0.5933535695075989,
      "step": 1120
    },
    {
      "epoch": 0.1912110030191211,
      "grad_norm": 2.152228593826294,
      "learning_rate": 4.6827127362182714e-05,
      "logits/chosen": 2.6583352088928223,
      "logits/rejected": 2.872239589691162,
      "logps/chosen": -190.92921447753906,
      "logps/rejected": -170.8048553466797,
      "loss": 0.5702,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.0038072229363024235,
      "rewards/margins": 0.7287536859512329,
      "rewards/rejected": -0.7249463796615601,
      "step": 1140
    },
    {
      "epoch": 0.19456558201945656,
      "grad_norm": 1.4344192743301392,
      "learning_rate": 4.677121771217713e-05,
      "logits/chosen": 2.7419424057006836,
      "logits/rejected": 2.838747501373291,
      "logps/chosen": -202.52919006347656,
      "logps/rejected": -198.24197387695312,
      "loss": 0.7083,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.19028718769550323,
      "rewards/margins": 0.37346431612968445,
      "rewards/rejected": -0.5637515187263489,
      "step": 1160
    },
    {
      "epoch": 0.197920161019792,
      "grad_norm": 1.7127985954284668,
      "learning_rate": 4.671530806217153e-05,
      "logits/chosen": 2.7605857849121094,
      "logits/rejected": 2.879946231842041,
      "logps/chosen": -191.52154541015625,
      "logps/rejected": -175.35330200195312,
      "loss": 0.67,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.32989105582237244,
      "rewards/margins": 0.4772856831550598,
      "rewards/rejected": -0.8071767687797546,
      "step": 1180
    },
    {
      "epoch": 0.20127474002012746,
      "grad_norm": 3.009479284286499,
      "learning_rate": 4.6659398412165945e-05,
      "logits/chosen": 2.739555597305298,
      "logits/rejected": 2.9367141723632812,
      "logps/chosen": -207.41036987304688,
      "logps/rejected": -185.8492431640625,
      "loss": 0.6646,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.07940585911273956,
      "rewards/margins": 0.6268823742866516,
      "rewards/rejected": -0.5474764704704285,
      "step": 1200
    },
    {
      "epoch": 0.20462931902046294,
      "grad_norm": 1.8901230096817017,
      "learning_rate": 4.660348876216035e-05,
      "logits/chosen": 2.8818933963775635,
      "logits/rejected": 3.0828659534454346,
      "logps/chosen": -197.94046020507812,
      "logps/rejected": -173.69851684570312,
      "loss": 0.5948,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.13833126425743103,
      "rewards/margins": 0.6944016814231873,
      "rewards/rejected": -0.5560704469680786,
      "step": 1220
    },
    {
      "epoch": 0.2079838980207984,
      "grad_norm": 1.6352232694625854,
      "learning_rate": 4.654757911215476e-05,
      "logits/chosen": 2.9219741821289062,
      "logits/rejected": 3.000694751739502,
      "logps/chosen": -183.34188842773438,
      "logps/rejected": -171.1654815673828,
      "loss": 0.6204,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.012208312749862671,
      "rewards/margins": 0.47238317131996155,
      "rewards/rejected": -0.48459142446517944,
      "step": 1240
    },
    {
      "epoch": 0.21133847702113384,
      "grad_norm": 1.7623707056045532,
      "learning_rate": 4.6494464944649444e-05,
      "logits/chosen": 2.847513198852539,
      "logits/rejected": 3.0358169078826904,
      "logps/chosen": -174.79080200195312,
      "logps/rejected": -171.7619171142578,
      "loss": 0.6878,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.045363448560237885,
      "rewards/margins": 0.32937246561050415,
      "rewards/rejected": -0.37473592162132263,
      "step": 1260
    },
    {
      "epoch": 0.2146930560214693,
      "grad_norm": 1.776387095451355,
      "learning_rate": 4.6438555294643856e-05,
      "logits/chosen": 2.749873399734497,
      "logits/rejected": 2.9151151180267334,
      "logps/chosen": -201.69847106933594,
      "logps/rejected": -180.87509155273438,
      "loss": 0.5987,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.1851310431957245,
      "rewards/margins": 0.5627243518829346,
      "rewards/rejected": -0.37759333848953247,
      "step": 1280
    },
    {
      "epoch": 0.21804763502180477,
      "grad_norm": 1.9198179244995117,
      "learning_rate": 4.638264564463827e-05,
      "logits/chosen": 2.8809192180633545,
      "logits/rejected": 3.2293925285339355,
      "logps/chosen": -192.32887268066406,
      "logps/rejected": -181.0729522705078,
      "loss": 0.4532,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": 0.4414433538913727,
      "rewards/margins": 1.0026954412460327,
      "rewards/rejected": -0.5612521171569824,
      "step": 1300
    },
    {
      "epoch": 0.22140221402214022,
      "grad_norm": 1.3908400535583496,
      "learning_rate": 4.6326735994632674e-05,
      "logits/chosen": 2.73606014251709,
      "logits/rejected": 2.963797092437744,
      "logps/chosen": -187.89080810546875,
      "logps/rejected": -170.29730224609375,
      "loss": 0.6483,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.33159691095352173,
      "rewards/margins": 0.5539210438728333,
      "rewards/rejected": -0.2223241627216339,
      "step": 1320
    },
    {
      "epoch": 0.22475679302247567,
      "grad_norm": 1.8486354351043701,
      "learning_rate": 4.627082634462708e-05,
      "logits/chosen": 2.8081295490264893,
      "logits/rejected": 2.899970054626465,
      "logps/chosen": -190.7811737060547,
      "logps/rejected": -166.6055450439453,
      "loss": 0.6789,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.0071166157722473145,
      "rewards/margins": 0.4105805456638336,
      "rewards/rejected": -0.4176971912384033,
      "step": 1340
    },
    {
      "epoch": 0.22811137202281115,
      "grad_norm": 1.2440013885498047,
      "learning_rate": 4.62149166946215e-05,
      "logits/chosen": 2.8061723709106445,
      "logits/rejected": 2.9848194122314453,
      "logps/chosen": -189.35194396972656,
      "logps/rejected": -167.65499877929688,
      "loss": 0.6476,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.19322548806667328,
      "rewards/margins": 0.5203421115875244,
      "rewards/rejected": -0.32711657881736755,
      "step": 1360
    },
    {
      "epoch": 0.2314659510231466,
      "grad_norm": 2.750546932220459,
      "learning_rate": 4.6159007044615904e-05,
      "logits/chosen": 2.962371587753296,
      "logits/rejected": 3.1282668113708496,
      "logps/chosen": -200.39010620117188,
      "logps/rejected": -178.02674865722656,
      "loss": 0.5964,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.010488411411643028,
      "rewards/margins": 0.6914658546447754,
      "rewards/rejected": -0.6809772849082947,
      "step": 1380
    },
    {
      "epoch": 0.23482053002348205,
      "grad_norm": 2.5916812419891357,
      "learning_rate": 4.610309739461031e-05,
      "logits/chosen": 2.9312222003936768,
      "logits/rejected": 3.002093553543091,
      "logps/chosen": -190.09742736816406,
      "logps/rejected": -187.31173706054688,
      "loss": 0.7296,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.13933098316192627,
      "rewards/margins": 0.3330801725387573,
      "rewards/rejected": -0.19374921917915344,
      "step": 1400
    },
    {
      "epoch": 0.2381751090238175,
      "grad_norm": 1.9241539239883423,
      "learning_rate": 4.604718774460472e-05,
      "logits/chosen": 2.8602919578552246,
      "logits/rejected": 2.8752975463867188,
      "logps/chosen": -194.47250366210938,
      "logps/rejected": -173.77407836914062,
      "loss": 0.7667,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.0010987833375111222,
      "rewards/margins": 0.27930593490600586,
      "rewards/rejected": -0.2782072126865387,
      "step": 1420
    },
    {
      "epoch": 0.24152968802415298,
      "grad_norm": 1.6415358781814575,
      "learning_rate": 4.599127809459913e-05,
      "logits/chosen": 2.8557536602020264,
      "logits/rejected": 3.0227644443511963,
      "logps/chosen": -196.44070434570312,
      "logps/rejected": -172.00035095214844,
      "loss": 0.5947,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.284423291683197,
      "rewards/margins": 0.6273439526557922,
      "rewards/rejected": -0.3429206907749176,
      "step": 1440
    },
    {
      "epoch": 0.24488426702448843,
      "grad_norm": 1.702646017074585,
      "learning_rate": 4.593536844459354e-05,
      "logits/chosen": 2.814981698989868,
      "logits/rejected": 3.056002140045166,
      "logps/chosen": -187.6610107421875,
      "logps/rejected": -175.52976989746094,
      "loss": 0.6285,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.2714950740337372,
      "rewards/margins": 0.506729781627655,
      "rewards/rejected": -0.23523469269275665,
      "step": 1460
    },
    {
      "epoch": 0.24823884602482388,
      "grad_norm": 1.1619243621826172,
      "learning_rate": 4.5879458794587945e-05,
      "logits/chosen": 2.655930757522583,
      "logits/rejected": 2.9509406089782715,
      "logps/chosen": -196.2093963623047,
      "logps/rejected": -168.30740356445312,
      "loss": 0.5411,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.31507715582847595,
      "rewards/margins": 0.6702709794044495,
      "rewards/rejected": -0.3551937937736511,
      "step": 1480
    },
    {
      "epoch": 0.25159342502515936,
      "grad_norm": 2.702629327774048,
      "learning_rate": 4.582354914458236e-05,
      "logits/chosen": 2.8106045722961426,
      "logits/rejected": 2.9892542362213135,
      "logps/chosen": -183.1688232421875,
      "logps/rejected": -172.21875,
      "loss": 0.744,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.17225079238414764,
      "rewards/margins": 0.18049050867557526,
      "rewards/rejected": -0.3527413010597229,
      "step": 1500
    },
    {
      "epoch": 0.2549480040254948,
      "grad_norm": 1.7557910680770874,
      "learning_rate": 4.576763949457676e-05,
      "logits/chosen": 2.6929688453674316,
      "logits/rejected": 2.9845316410064697,
      "logps/chosen": -191.45265197753906,
      "logps/rejected": -183.43341064453125,
      "loss": 0.5543,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.03900742530822754,
      "rewards/margins": 0.5555943250656128,
      "rewards/rejected": -0.5165870189666748,
      "step": 1520
    },
    {
      "epoch": 0.25830258302583026,
      "grad_norm": 1.7239269018173218,
      "learning_rate": 4.5711729844571176e-05,
      "logits/chosen": 2.924578905105591,
      "logits/rejected": 3.1114726066589355,
      "logps/chosen": -184.79998779296875,
      "logps/rejected": -169.96888732910156,
      "loss": 0.5564,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.19753490388393402,
      "rewards/margins": 0.7164515256881714,
      "rewards/rejected": -0.5189166069030762,
      "step": 1540
    },
    {
      "epoch": 0.26165716202616573,
      "grad_norm": 1.0824615955352783,
      "learning_rate": 4.565582019456559e-05,
      "logits/chosen": 2.7006912231445312,
      "logits/rejected": 2.930140256881714,
      "logps/chosen": -194.8668975830078,
      "logps/rejected": -170.6809844970703,
      "loss": 0.5806,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.4196966588497162,
      "rewards/margins": 0.6087958812713623,
      "rewards/rejected": -0.18909917771816254,
      "step": 1560
    },
    {
      "epoch": 0.26501174102650116,
      "grad_norm": 2.255603551864624,
      "learning_rate": 4.559991054455999e-05,
      "logits/chosen": 2.805849313735962,
      "logits/rejected": 2.9056618213653564,
      "logps/chosen": -188.3343048095703,
      "logps/rejected": -171.74270629882812,
      "loss": 0.5984,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.3200005888938904,
      "rewards/margins": 0.5193842649459839,
      "rewards/rejected": -0.1993836611509323,
      "step": 1580
    },
    {
      "epoch": 0.26836632002683664,
      "grad_norm": 2.4146456718444824,
      "learning_rate": 4.55440008945544e-05,
      "logits/chosen": 2.644057035446167,
      "logits/rejected": 2.8639886379241943,
      "logps/chosen": -186.5858154296875,
      "logps/rejected": -183.23939514160156,
      "loss": 0.6168,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.3069140315055847,
      "rewards/margins": 0.5315120816230774,
      "rewards/rejected": -0.2245979756116867,
      "step": 1600
    },
    {
      "epoch": 0.2717208990271721,
      "grad_norm": 2.2829129695892334,
      "learning_rate": 4.548809124454881e-05,
      "logits/chosen": 2.65161395072937,
      "logits/rejected": 2.780841827392578,
      "logps/chosen": -177.70169067382812,
      "logps/rejected": -170.65870666503906,
      "loss": 0.6546,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.26359838247299194,
      "rewards/margins": 0.5489163398742676,
      "rewards/rejected": -0.28531792759895325,
      "step": 1620
    },
    {
      "epoch": 0.27507547802750754,
      "grad_norm": 0.7274563908576965,
      "learning_rate": 4.5432181594543223e-05,
      "logits/chosen": 2.6168713569641113,
      "logits/rejected": 2.8130576610565186,
      "logps/chosen": -195.58888244628906,
      "logps/rejected": -179.6533660888672,
      "loss": 0.6775,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.017256297171115875,
      "rewards/margins": 0.3503745496273041,
      "rewards/rejected": -0.3331182897090912,
      "step": 1640
    },
    {
      "epoch": 0.278430057027843,
      "grad_norm": 3.1045138835906982,
      "learning_rate": 4.537627194453763e-05,
      "logits/chosen": 2.73667311668396,
      "logits/rejected": 2.9971556663513184,
      "logps/chosen": -207.13748168945312,
      "logps/rejected": -209.59432983398438,
      "loss": 0.5539,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.20231500267982483,
      "rewards/margins": 0.7939058542251587,
      "rewards/rejected": -0.5915908217430115,
      "step": 1660
    },
    {
      "epoch": 0.28178463602817844,
      "grad_norm": 2.5021231174468994,
      "learning_rate": 4.5320362294532035e-05,
      "logits/chosen": 2.674607276916504,
      "logits/rejected": 2.911914348602295,
      "logps/chosen": -197.8157958984375,
      "logps/rejected": -187.22454833984375,
      "loss": 0.5293,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.2758454978466034,
      "rewards/margins": 0.7771314382553101,
      "rewards/rejected": -1.0529768466949463,
      "step": 1680
    },
    {
      "epoch": 0.2851392150285139,
      "grad_norm": 3.7879137992858887,
      "learning_rate": 4.526445264452645e-05,
      "logits/chosen": 2.6928467750549316,
      "logits/rejected": 2.8985631465911865,
      "logps/chosen": -205.3885498046875,
      "logps/rejected": -187.67457580566406,
      "loss": 0.6064,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.8330181837081909,
      "rewards/margins": 0.7694709897041321,
      "rewards/rejected": -1.6024892330169678,
      "step": 1700
    },
    {
      "epoch": 0.2884937940288494,
      "grad_norm": 1.4705333709716797,
      "learning_rate": 4.520854299452086e-05,
      "logits/chosen": 2.7416396141052246,
      "logits/rejected": 2.858508586883545,
      "logps/chosen": -210.36083984375,
      "logps/rejected": -187.78668212890625,
      "loss": 0.7029,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.8395549058914185,
      "rewards/margins": 0.47336944937705994,
      "rewards/rejected": -1.3129241466522217,
      "step": 1720
    },
    {
      "epoch": 0.2918483730291848,
      "grad_norm": 1.8370307683944702,
      "learning_rate": 4.5152633344515265e-05,
      "logits/chosen": 2.5303781032562256,
      "logits/rejected": 2.8052573204040527,
      "logps/chosen": -211.6718292236328,
      "logps/rejected": -191.20518493652344,
      "loss": 0.5445,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.477154403924942,
      "rewards/margins": 0.8721247911453247,
      "rewards/rejected": -1.3492791652679443,
      "step": 1740
    },
    {
      "epoch": 0.2952029520295203,
      "grad_norm": 1.0245475769042969,
      "learning_rate": 4.509672369450968e-05,
      "logits/chosen": 2.4986355304718018,
      "logits/rejected": 2.7053232192993164,
      "logps/chosen": -204.20452880859375,
      "logps/rejected": -192.7699737548828,
      "loss": 0.5322,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.17714866995811462,
      "rewards/margins": 0.7417283058166504,
      "rewards/rejected": -0.9188769459724426,
      "step": 1760
    },
    {
      "epoch": 0.29855753102985577,
      "grad_norm": 0.4525226652622223,
      "learning_rate": 4.504081404450408e-05,
      "logits/chosen": 2.633876323699951,
      "logits/rejected": 3.015293598175049,
      "logps/chosen": -209.87564086914062,
      "logps/rejected": -189.03421020507812,
      "loss": 0.4998,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.2715519666671753,
      "rewards/margins": 1.1095305681228638,
      "rewards/rejected": -1.38108229637146,
      "step": 1780
    },
    {
      "epoch": 0.3019121100301912,
      "grad_norm": 2.4947617053985596,
      "learning_rate": 4.4984904394498495e-05,
      "logits/chosen": 2.7628743648529053,
      "logits/rejected": 3.053438186645508,
      "logps/chosen": -200.05441284179688,
      "logps/rejected": -182.7847900390625,
      "loss": 0.5453,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.20459870994091034,
      "rewards/margins": 0.9898303747177124,
      "rewards/rejected": -1.1944291591644287,
      "step": 1800
    },
    {
      "epoch": 0.3052666890305267,
      "grad_norm": 3.046786069869995,
      "learning_rate": 4.49289947444929e-05,
      "logits/chosen": 2.907705307006836,
      "logits/rejected": 3.073054313659668,
      "logps/chosen": -188.5867462158203,
      "logps/rejected": -179.1103057861328,
      "loss": 0.6429,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6470662355422974,
      "rewards/margins": 0.7237369418144226,
      "rewards/rejected": -1.3708031177520752,
      "step": 1820
    },
    {
      "epoch": 0.30862126803086215,
      "grad_norm": 2.2295937538146973,
      "learning_rate": 4.487308509448731e-05,
      "logits/chosen": 2.8506884574890137,
      "logits/rejected": 3.044529438018799,
      "logps/chosen": -191.73574829101562,
      "logps/rejected": -175.36044311523438,
      "loss": 0.7491,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.7017298936843872,
      "rewards/margins": 0.3678732216358185,
      "rewards/rejected": -1.0696029663085938,
      "step": 1840
    },
    {
      "epoch": 0.3119758470311976,
      "grad_norm": 2.578238010406494,
      "learning_rate": 4.481717544448172e-05,
      "logits/chosen": 2.6953723430633545,
      "logits/rejected": 2.929734468460083,
      "logps/chosen": -203.0450439453125,
      "logps/rejected": -181.44744873046875,
      "loss": 0.5854,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3635007441043854,
      "rewards/margins": 0.7464398145675659,
      "rewards/rejected": -1.109940528869629,
      "step": 1860
    },
    {
      "epoch": 0.31533042603153305,
      "grad_norm": 1.6139929294586182,
      "learning_rate": 4.4761265794476124e-05,
      "logits/chosen": 2.77726411819458,
      "logits/rejected": 3.0679564476013184,
      "logps/chosen": -202.256103515625,
      "logps/rejected": -197.63204956054688,
      "loss": 0.7174,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.6229091882705688,
      "rewards/margins": 0.43002089858055115,
      "rewards/rejected": -1.0529301166534424,
      "step": 1880
    },
    {
      "epoch": 0.3186850050318685,
      "grad_norm": 2.71814227104187,
      "learning_rate": 4.4705356144470536e-05,
      "logits/chosen": 2.8330836296081543,
      "logits/rejected": 3.022156238555908,
      "logps/chosen": -202.096435546875,
      "logps/rejected": -193.51919555664062,
      "loss": 0.6209,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.40564170479774475,
      "rewards/margins": 0.5052298307418823,
      "rewards/rejected": -0.9108716249465942,
      "step": 1900
    },
    {
      "epoch": 0.32203958403220395,
      "grad_norm": 1.4118139743804932,
      "learning_rate": 4.464944649446495e-05,
      "logits/chosen": 2.8265883922576904,
      "logits/rejected": 2.977292776107788,
      "logps/chosen": -202.06558227539062,
      "logps/rejected": -194.35134887695312,
      "loss": 0.6319,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.5125928521156311,
      "rewards/margins": 0.4837911128997803,
      "rewards/rejected": -0.9963839650154114,
      "step": 1920
    },
    {
      "epoch": 0.32539416303253943,
      "grad_norm": 2.476072311401367,
      "learning_rate": 4.4593536844459354e-05,
      "logits/chosen": 2.714482545852661,
      "logits/rejected": 2.923138380050659,
      "logps/chosen": -211.786865234375,
      "logps/rejected": -179.99179077148438,
      "loss": 0.5803,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.15172384679317474,
      "rewards/margins": 0.6472682356834412,
      "rewards/rejected": -0.7989920377731323,
      "step": 1940
    },
    {
      "epoch": 0.32874874203287485,
      "grad_norm": 2.741716146469116,
      "learning_rate": 4.453762719445376e-05,
      "logits/chosen": 2.833334445953369,
      "logits/rejected": 2.8661046028137207,
      "logps/chosen": -198.84280395507812,
      "logps/rejected": -192.76846313476562,
      "loss": 0.701,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.5670657753944397,
      "rewards/margins": 0.29083067178726196,
      "rewards/rejected": -0.8578964471817017,
      "step": 1960
    },
    {
      "epoch": 0.33210332103321033,
      "grad_norm": 1.7289817333221436,
      "learning_rate": 4.448171754444818e-05,
      "logits/chosen": 2.637587070465088,
      "logits/rejected": 2.925295114517212,
      "logps/chosen": -204.3018341064453,
      "logps/rejected": -177.2010040283203,
      "loss": 0.5681,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.04614410549402237,
      "rewards/margins": 0.6450904607772827,
      "rewards/rejected": -0.6912346482276917,
      "step": 1980
    },
    {
      "epoch": 0.3354579000335458,
      "grad_norm": 1.9437228441238403,
      "learning_rate": 4.4425807894442584e-05,
      "logits/chosen": 2.827829360961914,
      "logits/rejected": 3.024723529815674,
      "logps/chosen": -190.33387756347656,
      "logps/rejected": -179.97520446777344,
      "loss": 0.5825,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.41262370347976685,
      "rewards/margins": 0.5798867344856262,
      "rewards/rejected": -0.9925103187561035,
      "step": 2000
    },
    {
      "epoch": 0.33881247903388123,
      "grad_norm": 1.469312071800232,
      "learning_rate": 4.436989824443699e-05,
      "logits/chosen": 2.8161938190460205,
      "logits/rejected": 2.8890669345855713,
      "logps/chosen": -196.30075073242188,
      "logps/rejected": -186.1709442138672,
      "loss": 0.7017,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.6338083148002625,
      "rewards/margins": 0.37530556321144104,
      "rewards/rejected": -1.0091137886047363,
      "step": 2020
    },
    {
      "epoch": 0.3421670580342167,
      "grad_norm": 2.123584032058716,
      "learning_rate": 4.43139885944314e-05,
      "logits/chosen": 2.9556021690368652,
      "logits/rejected": 3.0238165855407715,
      "logps/chosen": -192.7770233154297,
      "logps/rejected": -180.98764038085938,
      "loss": 0.6414,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6541346311569214,
      "rewards/margins": 0.4402243494987488,
      "rewards/rejected": -1.0943589210510254,
      "step": 2040
    },
    {
      "epoch": 0.3455216370345522,
      "grad_norm": 1.8291842937469482,
      "learning_rate": 4.4258078944425814e-05,
      "logits/chosen": 2.837162494659424,
      "logits/rejected": 2.9468941688537598,
      "logps/chosen": -198.14920043945312,
      "logps/rejected": -185.42074584960938,
      "loss": 0.6178,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.000596284866333,
      "rewards/margins": 0.49151715636253357,
      "rewards/rejected": -1.4921133518218994,
      "step": 2060
    },
    {
      "epoch": 0.3488762160348876,
      "grad_norm": 1.6087722778320312,
      "learning_rate": 4.420216929442022e-05,
      "logits/chosen": 2.950620651245117,
      "logits/rejected": 3.0746560096740723,
      "logps/chosen": -196.35169982910156,
      "logps/rejected": -169.5908966064453,
      "loss": 0.5788,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.5662888884544373,
      "rewards/margins": 0.6219181418418884,
      "rewards/rejected": -1.1882070302963257,
      "step": 2080
    },
    {
      "epoch": 0.3522307950352231,
      "grad_norm": 0.9959837198257446,
      "learning_rate": 4.4146259644414625e-05,
      "logits/chosen": 2.8401026725769043,
      "logits/rejected": 3.1381425857543945,
      "logps/chosen": -200.38558959960938,
      "logps/rejected": -189.77572631835938,
      "loss": 0.5908,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.17346860468387604,
      "rewards/margins": 0.5781573057174683,
      "rewards/rejected": -0.7516258955001831,
      "step": 2100
    },
    {
      "epoch": 0.3555853740355585,
      "grad_norm": 2.161412239074707,
      "learning_rate": 4.409034999440904e-05,
      "logits/chosen": 3.005664348602295,
      "logits/rejected": 3.170349359512329,
      "logps/chosen": -199.85354614257812,
      "logps/rejected": -174.76885986328125,
      "loss": 0.6313,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5702537894248962,
      "rewards/margins": 0.7187992334365845,
      "rewards/rejected": -1.289052963256836,
      "step": 2120
    },
    {
      "epoch": 0.358939953035894,
      "grad_norm": 2.4069297313690186,
      "learning_rate": 4.403444034440344e-05,
      "logits/chosen": 3.0887436866760254,
      "logits/rejected": 3.165670156478882,
      "logps/chosen": -194.58932495117188,
      "logps/rejected": -175.69564819335938,
      "loss": 0.6705,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.05081770941615105,
      "rewards/margins": 0.5272107720375061,
      "rewards/rejected": -0.47639307379722595,
      "step": 2140
    },
    {
      "epoch": 0.36229453203622947,
      "grad_norm": 1.164085030555725,
      "learning_rate": 4.3978530694397855e-05,
      "logits/chosen": 3.1119508743286133,
      "logits/rejected": 3.275038957595825,
      "logps/chosen": -195.22457885742188,
      "logps/rejected": -179.3866729736328,
      "loss": 0.5961,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.16094455122947693,
      "rewards/margins": 0.6518194079399109,
      "rewards/rejected": -0.8127639889717102,
      "step": 2160
    },
    {
      "epoch": 0.3656491110365649,
      "grad_norm": 2.9328980445861816,
      "learning_rate": 4.392262104439227e-05,
      "logits/chosen": 3.108416795730591,
      "logits/rejected": 3.124096155166626,
      "logps/chosen": -180.47421264648438,
      "logps/rejected": -175.34890747070312,
      "loss": 0.7835,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.11011146008968353,
      "rewards/margins": 0.4055139124393463,
      "rewards/rejected": -0.5156253576278687,
      "step": 2180
    },
    {
      "epoch": 0.36900369003690037,
      "grad_norm": 1.7621159553527832,
      "learning_rate": 4.386671139438667e-05,
      "logits/chosen": 2.7958931922912598,
      "logits/rejected": 3.101837396621704,
      "logps/chosen": -206.44009399414062,
      "logps/rejected": -179.9517364501953,
      "loss": 0.5567,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.06644414365291595,
      "rewards/margins": 0.6720311045646667,
      "rewards/rejected": -0.6055870056152344,
      "step": 2200
    },
    {
      "epoch": 0.37235826903723585,
      "grad_norm": 1.3739677667617798,
      "learning_rate": 4.381080174438108e-05,
      "logits/chosen": 2.8716800212860107,
      "logits/rejected": 3.0796492099761963,
      "logps/chosen": -179.62966918945312,
      "logps/rejected": -173.5513916015625,
      "loss": 0.573,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5223573446273804,
      "rewards/margins": 0.6499050855636597,
      "rewards/rejected": -1.17226243019104,
      "step": 2220
    },
    {
      "epoch": 0.37571284803757127,
      "grad_norm": 1.6672474145889282,
      "learning_rate": 4.375489209437549e-05,
      "logits/chosen": 2.7449488639831543,
      "logits/rejected": 3.0320911407470703,
      "logps/chosen": -210.1312713623047,
      "logps/rejected": -192.51950073242188,
      "loss": 0.5467,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.30919724702835083,
      "rewards/margins": 0.6946173906326294,
      "rewards/rejected": -1.003814697265625,
      "step": 2240
    },
    {
      "epoch": 0.37906742703790675,
      "grad_norm": 3.0970675945281982,
      "learning_rate": 4.36989824443699e-05,
      "logits/chosen": 2.882728338241577,
      "logits/rejected": 3.0215280055999756,
      "logps/chosen": -209.1936798095703,
      "logps/rejected": -203.27554321289062,
      "loss": 0.6357,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5296372175216675,
      "rewards/margins": 0.45452237129211426,
      "rewards/rejected": -0.9841594696044922,
      "step": 2260
    },
    {
      "epoch": 0.3824220060382422,
      "grad_norm": 1.7003040313720703,
      "learning_rate": 4.364307279436431e-05,
      "logits/chosen": 2.9077019691467285,
      "logits/rejected": 3.147679567337036,
      "logps/chosen": -188.74169921875,
      "logps/rejected": -182.27035522460938,
      "loss": 0.766,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -0.735304594039917,
      "rewards/margins": 0.3666440546512604,
      "rewards/rejected": -1.1019484996795654,
      "step": 2280
    },
    {
      "epoch": 0.38577658503857765,
      "grad_norm": 1.3401577472686768,
      "learning_rate": 4.3587163144358714e-05,
      "logits/chosen": 2.928173542022705,
      "logits/rejected": 3.1728134155273438,
      "logps/chosen": -199.40841674804688,
      "logps/rejected": -185.5493927001953,
      "loss": 0.6974,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.4106295108795166,
      "rewards/margins": 0.3454659581184387,
      "rewards/rejected": -0.7560955286026001,
      "step": 2300
    },
    {
      "epoch": 0.3891311640389131,
      "grad_norm": 2.274644136428833,
      "learning_rate": 4.353125349435313e-05,
      "logits/chosen": 2.799534320831299,
      "logits/rejected": 2.9436614513397217,
      "logps/chosen": -184.27732849121094,
      "logps/rejected": -163.429443359375,
      "loss": 0.6166,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.0992768406867981,
      "rewards/margins": 0.5811963677406311,
      "rewards/rejected": -0.6804732084274292,
      "step": 2320
    },
    {
      "epoch": 0.39248574303924855,
      "grad_norm": 1.22232186794281,
      "learning_rate": 4.347534384434754e-05,
      "logits/chosen": 2.67098331451416,
      "logits/rejected": 3.0714056491851807,
      "logps/chosen": -187.02894592285156,
      "logps/rejected": -156.3194580078125,
      "loss": 0.5243,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.10103688389062881,
      "rewards/margins": 0.8936624526977539,
      "rewards/rejected": -0.7926255464553833,
      "step": 2340
    },
    {
      "epoch": 0.395840322039584,
      "grad_norm": 4.139960289001465,
      "learning_rate": 4.3419434194341945e-05,
      "logits/chosen": 2.9523661136627197,
      "logits/rejected": 3.042646646499634,
      "logps/chosen": -190.34117126464844,
      "logps/rejected": -178.37208557128906,
      "loss": 0.7547,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.14489424228668213,
      "rewards/margins": 0.23350267112255096,
      "rewards/rejected": -0.3783968985080719,
      "step": 2360
    },
    {
      "epoch": 0.3991949010399195,
      "grad_norm": 1.3437987565994263,
      "learning_rate": 4.336352454433636e-05,
      "logits/chosen": 3.0393872261047363,
      "logits/rejected": 3.229388475418091,
      "logps/chosen": -188.5765380859375,
      "logps/rejected": -172.29995727539062,
      "loss": 0.6986,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.11190233379602432,
      "rewards/margins": 0.4062120020389557,
      "rewards/rejected": -0.29430967569351196,
      "step": 2380
    },
    {
      "epoch": 0.4025494800402549,
      "grad_norm": 2.150698661804199,
      "learning_rate": 4.330761489433076e-05,
      "logits/chosen": 3.1297078132629395,
      "logits/rejected": 3.3117785453796387,
      "logps/chosen": -205.1404266357422,
      "logps/rejected": -176.23745727539062,
      "loss": 0.628,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.4364129900932312,
      "rewards/margins": 0.6162708401679993,
      "rewards/rejected": -0.17985786497592926,
      "step": 2400
    },
    {
      "epoch": 0.4059040590405904,
      "grad_norm": 1.2052401304244995,
      "learning_rate": 4.3251705244325175e-05,
      "logits/chosen": 3.040109157562256,
      "logits/rejected": 3.1057426929473877,
      "logps/chosen": -187.9131317138672,
      "logps/rejected": -181.72824096679688,
      "loss": 0.7187,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.38912519812583923,
      "rewards/margins": 0.21984294056892395,
      "rewards/rejected": 0.16928225755691528,
      "step": 2420
    },
    {
      "epoch": 0.4092586380409259,
      "grad_norm": 2.1183032989501953,
      "learning_rate": 4.319579559431958e-05,
      "logits/chosen": 3.035909414291382,
      "logits/rejected": 3.3287405967712402,
      "logps/chosen": -191.81253051757812,
      "logps/rejected": -168.0116424560547,
      "loss": 0.5666,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.6114468574523926,
      "rewards/margins": 0.5750119686126709,
      "rewards/rejected": 0.03643482178449631,
      "step": 2440
    },
    {
      "epoch": 0.4126132170412613,
      "grad_norm": 1.3054430484771729,
      "learning_rate": 4.313988594431399e-05,
      "logits/chosen": 2.9647088050842285,
      "logits/rejected": 3.182715892791748,
      "logps/chosen": -191.34683227539062,
      "logps/rejected": -185.57144165039062,
      "loss": 0.5199,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.5367984771728516,
      "rewards/margins": 0.668289303779602,
      "rewards/rejected": -0.13149075210094452,
      "step": 2460
    },
    {
      "epoch": 0.4159677960415968,
      "grad_norm": 1.7034893035888672,
      "learning_rate": 4.30839762943084e-05,
      "logits/chosen": 3.1462748050689697,
      "logits/rejected": 3.2225139141082764,
      "logps/chosen": -179.57040405273438,
      "logps/rejected": -171.92239379882812,
      "loss": 0.6164,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.23097839951515198,
      "rewards/margins": 0.40729063749313354,
      "rewards/rejected": -0.17631228268146515,
      "step": 2480
    },
    {
      "epoch": 0.41932237504193226,
      "grad_norm": 0.9610146880149841,
      "learning_rate": 4.302806664430281e-05,
      "logits/chosen": 2.8474173545837402,
      "logits/rejected": 3.2215888500213623,
      "logps/chosen": -187.86221313476562,
      "logps/rejected": -163.05140686035156,
      "loss": 0.5257,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.5714876055717468,
      "rewards/margins": 0.7939273118972778,
      "rewards/rejected": -0.2224397212266922,
      "step": 2500
    },
    {
      "epoch": 0.4226769540422677,
      "grad_norm": 1.9793808460235596,
      "learning_rate": 4.2972156994297216e-05,
      "logits/chosen": 2.8253989219665527,
      "logits/rejected": 3.0309219360351562,
      "logps/chosen": -176.944091796875,
      "logps/rejected": -159.55288696289062,
      "loss": 0.5978,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.011422872543334961,
      "rewards/margins": 0.5044411420822144,
      "rewards/rejected": -0.5158640146255493,
      "step": 2520
    },
    {
      "epoch": 0.42603153304260316,
      "grad_norm": 2.5891647338867188,
      "learning_rate": 4.291624734429163e-05,
      "logits/chosen": 2.980029582977295,
      "logits/rejected": 3.105163335800171,
      "logps/chosen": -184.23292541503906,
      "logps/rejected": -173.0922393798828,
      "loss": 0.6149,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.10155375301837921,
      "rewards/margins": 0.5413665175437927,
      "rewards/rejected": -0.4398127496242523,
      "step": 2540
    },
    {
      "epoch": 0.4293861120429386,
      "grad_norm": 2.588334321975708,
      "learning_rate": 4.2860337694286034e-05,
      "logits/chosen": 2.941089153289795,
      "logits/rejected": 2.9873087406158447,
      "logps/chosen": -189.76498413085938,
      "logps/rejected": -167.38235473632812,
      "loss": 0.657,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.19200918078422546,
      "rewards/margins": 0.5058883428573608,
      "rewards/rejected": -0.6978974938392639,
      "step": 2560
    },
    {
      "epoch": 0.43274069104327406,
      "grad_norm": 1.6778769493103027,
      "learning_rate": 4.280442804428044e-05,
      "logits/chosen": 2.8221874237060547,
      "logits/rejected": 2.846001148223877,
      "logps/chosen": -176.32595825195312,
      "logps/rejected": -168.83334350585938,
      "loss": 0.7225,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": -0.06203564256429672,
      "rewards/margins": 0.3101041913032532,
      "rewards/rejected": -0.3721398115158081,
      "step": 2580
    },
    {
      "epoch": 0.43609527004360954,
      "grad_norm": 2.7062511444091797,
      "learning_rate": 4.274851839427486e-05,
      "logits/chosen": 2.7505526542663574,
      "logits/rejected": 2.9547247886657715,
      "logps/chosen": -194.13084411621094,
      "logps/rejected": -171.19639587402344,
      "loss": 0.6208,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.33449786901474,
      "rewards/margins": 0.6169547438621521,
      "rewards/rejected": -0.2824569344520569,
      "step": 2600
    },
    {
      "epoch": 0.43944984904394496,
      "grad_norm": 2.669630527496338,
      "learning_rate": 4.2692608744269264e-05,
      "logits/chosen": 2.8184237480163574,
      "logits/rejected": 3.0474801063537598,
      "logps/chosen": -177.70907592773438,
      "logps/rejected": -170.23724365234375,
      "loss": 0.6459,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.3873916268348694,
      "rewards/margins": 0.47987857460975647,
      "rewards/rejected": -0.09248699247837067,
      "step": 2620
    },
    {
      "epoch": 0.44280442804428044,
      "grad_norm": 2.730682373046875,
      "learning_rate": 4.263669909426367e-05,
      "logits/chosen": 3.10514760017395,
      "logits/rejected": 3.2613747119903564,
      "logps/chosen": -183.1504669189453,
      "logps/rejected": -177.27235412597656,
      "loss": 0.7004,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.20793628692626953,
      "rewards/margins": 0.3996645510196686,
      "rewards/rejected": -0.19172827899456024,
      "step": 2640
    },
    {
      "epoch": 0.4461590070446159,
      "grad_norm": 1.205130696296692,
      "learning_rate": 4.258078944425808e-05,
      "logits/chosen": 2.7804794311523438,
      "logits/rejected": 2.900252342224121,
      "logps/chosen": -179.61007690429688,
      "logps/rejected": -171.7136993408203,
      "loss": 0.6898,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.21848252415657043,
      "rewards/margins": 0.27098754048347473,
      "rewards/rejected": -0.0525050163269043,
      "step": 2660
    },
    {
      "epoch": 0.44951358604495134,
      "grad_norm": 2.1382312774658203,
      "learning_rate": 4.2524879794252494e-05,
      "logits/chosen": 2.869274854660034,
      "logits/rejected": 3.03737735748291,
      "logps/chosen": -188.05197143554688,
      "logps/rejected": -178.72799682617188,
      "loss": 0.6267,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.23791277408599854,
      "rewards/margins": 0.44110265374183655,
      "rewards/rejected": -0.203189879655838,
      "step": 2680
    },
    {
      "epoch": 0.4528681650452868,
      "grad_norm": 2.1353797912597656,
      "learning_rate": 4.24689701442469e-05,
      "logits/chosen": 2.7398266792297363,
      "logits/rejected": 3.078139543533325,
      "logps/chosen": -199.30484008789062,
      "logps/rejected": -177.68898010253906,
      "loss": 0.6497,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.1871880739927292,
      "rewards/margins": 0.4590238928794861,
      "rewards/rejected": -0.2718358635902405,
      "step": 2700
    },
    {
      "epoch": 0.4562227440456223,
      "grad_norm": 3.368961811065674,
      "learning_rate": 4.2413060494241305e-05,
      "logits/chosen": 2.737522602081299,
      "logits/rejected": 3.052999973297119,
      "logps/chosen": -211.336181640625,
      "logps/rejected": -186.54603576660156,
      "loss": 0.6082,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.04020008444786072,
      "rewards/margins": 0.6195526719093323,
      "rewards/rejected": -0.6597526669502258,
      "step": 2720
    },
    {
      "epoch": 0.4595773230459577,
      "grad_norm": 3.1117169857025146,
      "learning_rate": 4.235715084423572e-05,
      "logits/chosen": 2.8726859092712402,
      "logits/rejected": 3.007715940475464,
      "logps/chosen": -183.83938598632812,
      "logps/rejected": -160.82791137695312,
      "loss": 0.6112,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.4204126000404358,
      "rewards/margins": 0.6291370391845703,
      "rewards/rejected": -1.0495494604110718,
      "step": 2740
    },
    {
      "epoch": 0.4629319020462932,
      "grad_norm": 1.4356564283370972,
      "learning_rate": 4.230124119423012e-05,
      "logits/chosen": 2.5936436653137207,
      "logits/rejected": 2.764319896697998,
      "logps/chosen": -187.4112548828125,
      "logps/rejected": -176.14593505859375,
      "loss": 0.6762,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6042052507400513,
      "rewards/margins": 0.4177398681640625,
      "rewards/rejected": -1.0219451189041138,
      "step": 2760
    },
    {
      "epoch": 0.4662864810466287,
      "grad_norm": 2.3606629371643066,
      "learning_rate": 4.2245331544224535e-05,
      "logits/chosen": 2.819546937942505,
      "logits/rejected": 3.0057291984558105,
      "logps/chosen": -196.9417266845703,
      "logps/rejected": -186.35438537597656,
      "loss": 0.5748,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.47216129302978516,
      "rewards/margins": 0.4706593155860901,
      "rewards/rejected": -0.94282066822052,
      "step": 2780
    },
    {
      "epoch": 0.4696410600469641,
      "grad_norm": 1.572913646697998,
      "learning_rate": 4.218942189421895e-05,
      "logits/chosen": 2.6220412254333496,
      "logits/rejected": 2.7313072681427,
      "logps/chosen": -172.59226989746094,
      "logps/rejected": -189.7403564453125,
      "loss": 0.6635,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5263246297836304,
      "rewards/margins": 0.43006762862205505,
      "rewards/rejected": -0.9563922882080078,
      "step": 2800
    },
    {
      "epoch": 0.4729956390472996,
      "grad_norm": 2.0426859855651855,
      "learning_rate": 4.213351224421335e-05,
      "logits/chosen": 2.5875515937805176,
      "logits/rejected": 2.8855910301208496,
      "logps/chosen": -198.263671875,
      "logps/rejected": -177.98135375976562,
      "loss": 0.5646,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.35298898816108704,
      "rewards/margins": 0.669438898563385,
      "rewards/rejected": -1.0224277973175049,
      "step": 2820
    },
    {
      "epoch": 0.476350218047635,
      "grad_norm": 1.3293136358261108,
      "learning_rate": 4.207760259420776e-05,
      "logits/chosen": 2.6414012908935547,
      "logits/rejected": 2.8989455699920654,
      "logps/chosen": -203.59323120117188,
      "logps/rejected": -176.6416778564453,
      "loss": 0.5914,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.4485476016998291,
      "rewards/margins": 0.5553566217422485,
      "rewards/rejected": -1.003904104232788,
      "step": 2840
    },
    {
      "epoch": 0.4797047970479705,
      "grad_norm": 1.1855452060699463,
      "learning_rate": 4.202169294420217e-05,
      "logits/chosen": 2.6922030448913574,
      "logits/rejected": 2.9034602642059326,
      "logps/chosen": -195.1356201171875,
      "logps/rejected": -174.27053833007812,
      "loss": 0.5799,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.2039286196231842,
      "rewards/margins": 0.6716079711914062,
      "rewards/rejected": -0.8755365610122681,
      "step": 2860
    },
    {
      "epoch": 0.48305937604830596,
      "grad_norm": 0.7159883379936218,
      "learning_rate": 4.196578329419658e-05,
      "logits/chosen": 2.737637996673584,
      "logits/rejected": 2.828982353210449,
      "logps/chosen": -194.06198120117188,
      "logps/rejected": -175.496826171875,
      "loss": 0.6014,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.12128973007202148,
      "rewards/margins": 0.7962220311164856,
      "rewards/rejected": -0.6749323606491089,
      "step": 2880
    },
    {
      "epoch": 0.4864139550486414,
      "grad_norm": 1.17448890209198,
      "learning_rate": 4.190987364419099e-05,
      "logits/chosen": 2.5654380321502686,
      "logits/rejected": 2.8400471210479736,
      "logps/chosen": -188.21795654296875,
      "logps/rejected": -179.4214324951172,
      "loss": 0.5523,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.4218703806400299,
      "rewards/margins": 0.8841961622238159,
      "rewards/rejected": -0.4623257517814636,
      "step": 2900
    },
    {
      "epoch": 0.48976853404897686,
      "grad_norm": 1.591562032699585,
      "learning_rate": 4.1853963994185394e-05,
      "logits/chosen": 2.6540493965148926,
      "logits/rejected": 2.850435733795166,
      "logps/chosen": -192.19813537597656,
      "logps/rejected": -162.80419921875,
      "loss": 0.5435,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.07714047282934189,
      "rewards/margins": 0.7283299565315247,
      "rewards/rejected": -0.6511894464492798,
      "step": 2920
    },
    {
      "epoch": 0.49312311304931233,
      "grad_norm": 2.683486223220825,
      "learning_rate": 4.179805434417981e-05,
      "logits/chosen": 2.534797430038452,
      "logits/rejected": 2.7314679622650146,
      "logps/chosen": -192.86846923828125,
      "logps/rejected": -185.9301300048828,
      "loss": 0.6572,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.4833575189113617,
      "rewards/margins": 0.46600937843322754,
      "rewards/rejected": -0.9493669271469116,
      "step": 2940
    },
    {
      "epoch": 0.49647769204964776,
      "grad_norm": 3.5948736667633057,
      "learning_rate": 4.174214469417422e-05,
      "logits/chosen": 2.7168452739715576,
      "logits/rejected": 2.7301087379455566,
      "logps/chosen": -206.70361328125,
      "logps/rejected": -199.08872985839844,
      "loss": 0.6456,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5858163833618164,
      "rewards/margins": 0.4731210768222809,
      "rewards/rejected": -1.058937430381775,
      "step": 2960
    },
    {
      "epoch": 0.49983227104998323,
      "grad_norm": 2.9429421424865723,
      "learning_rate": 4.1686235044168624e-05,
      "logits/chosen": 2.593900203704834,
      "logits/rejected": 2.8397231101989746,
      "logps/chosen": -214.30874633789062,
      "logps/rejected": -192.6549835205078,
      "loss": 0.6033,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.31140053272247314,
      "rewards/margins": 0.6702982187271118,
      "rewards/rejected": -0.9816986322402954,
      "step": 2980
    },
    {
      "epoch": 0.5031868500503187,
      "grad_norm": 1.7524679899215698,
      "learning_rate": 4.163032539416304e-05,
      "logits/chosen": 2.6052517890930176,
      "logits/rejected": 2.7565598487854004,
      "logps/chosen": -180.9446258544922,
      "logps/rejected": -173.24227905273438,
      "loss": 0.7437,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.763192355632782,
      "rewards/margins": 0.4874970316886902,
      "rewards/rejected": -1.2506893873214722,
      "step": 3000
    },
    {
      "epoch": 0.5065414290506541,
      "grad_norm": 2.1994690895080566,
      "learning_rate": 4.157441574415744e-05,
      "logits/chosen": 2.618198871612549,
      "logits/rejected": 2.852321147918701,
      "logps/chosen": -195.66148376464844,
      "logps/rejected": -187.19412231445312,
      "loss": 0.5639,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.5443682670593262,
      "rewards/margins": 0.626086950302124,
      "rewards/rejected": -1.1704552173614502,
      "step": 3020
    },
    {
      "epoch": 0.5098960080509896,
      "grad_norm": 1.6248393058776855,
      "learning_rate": 4.1518506094151854e-05,
      "logits/chosen": 2.834230899810791,
      "logits/rejected": 2.857227325439453,
      "logps/chosen": -197.96505737304688,
      "logps/rejected": -180.02841186523438,
      "loss": 0.6472,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6958346366882324,
      "rewards/margins": 0.6019895672798157,
      "rewards/rejected": -1.2978241443634033,
      "step": 3040
    },
    {
      "epoch": 0.5132505870513251,
      "grad_norm": 1.389549732208252,
      "learning_rate": 4.146259644414626e-05,
      "logits/chosen": 2.772037982940674,
      "logits/rejected": 2.9160361289978027,
      "logps/chosen": -206.8712158203125,
      "logps/rejected": -180.67453002929688,
      "loss": 0.6054,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.4717109799385071,
      "rewards/margins": 0.5616124868392944,
      "rewards/rejected": -1.0333235263824463,
      "step": 3060
    },
    {
      "epoch": 0.5166051660516605,
      "grad_norm": 2.126589059829712,
      "learning_rate": 4.140668679414067e-05,
      "logits/chosen": 2.7697155475616455,
      "logits/rejected": 2.958447217941284,
      "logps/chosen": -200.8055419921875,
      "logps/rejected": -195.24749755859375,
      "loss": 0.6634,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.6324774026870728,
      "rewards/margins": 0.4862293601036072,
      "rewards/rejected": -1.1187068223953247,
      "step": 3080
    },
    {
      "epoch": 0.5199597450519959,
      "grad_norm": 2.0299856662750244,
      "learning_rate": 4.135077714413508e-05,
      "logits/chosen": 2.7472918033599854,
      "logits/rejected": 2.9979684352874756,
      "logps/chosen": -199.74874877929688,
      "logps/rejected": -180.38668823242188,
      "loss": 0.6347,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5029118061065674,
      "rewards/margins": 0.5731945037841797,
      "rewards/rejected": -1.076106309890747,
      "step": 3100
    },
    {
      "epoch": 0.5233143240523315,
      "grad_norm": 1.7697958946228027,
      "learning_rate": 4.129486749412949e-05,
      "logits/chosen": 2.9557864665985107,
      "logits/rejected": 3.033637285232544,
      "logps/chosen": -189.1653594970703,
      "logps/rejected": -179.10809326171875,
      "loss": 0.6415,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.8159807920455933,
      "rewards/margins": 0.32559123635292053,
      "rewards/rejected": -1.1415719985961914,
      "step": 3120
    },
    {
      "epoch": 0.5266689030526669,
      "grad_norm": 0.6644032001495361,
      "learning_rate": 4.1238957844123896e-05,
      "logits/chosen": 2.774733066558838,
      "logits/rejected": 2.9325108528137207,
      "logps/chosen": -224.8027801513672,
      "logps/rejected": -193.7506561279297,
      "loss": 0.5901,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.5601698160171509,
      "rewards/margins": 0.796612560749054,
      "rewards/rejected": -1.35678231716156,
      "step": 3140
    },
    {
      "epoch": 0.5300234820530023,
      "grad_norm": 2.7353968620300293,
      "learning_rate": 4.118304819411831e-05,
      "logits/chosen": 2.751798152923584,
      "logits/rejected": 2.9310755729675293,
      "logps/chosen": -212.2117919921875,
      "logps/rejected": -192.9617156982422,
      "loss": 0.5968,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8216950297355652,
      "rewards/margins": 0.9482089281082153,
      "rewards/rejected": -1.7699041366577148,
      "step": 3160
    },
    {
      "epoch": 0.5333780610533378,
      "grad_norm": 5.321756839752197,
      "learning_rate": 4.1127138544112714e-05,
      "logits/chosen": 2.515066146850586,
      "logits/rejected": 2.685734987258911,
      "logps/chosen": -200.96926879882812,
      "logps/rejected": -195.27542114257812,
      "loss": 0.6565,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.8145707845687866,
      "rewards/margins": 0.585578203201294,
      "rewards/rejected": -1.4001491069793701,
      "step": 3180
    },
    {
      "epoch": 0.5367326400536733,
      "grad_norm": 2.0670294761657715,
      "learning_rate": 4.107122889410712e-05,
      "logits/chosen": 2.732386589050293,
      "logits/rejected": 2.8794426918029785,
      "logps/chosen": -181.68283081054688,
      "logps/rejected": -172.26419067382812,
      "loss": 0.7053,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.0004551410675049,
      "rewards/margins": 0.5284551382064819,
      "rewards/rejected": -1.5289102792739868,
      "step": 3200
    },
    {
      "epoch": 0.5400872190540087,
      "grad_norm": 1.378537654876709,
      "learning_rate": 4.101531924410154e-05,
      "logits/chosen": 2.654496669769287,
      "logits/rejected": 2.882929801940918,
      "logps/chosen": -197.1908416748047,
      "logps/rejected": -183.06204223632812,
      "loss": 0.5786,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5810664892196655,
      "rewards/margins": 0.6499514579772949,
      "rewards/rejected": -1.231017827987671,
      "step": 3220
    },
    {
      "epoch": 0.5434417980543442,
      "grad_norm": 0.8515722155570984,
      "learning_rate": 4.0959409594095944e-05,
      "logits/chosen": 2.651421308517456,
      "logits/rejected": 2.8547465801239014,
      "logps/chosen": -203.3429718017578,
      "logps/rejected": -184.51437377929688,
      "loss": 0.6645,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.756409227848053,
      "rewards/margins": 0.6106856465339661,
      "rewards/rejected": -1.3670947551727295,
      "step": 3240
    },
    {
      "epoch": 0.5467963770546796,
      "grad_norm": 2.6672775745391846,
      "learning_rate": 4.090349994409035e-05,
      "logits/chosen": 2.8340649604797363,
      "logits/rejected": 3.0938894748687744,
      "logps/chosen": -217.34457397460938,
      "logps/rejected": -194.97463989257812,
      "loss": 0.5288,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.9618932604789734,
      "rewards/margins": 0.8752099275588989,
      "rewards/rejected": -1.837103247642517,
      "step": 3260
    },
    {
      "epoch": 0.5501509560550151,
      "grad_norm": 1.0834649801254272,
      "learning_rate": 4.084759029408476e-05,
      "logits/chosen": 2.714240312576294,
      "logits/rejected": 2.9314796924591064,
      "logps/chosen": -195.5305938720703,
      "logps/rejected": -188.69320678710938,
      "loss": 0.6117,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.2207903861999512,
      "rewards/margins": 0.7151281833648682,
      "rewards/rejected": -1.9359184503555298,
      "step": 3280
    },
    {
      "epoch": 0.5535055350553506,
      "grad_norm": 2.9404213428497314,
      "learning_rate": 4.0791680644079174e-05,
      "logits/chosen": 2.6053876876831055,
      "logits/rejected": 2.873776912689209,
      "logps/chosen": -222.77963256835938,
      "logps/rejected": -211.6189422607422,
      "loss": 0.5948,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0094029903411865,
      "rewards/margins": 0.7048524022102356,
      "rewards/rejected": -1.7142553329467773,
      "step": 3300
    },
    {
      "epoch": 0.556860114055686,
      "grad_norm": 1.904183030128479,
      "learning_rate": 4.073577099407358e-05,
      "logits/chosen": 2.778451919555664,
      "logits/rejected": 3.0325188636779785,
      "logps/chosen": -206.8330078125,
      "logps/rejected": -191.19410705566406,
      "loss": 0.6735,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1032909154891968,
      "rewards/margins": 0.5159849524497986,
      "rewards/rejected": -1.6192758083343506,
      "step": 3320
    },
    {
      "epoch": 0.5602146930560215,
      "grad_norm": 1.5424039363861084,
      "learning_rate": 4.0679861344067985e-05,
      "logits/chosen": 2.75559663772583,
      "logits/rejected": 2.9007771015167236,
      "logps/chosen": -204.78662109375,
      "logps/rejected": -183.0181427001953,
      "loss": 0.5937,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6486920118331909,
      "rewards/margins": 0.6551996469497681,
      "rewards/rejected": -1.3038917779922485,
      "step": 3340
    },
    {
      "epoch": 0.5635692720563569,
      "grad_norm": 2.15156888961792,
      "learning_rate": 4.06239516940624e-05,
      "logits/chosen": 2.7396342754364014,
      "logits/rejected": 2.787550449371338,
      "logps/chosen": -198.5895233154297,
      "logps/rejected": -195.4596710205078,
      "loss": 0.7511,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": -0.801832377910614,
      "rewards/margins": 0.30232053995132446,
      "rewards/rejected": -1.104152798652649,
      "step": 3360
    },
    {
      "epoch": 0.5669238510566924,
      "grad_norm": 1.5264016389846802,
      "learning_rate": 4.056804204405681e-05,
      "logits/chosen": 2.5999064445495605,
      "logits/rejected": 2.7428314685821533,
      "logps/chosen": -198.14242553710938,
      "logps/rejected": -172.54246520996094,
      "loss": 0.5891,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8863712549209595,
      "rewards/margins": 0.5567976832389832,
      "rewards/rejected": -1.4431689977645874,
      "step": 3380
    },
    {
      "epoch": 0.5702784300570278,
      "grad_norm": 0.8236344456672668,
      "learning_rate": 4.0512132394051215e-05,
      "logits/chosen": 2.748800754547119,
      "logits/rejected": 2.971526622772217,
      "logps/chosen": -198.33837890625,
      "logps/rejected": -182.65179443359375,
      "loss": 0.5797,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6247855424880981,
      "rewards/margins": 0.7442371249198914,
      "rewards/rejected": -1.3690227270126343,
      "step": 3400
    },
    {
      "epoch": 0.5736330090573633,
      "grad_norm": 2.214315176010132,
      "learning_rate": 4.045622274404563e-05,
      "logits/chosen": 2.70756459236145,
      "logits/rejected": 3.0182979106903076,
      "logps/chosen": -184.8535614013672,
      "logps/rejected": -173.39993286132812,
      "loss": 0.584,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.7070414423942566,
      "rewards/margins": 0.6091858148574829,
      "rewards/rejected": -1.3162273168563843,
      "step": 3420
    },
    {
      "epoch": 0.5769875880576988,
      "grad_norm": 2.8274927139282227,
      "learning_rate": 4.040031309404003e-05,
      "logits/chosen": 2.9295997619628906,
      "logits/rejected": 2.9512343406677246,
      "logps/chosen": -202.66763305664062,
      "logps/rejected": -196.60720825195312,
      "loss": 0.829,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -0.9452506899833679,
      "rewards/margins": 0.15043750405311584,
      "rewards/rejected": -1.0956881046295166,
      "step": 3440
    },
    {
      "epoch": 0.5803421670580342,
      "grad_norm": 1.1251178979873657,
      "learning_rate": 4.034440344403444e-05,
      "logits/chosen": 2.7741336822509766,
      "logits/rejected": 3.045069456100464,
      "logps/chosen": -208.8970947265625,
      "logps/rejected": -191.10057067871094,
      "loss": 0.5874,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5532708168029785,
      "rewards/margins": 0.6474514007568359,
      "rewards/rejected": -1.2007222175598145,
      "step": 3460
    },
    {
      "epoch": 0.5836967460583696,
      "grad_norm": 2.128681182861328,
      "learning_rate": 4.028849379402885e-05,
      "logits/chosen": 2.7493648529052734,
      "logits/rejected": 2.859226703643799,
      "logps/chosen": -197.6342315673828,
      "logps/rejected": -173.173828125,
      "loss": 0.5787,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6074179410934448,
      "rewards/margins": 0.6469713449478149,
      "rewards/rejected": -1.2543894052505493,
      "step": 3480
    },
    {
      "epoch": 0.5870513250587052,
      "grad_norm": 1.390032410621643,
      "learning_rate": 4.023258414402326e-05,
      "logits/chosen": 2.6388797760009766,
      "logits/rejected": 2.7331202030181885,
      "logps/chosen": -195.75729370117188,
      "logps/rejected": -178.52748107910156,
      "loss": 0.6248,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.42236295342445374,
      "rewards/margins": 0.5327142477035522,
      "rewards/rejected": -0.9550771713256836,
      "step": 3500
    },
    {
      "epoch": 0.5904059040590406,
      "grad_norm": 2.061129093170166,
      "learning_rate": 4.017667449401767e-05,
      "logits/chosen": 2.391195058822632,
      "logits/rejected": 2.702948570251465,
      "logps/chosen": -180.83779907226562,
      "logps/rejected": -169.92079162597656,
      "loss": 0.6489,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7439187169075012,
      "rewards/margins": 0.5835321545600891,
      "rewards/rejected": -1.3274509906768799,
      "step": 3520
    },
    {
      "epoch": 0.593760483059376,
      "grad_norm": 0.9876676797866821,
      "learning_rate": 4.0120764844012074e-05,
      "logits/chosen": 2.717679262161255,
      "logits/rejected": 2.906630277633667,
      "logps/chosen": -220.62551879882812,
      "logps/rejected": -185.05926513671875,
      "loss": 0.5059,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.3089343011379242,
      "rewards/margins": 0.8559035062789917,
      "rewards/rejected": -1.1648378372192383,
      "step": 3540
    },
    {
      "epoch": 0.5971150620597115,
      "grad_norm": 2.0692379474639893,
      "learning_rate": 4.006485519400649e-05,
      "logits/chosen": 2.6027846336364746,
      "logits/rejected": 2.860307216644287,
      "logps/chosen": -207.88314819335938,
      "logps/rejected": -188.13050842285156,
      "loss": 0.592,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.39337268471717834,
      "rewards/margins": 0.6021307706832886,
      "rewards/rejected": -0.9955034255981445,
      "step": 3560
    },
    {
      "epoch": 0.600469641060047,
      "grad_norm": 1.2379839420318604,
      "learning_rate": 4.00089455440009e-05,
      "logits/chosen": 2.7064638137817383,
      "logits/rejected": 2.920344829559326,
      "logps/chosen": -186.15052795410156,
      "logps/rejected": -171.80841064453125,
      "loss": 0.6606,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6727122068405151,
      "rewards/margins": 0.6418396830558777,
      "rewards/rejected": -1.3145519495010376,
      "step": 3580
    },
    {
      "epoch": 0.6038242200603824,
      "grad_norm": 2.0508346557617188,
      "learning_rate": 3.9953035893995304e-05,
      "logits/chosen": 2.5706887245178223,
      "logits/rejected": 2.913573980331421,
      "logps/chosen": -193.13088989257812,
      "logps/rejected": -177.7648162841797,
      "loss": 0.6072,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.1881522387266159,
      "rewards/margins": 0.698078989982605,
      "rewards/rejected": -0.8862312436103821,
      "step": 3600
    },
    {
      "epoch": 0.6071787990607179,
      "grad_norm": 2.433746576309204,
      "learning_rate": 3.989712624398971e-05,
      "logits/chosen": 2.8495538234710693,
      "logits/rejected": 3.0333752632141113,
      "logps/chosen": -212.5301971435547,
      "logps/rejected": -194.14999389648438,
      "loss": 0.6465,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.27134236693382263,
      "rewards/margins": 0.5695697069168091,
      "rewards/rejected": -0.8409121632575989,
      "step": 3620
    },
    {
      "epoch": 0.6105333780610533,
      "grad_norm": 1.3276222944259644,
      "learning_rate": 3.984121659398412e-05,
      "logits/chosen": 2.6775336265563965,
      "logits/rejected": 2.830571413040161,
      "logps/chosen": -200.62216186523438,
      "logps/rejected": -188.68310546875,
      "loss": 0.6388,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.736308753490448,
      "rewards/margins": 0.45792046189308167,
      "rewards/rejected": -1.194229245185852,
      "step": 3640
    },
    {
      "epoch": 0.6138879570613888,
      "grad_norm": 1.1983693838119507,
      "learning_rate": 3.9785306943978534e-05,
      "logits/chosen": 2.501588821411133,
      "logits/rejected": 2.7564473152160645,
      "logps/chosen": -189.92770385742188,
      "logps/rejected": -175.0491180419922,
      "loss": 0.5533,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6082355380058289,
      "rewards/margins": 0.739618182182312,
      "rewards/rejected": -1.3478538990020752,
      "step": 3660
    },
    {
      "epoch": 0.6172425360617243,
      "grad_norm": 1.6352351903915405,
      "learning_rate": 3.972939729397294e-05,
      "logits/chosen": 2.7609314918518066,
      "logits/rejected": 2.9823126792907715,
      "logps/chosen": -203.56016540527344,
      "logps/rejected": -202.29954528808594,
      "loss": 0.5986,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7682462334632874,
      "rewards/margins": 0.5719197988510132,
      "rewards/rejected": -1.3401660919189453,
      "step": 3680
    },
    {
      "epoch": 0.6205971150620597,
      "grad_norm": 2.4328348636627197,
      "learning_rate": 3.967348764396735e-05,
      "logits/chosen": 2.9056406021118164,
      "logits/rejected": 2.929853916168213,
      "logps/chosen": -193.88906860351562,
      "logps/rejected": -185.36029052734375,
      "loss": 0.8377,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": -1.2720592021942139,
      "rewards/margins": 0.10853838920593262,
      "rewards/rejected": -1.3805975914001465,
      "step": 3700
    },
    {
      "epoch": 0.6239516940623951,
      "grad_norm": 3.5928468704223633,
      "learning_rate": 3.961757799396176e-05,
      "logits/chosen": 2.6552817821502686,
      "logits/rejected": 2.6909966468811035,
      "logps/chosen": -196.52806091308594,
      "logps/rejected": -192.23428344726562,
      "loss": 0.715,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.7298482656478882,
      "rewards/margins": 0.30049845576286316,
      "rewards/rejected": -1.0303466320037842,
      "step": 3720
    },
    {
      "epoch": 0.6273062730627307,
      "grad_norm": 3.4520931243896484,
      "learning_rate": 3.956166834395617e-05,
      "logits/chosen": 2.631168842315674,
      "logits/rejected": 2.7895588874816895,
      "logps/chosen": -194.03817749023438,
      "logps/rejected": -204.36720275878906,
      "loss": 0.6169,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6686457395553589,
      "rewards/margins": 0.4678735136985779,
      "rewards/rejected": -1.1365193128585815,
      "step": 3740
    },
    {
      "epoch": 0.6306608520630661,
      "grad_norm": 0.9285279512405396,
      "learning_rate": 3.9505758693950576e-05,
      "logits/chosen": 2.550675630569458,
      "logits/rejected": 2.8099677562713623,
      "logps/chosen": -208.0754852294922,
      "logps/rejected": -176.99037170410156,
      "loss": 0.557,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.4798417091369629,
      "rewards/margins": 0.6004337072372437,
      "rewards/rejected": -1.080275297164917,
      "step": 3760
    },
    {
      "epoch": 0.6340154310634015,
      "grad_norm": 2.057677745819092,
      "learning_rate": 3.944984904394499e-05,
      "logits/chosen": 2.7352943420410156,
      "logits/rejected": 2.8356070518493652,
      "logps/chosen": -201.47799682617188,
      "logps/rejected": -179.14755249023438,
      "loss": 0.6602,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.6804476380348206,
      "rewards/margins": 0.4756750464439392,
      "rewards/rejected": -1.1561226844787598,
      "step": 3780
    },
    {
      "epoch": 0.637370010063737,
      "grad_norm": 1.0157045125961304,
      "learning_rate": 3.939393939393939e-05,
      "logits/chosen": 2.7046658992767334,
      "logits/rejected": 2.907017946243286,
      "logps/chosen": -200.58071899414062,
      "logps/rejected": -179.1482391357422,
      "loss": 0.5962,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6408165693283081,
      "rewards/margins": 0.7065471410751343,
      "rewards/rejected": -1.3473637104034424,
      "step": 3800
    },
    {
      "epoch": 0.6407245890640725,
      "grad_norm": 2.0717763900756836,
      "learning_rate": 3.9338029743933806e-05,
      "logits/chosen": 2.690697431564331,
      "logits/rejected": 2.8800244331359863,
      "logps/chosen": -189.53089904785156,
      "logps/rejected": -177.03091430664062,
      "loss": 0.5812,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5567950010299683,
      "rewards/margins": 0.7602193355560303,
      "rewards/rejected": -1.317014455795288,
      "step": 3820
    },
    {
      "epoch": 0.6440791680644079,
      "grad_norm": 2.1822993755340576,
      "learning_rate": 3.928212009392822e-05,
      "logits/chosen": 2.609891176223755,
      "logits/rejected": 2.7743887901306152,
      "logps/chosen": -200.30880737304688,
      "logps/rejected": -185.46109008789062,
      "loss": 0.6202,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.5829814672470093,
      "rewards/margins": 0.5013330578804016,
      "rewards/rejected": -1.0843145847320557,
      "step": 3840
    },
    {
      "epoch": 0.6474337470647433,
      "grad_norm": 2.1491005420684814,
      "learning_rate": 3.9226210443922624e-05,
      "logits/chosen": 2.5395686626434326,
      "logits/rejected": 2.6350505352020264,
      "logps/chosen": -214.8468017578125,
      "logps/rejected": -193.5880584716797,
      "loss": 0.5979,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.322445809841156,
      "rewards/margins": 0.6043119430541992,
      "rewards/rejected": -0.9267576932907104,
      "step": 3860
    },
    {
      "epoch": 0.6507883260650789,
      "grad_norm": 1.878676176071167,
      "learning_rate": 3.917030079391703e-05,
      "logits/chosen": 2.5552802085876465,
      "logits/rejected": 2.702810049057007,
      "logps/chosen": -186.8396759033203,
      "logps/rejected": -180.72213745117188,
      "loss": 0.6466,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.3125615119934082,
      "rewards/margins": 0.45102834701538086,
      "rewards/rejected": -0.7635899186134338,
      "step": 3880
    },
    {
      "epoch": 0.6541429050654143,
      "grad_norm": 0.9696924090385437,
      "learning_rate": 3.911439114391144e-05,
      "logits/chosen": 2.688991069793701,
      "logits/rejected": 2.862659215927124,
      "logps/chosen": -204.8184356689453,
      "logps/rejected": -189.88345336914062,
      "loss": 0.5945,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.30688947439193726,
      "rewards/margins": 0.6613246202468872,
      "rewards/rejected": -0.9682140350341797,
      "step": 3900
    },
    {
      "epoch": 0.6574974840657497,
      "grad_norm": 1.0106207132339478,
      "learning_rate": 3.9058481493905854e-05,
      "logits/chosen": 2.5984063148498535,
      "logits/rejected": 2.777620792388916,
      "logps/chosen": -190.52511596679688,
      "logps/rejected": -180.22669982910156,
      "loss": 0.626,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.3095305860042572,
      "rewards/margins": 0.477041095495224,
      "rewards/rejected": -0.7865716814994812,
      "step": 3920
    },
    {
      "epoch": 0.6608520630660852,
      "grad_norm": 1.4239298105239868,
      "learning_rate": 3.900257184390026e-05,
      "logits/chosen": 2.638798236846924,
      "logits/rejected": 2.7917442321777344,
      "logps/chosen": -202.82398986816406,
      "logps/rejected": -181.26153564453125,
      "loss": 0.5861,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3618625998497009,
      "rewards/margins": 0.5757433176040649,
      "rewards/rejected": -0.9376059770584106,
      "step": 3940
    },
    {
      "epoch": 0.6642066420664207,
      "grad_norm": 1.4546489715576172,
      "learning_rate": 3.8946662193894665e-05,
      "logits/chosen": 2.863025188446045,
      "logits/rejected": 3.063725709915161,
      "logps/chosen": -194.78150939941406,
      "logps/rejected": -173.02879333496094,
      "loss": 0.5524,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5691383481025696,
      "rewards/margins": 0.680569052696228,
      "rewards/rejected": -1.2497074604034424,
      "step": 3960
    },
    {
      "epoch": 0.6675612210667561,
      "grad_norm": 3.8641703128814697,
      "learning_rate": 3.889075254388908e-05,
      "logits/chosen": 2.776684284210205,
      "logits/rejected": 2.90065860748291,
      "logps/chosen": -205.98526000976562,
      "logps/rejected": -199.7255401611328,
      "loss": 0.6278,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.4783119559288025,
      "rewards/margins": 0.5501366853713989,
      "rewards/rejected": -1.0284487009048462,
      "step": 3980
    },
    {
      "epoch": 0.6709158000670916,
      "grad_norm": 1.335120439529419,
      "learning_rate": 3.883484289388349e-05,
      "logits/chosen": 2.744968891143799,
      "logits/rejected": 2.9293274879455566,
      "logps/chosen": -186.23983764648438,
      "logps/rejected": -183.03729248046875,
      "loss": 0.6742,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.31011152267456055,
      "rewards/margins": 0.5588033199310303,
      "rewards/rejected": -0.868914783000946,
      "step": 4000
    },
    {
      "epoch": 0.674270379067427,
      "grad_norm": 1.0979697704315186,
      "learning_rate": 3.8778933243877895e-05,
      "logits/chosen": 2.6996607780456543,
      "logits/rejected": 2.968626022338867,
      "logps/chosen": -200.58828735351562,
      "logps/rejected": -173.27517700195312,
      "loss": 0.5258,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.46398526430130005,
      "rewards/margins": 1.0730018615722656,
      "rewards/rejected": -1.536987066268921,
      "step": 4020
    },
    {
      "epoch": 0.6776249580677625,
      "grad_norm": 2.5746066570281982,
      "learning_rate": 3.872302359387231e-05,
      "logits/chosen": 2.7826590538024902,
      "logits/rejected": 2.8898050785064697,
      "logps/chosen": -184.2519073486328,
      "logps/rejected": -174.21693420410156,
      "loss": 0.7222,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.9077448844909668,
      "rewards/margins": 0.3593286871910095,
      "rewards/rejected": -1.267073631286621,
      "step": 4040
    },
    {
      "epoch": 0.680979537068098,
      "grad_norm": 1.8873201608657837,
      "learning_rate": 3.866711394386671e-05,
      "logits/chosen": 2.7401161193847656,
      "logits/rejected": 2.94130802154541,
      "logps/chosen": -201.42898559570312,
      "logps/rejected": -190.8593292236328,
      "loss": 0.5722,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.511206328868866,
      "rewards/margins": 0.8171922564506531,
      "rewards/rejected": -1.328398585319519,
      "step": 4060
    },
    {
      "epoch": 0.6843341160684334,
      "grad_norm": 1.1573406457901,
      "learning_rate": 3.861120429386112e-05,
      "logits/chosen": 2.707233190536499,
      "logits/rejected": 2.861072063446045,
      "logps/chosen": -207.443603515625,
      "logps/rejected": -209.7416229248047,
      "loss": 0.5807,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.04594633728265762,
      "rewards/margins": 0.7136653065681458,
      "rewards/rejected": -0.7596116662025452,
      "step": 4080
    },
    {
      "epoch": 0.6876886950687688,
      "grad_norm": 1.0443024635314941,
      "learning_rate": 3.855529464385553e-05,
      "logits/chosen": 2.5232701301574707,
      "logits/rejected": 2.738355875015259,
      "logps/chosen": -195.281982421875,
      "logps/rejected": -185.69564819335938,
      "loss": 0.7387,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.5828468799591064,
      "rewards/margins": 0.23500680923461914,
      "rewards/rejected": -0.8178537487983704,
      "step": 4100
    },
    {
      "epoch": 0.6910432740691044,
      "grad_norm": 1.796910047531128,
      "learning_rate": 3.849938499384994e-05,
      "logits/chosen": 2.698964834213257,
      "logits/rejected": 2.862276554107666,
      "logps/chosen": -201.093994140625,
      "logps/rejected": -178.70068359375,
      "loss": 0.6254,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6541263461112976,
      "rewards/margins": 0.5427011251449585,
      "rewards/rejected": -1.1968275308609009,
      "step": 4120
    },
    {
      "epoch": 0.6943978530694398,
      "grad_norm": 1.0968797206878662,
      "learning_rate": 3.844347534384435e-05,
      "logits/chosen": 2.91866135597229,
      "logits/rejected": 3.1145853996276855,
      "logps/chosen": -181.99642944335938,
      "logps/rejected": -171.59024047851562,
      "loss": 0.5589,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.7992438077926636,
      "rewards/margins": 0.7600713968276978,
      "rewards/rejected": -1.5593153238296509,
      "step": 4140
    },
    {
      "epoch": 0.6977524320697752,
      "grad_norm": 1.8980071544647217,
      "learning_rate": 3.8387565693838754e-05,
      "logits/chosen": 2.8368351459503174,
      "logits/rejected": 3.029390811920166,
      "logps/chosen": -194.69259643554688,
      "logps/rejected": -182.01670837402344,
      "loss": 0.6342,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.37567323446273804,
      "rewards/margins": 0.7154247164726257,
      "rewards/rejected": -1.0910978317260742,
      "step": 4160
    },
    {
      "epoch": 0.7011070110701108,
      "grad_norm": 1.350001573562622,
      "learning_rate": 3.8331656043833166e-05,
      "logits/chosen": 2.8050644397735596,
      "logits/rejected": 2.9613547325134277,
      "logps/chosen": -197.28424072265625,
      "logps/rejected": -200.14218139648438,
      "loss": 0.5705,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.2977081835269928,
      "rewards/margins": 0.6462827920913696,
      "rewards/rejected": -0.9439908862113953,
      "step": 4180
    },
    {
      "epoch": 0.7044615900704462,
      "grad_norm": 2.52175235748291,
      "learning_rate": 3.827574639382758e-05,
      "logits/chosen": 2.839462995529175,
      "logits/rejected": 2.990189790725708,
      "logps/chosen": -197.5218505859375,
      "logps/rejected": -180.31478881835938,
      "loss": 0.622,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5950815081596375,
      "rewards/margins": 0.592758297920227,
      "rewards/rejected": -1.1878399848937988,
      "step": 4200
    },
    {
      "epoch": 0.7078161690707816,
      "grad_norm": 0.7062105536460876,
      "learning_rate": 3.8219836743821984e-05,
      "logits/chosen": 2.9930458068847656,
      "logits/rejected": 3.156933307647705,
      "logps/chosen": -198.78994750976562,
      "logps/rejected": -175.65066528320312,
      "loss": 0.5259,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.626017689704895,
      "rewards/margins": 0.7521769404411316,
      "rewards/rejected": -1.3781946897506714,
      "step": 4220
    },
    {
      "epoch": 0.711170748071117,
      "grad_norm": 1.6382795572280884,
      "learning_rate": 3.816392709381639e-05,
      "logits/chosen": 2.807079792022705,
      "logits/rejected": 2.9841017723083496,
      "logps/chosen": -189.38912963867188,
      "logps/rejected": -183.7892303466797,
      "loss": 0.5955,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4350161552429199,
      "rewards/margins": 0.5092095136642456,
      "rewards/rejected": -0.9442256689071655,
      "step": 4240
    },
    {
      "epoch": 0.7145253270714526,
      "grad_norm": 2.70448899269104,
      "learning_rate": 3.810801744381081e-05,
      "logits/chosen": 2.8868229389190674,
      "logits/rejected": 3.0370090007781982,
      "logps/chosen": -186.33787536621094,
      "logps/rejected": -173.66781616210938,
      "loss": 0.6191,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.572812557220459,
      "rewards/margins": 0.6133200526237488,
      "rewards/rejected": -1.1861326694488525,
      "step": 4260
    },
    {
      "epoch": 0.717879906071788,
      "grad_norm": 1.5750056505203247,
      "learning_rate": 3.8052107793805214e-05,
      "logits/chosen": 2.7018537521362305,
      "logits/rejected": 2.987082004547119,
      "logps/chosen": -194.87857055664062,
      "logps/rejected": -176.62472534179688,
      "loss": 0.5066,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5121991634368896,
      "rewards/margins": 0.9576658010482788,
      "rewards/rejected": -1.469864845275879,
      "step": 4280
    },
    {
      "epoch": 0.7212344850721234,
      "grad_norm": 2.8503003120422363,
      "learning_rate": 3.799619814379962e-05,
      "logits/chosen": 2.616117238998413,
      "logits/rejected": 2.7142341136932373,
      "logps/chosen": -179.32180786132812,
      "logps/rejected": -185.2348175048828,
      "loss": 0.692,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.4265642762184143,
      "rewards/margins": 0.4450393617153168,
      "rewards/rejected": -0.871603786945343,
      "step": 4300
    },
    {
      "epoch": 0.7245890640724589,
      "grad_norm": 1.3080737590789795,
      "learning_rate": 3.794028849379403e-05,
      "logits/chosen": 2.7257039546966553,
      "logits/rejected": 2.922076940536499,
      "logps/chosen": -211.6341552734375,
      "logps/rejected": -201.10264587402344,
      "loss": 0.6074,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3293670117855072,
      "rewards/margins": 0.7039083242416382,
      "rewards/rejected": -1.0332753658294678,
      "step": 4320
    },
    {
      "epoch": 0.7279436430727944,
      "grad_norm": 2.555169105529785,
      "learning_rate": 3.788437884378844e-05,
      "logits/chosen": 2.851379871368408,
      "logits/rejected": 3.0466854572296143,
      "logps/chosen": -195.9786376953125,
      "logps/rejected": -192.30233764648438,
      "loss": 0.5985,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.4192947447299957,
      "rewards/margins": 0.6966395974159241,
      "rewards/rejected": -1.115934133529663,
      "step": 4340
    },
    {
      "epoch": 0.7312982220731298,
      "grad_norm": 1.7488646507263184,
      "learning_rate": 3.782846919378285e-05,
      "logits/chosen": 2.4977715015411377,
      "logits/rejected": 2.772956371307373,
      "logps/chosen": -192.18344116210938,
      "logps/rejected": -172.6077117919922,
      "loss": 0.5686,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.20358166098594666,
      "rewards/margins": 0.8352410197257996,
      "rewards/rejected": -1.0388227701187134,
      "step": 4360
    },
    {
      "epoch": 0.7346528010734653,
      "grad_norm": 1.312117338180542,
      "learning_rate": 3.7772559543777255e-05,
      "logits/chosen": 2.733738422393799,
      "logits/rejected": 2.851175308227539,
      "logps/chosen": -193.34463500976562,
      "logps/rejected": -170.61744689941406,
      "loss": 0.7474,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.4830765128135681,
      "rewards/margins": 0.3855733275413513,
      "rewards/rejected": -0.8686498403549194,
      "step": 4380
    },
    {
      "epoch": 0.7380073800738007,
      "grad_norm": 1.8576806783676147,
      "learning_rate": 3.771664989377167e-05,
      "logits/chosen": 2.59053373336792,
      "logits/rejected": 2.7820847034454346,
      "logps/chosen": -191.8177032470703,
      "logps/rejected": -183.28890991210938,
      "loss": 0.5694,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.3593009114265442,
      "rewards/margins": 0.6863504648208618,
      "rewards/rejected": -1.0456511974334717,
      "step": 4400
    },
    {
      "epoch": 0.7413619590741362,
      "grad_norm": 2.3225739002227783,
      "learning_rate": 3.766074024376607e-05,
      "logits/chosen": 2.5417861938476562,
      "logits/rejected": 2.6607158184051514,
      "logps/chosen": -185.51165771484375,
      "logps/rejected": -175.16244506835938,
      "loss": 0.7025,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.28297075629234314,
      "rewards/margins": 0.3190871775150299,
      "rewards/rejected": -0.602057933807373,
      "step": 4420
    },
    {
      "epoch": 0.7447165380744717,
      "grad_norm": 2.1676318645477295,
      "learning_rate": 3.7604830593760486e-05,
      "logits/chosen": 2.6860337257385254,
      "logits/rejected": 2.8852741718292236,
      "logps/chosen": -208.83261108398438,
      "logps/rejected": -186.71646118164062,
      "loss": 0.6307,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.295937716960907,
      "rewards/margins": 0.493449866771698,
      "rewards/rejected": -0.7893876433372498,
      "step": 4440
    },
    {
      "epoch": 0.7480711170748071,
      "grad_norm": 1.059045672416687,
      "learning_rate": 3.75489209437549e-05,
      "logits/chosen": 2.738914966583252,
      "logits/rejected": 2.921936511993408,
      "logps/chosen": -202.44873046875,
      "logps/rejected": -180.53311157226562,
      "loss": 0.5101,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.2586018443107605,
      "rewards/margins": 0.782007098197937,
      "rewards/rejected": -1.0406088829040527,
      "step": 4460
    },
    {
      "epoch": 0.7514256960751425,
      "grad_norm": 2.7654120922088623,
      "learning_rate": 3.74930112937493e-05,
      "logits/chosen": 2.5704445838928223,
      "logits/rejected": 2.8092525005340576,
      "logps/chosen": -188.4492645263672,
      "logps/rejected": -186.66357421875,
      "loss": 0.6533,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.24264225363731384,
      "rewards/margins": 0.5224130749702454,
      "rewards/rejected": -0.765055239200592,
      "step": 4480
    },
    {
      "epoch": 0.7547802750754781,
      "grad_norm": 1.7060548067092896,
      "learning_rate": 3.743710164374371e-05,
      "logits/chosen": 2.638291597366333,
      "logits/rejected": 2.830531597137451,
      "logps/chosen": -206.94314575195312,
      "logps/rejected": -196.29283142089844,
      "loss": 0.6247,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.27394381165504456,
      "rewards/margins": 0.586639404296875,
      "rewards/rejected": -0.8605831861495972,
      "step": 4500
    },
    {
      "epoch": 0.7581348540758135,
      "grad_norm": 1.0365172624588013,
      "learning_rate": 3.738119199373812e-05,
      "logits/chosen": 2.5822088718414307,
      "logits/rejected": 2.865704298019409,
      "logps/chosen": -197.11172485351562,
      "logps/rejected": -182.4716339111328,
      "loss": 0.6547,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.31601110100746155,
      "rewards/margins": 0.4543876051902771,
      "rewards/rejected": -0.7703986763954163,
      "step": 4520
    },
    {
      "epoch": 0.7614894330761489,
      "grad_norm": 2.974040985107422,
      "learning_rate": 3.7325282343732533e-05,
      "logits/chosen": 2.7536919116973877,
      "logits/rejected": 2.854287624359131,
      "logps/chosen": -207.6501007080078,
      "logps/rejected": -199.49295043945312,
      "loss": 0.6713,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.5069640278816223,
      "rewards/margins": 0.5531604886054993,
      "rewards/rejected": -1.0601245164871216,
      "step": 4540
    },
    {
      "epoch": 0.7648440120764844,
      "grad_norm": 1.2779760360717773,
      "learning_rate": 3.726937269372694e-05,
      "logits/chosen": 2.684264659881592,
      "logits/rejected": 2.978266954421997,
      "logps/chosen": -199.57546997070312,
      "logps/rejected": -177.55630493164062,
      "loss": 0.5166,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.39852145314216614,
      "rewards/margins": 0.8560495376586914,
      "rewards/rejected": -1.2545709609985352,
      "step": 4560
    },
    {
      "epoch": 0.7681985910768199,
      "grad_norm": 1.565507173538208,
      "learning_rate": 3.7213463043721345e-05,
      "logits/chosen": 2.579202651977539,
      "logits/rejected": 2.8189682960510254,
      "logps/chosen": -207.25497436523438,
      "logps/rejected": -201.68252563476562,
      "loss": 0.5322,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.30688613653182983,
      "rewards/margins": 0.749051570892334,
      "rewards/rejected": -1.055937647819519,
      "step": 4580
    },
    {
      "epoch": 0.7715531700771553,
      "grad_norm": 1.1437034606933594,
      "learning_rate": 3.715755339371576e-05,
      "logits/chosen": 2.7485766410827637,
      "logits/rejected": 3.008307933807373,
      "logps/chosen": -191.59671020507812,
      "logps/rejected": -187.331298828125,
      "loss": 0.5929,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.5236583948135376,
      "rewards/margins": 0.6562541723251343,
      "rewards/rejected": -1.1799124479293823,
      "step": 4600
    },
    {
      "epoch": 0.7749077490774908,
      "grad_norm": 2.7811391353607178,
      "learning_rate": 3.710164374371017e-05,
      "logits/chosen": 2.6361794471740723,
      "logits/rejected": 2.6786892414093018,
      "logps/chosen": -195.933349609375,
      "logps/rejected": -185.0607147216797,
      "loss": 0.6642,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.5686740279197693,
      "rewards/margins": 0.518959641456604,
      "rewards/rejected": -1.0876336097717285,
      "step": 4620
    },
    {
      "epoch": 0.7782623280778262,
      "grad_norm": 1.701859474182129,
      "learning_rate": 3.7045734093704575e-05,
      "logits/chosen": 2.6624321937561035,
      "logits/rejected": 2.873746156692505,
      "logps/chosen": -216.4184112548828,
      "logps/rejected": -196.2427520751953,
      "loss": 0.574,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6134144067764282,
      "rewards/margins": 0.8536938428878784,
      "rewards/rejected": -1.467108130455017,
      "step": 4640
    },
    {
      "epoch": 0.7816169070781617,
      "grad_norm": 1.76076078414917,
      "learning_rate": 3.698982444369899e-05,
      "logits/chosen": 2.6797235012054443,
      "logits/rejected": 2.933411121368408,
      "logps/chosen": -206.4675750732422,
      "logps/rejected": -182.17404174804688,
      "loss": 0.7229,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -1.056229829788208,
      "rewards/margins": 0.5101147890090942,
      "rewards/rejected": -1.5663446187973022,
      "step": 4660
    },
    {
      "epoch": 0.7849714860784971,
      "grad_norm": 1.4242475032806396,
      "learning_rate": 3.693391479369339e-05,
      "logits/chosen": 2.7114908695220947,
      "logits/rejected": 2.9844307899475098,
      "logps/chosen": -205.0061492919922,
      "logps/rejected": -187.90916442871094,
      "loss": 0.5578,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.7916472554206848,
      "rewards/margins": 0.9581688046455383,
      "rewards/rejected": -1.7498159408569336,
      "step": 4680
    },
    {
      "epoch": 0.7883260650788326,
      "grad_norm": 1.9579209089279175,
      "learning_rate": 3.6878005143687805e-05,
      "logits/chosen": 2.556307554244995,
      "logits/rejected": 2.937868118286133,
      "logps/chosen": -209.57687377929688,
      "logps/rejected": -187.9156036376953,
      "loss": 0.5683,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5547336935997009,
      "rewards/margins": 0.798907995223999,
      "rewards/rejected": -1.3536417484283447,
      "step": 4700
    },
    {
      "epoch": 0.791680644079168,
      "grad_norm": 1.9745503664016724,
      "learning_rate": 3.682209549368221e-05,
      "logits/chosen": 2.774895668029785,
      "logits/rejected": 2.865281343460083,
      "logps/chosen": -208.6219482421875,
      "logps/rejected": -201.4730224609375,
      "loss": 0.7351,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.9937898516654968,
      "rewards/margins": 0.3933439254760742,
      "rewards/rejected": -1.3871338367462158,
      "step": 4720
    },
    {
      "epoch": 0.7950352230795035,
      "grad_norm": 3.3499131202697754,
      "learning_rate": 3.676618584367662e-05,
      "logits/chosen": 2.7078118324279785,
      "logits/rejected": 2.809905529022217,
      "logps/chosen": -215.0470428466797,
      "logps/rejected": -202.8500213623047,
      "loss": 0.6815,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.8119847178459167,
      "rewards/margins": 0.5000425577163696,
      "rewards/rejected": -1.3120272159576416,
      "step": 4740
    },
    {
      "epoch": 0.798389802079839,
      "grad_norm": 2.3036484718322754,
      "learning_rate": 3.671027619367103e-05,
      "logits/chosen": 2.6939706802368164,
      "logits/rejected": 2.9614834785461426,
      "logps/chosen": -192.0198211669922,
      "logps/rejected": -181.9978485107422,
      "loss": 0.5906,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7865484952926636,
      "rewards/margins": 0.6085317730903625,
      "rewards/rejected": -1.3950802087783813,
      "step": 4760
    },
    {
      "epoch": 0.8017443810801744,
      "grad_norm": 2.820960760116577,
      "learning_rate": 3.6654366543665434e-05,
      "logits/chosen": 2.5916621685028076,
      "logits/rejected": 2.728361129760742,
      "logps/chosen": -197.65841674804688,
      "logps/rejected": -182.82986450195312,
      "loss": 0.7636,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.8908494114875793,
      "rewards/margins": 0.3271021842956543,
      "rewards/rejected": -1.2179515361785889,
      "step": 4780
    },
    {
      "epoch": 0.8050989600805099,
      "grad_norm": 2.3645260334014893,
      "learning_rate": 3.6598456893659846e-05,
      "logits/chosen": 2.6833436489105225,
      "logits/rejected": 2.8577938079833984,
      "logps/chosen": -213.8722686767578,
      "logps/rejected": -192.49598693847656,
      "loss": 0.6176,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.7451624870300293,
      "rewards/margins": 0.559653639793396,
      "rewards/rejected": -1.3048162460327148,
      "step": 4800
    },
    {
      "epoch": 0.8084535390808454,
      "grad_norm": 2.878089666366577,
      "learning_rate": 3.654254724365426e-05,
      "logits/chosen": 2.482537031173706,
      "logits/rejected": 2.68526029586792,
      "logps/chosen": -205.0669708251953,
      "logps/rejected": -190.83021545410156,
      "loss": 0.6339,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.3850089907646179,
      "rewards/margins": 0.6407964825630188,
      "rewards/rejected": -1.0258054733276367,
      "step": 4820
    },
    {
      "epoch": 0.8118081180811808,
      "grad_norm": 4.881666660308838,
      "learning_rate": 3.6486637593648664e-05,
      "logits/chosen": 2.8469338417053223,
      "logits/rejected": 2.94061541557312,
      "logps/chosen": -197.03125,
      "logps/rejected": -187.8494873046875,
      "loss": 0.6408,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5072776079177856,
      "rewards/margins": 0.5524962544441223,
      "rewards/rejected": -1.0597736835479736,
      "step": 4840
    },
    {
      "epoch": 0.8151626970815162,
      "grad_norm": 1.879914402961731,
      "learning_rate": 3.643072794364307e-05,
      "logits/chosen": 2.800006866455078,
      "logits/rejected": 3.0146238803863525,
      "logps/chosen": -199.1487579345703,
      "logps/rejected": -182.0741424560547,
      "loss": 0.6959,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.5343619585037231,
      "rewards/margins": 0.5566011667251587,
      "rewards/rejected": -1.0909631252288818,
      "step": 4860
    },
    {
      "epoch": 0.8185172760818518,
      "grad_norm": 0.9843375086784363,
      "learning_rate": 3.637481829363749e-05,
      "logits/chosen": 2.752013921737671,
      "logits/rejected": 2.8598599433898926,
      "logps/chosen": -198.880615234375,
      "logps/rejected": -178.6391143798828,
      "loss": 0.5554,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.47964659333229065,
      "rewards/margins": 0.9035449028015137,
      "rewards/rejected": -1.383191466331482,
      "step": 4880
    },
    {
      "epoch": 0.8218718550821872,
      "grad_norm": 2.316843032836914,
      "learning_rate": 3.6318908643631894e-05,
      "logits/chosen": 2.7880120277404785,
      "logits/rejected": 2.985882520675659,
      "logps/chosen": -172.0377197265625,
      "logps/rejected": -165.33985900878906,
      "loss": 0.5726,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5730411410331726,
      "rewards/margins": 0.7653542160987854,
      "rewards/rejected": -1.338395357131958,
      "step": 4900
    },
    {
      "epoch": 0.8252264340825226,
      "grad_norm": 4.934859275817871,
      "learning_rate": 3.62629989936263e-05,
      "logits/chosen": 2.836653232574463,
      "logits/rejected": 2.950026750564575,
      "logps/chosen": -198.24853515625,
      "logps/rejected": -175.51148986816406,
      "loss": 0.6832,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.7660964727401733,
      "rewards/margins": 0.5009037256240845,
      "rewards/rejected": -1.2670001983642578,
      "step": 4920
    },
    {
      "epoch": 0.8285810130828581,
      "grad_norm": 1.6064708232879639,
      "learning_rate": 3.620708934362071e-05,
      "logits/chosen": 2.8352651596069336,
      "logits/rejected": 3.0273711681365967,
      "logps/chosen": -195.26922607421875,
      "logps/rejected": -179.65560913085938,
      "loss": 0.6967,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.9607012867927551,
      "rewards/margins": 0.35834744572639465,
      "rewards/rejected": -1.3190486431121826,
      "step": 4940
    },
    {
      "epoch": 0.8319355920831936,
      "grad_norm": 1.289299488067627,
      "learning_rate": 3.615117969361512e-05,
      "logits/chosen": 2.6757640838623047,
      "logits/rejected": 2.950996160507202,
      "logps/chosen": -200.3157196044922,
      "logps/rejected": -191.29197692871094,
      "loss": 0.6294,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7129065990447998,
      "rewards/margins": 0.5844660997390747,
      "rewards/rejected": -1.297372579574585,
      "step": 4960
    },
    {
      "epoch": 0.835290171083529,
      "grad_norm": 1.489946961402893,
      "learning_rate": 3.609527004360953e-05,
      "logits/chosen": 2.622063159942627,
      "logits/rejected": 2.8674092292785645,
      "logps/chosen": -212.27621459960938,
      "logps/rejected": -176.94467163085938,
      "loss": 0.5696,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6151925325393677,
      "rewards/margins": 0.7909755706787109,
      "rewards/rejected": -1.4061682224273682,
      "step": 4980
    },
    {
      "epoch": 0.8386447500838645,
      "grad_norm": 3.109912395477295,
      "learning_rate": 3.6039360393603935e-05,
      "logits/chosen": 2.805778980255127,
      "logits/rejected": 3.0089781284332275,
      "logps/chosen": -198.27456665039062,
      "logps/rejected": -182.2730712890625,
      "loss": 0.5486,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5642101764678955,
      "rewards/margins": 0.729491651058197,
      "rewards/rejected": -1.2937018871307373,
      "step": 5000
    },
    {
      "epoch": 0.8419993290841999,
      "grad_norm": 2.5992748737335205,
      "learning_rate": 3.598345074359835e-05,
      "logits/chosen": 2.83583664894104,
      "logits/rejected": 3.008777379989624,
      "logps/chosen": -199.37884521484375,
      "logps/rejected": -191.44711303710938,
      "loss": 0.7059,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.6599545478820801,
      "rewards/margins": 0.543789267539978,
      "rewards/rejected": -1.203743815422058,
      "step": 5020
    },
    {
      "epoch": 0.8453539080845354,
      "grad_norm": 1.5131421089172363,
      "learning_rate": 3.592754109359275e-05,
      "logits/chosen": 2.652036666870117,
      "logits/rejected": 2.891284942626953,
      "logps/chosen": -207.4352569580078,
      "logps/rejected": -173.38711547851562,
      "loss": 0.6262,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.42635512351989746,
      "rewards/margins": 0.7640249133110046,
      "rewards/rejected": -1.1903799772262573,
      "step": 5040
    },
    {
      "epoch": 0.8487084870848709,
      "grad_norm": 0.9427804350852966,
      "learning_rate": 3.5871631443587165e-05,
      "logits/chosen": 2.5067825317382812,
      "logits/rejected": 2.834674835205078,
      "logps/chosen": -187.24972534179688,
      "logps/rejected": -170.96939086914062,
      "loss": 0.5416,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.443595826625824,
      "rewards/margins": 0.7735332250595093,
      "rewards/rejected": -1.217129111289978,
      "step": 5060
    },
    {
      "epoch": 0.8520630660852063,
      "grad_norm": 1.4874635934829712,
      "learning_rate": 3.581572179358158e-05,
      "logits/chosen": 2.852900505065918,
      "logits/rejected": 2.9939377307891846,
      "logps/chosen": -192.96389770507812,
      "logps/rejected": -188.58609008789062,
      "loss": 0.8342,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.7280617952346802,
      "rewards/margins": 0.1588687300682068,
      "rewards/rejected": -0.8869304656982422,
      "step": 5080
    },
    {
      "epoch": 0.8554176450855417,
      "grad_norm": 1.0805766582489014,
      "learning_rate": 3.575981214357598e-05,
      "logits/chosen": 2.834394931793213,
      "logits/rejected": 3.1005101203918457,
      "logps/chosen": -191.15780639648438,
      "logps/rejected": -174.95970153808594,
      "loss": 0.5726,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.3579889237880707,
      "rewards/margins": 0.7859588861465454,
      "rewards/rejected": -1.143947720527649,
      "step": 5100
    },
    {
      "epoch": 0.8587722240858772,
      "grad_norm": 2.7868449687957764,
      "learning_rate": 3.570390249357039e-05,
      "logits/chosen": 2.7165582180023193,
      "logits/rejected": 3.0266621112823486,
      "logps/chosen": -200.8298797607422,
      "logps/rejected": -192.7842559814453,
      "loss": 0.613,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.39101642370224,
      "rewards/margins": 0.6926674842834473,
      "rewards/rejected": -1.0836838483810425,
      "step": 5120
    },
    {
      "epoch": 0.8621268030862127,
      "grad_norm": 0.8035220503807068,
      "learning_rate": 3.56479928435648e-05,
      "logits/chosen": 2.6080234050750732,
      "logits/rejected": 2.871476650238037,
      "logps/chosen": -199.401123046875,
      "logps/rejected": -181.22776794433594,
      "loss": 0.7442,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.760949969291687,
      "rewards/margins": 0.4378095269203186,
      "rewards/rejected": -1.1987595558166504,
      "step": 5140
    },
    {
      "epoch": 0.8654813820865481,
      "grad_norm": 5.065385341644287,
      "learning_rate": 3.559208319355921e-05,
      "logits/chosen": 2.8789167404174805,
      "logits/rejected": 3.1181540489196777,
      "logps/chosen": -194.41690063476562,
      "logps/rejected": -181.7683563232422,
      "loss": 0.7274,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.7614617347717285,
      "rewards/margins": 0.4376664161682129,
      "rewards/rejected": -1.1991280317306519,
      "step": 5160
    },
    {
      "epoch": 0.8688359610868835,
      "grad_norm": 3.1325690746307373,
      "learning_rate": 3.553617354355362e-05,
      "logits/chosen": 3.0147323608398438,
      "logits/rejected": 3.15901255607605,
      "logps/chosen": -191.62808227539062,
      "logps/rejected": -176.01510620117188,
      "loss": 0.7146,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.8309043645858765,
      "rewards/margins": 0.3455725908279419,
      "rewards/rejected": -1.1764768362045288,
      "step": 5180
    },
    {
      "epoch": 0.8721905400872191,
      "grad_norm": 0.9636686444282532,
      "learning_rate": 3.5480263893548024e-05,
      "logits/chosen": 3.0429484844207764,
      "logits/rejected": 3.317352294921875,
      "logps/chosen": -198.34596252441406,
      "logps/rejected": -180.11143493652344,
      "loss": 0.5239,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.4238279461860657,
      "rewards/margins": 0.771317720413208,
      "rewards/rejected": -1.195145606994629,
      "step": 5200
    },
    {
      "epoch": 0.8755451190875545,
      "grad_norm": 1.1482278108596802,
      "learning_rate": 3.542435424354244e-05,
      "logits/chosen": 2.993572473526001,
      "logits/rejected": 3.1971027851104736,
      "logps/chosen": -188.86026000976562,
      "logps/rejected": -176.23843383789062,
      "loss": 0.5743,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6374630928039551,
      "rewards/margins": 0.6066105365753174,
      "rewards/rejected": -1.244073510169983,
      "step": 5220
    },
    {
      "epoch": 0.8788996980878899,
      "grad_norm": 2.9805569648742676,
      "learning_rate": 3.536844459353685e-05,
      "logits/chosen": 2.8431856632232666,
      "logits/rejected": 2.981870174407959,
      "logps/chosen": -186.452880859375,
      "logps/rejected": -177.8446502685547,
      "loss": 0.6153,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.6060303449630737,
      "rewards/margins": 0.6545589566230774,
      "rewards/rejected": -1.260589361190796,
      "step": 5240
    },
    {
      "epoch": 0.8822542770882255,
      "grad_norm": 2.5286269187927246,
      "learning_rate": 3.5312534943531255e-05,
      "logits/chosen": 2.863752841949463,
      "logits/rejected": 3.039750099182129,
      "logps/chosen": -196.9418182373047,
      "logps/rejected": -177.17178344726562,
      "loss": 0.64,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.4570610523223877,
      "rewards/margins": 0.5335514545440674,
      "rewards/rejected": -0.9906125068664551,
      "step": 5260
    },
    {
      "epoch": 0.8856088560885609,
      "grad_norm": 1.6619595289230347,
      "learning_rate": 3.525662529352567e-05,
      "logits/chosen": 2.7544262409210205,
      "logits/rejected": 3.0148704051971436,
      "logps/chosen": -209.25161743164062,
      "logps/rejected": -176.6923828125,
      "loss": 0.5333,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.16378667950630188,
      "rewards/margins": 0.7888487577438354,
      "rewards/rejected": -0.9526354670524597,
      "step": 5280
    },
    {
      "epoch": 0.8889634350888963,
      "grad_norm": 2.1834893226623535,
      "learning_rate": 3.520071564352007e-05,
      "logits/chosen": 2.7016215324401855,
      "logits/rejected": 2.8170554637908936,
      "logps/chosen": -212.7013702392578,
      "logps/rejected": -185.9668426513672,
      "loss": 0.5486,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.0456555113196373,
      "rewards/margins": 0.6938324570655823,
      "rewards/rejected": -0.6481770277023315,
      "step": 5300
    },
    {
      "epoch": 0.8923180140892318,
      "grad_norm": 1.456844687461853,
      "learning_rate": 3.5144805993514485e-05,
      "logits/chosen": 2.951476573944092,
      "logits/rejected": 3.205862045288086,
      "logps/chosen": -188.77511596679688,
      "logps/rejected": -173.6178436279297,
      "loss": 0.5157,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.15070493519306183,
      "rewards/margins": 0.7867665886878967,
      "rewards/rejected": -0.9374715685844421,
      "step": 5320
    },
    {
      "epoch": 0.8956725930895673,
      "grad_norm": 1.952390193939209,
      "learning_rate": 3.508889634350889e-05,
      "logits/chosen": 2.9019832611083984,
      "logits/rejected": 3.0744166374206543,
      "logps/chosen": -201.33560180664062,
      "logps/rejected": -186.49716186523438,
      "loss": 0.6469,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.34553760290145874,
      "rewards/margins": 0.46419328451156616,
      "rewards/rejected": -0.8097308874130249,
      "step": 5340
    },
    {
      "epoch": 0.8990271720899027,
      "grad_norm": 0.9903384447097778,
      "learning_rate": 3.50329866935033e-05,
      "logits/chosen": 2.9539661407470703,
      "logits/rejected": 3.218100070953369,
      "logps/chosen": -194.01097106933594,
      "logps/rejected": -180.9438934326172,
      "loss": 0.5759,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3573164641857147,
      "rewards/margins": 0.6216464042663574,
      "rewards/rejected": -0.9789628982543945,
      "step": 5360
    },
    {
      "epoch": 0.9023817510902382,
      "grad_norm": 1.3220261335372925,
      "learning_rate": 3.497707704349771e-05,
      "logits/chosen": 2.838447093963623,
      "logits/rejected": 3.1566290855407715,
      "logps/chosen": -199.00437927246094,
      "logps/rejected": -187.3219757080078,
      "loss": 0.6251,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.31888455152511597,
      "rewards/margins": 0.7648876905441284,
      "rewards/rejected": -1.0837723016738892,
      "step": 5380
    },
    {
      "epoch": 0.9057363300905736,
      "grad_norm": 1.2406922578811646,
      "learning_rate": 3.4921167393492114e-05,
      "logits/chosen": 2.8962178230285645,
      "logits/rejected": 3.0402755737304688,
      "logps/chosen": -194.73654174804688,
      "logps/rejected": -184.0350341796875,
      "loss": 0.651,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.8500022888183594,
      "rewards/margins": 0.46145278215408325,
      "rewards/rejected": -1.3114550113677979,
      "step": 5400
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 1.3566322326660156,
      "learning_rate": 3.4865257743486526e-05,
      "logits/chosen": 2.6742377281188965,
      "logits/rejected": 2.8272669315338135,
      "logps/chosen": -188.85568237304688,
      "logps/rejected": -187.859619140625,
      "loss": 0.8193,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -0.9252856969833374,
      "rewards/margins": 0.22536858916282654,
      "rewards/rejected": -1.1506543159484863,
      "step": 5420
    },
    {
      "epoch": 0.9124454880912446,
      "grad_norm": 1.3547688722610474,
      "learning_rate": 3.480934809348094e-05,
      "logits/chosen": 3.068864107131958,
      "logits/rejected": 3.307671070098877,
      "logps/chosen": -203.88577270507812,
      "logps/rejected": -165.19908142089844,
      "loss": 0.5188,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6992791295051575,
      "rewards/margins": 0.9531337022781372,
      "rewards/rejected": -1.65241277217865,
      "step": 5440
    },
    {
      "epoch": 0.91580006709158,
      "grad_norm": 3.4887142181396484,
      "learning_rate": 3.4753438443475344e-05,
      "logits/chosen": 2.6919941902160645,
      "logits/rejected": 2.874887466430664,
      "logps/chosen": -200.2425079345703,
      "logps/rejected": -184.84121704101562,
      "loss": 0.6379,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.4843422770500183,
      "rewards/margins": 0.5764309763908386,
      "rewards/rejected": -1.060773491859436,
      "step": 5460
    },
    {
      "epoch": 0.9191546460919154,
      "grad_norm": 2.7661190032958984,
      "learning_rate": 3.469752879346975e-05,
      "logits/chosen": 2.8175337314605713,
      "logits/rejected": 3.021773099899292,
      "logps/chosen": -189.7709503173828,
      "logps/rejected": -172.50747680664062,
      "loss": 0.6663,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4314822256565094,
      "rewards/margins": 0.7292736172676086,
      "rewards/rejected": -1.1607557535171509,
      "step": 5480
    },
    {
      "epoch": 0.922509225092251,
      "grad_norm": 2.331963062286377,
      "learning_rate": 3.464161914346417e-05,
      "logits/chosen": 3.0010600090026855,
      "logits/rejected": 3.215855121612549,
      "logps/chosen": -223.0026397705078,
      "logps/rejected": -206.24594116210938,
      "loss": 0.5807,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6228941679000854,
      "rewards/margins": 0.7030065655708313,
      "rewards/rejected": -1.325900673866272,
      "step": 5500
    },
    {
      "epoch": 0.9258638040925864,
      "grad_norm": 2.2392590045928955,
      "learning_rate": 3.4585709493458574e-05,
      "logits/chosen": 2.803258180618286,
      "logits/rejected": 2.959653377532959,
      "logps/chosen": -189.07449340820312,
      "logps/rejected": -183.73403930664062,
      "loss": 0.587,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6685042977333069,
      "rewards/margins": 0.6785076856613159,
      "rewards/rejected": -1.3470120429992676,
      "step": 5520
    },
    {
      "epoch": 0.9292183830929218,
      "grad_norm": 1.8938738107681274,
      "learning_rate": 3.452979984345298e-05,
      "logits/chosen": 2.9737532138824463,
      "logits/rejected": 3.0707201957702637,
      "logps/chosen": -199.6172637939453,
      "logps/rejected": -182.0323028564453,
      "loss": 0.6984,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.7937829494476318,
      "rewards/margins": 0.3062306046485901,
      "rewards/rejected": -1.1000136137008667,
      "step": 5540
    },
    {
      "epoch": 0.9325729620932574,
      "grad_norm": 1.1567362546920776,
      "learning_rate": 3.447389019344739e-05,
      "logits/chosen": 2.7235729694366455,
      "logits/rejected": 3.0312085151672363,
      "logps/chosen": -225.9897918701172,
      "logps/rejected": -192.37948608398438,
      "loss": 0.5285,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.4927178919315338,
      "rewards/margins": 0.7804754972457886,
      "rewards/rejected": -1.2731934785842896,
      "step": 5560
    },
    {
      "epoch": 0.9359275410935928,
      "grad_norm": 2.930551290512085,
      "learning_rate": 3.442077602594208e-05,
      "logits/chosen": 3.021719455718994,
      "logits/rejected": 3.187079668045044,
      "logps/chosen": -210.65719604492188,
      "logps/rejected": -190.3162841796875,
      "loss": 0.5942,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.8037117719650269,
      "rewards/margins": 0.6203833222389221,
      "rewards/rejected": -1.4240951538085938,
      "step": 5580
    },
    {
      "epoch": 0.9392821200939282,
      "grad_norm": 2.956630229949951,
      "learning_rate": 3.4364866375936485e-05,
      "logits/chosen": 2.859257459640503,
      "logits/rejected": 3.031320571899414,
      "logps/chosen": -203.82325744628906,
      "logps/rejected": -174.7882080078125,
      "loss": 0.6063,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.5820046067237854,
      "rewards/margins": 0.7201274633407593,
      "rewards/rejected": -1.3021320104599,
      "step": 5600
    },
    {
      "epoch": 0.9426366990942636,
      "grad_norm": 2.2086384296417236,
      "learning_rate": 3.43089567259309e-05,
      "logits/chosen": 2.960496425628662,
      "logits/rejected": 3.134479522705078,
      "logps/chosen": -193.1117401123047,
      "logps/rejected": -178.0401153564453,
      "loss": 0.5377,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.4593968391418457,
      "rewards/margins": 0.9502328634262085,
      "rewards/rejected": -1.4096297025680542,
      "step": 5620
    },
    {
      "epoch": 0.9459912780945992,
      "grad_norm": 3.643270492553711,
      "learning_rate": 3.42530470759253e-05,
      "logits/chosen": 3.056912899017334,
      "logits/rejected": 3.1600232124328613,
      "logps/chosen": -193.8279571533203,
      "logps/rejected": -190.7955322265625,
      "loss": 0.7099,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.33382171392440796,
      "rewards/margins": 0.4235526919364929,
      "rewards/rejected": -0.7573744058609009,
      "step": 5640
    },
    {
      "epoch": 0.9493458570949346,
      "grad_norm": 2.121236562728882,
      "learning_rate": 3.4197137425919716e-05,
      "logits/chosen": 2.7401583194732666,
      "logits/rejected": 2.9106340408325195,
      "logps/chosen": -195.54530334472656,
      "logps/rejected": -172.70587158203125,
      "loss": 0.7126,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.47095856070518494,
      "rewards/margins": 0.4773290157318115,
      "rewards/rejected": -0.9482876062393188,
      "step": 5660
    },
    {
      "epoch": 0.95270043609527,
      "grad_norm": 2.370818614959717,
      "learning_rate": 3.414122777591413e-05,
      "logits/chosen": 2.885568141937256,
      "logits/rejected": 3.078434467315674,
      "logps/chosen": -185.38145446777344,
      "logps/rejected": -171.558349609375,
      "loss": 0.5182,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.3774030804634094,
      "rewards/margins": 0.7706303000450134,
      "rewards/rejected": -1.1480333805084229,
      "step": 5680
    },
    {
      "epoch": 0.9560550150956055,
      "grad_norm": 1.3679375648498535,
      "learning_rate": 3.4085318125908533e-05,
      "logits/chosen": 2.968998432159424,
      "logits/rejected": 3.1244266033172607,
      "logps/chosen": -197.6127166748047,
      "logps/rejected": -174.9600372314453,
      "loss": 0.623,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.2778106927871704,
      "rewards/margins": 0.7293146848678589,
      "rewards/rejected": -1.0071253776550293,
      "step": 5700
    },
    {
      "epoch": 0.959409594095941,
      "grad_norm": 0.6699498295783997,
      "learning_rate": 3.402940847590294e-05,
      "logits/chosen": 2.856023073196411,
      "logits/rejected": 3.040299892425537,
      "logps/chosen": -195.69174194335938,
      "logps/rejected": -179.99551391601562,
      "loss": 0.6597,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5399853587150574,
      "rewards/margins": 0.6239537596702576,
      "rewards/rejected": -1.1639392375946045,
      "step": 5720
    },
    {
      "epoch": 0.9627641730962764,
      "grad_norm": 1.6321645975112915,
      "learning_rate": 3.397349882589735e-05,
      "logits/chosen": 2.8674492835998535,
      "logits/rejected": 3.034651517868042,
      "logps/chosen": -207.8708953857422,
      "logps/rejected": -190.5782928466797,
      "loss": 0.6037,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.12360510975122452,
      "rewards/margins": 0.6796241402626038,
      "rewards/rejected": -0.8032292127609253,
      "step": 5740
    },
    {
      "epoch": 0.9661187520966119,
      "grad_norm": 1.5400961637496948,
      "learning_rate": 3.3917589175891764e-05,
      "logits/chosen": 2.982470750808716,
      "logits/rejected": 3.037245512008667,
      "logps/chosen": -191.2550811767578,
      "logps/rejected": -185.96066284179688,
      "loss": 0.6377,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.20997793972492218,
      "rewards/margins": 0.4056398868560791,
      "rewards/rejected": -0.6156178116798401,
      "step": 5760
    },
    {
      "epoch": 0.9694733310969473,
      "grad_norm": 2.004751682281494,
      "learning_rate": 3.386167952588617e-05,
      "logits/chosen": 2.9753620624542236,
      "logits/rejected": 3.160722017288208,
      "logps/chosen": -178.0568389892578,
      "logps/rejected": -173.20315551757812,
      "loss": 0.6678,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.19563952088356018,
      "rewards/margins": 0.5497592687606812,
      "rewards/rejected": -0.7453988790512085,
      "step": 5780
    },
    {
      "epoch": 0.9728279100972828,
      "grad_norm": 3.6484029293060303,
      "learning_rate": 3.3805769875880575e-05,
      "logits/chosen": 3.1820976734161377,
      "logits/rejected": 3.3193764686584473,
      "logps/chosen": -185.8913116455078,
      "logps/rejected": -175.10574340820312,
      "loss": 0.6022,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.34221166372299194,
      "rewards/margins": 0.6165079474449158,
      "rewards/rejected": -0.9587196111679077,
      "step": 5800
    },
    {
      "epoch": 0.9761824890976183,
      "grad_norm": 1.3583475351333618,
      "learning_rate": 3.374986022587499e-05,
      "logits/chosen": 2.9121994972229004,
      "logits/rejected": 3.0512473583221436,
      "logps/chosen": -190.6607208251953,
      "logps/rejected": -192.90341186523438,
      "loss": 0.6927,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.14787952601909637,
      "rewards/margins": 0.5567612648010254,
      "rewards/rejected": -0.7046406865119934,
      "step": 5820
    },
    {
      "epoch": 0.9795370680979537,
      "grad_norm": 2.936286687850952,
      "learning_rate": 3.36939505758694e-05,
      "logits/chosen": 2.936260223388672,
      "logits/rejected": 3.162163257598877,
      "logps/chosen": -190.51071166992188,
      "logps/rejected": -174.37437438964844,
      "loss": 0.5456,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.12682217359542847,
      "rewards/margins": 0.7644507884979248,
      "rewards/rejected": -0.8912729024887085,
      "step": 5840
    },
    {
      "epoch": 0.9828916470982891,
      "grad_norm": 2.228036880493164,
      "learning_rate": 3.3638040925863805e-05,
      "logits/chosen": 2.8535561561584473,
      "logits/rejected": 3.0385279655456543,
      "logps/chosen": -183.68692016601562,
      "logps/rejected": -169.58108520507812,
      "loss": 0.687,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.32215508818626404,
      "rewards/margins": 0.6598628759384155,
      "rewards/rejected": -0.9820178747177124,
      "step": 5860
    },
    {
      "epoch": 0.9862462260986247,
      "grad_norm": 2.1320149898529053,
      "learning_rate": 3.358213127585822e-05,
      "logits/chosen": 2.9448859691619873,
      "logits/rejected": 3.047840118408203,
      "logps/chosen": -192.5936279296875,
      "logps/rejected": -187.95889282226562,
      "loss": 0.6092,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.10264426469802856,
      "rewards/margins": 0.8409868478775024,
      "rewards/rejected": -0.9436310529708862,
      "step": 5880
    },
    {
      "epoch": 0.9896008050989601,
      "grad_norm": 1.65633225440979,
      "learning_rate": 3.352622162585262e-05,
      "logits/chosen": 2.7329254150390625,
      "logits/rejected": 2.9218268394470215,
      "logps/chosen": -195.16514587402344,
      "logps/rejected": -187.94100952148438,
      "loss": 0.6838,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.07794483751058578,
      "rewards/margins": 0.45313072204589844,
      "rewards/rejected": -0.37518590688705444,
      "step": 5900
    },
    {
      "epoch": 0.9929553840992955,
      "grad_norm": 1.7587101459503174,
      "learning_rate": 3.3470311975847035e-05,
      "logits/chosen": 2.8942463397979736,
      "logits/rejected": 3.0865230560302734,
      "logps/chosen": -185.74893188476562,
      "logps/rejected": -174.59371948242188,
      "loss": 0.6214,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.39317286014556885,
      "rewards/margins": 0.49949026107788086,
      "rewards/rejected": -0.8926631808280945,
      "step": 5920
    },
    {
      "epoch": 0.996309963099631,
      "grad_norm": 2.0062315464019775,
      "learning_rate": 3.341440232584144e-05,
      "logits/chosen": 2.983828067779541,
      "logits/rejected": 3.0347769260406494,
      "logps/chosen": -184.22047424316406,
      "logps/rejected": -177.94735717773438,
      "loss": 0.6427,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.36977383494377136,
      "rewards/margins": 0.6646506190299988,
      "rewards/rejected": -1.0344244241714478,
      "step": 5940
    },
    {
      "epoch": 0.9996645420999665,
      "grad_norm": 4.831537246704102,
      "learning_rate": 3.335849267583585e-05,
      "logits/chosen": 2.9189844131469727,
      "logits/rejected": 3.0084476470947266,
      "logps/chosen": -185.65182495117188,
      "logps/rejected": -185.37796020507812,
      "loss": 0.7159,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.2604025602340698,
      "rewards/margins": 0.45293378829956055,
      "rewards/rejected": -0.7133363485336304,
      "step": 5960
    },
    {
      "epoch": 1.003019121100302,
      "grad_norm": 3.507002830505371,
      "learning_rate": 3.330258302583026e-05,
      "logits/chosen": 2.794577121734619,
      "logits/rejected": 3.1097373962402344,
      "logps/chosen": -193.17578125,
      "logps/rejected": -163.8563232421875,
      "loss": 0.3553,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0486343689262867,
      "rewards/margins": 1.4751781225204468,
      "rewards/rejected": -1.5238122940063477,
      "step": 5980
    },
    {
      "epoch": 1.0063737001006374,
      "grad_norm": 4.609161853790283,
      "learning_rate": 3.3246673375824664e-05,
      "logits/chosen": 2.6421058177948,
      "logits/rejected": 2.875239849090576,
      "logps/chosen": -195.0882110595703,
      "logps/rejected": -178.99658203125,
      "loss": 0.5472,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.4015623927116394,
      "rewards/margins": 0.7342477440834045,
      "rewards/rejected": -1.135810136795044,
      "step": 6000
    },
    {
      "epoch": 1.0097282791009727,
      "grad_norm": 3.1374380588531494,
      "learning_rate": 3.319076372581908e-05,
      "logits/chosen": 2.8712620735168457,
      "logits/rejected": 2.966275691986084,
      "logps/chosen": -200.33335876464844,
      "logps/rejected": -184.32972717285156,
      "loss": 0.566,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.22522428631782532,
      "rewards/margins": 0.9869701266288757,
      "rewards/rejected": -1.2121944427490234,
      "step": 6020
    },
    {
      "epoch": 1.0130828581013083,
      "grad_norm": 1.1846359968185425,
      "learning_rate": 3.313485407581349e-05,
      "logits/chosen": 2.8464934825897217,
      "logits/rejected": 3.0073976516723633,
      "logps/chosen": -202.23300170898438,
      "logps/rejected": -181.13449096679688,
      "loss": 0.4205,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.2974208891391754,
      "rewards/margins": 0.999671459197998,
      "rewards/rejected": -1.2970921993255615,
      "step": 6040
    },
    {
      "epoch": 1.0164374371016438,
      "grad_norm": 1.191857933998108,
      "learning_rate": 3.3078944425807894e-05,
      "logits/chosen": 2.883679151535034,
      "logits/rejected": 3.083408832550049,
      "logps/chosen": -188.0045623779297,
      "logps/rejected": -165.09603881835938,
      "loss": 0.4346,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.6081708669662476,
      "rewards/margins": 1.0608550310134888,
      "rewards/rejected": -1.6690257787704468,
      "step": 6060
    },
    {
      "epoch": 1.0197920161019791,
      "grad_norm": 0.8936764001846313,
      "learning_rate": 3.30230347758023e-05,
      "logits/chosen": 2.5331473350524902,
      "logits/rejected": 2.7685391902923584,
      "logps/chosen": -182.22052001953125,
      "logps/rejected": -176.03553771972656,
      "loss": 0.4342,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5526679158210754,
      "rewards/margins": 1.1571242809295654,
      "rewards/rejected": -1.7097923755645752,
      "step": 6080
    },
    {
      "epoch": 1.0231465951023146,
      "grad_norm": 1.1560100317001343,
      "learning_rate": 3.296712512579672e-05,
      "logits/chosen": 2.9302754402160645,
      "logits/rejected": 3.1631417274475098,
      "logps/chosen": -190.61856079101562,
      "logps/rejected": -177.7620391845703,
      "loss": 0.4598,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8504331707954407,
      "rewards/margins": 0.9945653080940247,
      "rewards/rejected": -1.8449985980987549,
      "step": 6100
    },
    {
      "epoch": 1.0265011741026502,
      "grad_norm": 2.4975388050079346,
      "learning_rate": 3.2911215475791124e-05,
      "logits/chosen": 3.0398800373077393,
      "logits/rejected": 3.099972724914551,
      "logps/chosen": -206.30477905273438,
      "logps/rejected": -190.37149047851562,
      "loss": 0.4628,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.49358072876930237,
      "rewards/margins": 1.0709683895111084,
      "rewards/rejected": -1.564549207687378,
      "step": 6120
    },
    {
      "epoch": 1.0298557531029855,
      "grad_norm": 2.103952169418335,
      "learning_rate": 3.285530582578553e-05,
      "logits/chosen": 2.6698193550109863,
      "logits/rejected": 2.8849093914031982,
      "logps/chosen": -188.34225463867188,
      "logps/rejected": -177.95242309570312,
      "loss": 0.5527,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6592711210250854,
      "rewards/margins": 0.7503170967102051,
      "rewards/rejected": -1.4095884561538696,
      "step": 6140
    },
    {
      "epoch": 1.033210332103321,
      "grad_norm": 1.5894041061401367,
      "learning_rate": 3.279939617577994e-05,
      "logits/chosen": 2.7199244499206543,
      "logits/rejected": 2.8841278553009033,
      "logps/chosen": -207.27096557617188,
      "logps/rejected": -191.8440704345703,
      "loss": 0.4519,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.312696635723114,
      "rewards/margins": 1.2120929956436157,
      "rewards/rejected": -1.524789571762085,
      "step": 6160
    },
    {
      "epoch": 1.0365649111036566,
      "grad_norm": 2.5948307514190674,
      "learning_rate": 3.2743486525774354e-05,
      "logits/chosen": 2.6607823371887207,
      "logits/rejected": 2.886401653289795,
      "logps/chosen": -199.45867919921875,
      "logps/rejected": -187.88702392578125,
      "loss": 0.4608,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.369674950838089,
      "rewards/margins": 1.068868637084961,
      "rewards/rejected": -1.4385435581207275,
      "step": 6180
    },
    {
      "epoch": 1.0399194901039919,
      "grad_norm": 3.2529287338256836,
      "learning_rate": 3.268757687576876e-05,
      "logits/chosen": 2.757580518722534,
      "logits/rejected": 3.0506484508514404,
      "logps/chosen": -200.1606903076172,
      "logps/rejected": -181.137939453125,
      "loss": 0.4504,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.34129002690315247,
      "rewards/margins": 1.1235376596450806,
      "rewards/rejected": -1.464827537536621,
      "step": 6200
    },
    {
      "epoch": 1.0432740691043274,
      "grad_norm": 2.4856889247894287,
      "learning_rate": 3.2631667225763165e-05,
      "logits/chosen": 2.8704564571380615,
      "logits/rejected": 3.0078372955322266,
      "logps/chosen": -201.2180633544922,
      "logps/rejected": -191.8632049560547,
      "loss": 0.551,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.35860475897789,
      "rewards/margins": 0.793416440486908,
      "rewards/rejected": -1.1520211696624756,
      "step": 6220
    },
    {
      "epoch": 1.046628648104663,
      "grad_norm": 2.1773853302001953,
      "learning_rate": 3.257575757575758e-05,
      "logits/chosen": 2.7582151889801025,
      "logits/rejected": 2.9370739459991455,
      "logps/chosen": -186.7648162841797,
      "logps/rejected": -180.37538146972656,
      "loss": 0.4015,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.3212815821170807,
      "rewards/margins": 1.1826825141906738,
      "rewards/rejected": -1.5039640665054321,
      "step": 6240
    },
    {
      "epoch": 1.0499832271049983,
      "grad_norm": 3.203197717666626,
      "learning_rate": 3.251984792575198e-05,
      "logits/chosen": 2.804100513458252,
      "logits/rejected": 3.022043228149414,
      "logps/chosen": -200.96144104003906,
      "logps/rejected": -193.64126586914062,
      "loss": 0.4256,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.6349417567253113,
      "rewards/margins": 1.098752498626709,
      "rewards/rejected": -1.733694314956665,
      "step": 6260
    },
    {
      "epoch": 1.0533378061053338,
      "grad_norm": 1.6309196949005127,
      "learning_rate": 3.2463938275746395e-05,
      "logits/chosen": 2.756495952606201,
      "logits/rejected": 2.870999336242676,
      "logps/chosen": -204.8727264404297,
      "logps/rejected": -203.60484313964844,
      "loss": 0.5197,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.871969997882843,
      "rewards/margins": 1.0680049657821655,
      "rewards/rejected": -1.9399750232696533,
      "step": 6280
    },
    {
      "epoch": 1.0566923851056693,
      "grad_norm": 1.6896110773086548,
      "learning_rate": 3.240802862574081e-05,
      "logits/chosen": 2.6525673866271973,
      "logits/rejected": 2.845890522003174,
      "logps/chosen": -185.93359375,
      "logps/rejected": -188.96473693847656,
      "loss": 0.4414,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.8410552144050598,
      "rewards/margins": 1.2206683158874512,
      "rewards/rejected": -2.061723470687866,
      "step": 6300
    },
    {
      "epoch": 1.0600469641060046,
      "grad_norm": 2.1064298152923584,
      "learning_rate": 3.235211897573521e-05,
      "logits/chosen": 2.5960514545440674,
      "logits/rejected": 2.850283145904541,
      "logps/chosen": -205.1772918701172,
      "logps/rejected": -191.03765869140625,
      "loss": 0.389,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.6509894132614136,
      "rewards/margins": 1.5210587978363037,
      "rewards/rejected": -2.172048330307007,
      "step": 6320
    },
    {
      "epoch": 1.0634015431063402,
      "grad_norm": 2.1870429515838623,
      "learning_rate": 3.229620932572962e-05,
      "logits/chosen": 2.7036237716674805,
      "logits/rejected": 2.7814571857452393,
      "logps/chosen": -204.40289306640625,
      "logps/rejected": -205.8976593017578,
      "loss": 0.5126,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.106351375579834,
      "rewards/margins": 0.9716466069221497,
      "rewards/rejected": -2.077997922897339,
      "step": 6340
    },
    {
      "epoch": 1.0667561221066757,
      "grad_norm": 2.1446595191955566,
      "learning_rate": 3.224029967572403e-05,
      "logits/chosen": 2.6012964248657227,
      "logits/rejected": 2.9041686058044434,
      "logps/chosen": -212.903076171875,
      "logps/rejected": -205.0285186767578,
      "loss": 0.4722,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7961797118186951,
      "rewards/margins": 1.09001886844635,
      "rewards/rejected": -1.8861984014511108,
      "step": 6360
    },
    {
      "epoch": 1.070110701107011,
      "grad_norm": 1.0619549751281738,
      "learning_rate": 3.2184390025718443e-05,
      "logits/chosen": 2.669881820678711,
      "logits/rejected": 2.972566604614258,
      "logps/chosen": -203.4895477294922,
      "logps/rejected": -188.92330932617188,
      "loss": 0.5026,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8507604598999023,
      "rewards/margins": 1.0943174362182617,
      "rewards/rejected": -1.9450781345367432,
      "step": 6380
    },
    {
      "epoch": 1.0734652801073465,
      "grad_norm": 2.907907247543335,
      "learning_rate": 3.212848037571285e-05,
      "logits/chosen": 2.770937442779541,
      "logits/rejected": 2.841888427734375,
      "logps/chosen": -201.58978271484375,
      "logps/rejected": -201.38803100585938,
      "loss": 0.4939,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8946390151977539,
      "rewards/margins": 1.0904124975204468,
      "rewards/rejected": -1.9850515127182007,
      "step": 6400
    },
    {
      "epoch": 1.076819859107682,
      "grad_norm": 1.9311953783035278,
      "learning_rate": 3.2072570725707254e-05,
      "logits/chosen": 2.6447393894195557,
      "logits/rejected": 2.80436372756958,
      "logps/chosen": -190.31582641601562,
      "logps/rejected": -183.7861328125,
      "loss": 0.3945,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.9365229606628418,
      "rewards/margins": 1.2277623414993286,
      "rewards/rejected": -2.164285182952881,
      "step": 6420
    },
    {
      "epoch": 1.0801744381080174,
      "grad_norm": 1.2446788549423218,
      "learning_rate": 3.201666107570167e-05,
      "logits/chosen": 2.4797189235687256,
      "logits/rejected": 2.763054370880127,
      "logps/chosen": -197.9258270263672,
      "logps/rejected": -196.3283233642578,
      "loss": 0.5093,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0181771516799927,
      "rewards/margins": 1.1590383052825928,
      "rewards/rejected": -2.177215576171875,
      "step": 6440
    },
    {
      "epoch": 1.083529017108353,
      "grad_norm": 5.330489635467529,
      "learning_rate": 3.196075142569608e-05,
      "logits/chosen": 2.4536709785461426,
      "logits/rejected": 2.6149160861968994,
      "logps/chosen": -212.2157745361328,
      "logps/rejected": -200.0312957763672,
      "loss": 0.479,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.803543210029602,
      "rewards/margins": 1.041332483291626,
      "rewards/rejected": -1.844875693321228,
      "step": 6460
    },
    {
      "epoch": 1.0868835961086885,
      "grad_norm": 1.2443872690200806,
      "learning_rate": 3.1904841775690485e-05,
      "logits/chosen": 2.573308229446411,
      "logits/rejected": 2.9436118602752686,
      "logps/chosen": -194.998046875,
      "logps/rejected": -188.26800537109375,
      "loss": 0.3725,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.044405221939087,
      "rewards/margins": 1.48232901096344,
      "rewards/rejected": -2.5267341136932373,
      "step": 6480
    },
    {
      "epoch": 1.0902381751090238,
      "grad_norm": 2.0588338375091553,
      "learning_rate": 3.18489321256849e-05,
      "logits/chosen": 2.4334208965301514,
      "logits/rejected": 2.5079026222229004,
      "logps/chosen": -213.1338653564453,
      "logps/rejected": -201.67591857910156,
      "loss": 0.424,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.902772068977356,
      "rewards/margins": 1.393552303314209,
      "rewards/rejected": -2.2963242530822754,
      "step": 6500
    },
    {
      "epoch": 1.0935927541093593,
      "grad_norm": 2.863618850708008,
      "learning_rate": 3.17930224756793e-05,
      "logits/chosen": 2.544806718826294,
      "logits/rejected": 2.822834014892578,
      "logps/chosen": -219.7407684326172,
      "logps/rejected": -195.39697265625,
      "loss": 0.4255,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.8032213449478149,
      "rewards/margins": 1.3700709342956543,
      "rewards/rejected": -2.1732921600341797,
      "step": 6520
    },
    {
      "epoch": 1.0969473331096948,
      "grad_norm": 2.776411771774292,
      "learning_rate": 3.1737112825673715e-05,
      "logits/chosen": 2.8300228118896484,
      "logits/rejected": 3.0604262351989746,
      "logps/chosen": -213.6849365234375,
      "logps/rejected": -192.74041748046875,
      "loss": 0.4956,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2086398601531982,
      "rewards/margins": 1.2518184185028076,
      "rewards/rejected": -2.460458278656006,
      "step": 6540
    },
    {
      "epoch": 1.1003019121100301,
      "grad_norm": 2.2096750736236572,
      "learning_rate": 3.168120317566812e-05,
      "logits/chosen": 2.518627405166626,
      "logits/rejected": 2.7060632705688477,
      "logps/chosen": -197.01466369628906,
      "logps/rejected": -191.31541442871094,
      "loss": 0.5156,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.1323931217193604,
      "rewards/margins": 1.0312092304229736,
      "rewards/rejected": -2.163602590560913,
      "step": 6560
    },
    {
      "epoch": 1.1036564911103657,
      "grad_norm": 1.6981028318405151,
      "learning_rate": 3.162529352566253e-05,
      "logits/chosen": 2.529572010040283,
      "logits/rejected": 2.8585212230682373,
      "logps/chosen": -209.99966430664062,
      "logps/rejected": -187.8172607421875,
      "loss": 0.4133,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.7035471796989441,
      "rewards/margins": 1.2135659456253052,
      "rewards/rejected": -1.9171130657196045,
      "step": 6580
    },
    {
      "epoch": 1.1070110701107012,
      "grad_norm": 3.3170900344848633,
      "learning_rate": 3.156938387565694e-05,
      "logits/chosen": 2.5045089721679688,
      "logits/rejected": 2.716447353363037,
      "logps/chosen": -188.0913543701172,
      "logps/rejected": -188.70225524902344,
      "loss": 0.4826,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9721246957778931,
      "rewards/margins": 1.187854528427124,
      "rewards/rejected": -2.1599793434143066,
      "step": 6600
    },
    {
      "epoch": 1.1103656491110365,
      "grad_norm": 2.000110626220703,
      "learning_rate": 3.151347422565135e-05,
      "logits/chosen": 2.751357078552246,
      "logits/rejected": 2.906278133392334,
      "logps/chosen": -210.03842163085938,
      "logps/rejected": -190.8102264404297,
      "loss": 0.4483,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.1389796733856201,
      "rewards/margins": 1.4337530136108398,
      "rewards/rejected": -2.57273268699646,
      "step": 6620
    },
    {
      "epoch": 1.113720228111372,
      "grad_norm": 1.633400797843933,
      "learning_rate": 3.1457564575645756e-05,
      "logits/chosen": 2.5707921981811523,
      "logits/rejected": 2.8015828132629395,
      "logps/chosen": -206.6381378173828,
      "logps/rejected": -201.1292724609375,
      "loss": 0.3913,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8959587216377258,
      "rewards/margins": 1.4915359020233154,
      "rewards/rejected": -2.3874945640563965,
      "step": 6640
    },
    {
      "epoch": 1.1170748071117074,
      "grad_norm": 1.055361270904541,
      "learning_rate": 3.140165492564017e-05,
      "logits/chosen": 2.5532991886138916,
      "logits/rejected": 2.8233916759490967,
      "logps/chosen": -217.4148712158203,
      "logps/rejected": -195.71475219726562,
      "loss": 0.4402,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8992619514465332,
      "rewards/margins": 1.1130342483520508,
      "rewards/rejected": -2.012296199798584,
      "step": 6660
    },
    {
      "epoch": 1.120429386112043,
      "grad_norm": 5.51019811630249,
      "learning_rate": 3.1345745275634574e-05,
      "logits/chosen": 2.7127509117126465,
      "logits/rejected": 2.8810625076293945,
      "logps/chosen": -201.65145874023438,
      "logps/rejected": -197.8216552734375,
      "loss": 0.5575,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1572798490524292,
      "rewards/margins": 1.136196255683899,
      "rewards/rejected": -2.293476104736328,
      "step": 6680
    },
    {
      "epoch": 1.1237839651123784,
      "grad_norm": 1.1991032361984253,
      "learning_rate": 3.128983562562898e-05,
      "logits/chosen": 2.4597182273864746,
      "logits/rejected": 2.781461238861084,
      "logps/chosen": -204.05953979492188,
      "logps/rejected": -184.70260620117188,
      "loss": 0.4201,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.9929696917533875,
      "rewards/margins": 1.4116913080215454,
      "rewards/rejected": -2.404660940170288,
      "step": 6700
    },
    {
      "epoch": 1.127138544112714,
      "grad_norm": 3.595740795135498,
      "learning_rate": 3.12339259756234e-05,
      "logits/chosen": 2.545825481414795,
      "logits/rejected": 2.8549680709838867,
      "logps/chosen": -202.40670776367188,
      "logps/rejected": -201.68626403808594,
      "loss": 0.407,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8233086466789246,
      "rewards/margins": 1.4226677417755127,
      "rewards/rejected": -2.245976686477661,
      "step": 6720
    },
    {
      "epoch": 1.1304931231130493,
      "grad_norm": 2.3146579265594482,
      "learning_rate": 3.1178016325617804e-05,
      "logits/chosen": 2.781193971633911,
      "logits/rejected": 2.9402520656585693,
      "logps/chosen": -197.6458282470703,
      "logps/rejected": -186.5198516845703,
      "loss": 0.5156,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8693276643753052,
      "rewards/margins": 1.025324821472168,
      "rewards/rejected": -1.8946526050567627,
      "step": 6740
    },
    {
      "epoch": 1.1338477021133848,
      "grad_norm": 3.1548357009887695,
      "learning_rate": 3.112210667561221e-05,
      "logits/chosen": 2.4305310249328613,
      "logits/rejected": 2.654467821121216,
      "logps/chosen": -186.40440368652344,
      "logps/rejected": -187.19338989257812,
      "loss": 0.5179,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.057631492614746,
      "rewards/margins": 1.1920350790023804,
      "rewards/rejected": -2.249666452407837,
      "step": 6760
    },
    {
      "epoch": 1.1372022811137201,
      "grad_norm": 1.1770957708358765,
      "learning_rate": 3.106619702560662e-05,
      "logits/chosen": 2.513314723968506,
      "logits/rejected": 2.705296039581299,
      "logps/chosen": -200.14422607421875,
      "logps/rejected": -189.26541137695312,
      "loss": 0.4184,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.7344614267349243,
      "rewards/margins": 1.1368200778961182,
      "rewards/rejected": -1.871281623840332,
      "step": 6780
    },
    {
      "epoch": 1.1405568601140557,
      "grad_norm": 2.327523946762085,
      "learning_rate": 3.1010287375601034e-05,
      "logits/chosen": 2.716569185256958,
      "logits/rejected": 2.7483694553375244,
      "logps/chosen": -195.6783447265625,
      "logps/rejected": -198.84756469726562,
      "loss": 0.5511,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2859220504760742,
      "rewards/margins": 0.6709251403808594,
      "rewards/rejected": -1.9568469524383545,
      "step": 6800
    },
    {
      "epoch": 1.1439114391143912,
      "grad_norm": 3.8428149223327637,
      "learning_rate": 3.095437772559544e-05,
      "logits/chosen": 2.7672858238220215,
      "logits/rejected": 2.924412250518799,
      "logps/chosen": -206.7268524169922,
      "logps/rejected": -191.34384155273438,
      "loss": 0.4516,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.82868492603302,
      "rewards/margins": 1.230575680732727,
      "rewards/rejected": -2.059260606765747,
      "step": 6820
    },
    {
      "epoch": 1.1472660181147267,
      "grad_norm": 4.688711166381836,
      "learning_rate": 3.0898468075589845e-05,
      "logits/chosen": 2.90555739402771,
      "logits/rejected": 3.0498156547546387,
      "logps/chosen": -196.8609161376953,
      "logps/rejected": -208.8271942138672,
      "loss": 0.4582,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7802103757858276,
      "rewards/margins": 1.0060527324676514,
      "rewards/rejected": -1.786263108253479,
      "step": 6840
    },
    {
      "epoch": 1.150620597115062,
      "grad_norm": 4.3655595779418945,
      "learning_rate": 3.084255842558426e-05,
      "logits/chosen": 2.4939749240875244,
      "logits/rejected": 2.6666057109832764,
      "logps/chosen": -196.2101593017578,
      "logps/rejected": -185.25314331054688,
      "loss": 0.4892,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1899726390838623,
      "rewards/margins": 0.8990274667739868,
      "rewards/rejected": -2.0890002250671387,
      "step": 6860
    },
    {
      "epoch": 1.1539751761153976,
      "grad_norm": 2.0757033824920654,
      "learning_rate": 3.078664877557866e-05,
      "logits/chosen": 2.623817205429077,
      "logits/rejected": 2.85939359664917,
      "logps/chosen": -215.5019073486328,
      "logps/rejected": -211.40380859375,
      "loss": 0.5145,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1574573516845703,
      "rewards/margins": 1.0688704252243042,
      "rewards/rejected": -2.226327896118164,
      "step": 6880
    },
    {
      "epoch": 1.1573297551157329,
      "grad_norm": 0.718431293964386,
      "learning_rate": 3.0730739125573075e-05,
      "logits/chosen": 2.7039425373077393,
      "logits/rejected": 2.9185004234313965,
      "logps/chosen": -206.7287139892578,
      "logps/rejected": -201.18572998046875,
      "loss": 0.5787,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3197295665740967,
      "rewards/margins": 1.1163887977600098,
      "rewards/rejected": -2.4361183643341064,
      "step": 6900
    },
    {
      "epoch": 1.1606843341160684,
      "grad_norm": 7.135043144226074,
      "learning_rate": 3.067482947556749e-05,
      "logits/chosen": 2.5523455142974854,
      "logits/rejected": 2.7163891792297363,
      "logps/chosen": -207.20632934570312,
      "logps/rejected": -208.5938262939453,
      "loss": 0.6474,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.2501592636108398,
      "rewards/margins": 0.9020878672599792,
      "rewards/rejected": -2.152247190475464,
      "step": 6920
    },
    {
      "epoch": 1.164038913116404,
      "grad_norm": 1.026436448097229,
      "learning_rate": 3.061891982556189e-05,
      "logits/chosen": 2.6254446506500244,
      "logits/rejected": 2.7875354290008545,
      "logps/chosen": -192.4093475341797,
      "logps/rejected": -185.1629638671875,
      "loss": 0.4142,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8743578791618347,
      "rewards/margins": 1.1635606288909912,
      "rewards/rejected": -2.0379185676574707,
      "step": 6940
    },
    {
      "epoch": 1.1673934921167393,
      "grad_norm": 2.8350260257720947,
      "learning_rate": 3.05630101755563e-05,
      "logits/chosen": 2.7620184421539307,
      "logits/rejected": 2.8827149868011475,
      "logps/chosen": -197.11349487304688,
      "logps/rejected": -178.15724182128906,
      "loss": 0.5092,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8274043202400208,
      "rewards/margins": 0.8066374063491821,
      "rewards/rejected": -1.6340415477752686,
      "step": 6960
    },
    {
      "epoch": 1.1707480711170748,
      "grad_norm": 2.810417890548706,
      "learning_rate": 3.0507100525550714e-05,
      "logits/chosen": 2.756208658218384,
      "logits/rejected": 2.933168649673462,
      "logps/chosen": -204.23336791992188,
      "logps/rejected": -192.96337890625,
      "loss": 0.5191,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.786272406578064,
      "rewards/margins": 1.0439443588256836,
      "rewards/rejected": -1.8302167654037476,
      "step": 6980
    },
    {
      "epoch": 1.1741026501174103,
      "grad_norm": 2.5340614318847656,
      "learning_rate": 3.045119087554512e-05,
      "logits/chosen": 2.7103517055511475,
      "logits/rejected": 2.8839731216430664,
      "logps/chosen": -215.329345703125,
      "logps/rejected": -230.9166717529297,
      "loss": 0.4407,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.4646403193473816,
      "rewards/margins": 1.1133546829223633,
      "rewards/rejected": -1.5779949426651,
      "step": 7000
    },
    {
      "epoch": 1.1774572291177456,
      "grad_norm": 1.827114462852478,
      "learning_rate": 3.039528122553953e-05,
      "logits/chosen": 2.6515798568725586,
      "logits/rejected": 2.8886959552764893,
      "logps/chosen": -206.7976837158203,
      "logps/rejected": -193.2567138671875,
      "loss": 0.373,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.7698616981506348,
      "rewards/margins": 1.357712745666504,
      "rewards/rejected": -2.1275744438171387,
      "step": 7020
    },
    {
      "epoch": 1.1808118081180812,
      "grad_norm": 2.0587728023529053,
      "learning_rate": 3.0339371575533938e-05,
      "logits/chosen": 2.797969102859497,
      "logits/rejected": 2.9780993461608887,
      "logps/chosen": -200.46875,
      "logps/rejected": -194.72750854492188,
      "loss": 0.4411,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.030112385749817,
      "rewards/margins": 1.0859286785125732,
      "rewards/rejected": -2.1160411834716797,
      "step": 7040
    },
    {
      "epoch": 1.1841663871184167,
      "grad_norm": 2.2035980224609375,
      "learning_rate": 3.028346192552835e-05,
      "logits/chosen": 2.882866382598877,
      "logits/rejected": 2.9794974327087402,
      "logps/chosen": -198.0443878173828,
      "logps/rejected": -186.0521697998047,
      "loss": 0.5326,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1234900951385498,
      "rewards/margins": 0.7639562487602234,
      "rewards/rejected": -1.887446403503418,
      "step": 7060
    },
    {
      "epoch": 1.187520966118752,
      "grad_norm": 1.6259572505950928,
      "learning_rate": 3.022755227552276e-05,
      "logits/chosen": 2.671984910964966,
      "logits/rejected": 2.9198009967803955,
      "logps/chosen": -208.12008666992188,
      "logps/rejected": -190.79183959960938,
      "loss": 0.5521,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.8533776998519897,
      "rewards/margins": 0.7810419201850891,
      "rewards/rejected": -1.6344196796417236,
      "step": 7080
    },
    {
      "epoch": 1.1908755451190876,
      "grad_norm": 2.894587278366089,
      "learning_rate": 3.0171642625517164e-05,
      "logits/chosen": 2.6796231269836426,
      "logits/rejected": 2.8520658016204834,
      "logps/chosen": -210.8310546875,
      "logps/rejected": -199.8262176513672,
      "loss": 0.4544,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.8671875,
      "rewards/margins": 1.018324375152588,
      "rewards/rejected": -1.8855117559432983,
      "step": 7100
    },
    {
      "epoch": 1.194230124119423,
      "grad_norm": 2.8572616577148438,
      "learning_rate": 3.0115732975511573e-05,
      "logits/chosen": 2.569520950317383,
      "logits/rejected": 2.69966459274292,
      "logps/chosen": -206.42196655273438,
      "logps/rejected": -205.0182342529297,
      "loss": 0.5239,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0196583271026611,
      "rewards/margins": 0.9300479888916016,
      "rewards/rejected": -1.9497063159942627,
      "step": 7120
    },
    {
      "epoch": 1.1975847031197584,
      "grad_norm": 2.6350765228271484,
      "learning_rate": 3.0059823325505982e-05,
      "logits/chosen": 2.5951647758483887,
      "logits/rejected": 2.7111544609069824,
      "logps/chosen": -184.70350646972656,
      "logps/rejected": -182.27398681640625,
      "loss": 0.5029,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1865170001983643,
      "rewards/margins": 0.8367007970809937,
      "rewards/rejected": -2.0232176780700684,
      "step": 7140
    },
    {
      "epoch": 1.200939282120094,
      "grad_norm": 1.5646233558654785,
      "learning_rate": 3.0003913675500395e-05,
      "logits/chosen": 2.6874489784240723,
      "logits/rejected": 2.9301984310150146,
      "logps/chosen": -207.80947875976562,
      "logps/rejected": -200.89842224121094,
      "loss": 0.4571,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8345357775688171,
      "rewards/margins": 1.128219485282898,
      "rewards/rejected": -1.9627549648284912,
      "step": 7160
    },
    {
      "epoch": 1.2042938611204295,
      "grad_norm": 1.5192190408706665,
      "learning_rate": 2.9948004025494804e-05,
      "logits/chosen": 2.8073792457580566,
      "logits/rejected": 3.040442943572998,
      "logps/chosen": -206.98141479492188,
      "logps/rejected": -175.79867553710938,
      "loss": 0.4018,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.9207583665847778,
      "rewards/margins": 1.3194115161895752,
      "rewards/rejected": -2.2401697635650635,
      "step": 7180
    },
    {
      "epoch": 1.2076484401207648,
      "grad_norm": 3.252992630004883,
      "learning_rate": 2.989209437548921e-05,
      "logits/chosen": 2.348723888397217,
      "logits/rejected": 2.642408847808838,
      "logps/chosen": -198.6238555908203,
      "logps/rejected": -194.66329956054688,
      "loss": 0.4331,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.115929126739502,
      "rewards/margins": 1.1589136123657227,
      "rewards/rejected": -2.2748427391052246,
      "step": 7200
    },
    {
      "epoch": 1.2110030191211003,
      "grad_norm": 3.086427688598633,
      "learning_rate": 2.9836184725483618e-05,
      "logits/chosen": 2.709923267364502,
      "logits/rejected": 2.7824864387512207,
      "logps/chosen": -211.0029296875,
      "logps/rejected": -190.4563446044922,
      "loss": 0.53,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.3272696733474731,
      "rewards/margins": 0.9691485166549683,
      "rewards/rejected": -2.2964179515838623,
      "step": 7220
    },
    {
      "epoch": 1.2143575981214358,
      "grad_norm": 2.042475461959839,
      "learning_rate": 2.978027507547803e-05,
      "logits/chosen": 2.6369917392730713,
      "logits/rejected": 2.97312593460083,
      "logps/chosen": -207.87789916992188,
      "logps/rejected": -191.31777954101562,
      "loss": 0.4359,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1006720066070557,
      "rewards/margins": 1.3138045072555542,
      "rewards/rejected": -2.4144766330718994,
      "step": 7240
    },
    {
      "epoch": 1.2177121771217712,
      "grad_norm": 0.9063141345977783,
      "learning_rate": 2.972436542547244e-05,
      "logits/chosen": 2.751220464706421,
      "logits/rejected": 2.890266180038452,
      "logps/chosen": -201.3631134033203,
      "logps/rejected": -200.8993682861328,
      "loss": 0.4476,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9912768602371216,
      "rewards/margins": 1.0679471492767334,
      "rewards/rejected": -2.0592238903045654,
      "step": 7260
    },
    {
      "epoch": 1.2210667561221067,
      "grad_norm": 3.546224594116211,
      "learning_rate": 2.9668455775466848e-05,
      "logits/chosen": 2.6939172744750977,
      "logits/rejected": 2.8593199253082275,
      "logps/chosen": -196.22186279296875,
      "logps/rejected": -192.54177856445312,
      "loss": 0.4322,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1287672519683838,
      "rewards/margins": 1.2788053750991821,
      "rewards/rejected": -2.4075725078582764,
      "step": 7280
    },
    {
      "epoch": 1.2244213351224422,
      "grad_norm": 1.6121927499771118,
      "learning_rate": 2.9612546125461254e-05,
      "logits/chosen": 2.6529154777526855,
      "logits/rejected": 2.840075969696045,
      "logps/chosen": -204.0109405517578,
      "logps/rejected": -200.6238250732422,
      "loss": 0.4894,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1048980951309204,
      "rewards/margins": 1.0553081035614014,
      "rewards/rejected": -2.1602060794830322,
      "step": 7300
    },
    {
      "epoch": 1.2277759141227775,
      "grad_norm": 2.668717622756958,
      "learning_rate": 2.9556636475455663e-05,
      "logits/chosen": 2.405170440673828,
      "logits/rejected": 2.705756902694702,
      "logps/chosen": -214.9029541015625,
      "logps/rejected": -197.1798858642578,
      "loss": 0.4432,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9129465222358704,
      "rewards/margins": 1.2509934902191162,
      "rewards/rejected": -2.163939952850342,
      "step": 7320
    },
    {
      "epoch": 1.231130493123113,
      "grad_norm": 0.8316922783851624,
      "learning_rate": 2.9500726825450075e-05,
      "logits/chosen": 2.6867449283599854,
      "logits/rejected": 2.814753532409668,
      "logps/chosen": -217.2227325439453,
      "logps/rejected": -219.0824737548828,
      "loss": 0.5349,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.0290312767028809,
      "rewards/margins": 0.9965337514877319,
      "rewards/rejected": -2.0255649089813232,
      "step": 7340
    },
    {
      "epoch": 1.2344850721234486,
      "grad_norm": 2.316633462905884,
      "learning_rate": 2.9444817175444484e-05,
      "logits/chosen": 2.476506471633911,
      "logits/rejected": 2.6507012844085693,
      "logps/chosen": -204.8458709716797,
      "logps/rejected": -195.58624267578125,
      "loss": 0.4705,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9787272214889526,
      "rewards/margins": 1.0461583137512207,
      "rewards/rejected": -2.024885654449463,
      "step": 7360
    },
    {
      "epoch": 1.237839651123784,
      "grad_norm": 4.630642890930176,
      "learning_rate": 2.9388907525438893e-05,
      "logits/chosen": 2.552433729171753,
      "logits/rejected": 2.660721778869629,
      "logps/chosen": -201.36875915527344,
      "logps/rejected": -203.5961456298828,
      "loss": 0.4073,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.037082314491272,
      "rewards/margins": 1.2176146507263184,
      "rewards/rejected": -2.25469708442688,
      "step": 7380
    },
    {
      "epoch": 1.2411942301241194,
      "grad_norm": 1.3399643898010254,
      "learning_rate": 2.9332997875433298e-05,
      "logits/chosen": 2.653207540512085,
      "logits/rejected": 2.813305616378784,
      "logps/chosen": -211.97683715820312,
      "logps/rejected": -192.30023193359375,
      "loss": 0.4638,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9016883969306946,
      "rewards/margins": 1.0571786165237427,
      "rewards/rejected": -1.958866834640503,
      "step": 7400
    },
    {
      "epoch": 1.244548809124455,
      "grad_norm": 1.8748259544372559,
      "learning_rate": 2.9277088225427714e-05,
      "logits/chosen": 2.620887517929077,
      "logits/rejected": 2.917590856552124,
      "logps/chosen": -211.4447784423828,
      "logps/rejected": -195.08486938476562,
      "loss": 0.3471,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -0.8498725891113281,
      "rewards/margins": 1.4158579111099243,
      "rewards/rejected": -2.265730381011963,
      "step": 7420
    },
    {
      "epoch": 1.2479033881247903,
      "grad_norm": 1.3246768712997437,
      "learning_rate": 2.922117857542212e-05,
      "logits/chosen": 2.7325236797332764,
      "logits/rejected": 2.836669683456421,
      "logps/chosen": -208.6194610595703,
      "logps/rejected": -202.8695831298828,
      "loss": 0.5908,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9483212232589722,
      "rewards/margins": 0.9771978259086609,
      "rewards/rejected": -1.9255189895629883,
      "step": 7440
    },
    {
      "epoch": 1.2512579671251258,
      "grad_norm": 1.2114003896713257,
      "learning_rate": 2.916526892541653e-05,
      "logits/chosen": 2.812100887298584,
      "logits/rejected": 3.2069294452667236,
      "logps/chosen": -212.80612182617188,
      "logps/rejected": -193.66139221191406,
      "loss": 0.3438,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6249114871025085,
      "rewards/margins": 1.517712116241455,
      "rewards/rejected": -2.1426234245300293,
      "step": 7460
    },
    {
      "epoch": 1.2546125461254611,
      "grad_norm": 1.9651528596878052,
      "learning_rate": 2.9109359275410937e-05,
      "logits/chosen": 2.646498441696167,
      "logits/rejected": 2.939697742462158,
      "logps/chosen": -208.09689331054688,
      "logps/rejected": -200.15318298339844,
      "loss": 0.415,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.06166410446167,
      "rewards/margins": 1.359761118888855,
      "rewards/rejected": -2.4214255809783936,
      "step": 7480
    },
    {
      "epoch": 1.2579671251257967,
      "grad_norm": 2.6223626136779785,
      "learning_rate": 2.905344962540535e-05,
      "logits/chosen": 2.6851110458374023,
      "logits/rejected": 2.904890775680542,
      "logps/chosen": -200.58737182617188,
      "logps/rejected": -180.9939422607422,
      "loss": 0.4985,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3873634338378906,
      "rewards/margins": 1.1551589965820312,
      "rewards/rejected": -2.5425221920013428,
      "step": 7500
    },
    {
      "epoch": 1.2613217041261322,
      "grad_norm": 1.4937660694122314,
      "learning_rate": 2.8997539975399755e-05,
      "logits/chosen": 2.56286883354187,
      "logits/rejected": 2.862786054611206,
      "logps/chosen": -214.98220825195312,
      "logps/rejected": -196.408203125,
      "loss": 0.5555,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1357959508895874,
      "rewards/margins": 1.005838394165039,
      "rewards/rejected": -2.141634464263916,
      "step": 7520
    },
    {
      "epoch": 1.2646762831264677,
      "grad_norm": 1.5397392511367798,
      "learning_rate": 2.8941630325394164e-05,
      "logits/chosen": 2.683666706085205,
      "logits/rejected": 3.000213146209717,
      "logps/chosen": -212.944580078125,
      "logps/rejected": -192.71385192871094,
      "loss": 0.4161,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.0562187433242798,
      "rewards/margins": 1.401594877243042,
      "rewards/rejected": -2.4578137397766113,
      "step": 7540
    },
    {
      "epoch": 1.268030862126803,
      "grad_norm": 1.0845025777816772,
      "learning_rate": 2.8885720675388573e-05,
      "logits/chosen": 2.5703561305999756,
      "logits/rejected": 2.7492763996124268,
      "logps/chosen": -188.21932983398438,
      "logps/rejected": -180.0865478515625,
      "loss": 0.5328,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5473358631134033,
      "rewards/margins": 1.1149884462356567,
      "rewards/rejected": -2.6623241901397705,
      "step": 7560
    },
    {
      "epoch": 1.2713854411271386,
      "grad_norm": 1.244568109512329,
      "learning_rate": 2.882981102538298e-05,
      "logits/chosen": 2.6311869621276855,
      "logits/rejected": 2.8819098472595215,
      "logps/chosen": -203.94017028808594,
      "logps/rejected": -200.8917236328125,
      "loss": 0.3872,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2763110399246216,
      "rewards/margins": 1.800138235092163,
      "rewards/rejected": -3.076449155807495,
      "step": 7580
    },
    {
      "epoch": 1.274740020127474,
      "grad_norm": 2.517418622970581,
      "learning_rate": 2.8773901375377394e-05,
      "logits/chosen": 2.446178913116455,
      "logits/rejected": 2.715501308441162,
      "logps/chosen": -213.08792114257812,
      "logps/rejected": -207.60498046875,
      "loss": 0.4437,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5168893337249756,
      "rewards/margins": 1.4986265897750854,
      "rewards/rejected": -3.0155160427093506,
      "step": 7600
    },
    {
      "epoch": 1.2780945991278094,
      "grad_norm": 1.4027612209320068,
      "learning_rate": 2.87179917253718e-05,
      "logits/chosen": 2.626215934753418,
      "logits/rejected": 2.760195016860962,
      "logps/chosen": -217.05966186523438,
      "logps/rejected": -222.7595672607422,
      "loss": 0.5055,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5795869827270508,
      "rewards/margins": 1.3064337968826294,
      "rewards/rejected": -2.8860208988189697,
      "step": 7620
    },
    {
      "epoch": 1.281449178128145,
      "grad_norm": 4.6019463539123535,
      "learning_rate": 2.866208207536621e-05,
      "logits/chosen": 2.7176766395568848,
      "logits/rejected": 2.845698833465576,
      "logps/chosen": -207.9662322998047,
      "logps/rejected": -197.17373657226562,
      "loss": 0.4655,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5967819690704346,
      "rewards/margins": 1.3172943592071533,
      "rewards/rejected": -2.914076328277588,
      "step": 7640
    },
    {
      "epoch": 1.2848037571284805,
      "grad_norm": 0.7942712306976318,
      "learning_rate": 2.8606172425360618e-05,
      "logits/chosen": 2.8459486961364746,
      "logits/rejected": 2.903231620788574,
      "logps/chosen": -235.1802520751953,
      "logps/rejected": -228.9735870361328,
      "loss": 0.4961,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.5862436294555664,
      "rewards/margins": 1.0191724300384521,
      "rewards/rejected": -2.6054158210754395,
      "step": 7660
    },
    {
      "epoch": 1.2881583361288158,
      "grad_norm": 5.43780517578125,
      "learning_rate": 2.855026277535503e-05,
      "logits/chosen": 2.7234714031219482,
      "logits/rejected": 2.995041608810425,
      "logps/chosen": -212.90060424804688,
      "logps/rejected": -189.4037628173828,
      "loss": 0.3771,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6158214807510376,
      "rewards/margins": 1.5554817914962769,
      "rewards/rejected": -3.1713032722473145,
      "step": 7680
    },
    {
      "epoch": 1.2915129151291513,
      "grad_norm": 3.110684871673584,
      "learning_rate": 2.849435312534944e-05,
      "logits/chosen": 2.4823622703552246,
      "logits/rejected": 2.8056588172912598,
      "logps/chosen": -202.56195068359375,
      "logps/rejected": -195.2837677001953,
      "loss": 0.4173,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3275158405303955,
      "rewards/margins": 1.2273286581039429,
      "rewards/rejected": -2.554844617843628,
      "step": 7700
    },
    {
      "epoch": 1.2948674941294867,
      "grad_norm": 3.1194005012512207,
      "learning_rate": 2.8438443475343844e-05,
      "logits/chosen": 2.6533539295196533,
      "logits/rejected": 2.8458471298217773,
      "logps/chosen": -205.5053253173828,
      "logps/rejected": -186.3778076171875,
      "loss": 0.516,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6745948791503906,
      "rewards/margins": 0.9399102926254272,
      "rewards/rejected": -2.6145052909851074,
      "step": 7720
    },
    {
      "epoch": 1.2982220731298222,
      "grad_norm": 2.184359550476074,
      "learning_rate": 2.8382533825338253e-05,
      "logits/chosen": 2.6048216819763184,
      "logits/rejected": 2.8358445167541504,
      "logps/chosen": -225.5574188232422,
      "logps/rejected": -219.75558471679688,
      "loss": 0.5195,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5294896364212036,
      "rewards/margins": 1.388395071029663,
      "rewards/rejected": -2.917884588241577,
      "step": 7740
    },
    {
      "epoch": 1.3015766521301577,
      "grad_norm": 2.474677562713623,
      "learning_rate": 2.8326624175332662e-05,
      "logits/chosen": 2.651855230331421,
      "logits/rejected": 2.858710289001465,
      "logps/chosen": -216.42379760742188,
      "logps/rejected": -199.129638671875,
      "loss": 0.5785,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.7708171606063843,
      "rewards/margins": 1.053170919418335,
      "rewards/rejected": -2.823988199234009,
      "step": 7760
    },
    {
      "epoch": 1.3049312311304933,
      "grad_norm": 1.554290771484375,
      "learning_rate": 2.8270714525327074e-05,
      "logits/chosen": 2.6886487007141113,
      "logits/rejected": 2.9036965370178223,
      "logps/chosen": -211.019775390625,
      "logps/rejected": -194.55409240722656,
      "loss": 0.4866,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.253779649734497,
      "rewards/margins": 1.0952109098434448,
      "rewards/rejected": -2.3489906787872314,
      "step": 7780
    },
    {
      "epoch": 1.3082858101308286,
      "grad_norm": 1.8389577865600586,
      "learning_rate": 2.8214804875321483e-05,
      "logits/chosen": 2.6287245750427246,
      "logits/rejected": 2.88336181640625,
      "logps/chosen": -205.18814086914062,
      "logps/rejected": -197.48428344726562,
      "loss": 0.4607,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3843826055526733,
      "rewards/margins": 1.1973259449005127,
      "rewards/rejected": -2.5817084312438965,
      "step": 7800
    },
    {
      "epoch": 1.311640389131164,
      "grad_norm": 1.7317262887954712,
      "learning_rate": 2.815889522531589e-05,
      "logits/chosen": 2.428839683532715,
      "logits/rejected": 2.746647596359253,
      "logps/chosen": -198.26473999023438,
      "logps/rejected": -194.6752471923828,
      "loss": 0.5077,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2540663480758667,
      "rewards/margins": 1.1488784551620483,
      "rewards/rejected": -2.402945041656494,
      "step": 7820
    },
    {
      "epoch": 1.3149949681314994,
      "grad_norm": 2.3890089988708496,
      "learning_rate": 2.8102985575310298e-05,
      "logits/chosen": 2.623239278793335,
      "logits/rejected": 2.8612418174743652,
      "logps/chosen": -190.50379943847656,
      "logps/rejected": -191.78372192382812,
      "loss": 0.4585,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1149569749832153,
      "rewards/margins": 1.1085516214370728,
      "rewards/rejected": -2.223508358001709,
      "step": 7840
    },
    {
      "epoch": 1.318349547131835,
      "grad_norm": 1.8532613515853882,
      "learning_rate": 2.804707592530471e-05,
      "logits/chosen": 2.396904706954956,
      "logits/rejected": 2.7015626430511475,
      "logps/chosen": -205.56472778320312,
      "logps/rejected": -198.66561889648438,
      "loss": 0.4219,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7340768575668335,
      "rewards/margins": 1.456516146659851,
      "rewards/rejected": -2.1905932426452637,
      "step": 7860
    },
    {
      "epoch": 1.3217041261321705,
      "grad_norm": 1.132126808166504,
      "learning_rate": 2.799116627529912e-05,
      "logits/chosen": 2.565682888031006,
      "logits/rejected": 2.795745849609375,
      "logps/chosen": -208.66329956054688,
      "logps/rejected": -206.4412384033203,
      "loss": 0.4123,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0946314334869385,
      "rewards/margins": 1.3203898668289185,
      "rewards/rejected": -2.4150211811065674,
      "step": 7880
    },
    {
      "epoch": 1.3250587051325058,
      "grad_norm": 3.193814516067505,
      "learning_rate": 2.7935256625293528e-05,
      "logits/chosen": 2.4026520252227783,
      "logits/rejected": 2.698641538619995,
      "logps/chosen": -188.416259765625,
      "logps/rejected": -190.12368774414062,
      "loss": 0.4903,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.324838638305664,
      "rewards/margins": 0.9916931986808777,
      "rewards/rejected": -2.3165318965911865,
      "step": 7900
    },
    {
      "epoch": 1.3284132841328413,
      "grad_norm": 2.023078203201294,
      "learning_rate": 2.7879346975287933e-05,
      "logits/chosen": 2.5705068111419678,
      "logits/rejected": 2.7539963722229004,
      "logps/chosen": -197.0634307861328,
      "logps/rejected": -190.3397979736328,
      "loss": 0.3741,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.2649770975112915,
      "rewards/margins": 1.3070060014724731,
      "rewards/rejected": -2.5719828605651855,
      "step": 7920
    },
    {
      "epoch": 1.3317678631331769,
      "grad_norm": 3.1144087314605713,
      "learning_rate": 2.782343732528235e-05,
      "logits/chosen": 2.619415283203125,
      "logits/rejected": 2.80468487739563,
      "logps/chosen": -199.04632568359375,
      "logps/rejected": -195.45639038085938,
      "loss": 0.4662,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3459947109222412,
      "rewards/margins": 1.1511366367340088,
      "rewards/rejected": -2.497131109237671,
      "step": 7940
    },
    {
      "epoch": 1.3351224421335122,
      "grad_norm": 2.671274423599243,
      "learning_rate": 2.7767527675276755e-05,
      "logits/chosen": 2.575895309448242,
      "logits/rejected": 2.731536388397217,
      "logps/chosen": -203.08425903320312,
      "logps/rejected": -192.6709442138672,
      "loss": 0.4476,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.072994351387024,
      "rewards/margins": 1.2385176420211792,
      "rewards/rejected": -2.3115122318267822,
      "step": 7960
    },
    {
      "epoch": 1.3384770211338477,
      "grad_norm": 1.0014584064483643,
      "learning_rate": 2.7711618025271164e-05,
      "logits/chosen": 2.4919607639312744,
      "logits/rejected": 2.8267810344696045,
      "logps/chosen": -189.10206604003906,
      "logps/rejected": -183.0672607421875,
      "loss": 0.3836,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.9483109712600708,
      "rewards/margins": 1.5111629962921143,
      "rewards/rejected": -2.4594740867614746,
      "step": 7980
    },
    {
      "epoch": 1.3418316001341832,
      "grad_norm": 2.9532787799835205,
      "learning_rate": 2.7655708375265573e-05,
      "logits/chosen": 2.5931174755096436,
      "logits/rejected": 2.847799301147461,
      "logps/chosen": -208.5182342529297,
      "logps/rejected": -198.20980834960938,
      "loss": 0.4794,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1303499937057495,
      "rewards/margins": 1.2672592401504517,
      "rewards/rejected": -2.397609233856201,
      "step": 8000
    },
    {
      "epoch": 1.3451861791345185,
      "grad_norm": 3.0167763233184814,
      "learning_rate": 2.7599798725259978e-05,
      "logits/chosen": 2.7766172885894775,
      "logits/rejected": 2.852749824523926,
      "logps/chosen": -196.65011596679688,
      "logps/rejected": -199.79684448242188,
      "loss": 0.4312,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.192806601524353,
      "rewards/margins": 1.4240522384643555,
      "rewards/rejected": -2.616858720779419,
      "step": 8020
    },
    {
      "epoch": 1.348540758134854,
      "grad_norm": 2.440512180328369,
      "learning_rate": 2.7543889075254394e-05,
      "logits/chosen": 2.7610058784484863,
      "logits/rejected": 3.0150582790374756,
      "logps/chosen": -201.68392944335938,
      "logps/rejected": -190.61294555664062,
      "loss": 0.4804,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9093127250671387,
      "rewards/margins": 1.0190764665603638,
      "rewards/rejected": -1.9283891916275024,
      "step": 8040
    },
    {
      "epoch": 1.3518953371351896,
      "grad_norm": 1.9229296445846558,
      "learning_rate": 2.74879794252488e-05,
      "logits/chosen": 2.7264723777770996,
      "logits/rejected": 2.9298174381256104,
      "logps/chosen": -191.51296997070312,
      "logps/rejected": -187.7775115966797,
      "loss": 0.4155,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.2385058403015137,
      "rewards/margins": 1.3444387912750244,
      "rewards/rejected": -2.582944393157959,
      "step": 8060
    },
    {
      "epoch": 1.355249916135525,
      "grad_norm": 2.47334623336792,
      "learning_rate": 2.7432069775243208e-05,
      "logits/chosen": 2.508082151412964,
      "logits/rejected": 2.9052672386169434,
      "logps/chosen": -220.9416046142578,
      "logps/rejected": -208.01895141601562,
      "loss": 0.4205,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.168860912322998,
      "rewards/margins": 1.5190098285675049,
      "rewards/rejected": -2.687870502471924,
      "step": 8080
    },
    {
      "epoch": 1.3586044951358605,
      "grad_norm": 3.929704427719116,
      "learning_rate": 2.7376160125237614e-05,
      "logits/chosen": 2.575004816055298,
      "logits/rejected": 2.84074068069458,
      "logps/chosen": -208.02880859375,
      "logps/rejected": -194.4485626220703,
      "loss": 0.5334,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.9888156652450562,
      "rewards/margins": 1.0804531574249268,
      "rewards/rejected": -3.0692687034606934,
      "step": 8100
    },
    {
      "epoch": 1.361959074136196,
      "grad_norm": 0.9702862501144409,
      "learning_rate": 2.732025047523203e-05,
      "logits/chosen": 2.6293044090270996,
      "logits/rejected": 2.646876811981201,
      "logps/chosen": -200.62974548339844,
      "logps/rejected": -195.80044555664062,
      "loss": 0.5618,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3888849020004272,
      "rewards/margins": 0.9843627214431763,
      "rewards/rejected": -2.3732476234436035,
      "step": 8120
    },
    {
      "epoch": 1.3653136531365313,
      "grad_norm": 1.3170759677886963,
      "learning_rate": 2.7264340825226435e-05,
      "logits/chosen": 2.432839870452881,
      "logits/rejected": 2.6070213317871094,
      "logps/chosen": -204.30624389648438,
      "logps/rejected": -205.28604125976562,
      "loss": 0.3795,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.1554641723632812,
      "rewards/margins": 1.4400904178619385,
      "rewards/rejected": -2.5955545902252197,
      "step": 8140
    },
    {
      "epoch": 1.3686682321368668,
      "grad_norm": 4.045456886291504,
      "learning_rate": 2.7208431175220844e-05,
      "logits/chosen": 2.522749423980713,
      "logits/rejected": 2.8163325786590576,
      "logps/chosen": -211.7173309326172,
      "logps/rejected": -213.3361358642578,
      "loss": 0.5058,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3695999383926392,
      "rewards/margins": 1.1542489528656006,
      "rewards/rejected": -2.5238490104675293,
      "step": 8160
    },
    {
      "epoch": 1.3720228111372021,
      "grad_norm": 2.178823471069336,
      "learning_rate": 2.7152521525215253e-05,
      "logits/chosen": 2.6384177207946777,
      "logits/rejected": 2.8865180015563965,
      "logps/chosen": -206.79672241210938,
      "logps/rejected": -180.43397521972656,
      "loss": 0.4243,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.13943612575531,
      "rewards/margins": 1.331186056137085,
      "rewards/rejected": -2.4706223011016846,
      "step": 8180
    },
    {
      "epoch": 1.3753773901375377,
      "grad_norm": 1.642820119857788,
      "learning_rate": 2.709661187520966e-05,
      "logits/chosen": 2.559904098510742,
      "logits/rejected": 2.697073459625244,
      "logps/chosen": -208.40451049804688,
      "logps/rejected": -198.43385314941406,
      "loss": 0.4987,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8505185842514038,
      "rewards/margins": 0.9987041354179382,
      "rewards/rejected": -1.8492227792739868,
      "step": 8200
    },
    {
      "epoch": 1.3787319691378732,
      "grad_norm": 1.3324331045150757,
      "learning_rate": 2.7040702225204074e-05,
      "logits/chosen": 2.5881142616271973,
      "logits/rejected": 2.834987163543701,
      "logps/chosen": -190.36085510253906,
      "logps/rejected": -195.16868591308594,
      "loss": 0.5456,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.279544472694397,
      "rewards/margins": 1.0274450778961182,
      "rewards/rejected": -2.3069891929626465,
      "step": 8220
    },
    {
      "epoch": 1.3820865481382087,
      "grad_norm": 3.565098285675049,
      "learning_rate": 2.698479257519848e-05,
      "logits/chosen": 2.4623141288757324,
      "logits/rejected": 2.6873245239257812,
      "logps/chosen": -197.7654266357422,
      "logps/rejected": -200.02035522460938,
      "loss": 0.4303,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.0998761653900146,
      "rewards/margins": 1.318358063697815,
      "rewards/rejected": -2.418234348297119,
      "step": 8240
    },
    {
      "epoch": 1.385441127138544,
      "grad_norm": 2.41841983795166,
      "learning_rate": 2.692888292519289e-05,
      "logits/chosen": 2.4139742851257324,
      "logits/rejected": 2.7102320194244385,
      "logps/chosen": -203.48500061035156,
      "logps/rejected": -194.0729217529297,
      "loss": 0.4577,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4440157413482666,
      "rewards/margins": 1.3386716842651367,
      "rewards/rejected": -2.7826876640319824,
      "step": 8260
    },
    {
      "epoch": 1.3887957061388796,
      "grad_norm": 3.75948429107666,
      "learning_rate": 2.6872973275187297e-05,
      "logits/chosen": 2.6301865577697754,
      "logits/rejected": 2.795447826385498,
      "logps/chosen": -206.44577026367188,
      "logps/rejected": -210.9846954345703,
      "loss": 0.4288,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.111273169517517,
      "rewards/margins": 1.1873356103897095,
      "rewards/rejected": -2.2986085414886475,
      "step": 8280
    },
    {
      "epoch": 1.392150285139215,
      "grad_norm": 2.217082977294922,
      "learning_rate": 2.681706362518171e-05,
      "logits/chosen": 2.4565365314483643,
      "logits/rejected": 2.627747058868408,
      "logps/chosen": -202.3373260498047,
      "logps/rejected": -198.6049346923828,
      "loss": 0.5442,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.950729250907898,
      "rewards/margins": 1.029571294784546,
      "rewards/rejected": -1.9803005456924438,
      "step": 8300
    },
    {
      "epoch": 1.3955048641395504,
      "grad_norm": 2.2813568115234375,
      "learning_rate": 2.676115397517612e-05,
      "logits/chosen": 2.5294861793518066,
      "logits/rejected": 2.7278475761413574,
      "logps/chosen": -201.6458740234375,
      "logps/rejected": -200.6862030029297,
      "loss": 0.4527,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9440792202949524,
      "rewards/margins": 1.2972438335418701,
      "rewards/rejected": -2.2413229942321777,
      "step": 8320
    },
    {
      "epoch": 1.398859443139886,
      "grad_norm": 5.580501079559326,
      "learning_rate": 2.6705244325170524e-05,
      "logits/chosen": 2.6597890853881836,
      "logits/rejected": 2.6476104259490967,
      "logps/chosen": -211.0736541748047,
      "logps/rejected": -203.04574584960938,
      "loss": 0.589,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1535391807556152,
      "rewards/margins": 0.8173702359199524,
      "rewards/rejected": -1.9709094762802124,
      "step": 8340
    },
    {
      "epoch": 1.4022140221402215,
      "grad_norm": 3.058366537094116,
      "learning_rate": 2.6649334675164933e-05,
      "logits/chosen": 2.407372236251831,
      "logits/rejected": 2.622743606567383,
      "logps/chosen": -204.66311645507812,
      "logps/rejected": -183.47384643554688,
      "loss": 0.479,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8764398694038391,
      "rewards/margins": 0.9745616912841797,
      "rewards/rejected": -1.8510017395019531,
      "step": 8360
    },
    {
      "epoch": 1.4055686011405568,
      "grad_norm": 3.184338331222534,
      "learning_rate": 2.6593425025159345e-05,
      "logits/chosen": 2.396726369857788,
      "logits/rejected": 2.660649061203003,
      "logps/chosen": -193.26173400878906,
      "logps/rejected": -183.07205200195312,
      "loss": 0.462,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.128483533859253,
      "rewards/margins": 1.1553359031677246,
      "rewards/rejected": -2.2838196754455566,
      "step": 8380
    },
    {
      "epoch": 1.4089231801408924,
      "grad_norm": 2.632303476333618,
      "learning_rate": 2.6537515375153754e-05,
      "logits/chosen": 2.4633631706237793,
      "logits/rejected": 2.820908546447754,
      "logps/chosen": -207.75656127929688,
      "logps/rejected": -189.53733825683594,
      "loss": 0.5352,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7418836355209351,
      "rewards/margins": 1.0293152332305908,
      "rewards/rejected": -1.7711989879608154,
      "step": 8400
    },
    {
      "epoch": 1.4122777591412277,
      "grad_norm": 2.0011065006256104,
      "learning_rate": 2.6481605725148163e-05,
      "logits/chosen": 2.7791035175323486,
      "logits/rejected": 3.0381996631622314,
      "logps/chosen": -207.05075073242188,
      "logps/rejected": -203.75416564941406,
      "loss": 0.4687,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9265397191047668,
      "rewards/margins": 1.1689202785491943,
      "rewards/rejected": -2.0954601764678955,
      "step": 8420
    },
    {
      "epoch": 1.4156323381415632,
      "grad_norm": 3.0651941299438477,
      "learning_rate": 2.642569607514257e-05,
      "logits/chosen": 2.4633662700653076,
      "logits/rejected": 2.802609920501709,
      "logps/chosen": -202.3417205810547,
      "logps/rejected": -187.3061065673828,
      "loss": 0.3837,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8066482543945312,
      "rewards/margins": 1.4936668872833252,
      "rewards/rejected": -2.3003151416778564,
      "step": 8440
    },
    {
      "epoch": 1.4189869171418987,
      "grad_norm": 1.5040252208709717,
      "learning_rate": 2.6369786425136978e-05,
      "logits/chosen": 2.503754138946533,
      "logits/rejected": 2.8203682899475098,
      "logps/chosen": -205.49954223632812,
      "logps/rejected": -195.20616149902344,
      "loss": 0.3674,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.061218500137329,
      "rewards/margins": 1.594872236251831,
      "rewards/rejected": -2.656090497970581,
      "step": 8460
    },
    {
      "epoch": 1.4223414961422343,
      "grad_norm": 2.4238882064819336,
      "learning_rate": 2.631387677513139e-05,
      "logits/chosen": 2.5128417015075684,
      "logits/rejected": 2.6377835273742676,
      "logps/chosen": -203.71038818359375,
      "logps/rejected": -208.6746063232422,
      "loss": 0.4576,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.3040127754211426,
      "rewards/margins": 1.3213732242584229,
      "rewards/rejected": -2.6253857612609863,
      "step": 8480
    },
    {
      "epoch": 1.4256960751425696,
      "grad_norm": 4.21785306930542,
      "learning_rate": 2.62579671251258e-05,
      "logits/chosen": 2.5465996265411377,
      "logits/rejected": 2.7527880668640137,
      "logps/chosen": -206.5442657470703,
      "logps/rejected": -197.1116943359375,
      "loss": 0.4683,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.373340368270874,
      "rewards/margins": 1.221252679824829,
      "rewards/rejected": -2.594593048095703,
      "step": 8500
    },
    {
      "epoch": 1.429050654142905,
      "grad_norm": 1.9918625354766846,
      "learning_rate": 2.6202057475120208e-05,
      "logits/chosen": 2.543377637863159,
      "logits/rejected": 2.8717386722564697,
      "logps/chosen": -223.5504913330078,
      "logps/rejected": -199.422119140625,
      "loss": 0.4437,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2042107582092285,
      "rewards/margins": 1.439982533454895,
      "rewards/rejected": -2.644193172454834,
      "step": 8520
    },
    {
      "epoch": 1.4324052331432404,
      "grad_norm": 2.0596063137054443,
      "learning_rate": 2.6146147825114613e-05,
      "logits/chosen": 2.474370241165161,
      "logits/rejected": 2.750318765640259,
      "logps/chosen": -209.7456512451172,
      "logps/rejected": -206.0883026123047,
      "loss": 0.4731,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3198034763336182,
      "rewards/margins": 1.1442018747329712,
      "rewards/rejected": -2.4640049934387207,
      "step": 8540
    },
    {
      "epoch": 1.435759812143576,
      "grad_norm": 5.196152210235596,
      "learning_rate": 2.609023817510903e-05,
      "logits/chosen": 2.5293385982513428,
      "logits/rejected": 2.7884879112243652,
      "logps/chosen": -204.89193725585938,
      "logps/rejected": -195.59498596191406,
      "loss": 0.446,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2859747409820557,
      "rewards/margins": 1.3474528789520264,
      "rewards/rejected": -2.633427619934082,
      "step": 8560
    },
    {
      "epoch": 1.4391143911439115,
      "grad_norm": 1.7719790935516357,
      "learning_rate": 2.6034328525103435e-05,
      "logits/chosen": 2.5580062866210938,
      "logits/rejected": 2.7104430198669434,
      "logps/chosen": -216.1025848388672,
      "logps/rejected": -210.32308959960938,
      "loss": 0.5343,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.706392526626587,
      "rewards/margins": 0.917437732219696,
      "rewards/rejected": -2.6238303184509277,
      "step": 8580
    },
    {
      "epoch": 1.442468970144247,
      "grad_norm": 2.9654951095581055,
      "learning_rate": 2.5978418875097843e-05,
      "logits/chosen": 2.6670308113098145,
      "logits/rejected": 2.9420876502990723,
      "logps/chosen": -212.15914916992188,
      "logps/rejected": -195.32931518554688,
      "loss": 0.4309,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.386420488357544,
      "rewards/margins": 1.3527584075927734,
      "rewards/rejected": -2.7391788959503174,
      "step": 8600
    },
    {
      "epoch": 1.4458235491445823,
      "grad_norm": 3.4068970680236816,
      "learning_rate": 2.5922509225092252e-05,
      "logits/chosen": 2.5153915882110596,
      "logits/rejected": 2.810487985610962,
      "logps/chosen": -222.79086303710938,
      "logps/rejected": -214.6363067626953,
      "loss": 0.3439,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.1010956764221191,
      "rewards/margins": 1.633001685142517,
      "rewards/rejected": -2.7340972423553467,
      "step": 8620
    },
    {
      "epoch": 1.4491781281449179,
      "grad_norm": 3.133179187774658,
      "learning_rate": 2.5866599575086658e-05,
      "logits/chosen": 2.696268081665039,
      "logits/rejected": 2.8369064331054688,
      "logps/chosen": -201.7332305908203,
      "logps/rejected": -192.3568115234375,
      "loss": 0.5056,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8671703338623047,
      "rewards/margins": 0.9462044835090637,
      "rewards/rejected": -2.8133747577667236,
      "step": 8640
    },
    {
      "epoch": 1.4525327071452532,
      "grad_norm": 2.039597511291504,
      "learning_rate": 2.581068992508107e-05,
      "logits/chosen": 2.37317156791687,
      "logits/rejected": 2.585343599319458,
      "logps/chosen": -214.2686767578125,
      "logps/rejected": -209.3208465576172,
      "loss": 0.4826,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6433145999908447,
      "rewards/margins": 1.1210650205612183,
      "rewards/rejected": -2.7643799781799316,
      "step": 8660
    },
    {
      "epoch": 1.4558872861455887,
      "grad_norm": 3.403998613357544,
      "learning_rate": 2.575478027507548e-05,
      "logits/chosen": 2.6175684928894043,
      "logits/rejected": 2.805161952972412,
      "logps/chosen": -212.7220458984375,
      "logps/rejected": -218.5899200439453,
      "loss": 0.5832,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.3170479536056519,
      "rewards/margins": 0.854195773601532,
      "rewards/rejected": -2.17124342918396,
      "step": 8680
    },
    {
      "epoch": 1.4592418651459242,
      "grad_norm": 2.8260247707366943,
      "learning_rate": 2.5698870625069888e-05,
      "logits/chosen": 2.56148099899292,
      "logits/rejected": 2.8480443954467773,
      "logps/chosen": -202.2291259765625,
      "logps/rejected": -203.19085693359375,
      "loss": 0.4429,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.001144289970398,
      "rewards/margins": 1.2457001209259033,
      "rewards/rejected": -2.246844530105591,
      "step": 8700
    },
    {
      "epoch": 1.4625964441462598,
      "grad_norm": 1.5082693099975586,
      "learning_rate": 2.5642960975064294e-05,
      "logits/chosen": 2.5671987533569336,
      "logits/rejected": 2.7190914154052734,
      "logps/chosen": -203.08981323242188,
      "logps/rejected": -190.13455200195312,
      "loss": 0.4577,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3095309734344482,
      "rewards/margins": 1.0786874294281006,
      "rewards/rejected": -2.388218641281128,
      "step": 8720
    },
    {
      "epoch": 1.465951023146595,
      "grad_norm": 0.9847021102905273,
      "learning_rate": 2.558705132505871e-05,
      "logits/chosen": 2.6072640419006348,
      "logits/rejected": 2.9980335235595703,
      "logps/chosen": -214.9325714111328,
      "logps/rejected": -203.1979522705078,
      "loss": 0.4066,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1580674648284912,
      "rewards/margins": 1.5504149198532104,
      "rewards/rejected": -2.708482503890991,
      "step": 8740
    },
    {
      "epoch": 1.4693056021469306,
      "grad_norm": 1.382075309753418,
      "learning_rate": 2.5531141675053115e-05,
      "logits/chosen": 2.6136956214904785,
      "logits/rejected": 2.9336936473846436,
      "logps/chosen": -219.4178924560547,
      "logps/rejected": -206.34262084960938,
      "loss": 0.3785,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.1969146728515625,
      "rewards/margins": 1.5545145273208618,
      "rewards/rejected": -2.7514290809631348,
      "step": 8760
    },
    {
      "epoch": 1.472660181147266,
      "grad_norm": 4.800408363342285,
      "learning_rate": 2.5475232025047524e-05,
      "logits/chosen": 2.302502155303955,
      "logits/rejected": 2.7071313858032227,
      "logps/chosen": -210.6852264404297,
      "logps/rejected": -198.82412719726562,
      "loss": 0.4748,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9694733619689941,
      "rewards/margins": 1.364196538925171,
      "rewards/rejected": -2.333670139312744,
      "step": 8780
    },
    {
      "epoch": 1.4760147601476015,
      "grad_norm": 1.4873329401016235,
      "learning_rate": 2.5419322375041933e-05,
      "logits/chosen": 2.658883571624756,
      "logits/rejected": 2.7753939628601074,
      "logps/chosen": -193.0705108642578,
      "logps/rejected": -192.29959106445312,
      "loss": 0.5285,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5932199954986572,
      "rewards/margins": 0.9572976231575012,
      "rewards/rejected": -2.5505175590515137,
      "step": 8800
    },
    {
      "epoch": 1.479369339147937,
      "grad_norm": 2.0050950050354004,
      "learning_rate": 2.5363412725036345e-05,
      "logits/chosen": 2.5688297748565674,
      "logits/rejected": 2.7326292991638184,
      "logps/chosen": -205.5266876220703,
      "logps/rejected": -202.42474365234375,
      "loss": 0.5356,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6159603595733643,
      "rewards/margins": 1.1115081310272217,
      "rewards/rejected": -2.727468252182007,
      "step": 8820
    },
    {
      "epoch": 1.4827239181482723,
      "grad_norm": 1.5575186014175415,
      "learning_rate": 2.5307503075030754e-05,
      "logits/chosen": 2.487866163253784,
      "logits/rejected": 2.5977931022644043,
      "logps/chosen": -221.25796508789062,
      "logps/rejected": -204.82199096679688,
      "loss": 0.5384,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.61178719997406,
      "rewards/margins": 1.0083634853363037,
      "rewards/rejected": -2.6201508045196533,
      "step": 8840
    },
    {
      "epoch": 1.4860784971486078,
      "grad_norm": 1.6423310041427612,
      "learning_rate": 2.525159342502516e-05,
      "logits/chosen": 2.3900952339172363,
      "logits/rejected": 2.7265284061431885,
      "logps/chosen": -202.82647705078125,
      "logps/rejected": -185.3925018310547,
      "loss": 0.4122,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.3768339157104492,
      "rewards/margins": 1.2834478616714478,
      "rewards/rejected": -2.6602816581726074,
      "step": 8860
    },
    {
      "epoch": 1.4894330761489434,
      "grad_norm": 2.201399803161621,
      "learning_rate": 2.5195683775019568e-05,
      "logits/chosen": 2.415430784225464,
      "logits/rejected": 2.808473825454712,
      "logps/chosen": -207.4059600830078,
      "logps/rejected": -200.27047729492188,
      "loss": 0.3769,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5794341564178467,
      "rewards/margins": 1.4249871969223022,
      "rewards/rejected": -3.0044217109680176,
      "step": 8880
    },
    {
      "epoch": 1.4927876551492787,
      "grad_norm": 6.110218048095703,
      "learning_rate": 2.5139774125013977e-05,
      "logits/chosen": 2.630171298980713,
      "logits/rejected": 2.900508165359497,
      "logps/chosen": -199.35385131835938,
      "logps/rejected": -182.94821166992188,
      "loss": 0.4638,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.8194847106933594,
      "rewards/margins": 1.5004342794418335,
      "rewards/rejected": -3.3199191093444824,
      "step": 8900
    },
    {
      "epoch": 1.4961422341496142,
      "grad_norm": 4.82630729675293,
      "learning_rate": 2.508386447500839e-05,
      "logits/chosen": 2.3764214515686035,
      "logits/rejected": 2.6646230220794678,
      "logps/chosen": -210.99465942382812,
      "logps/rejected": -203.71163940429688,
      "loss": 0.413,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.697441816329956,
      "rewards/margins": 1.5319474935531616,
      "rewards/rejected": -3.2293896675109863,
      "step": 8920
    },
    {
      "epoch": 1.4994968131499498,
      "grad_norm": 4.9149603843688965,
      "learning_rate": 2.50279548250028e-05,
      "logits/chosen": 2.4889936447143555,
      "logits/rejected": 2.642838478088379,
      "logps/chosen": -205.60879516601562,
      "logps/rejected": -198.02301025390625,
      "loss": 0.5872,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9659287929534912,
      "rewards/margins": 1.0120705366134644,
      "rewards/rejected": -2.977999687194824,
      "step": 8940
    },
    {
      "epoch": 1.5028513921502853,
      "grad_norm": 1.3627785444259644,
      "learning_rate": 2.4972045174997204e-05,
      "logits/chosen": 2.548706531524658,
      "logits/rejected": 2.7744197845458984,
      "logps/chosen": -216.7686309814453,
      "logps/rejected": -208.9007568359375,
      "loss": 0.4787,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6491477489471436,
      "rewards/margins": 1.2176907062530518,
      "rewards/rejected": -2.8668384552001953,
      "step": 8960
    },
    {
      "epoch": 1.5062059711506206,
      "grad_norm": 3.530362129211426,
      "learning_rate": 2.4916135524991616e-05,
      "logits/chosen": 2.5763890743255615,
      "logits/rejected": 2.8444175720214844,
      "logps/chosen": -223.792724609375,
      "logps/rejected": -199.7288360595703,
      "loss": 0.3685,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8373918533325195,
      "rewards/margins": 1.6884918212890625,
      "rewards/rejected": -3.525883436203003,
      "step": 8980
    },
    {
      "epoch": 1.509560550150956,
      "grad_norm": 2.4393234252929688,
      "learning_rate": 2.4860225874986022e-05,
      "logits/chosen": 2.244722843170166,
      "logits/rejected": 2.6956329345703125,
      "logps/chosen": -212.267333984375,
      "logps/rejected": -203.32241821289062,
      "loss": 0.4094,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.555103063583374,
      "rewards/margins": 1.631763219833374,
      "rewards/rejected": -3.186866283416748,
      "step": 9000
    },
    {
      "epoch": 1.5129151291512914,
      "grad_norm": 5.3597731590271,
      "learning_rate": 2.4804316224980434e-05,
      "logits/chosen": 2.724717617034912,
      "logits/rejected": 2.911844253540039,
      "logps/chosen": -214.51986694335938,
      "logps/rejected": -222.9818878173828,
      "loss": 0.4176,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7816911935806274,
      "rewards/margins": 1.4871749877929688,
      "rewards/rejected": -3.2688663005828857,
      "step": 9020
    },
    {
      "epoch": 1.516269708151627,
      "grad_norm": 3.843965530395508,
      "learning_rate": 2.4748406574974843e-05,
      "logits/chosen": 2.6897003650665283,
      "logits/rejected": 2.978449821472168,
      "logps/chosen": -199.0113525390625,
      "logps/rejected": -190.37252807617188,
      "loss": 0.418,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6722745895385742,
      "rewards/margins": 1.3082135915756226,
      "rewards/rejected": -2.9804880619049072,
      "step": 9040
    },
    {
      "epoch": 1.5196242871519625,
      "grad_norm": 1.0234193801879883,
      "learning_rate": 2.469249692496925e-05,
      "logits/chosen": 2.500140428543091,
      "logits/rejected": 2.813650369644165,
      "logps/chosen": -208.94180297851562,
      "logps/rejected": -185.9824676513672,
      "loss": 0.4514,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7119773626327515,
      "rewards/margins": 1.351117730140686,
      "rewards/rejected": -3.0630948543548584,
      "step": 9060
    },
    {
      "epoch": 1.522978866152298,
      "grad_norm": 2.679396152496338,
      "learning_rate": 2.463658727496366e-05,
      "logits/chosen": 2.645667314529419,
      "logits/rejected": 2.8003990650177,
      "logps/chosen": -196.54541015625,
      "logps/rejected": -197.98248291015625,
      "loss": 0.4649,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4916436672210693,
      "rewards/margins": 1.0063974857330322,
      "rewards/rejected": -2.4980411529541016,
      "step": 9080
    },
    {
      "epoch": 1.5263334451526334,
      "grad_norm": 5.070355415344238,
      "learning_rate": 2.4580677624958066e-05,
      "logits/chosen": 2.5998480319976807,
      "logits/rejected": 2.7367348670959473,
      "logps/chosen": -216.92526245117188,
      "logps/rejected": -216.02853393554688,
      "loss": 0.4661,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8018795251846313,
      "rewards/margins": 1.250590205192566,
      "rewards/rejected": -3.0524699687957764,
      "step": 9100
    },
    {
      "epoch": 1.5296880241529687,
      "grad_norm": 5.684762954711914,
      "learning_rate": 2.4527563457452758e-05,
      "logits/chosen": 2.7391247749328613,
      "logits/rejected": 2.877514123916626,
      "logps/chosen": -201.4263458251953,
      "logps/rejected": -204.96780395507812,
      "loss": 0.466,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.033393383026123,
      "rewards/margins": 1.3422261476516724,
      "rewards/rejected": -3.375619411468506,
      "step": 9120
    },
    {
      "epoch": 1.5330426031533042,
      "grad_norm": 2.6723060607910156,
      "learning_rate": 2.4471653807447167e-05,
      "logits/chosen": 2.3971152305603027,
      "logits/rejected": 2.7837586402893066,
      "logps/chosen": -194.23574829101562,
      "logps/rejected": -193.65122985839844,
      "loss": 0.3294,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8308002948760986,
      "rewards/margins": 1.7174875736236572,
      "rewards/rejected": -3.548287868499756,
      "step": 9140
    },
    {
      "epoch": 1.5363971821536397,
      "grad_norm": 2.7807250022888184,
      "learning_rate": 2.4415744157441576e-05,
      "logits/chosen": 2.5707104206085205,
      "logits/rejected": 2.7873482704162598,
      "logps/chosen": -196.19808959960938,
      "logps/rejected": -214.3192596435547,
      "loss": 0.3781,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0656230449676514,
      "rewards/margins": 1.6630611419677734,
      "rewards/rejected": -3.7286839485168457,
      "step": 9160
    },
    {
      "epoch": 1.5397517611539753,
      "grad_norm": 1.3481794595718384,
      "learning_rate": 2.4359834507435985e-05,
      "logits/chosen": 2.5702662467956543,
      "logits/rejected": 2.8680946826934814,
      "logps/chosen": -198.27572631835938,
      "logps/rejected": -202.12557983398438,
      "loss": 0.4121,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.4131112098693848,
      "rewards/margins": 1.5846761465072632,
      "rewards/rejected": -3.9977869987487793,
      "step": 9180
    },
    {
      "epoch": 1.5431063401543106,
      "grad_norm": 3.2772631645202637,
      "learning_rate": 2.4303924857430394e-05,
      "logits/chosen": 2.272212505340576,
      "logits/rejected": 2.6572682857513428,
      "logps/chosen": -215.7794189453125,
      "logps/rejected": -192.88433837890625,
      "loss": 0.4933,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.4404659271240234,
      "rewards/margins": 1.1994521617889404,
      "rewards/rejected": -3.639918565750122,
      "step": 9200
    },
    {
      "epoch": 1.5464609191546461,
      "grad_norm": 5.32814884185791,
      "learning_rate": 2.4248015207424803e-05,
      "logits/chosen": 2.4389336109161377,
      "logits/rejected": 2.7975564002990723,
      "logps/chosen": -202.34292602539062,
      "logps/rejected": -197.59649658203125,
      "loss": 0.4965,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.3773818016052246,
      "rewards/margins": 1.5048067569732666,
      "rewards/rejected": -3.882188320159912,
      "step": 9220
    },
    {
      "epoch": 1.5498154981549814,
      "grad_norm": 6.597756385803223,
      "learning_rate": 2.419210555741921e-05,
      "logits/chosen": 2.50429630279541,
      "logits/rejected": 2.701620101928711,
      "logps/chosen": -204.32662963867188,
      "logps/rejected": -211.9517364501953,
      "loss": 0.5159,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.2887766361236572,
      "rewards/margins": 1.2647725343704224,
      "rewards/rejected": -3.553548812866211,
      "step": 9240
    },
    {
      "epoch": 1.553170077155317,
      "grad_norm": 2.46342396736145,
      "learning_rate": 2.413619590741362e-05,
      "logits/chosen": 2.5196616649627686,
      "logits/rejected": 2.6901469230651855,
      "logps/chosen": -196.68048095703125,
      "logps/rejected": -199.29656982421875,
      "loss": 0.5845,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.3697140216827393,
      "rewards/margins": 1.0069663524627686,
      "rewards/rejected": -3.3766798973083496,
      "step": 9260
    },
    {
      "epoch": 1.5565246561556525,
      "grad_norm": 4.966043949127197,
      "learning_rate": 2.408028625740803e-05,
      "logits/chosen": 2.5331127643585205,
      "logits/rejected": 2.645519733428955,
      "logps/chosen": -220.1649932861328,
      "logps/rejected": -214.2576904296875,
      "loss": 0.5008,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.087923288345337,
      "rewards/margins": 1.2529388666152954,
      "rewards/rejected": -3.3408617973327637,
      "step": 9280
    },
    {
      "epoch": 1.559879235155988,
      "grad_norm": 1.731602430343628,
      "learning_rate": 2.402437660740244e-05,
      "logits/chosen": 2.4853858947753906,
      "logits/rejected": 2.686497688293457,
      "logps/chosen": -207.8703155517578,
      "logps/rejected": -212.743896484375,
      "loss": 0.4445,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8052829504013062,
      "rewards/margins": 1.2809644937515259,
      "rewards/rejected": -3.086247682571411,
      "step": 9300
    },
    {
      "epoch": 1.5632338141563233,
      "grad_norm": 3.5899763107299805,
      "learning_rate": 2.3968466957396847e-05,
      "logits/chosen": 2.4521405696868896,
      "logits/rejected": 2.6777052879333496,
      "logps/chosen": -212.9051513671875,
      "logps/rejected": -204.55972290039062,
      "loss": 0.4712,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8157193660736084,
      "rewards/margins": 1.2313902378082275,
      "rewards/rejected": -3.047109842300415,
      "step": 9320
    },
    {
      "epoch": 1.5665883931566589,
      "grad_norm": 2.3397529125213623,
      "learning_rate": 2.3912557307391256e-05,
      "logits/chosen": 2.7294235229492188,
      "logits/rejected": 2.9074225425720215,
      "logps/chosen": -214.6092529296875,
      "logps/rejected": -205.53604125976562,
      "loss": 0.4816,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8915417194366455,
      "rewards/margins": 1.098689317703247,
      "rewards/rejected": -2.9902310371398926,
      "step": 9340
    },
    {
      "epoch": 1.5699429721569942,
      "grad_norm": 2.077444553375244,
      "learning_rate": 2.3856647657385665e-05,
      "logits/chosen": 2.461024522781372,
      "logits/rejected": 2.747838258743286,
      "logps/chosen": -212.50390625,
      "logps/rejected": -209.66714477539062,
      "loss": 0.4355,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2394168376922607,
      "rewards/margins": 1.342877984046936,
      "rewards/rejected": -2.5822947025299072,
      "step": 9360
    },
    {
      "epoch": 1.5732975511573297,
      "grad_norm": 3.7544474601745605,
      "learning_rate": 2.3800738007380074e-05,
      "logits/chosen": 2.55316424369812,
      "logits/rejected": 2.573254108428955,
      "logps/chosen": -201.46417236328125,
      "logps/rejected": -194.90145874023438,
      "loss": 0.5246,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.794274926185608,
      "rewards/margins": 1.0369150638580322,
      "rewards/rejected": -2.8311898708343506,
      "step": 9380
    },
    {
      "epoch": 1.5766521301576653,
      "grad_norm": 3.342646360397339,
      "learning_rate": 2.3744828357374486e-05,
      "logits/chosen": 2.678889036178589,
      "logits/rejected": 2.9806315898895264,
      "logps/chosen": -209.54049682617188,
      "logps/rejected": -184.92578125,
      "loss": 0.4661,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4119622707366943,
      "rewards/margins": 1.4184134006500244,
      "rewards/rejected": -2.830375909805298,
      "step": 9400
    },
    {
      "epoch": 1.5800067091580008,
      "grad_norm": 6.526463985443115,
      "learning_rate": 2.3688918707368892e-05,
      "logits/chosen": 2.7376973628997803,
      "logits/rejected": 2.964078903198242,
      "logps/chosen": -207.4429931640625,
      "logps/rejected": -200.73817443847656,
      "loss": 0.5047,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3393083810806274,
      "rewards/margins": 1.2659857273101807,
      "rewards/rejected": -2.6052942276000977,
      "step": 9420
    },
    {
      "epoch": 1.583361288158336,
      "grad_norm": 3.326509714126587,
      "learning_rate": 2.3633009057363304e-05,
      "logits/chosen": 2.5100674629211426,
      "logits/rejected": 2.7285377979278564,
      "logps/chosen": -206.2684326171875,
      "logps/rejected": -192.88754272460938,
      "loss": 0.3736,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.4764440059661865,
      "rewards/margins": 1.5008114576339722,
      "rewards/rejected": -2.9772558212280273,
      "step": 9440
    },
    {
      "epoch": 1.5867158671586716,
      "grad_norm": 3.6963729858398438,
      "learning_rate": 2.357709940735771e-05,
      "logits/chosen": 2.5139217376708984,
      "logits/rejected": 2.7984440326690674,
      "logps/chosen": -196.08937072753906,
      "logps/rejected": -198.7523956298828,
      "loss": 0.4322,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.3800866603851318,
      "rewards/margins": 1.1725775003433228,
      "rewards/rejected": -2.552664279937744,
      "step": 9460
    },
    {
      "epoch": 1.590070446159007,
      "grad_norm": 3.3438823223114014,
      "learning_rate": 2.352118975735212e-05,
      "logits/chosen": 2.6473476886749268,
      "logits/rejected": 2.863875150680542,
      "logps/chosen": -204.8386993408203,
      "logps/rejected": -205.4798583984375,
      "loss": 0.4853,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.375408411026001,
      "rewards/margins": 1.119830846786499,
      "rewards/rejected": -2.495239019393921,
      "step": 9480
    },
    {
      "epoch": 1.5934250251593425,
      "grad_norm": 3.7172183990478516,
      "learning_rate": 2.346528010734653e-05,
      "logits/chosen": 2.6206765174865723,
      "logits/rejected": 2.861107349395752,
      "logps/chosen": -198.0692596435547,
      "logps/rejected": -208.2417449951172,
      "loss": 0.4349,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6428594589233398,
      "rewards/margins": 1.4621127843856812,
      "rewards/rejected": -3.1049723625183105,
      "step": 9500
    },
    {
      "epoch": 1.596779604159678,
      "grad_norm": 3.978632926940918,
      "learning_rate": 2.3409370457340936e-05,
      "logits/chosen": 2.6881179809570312,
      "logits/rejected": 2.9117188453674316,
      "logps/chosen": -209.47848510742188,
      "logps/rejected": -219.65853881835938,
      "loss": 0.5389,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7728391885757446,
      "rewards/margins": 1.043289065361023,
      "rewards/rejected": -2.8161282539367676,
      "step": 9520
    },
    {
      "epoch": 1.6001341831600135,
      "grad_norm": 2.790557622909546,
      "learning_rate": 2.335346080733535e-05,
      "logits/chosen": 2.3752408027648926,
      "logits/rejected": 2.610933780670166,
      "logps/chosen": -210.80923461914062,
      "logps/rejected": -211.3992156982422,
      "loss": 0.4376,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7274219989776611,
      "rewards/margins": 1.314471960067749,
      "rewards/rejected": -3.04189395904541,
      "step": 9540
    },
    {
      "epoch": 1.6034887621603489,
      "grad_norm": 1.9896214008331299,
      "learning_rate": 2.3297551157329754e-05,
      "logits/chosen": 2.446268081665039,
      "logits/rejected": 2.7783777713775635,
      "logps/chosen": -204.81924438476562,
      "logps/rejected": -207.3027801513672,
      "loss": 0.3433,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6007747650146484,
      "rewards/margins": 1.631256103515625,
      "rewards/rejected": -3.2320313453674316,
      "step": 9560
    },
    {
      "epoch": 1.6068433411606842,
      "grad_norm": 3.8104376792907715,
      "learning_rate": 2.3241641507324167e-05,
      "logits/chosen": 2.5556812286376953,
      "logits/rejected": 2.6734251976013184,
      "logps/chosen": -198.35360717773438,
      "logps/rejected": -194.94778442382812,
      "loss": 0.4583,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8505980968475342,
      "rewards/margins": 1.162758708000183,
      "rewards/rejected": -3.013356924057007,
      "step": 9580
    },
    {
      "epoch": 1.6101979201610197,
      "grad_norm": 3.077185869216919,
      "learning_rate": 2.3185731857318575e-05,
      "logits/chosen": 2.436168909072876,
      "logits/rejected": 2.61584210395813,
      "logps/chosen": -210.563232421875,
      "logps/rejected": -205.9744110107422,
      "loss": 0.4924,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4799216985702515,
      "rewards/margins": 1.1644665002822876,
      "rewards/rejected": -2.644388198852539,
      "step": 9600
    },
    {
      "epoch": 1.6135524991613552,
      "grad_norm": 3.7988734245300293,
      "learning_rate": 2.3129822207312984e-05,
      "logits/chosen": 2.4078829288482666,
      "logits/rejected": 2.6100032329559326,
      "logps/chosen": -214.31765747070312,
      "logps/rejected": -204.8127899169922,
      "loss": 0.4611,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6048635244369507,
      "rewards/margins": 1.154548168182373,
      "rewards/rejected": -2.759411573410034,
      "step": 9620
    },
    {
      "epoch": 1.6169070781616908,
      "grad_norm": 7.165641784667969,
      "learning_rate": 2.3073912557307393e-05,
      "logits/chosen": 2.5988094806671143,
      "logits/rejected": 2.8202438354492188,
      "logps/chosen": -210.5620880126953,
      "logps/rejected": -201.95147705078125,
      "loss": 0.4008,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9529569149017334,
      "rewards/margins": 1.4479291439056396,
      "rewards/rejected": -3.400886058807373,
      "step": 9640
    },
    {
      "epoch": 1.6202616571620263,
      "grad_norm": 1.6128872632980347,
      "learning_rate": 2.3018002907301802e-05,
      "logits/chosen": 2.3942503929138184,
      "logits/rejected": 2.7330195903778076,
      "logps/chosen": -209.19845581054688,
      "logps/rejected": -193.36317443847656,
      "loss": 0.3556,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.6664772033691406,
      "rewards/margins": 1.6279195547103882,
      "rewards/rejected": -3.2943966388702393,
      "step": 9660
    },
    {
      "epoch": 1.6236162361623616,
      "grad_norm": 2.548445224761963,
      "learning_rate": 2.296209325729621e-05,
      "logits/chosen": 2.446437358856201,
      "logits/rejected": 2.7281405925750732,
      "logps/chosen": -203.2319793701172,
      "logps/rejected": -207.05105590820312,
      "loss": 0.4965,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9167749881744385,
      "rewards/margins": 1.3483048677444458,
      "rewards/rejected": -3.265079975128174,
      "step": 9680
    },
    {
      "epoch": 1.626970815162697,
      "grad_norm": 3.546161651611328,
      "learning_rate": 2.2906183607290617e-05,
      "logits/chosen": 2.366870164871216,
      "logits/rejected": 2.702061176300049,
      "logps/chosen": -225.78775024414062,
      "logps/rejected": -215.303955078125,
      "loss": 0.4223,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7340679168701172,
      "rewards/margins": 1.6067508459091187,
      "rewards/rejected": -3.340818405151367,
      "step": 9700
    },
    {
      "epoch": 1.6303253941630325,
      "grad_norm": 5.509170055389404,
      "learning_rate": 2.285027395728503e-05,
      "logits/chosen": 2.2819533348083496,
      "logits/rejected": 2.43678617477417,
      "logps/chosen": -207.70291137695312,
      "logps/rejected": -219.337646484375,
      "loss": 0.4311,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6937376260757446,
      "rewards/margins": 1.287689447402954,
      "rewards/rejected": -2.98142671585083,
      "step": 9720
    },
    {
      "epoch": 1.633679973163368,
      "grad_norm": 7.307106971740723,
      "learning_rate": 2.2794364307279438e-05,
      "logits/chosen": 2.387058734893799,
      "logits/rejected": 2.708672046661377,
      "logps/chosen": -221.58349609375,
      "logps/rejected": -208.02291870117188,
      "loss": 0.5672,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.6747887134552002,
      "rewards/margins": 0.9589290618896484,
      "rewards/rejected": -2.6337177753448486,
      "step": 9740
    },
    {
      "epoch": 1.6370345521637035,
      "grad_norm": 3.0149085521698,
      "learning_rate": 2.2738454657273847e-05,
      "logits/chosen": 2.6183459758758545,
      "logits/rejected": 2.8655312061309814,
      "logps/chosen": -221.64208984375,
      "logps/rejected": -220.79440307617188,
      "loss": 0.4471,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8386433124542236,
      "rewards/margins": 1.40732741355896,
      "rewards/rejected": -3.2459704875946045,
      "step": 9760
    },
    {
      "epoch": 1.640389131164039,
      "grad_norm": 3.1761796474456787,
      "learning_rate": 2.2682545007268256e-05,
      "logits/chosen": 2.5591671466827393,
      "logits/rejected": 2.7541286945343018,
      "logps/chosen": -213.57693481445312,
      "logps/rejected": -193.24407958984375,
      "loss": 0.4155,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.1137661933898926,
      "rewards/margins": 1.4496495723724365,
      "rewards/rejected": -3.563416004180908,
      "step": 9780
    },
    {
      "epoch": 1.6437437101643744,
      "grad_norm": 3.3421707153320312,
      "learning_rate": 2.2626635357262665e-05,
      "logits/chosen": 2.1878230571746826,
      "logits/rejected": 2.542276620864868,
      "logps/chosen": -201.33116149902344,
      "logps/rejected": -191.19686889648438,
      "loss": 0.4632,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7563718557357788,
      "rewards/margins": 1.623537302017212,
      "rewards/rejected": -3.379909038543701,
      "step": 9800
    },
    {
      "epoch": 1.6470982891647097,
      "grad_norm": 3.513169527053833,
      "learning_rate": 2.2570725707257074e-05,
      "logits/chosen": 2.606909990310669,
      "logits/rejected": 2.8599777221679688,
      "logps/chosen": -210.4749298095703,
      "logps/rejected": -204.11282348632812,
      "loss": 0.403,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.476069450378418,
      "rewards/margins": 1.4329044818878174,
      "rewards/rejected": -2.9089741706848145,
      "step": 9820
    },
    {
      "epoch": 1.6504528681650452,
      "grad_norm": 4.459157466888428,
      "learning_rate": 2.2514816057251482e-05,
      "logits/chosen": 2.51336669921875,
      "logits/rejected": 2.7757601737976074,
      "logps/chosen": -227.8359832763672,
      "logps/rejected": -202.4634246826172,
      "loss": 0.4399,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.82390558719635,
      "rewards/margins": 1.230534315109253,
      "rewards/rejected": -3.0544400215148926,
      "step": 9840
    },
    {
      "epoch": 1.6538074471653808,
      "grad_norm": 6.896820545196533,
      "learning_rate": 2.245890640724589e-05,
      "logits/chosen": 2.661571979522705,
      "logits/rejected": 2.848524808883667,
      "logps/chosen": -200.20266723632812,
      "logps/rejected": -206.9457244873047,
      "loss": 0.5887,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8251564502716064,
      "rewards/margins": 1.048164963722229,
      "rewards/rejected": -2.873321533203125,
      "step": 9860
    },
    {
      "epoch": 1.6571620261657163,
      "grad_norm": 3.8026442527770996,
      "learning_rate": 2.2402996757240304e-05,
      "logits/chosen": 2.3937606811523438,
      "logits/rejected": 2.5657684803009033,
      "logps/chosen": -199.34449768066406,
      "logps/rejected": -207.82284545898438,
      "loss": 0.4929,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.5279351472854614,
      "rewards/margins": 1.148937463760376,
      "rewards/rejected": -2.676872730255127,
      "step": 9880
    },
    {
      "epoch": 1.6605166051660518,
      "grad_norm": 1.0536481142044067,
      "learning_rate": 2.234708710723471e-05,
      "logits/chosen": 2.708425760269165,
      "logits/rejected": 2.823160409927368,
      "logps/chosen": -203.72903442382812,
      "logps/rejected": -197.66197204589844,
      "loss": 0.4479,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5150282382965088,
      "rewards/margins": 1.1941050291061401,
      "rewards/rejected": -2.7091331481933594,
      "step": 9900
    },
    {
      "epoch": 1.6638711841663871,
      "grad_norm": 3.3615152835845947,
      "learning_rate": 2.2291177457229118e-05,
      "logits/chosen": 2.682992458343506,
      "logits/rejected": 2.9266674518585205,
      "logps/chosen": -208.60653686523438,
      "logps/rejected": -198.7020721435547,
      "loss": 0.5236,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3275383710861206,
      "rewards/margins": 1.1170109510421753,
      "rewards/rejected": -2.444549560546875,
      "step": 9920
    },
    {
      "epoch": 1.6672257631667224,
      "grad_norm": 6.960923194885254,
      "learning_rate": 2.2235267807223527e-05,
      "logits/chosen": 2.637824535369873,
      "logits/rejected": 2.7391674518585205,
      "logps/chosen": -212.2263641357422,
      "logps/rejected": -201.60675048828125,
      "loss": 0.5448,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2823160886764526,
      "rewards/margins": 1.036209225654602,
      "rewards/rejected": -2.3185253143310547,
      "step": 9940
    },
    {
      "epoch": 1.670580342167058,
      "grad_norm": 6.902522087097168,
      "learning_rate": 2.2179358157217936e-05,
      "logits/chosen": 2.340705633163452,
      "logits/rejected": 2.692500114440918,
      "logps/chosen": -209.17807006835938,
      "logps/rejected": -199.88140869140625,
      "loss": 0.3613,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.1917246580123901,
      "rewards/margins": 1.508388638496399,
      "rewards/rejected": -2.700113534927368,
      "step": 9960
    },
    {
      "epoch": 1.6739349211673935,
      "grad_norm": 5.747025012969971,
      "learning_rate": 2.2123448507212345e-05,
      "logits/chosen": 2.4283668994903564,
      "logits/rejected": 2.736201047897339,
      "logps/chosen": -209.61587524414062,
      "logps/rejected": -196.11453247070312,
      "loss": 0.4256,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3245823383331299,
      "rewards/margins": 1.475429892539978,
      "rewards/rejected": -2.8000121116638184,
      "step": 9980
    },
    {
      "epoch": 1.677289500167729,
      "grad_norm": 7.300002574920654,
      "learning_rate": 2.2067538857206754e-05,
      "logits/chosen": 2.5025346279144287,
      "logits/rejected": 2.7822341918945312,
      "logps/chosen": -210.8192596435547,
      "logps/rejected": -210.9803009033203,
      "loss": 0.4861,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.0454230308532715,
      "rewards/margins": 1.2854795455932617,
      "rewards/rejected": -3.330902576446533,
      "step": 10000
    },
    {
      "epoch": 1.6806440791680644,
      "grad_norm": 2.8489668369293213,
      "learning_rate": 2.2011629207201166e-05,
      "logits/chosen": 2.5328049659729004,
      "logits/rejected": 2.8333897590637207,
      "logps/chosen": -217.26876831054688,
      "logps/rejected": -201.65121459960938,
      "loss": 0.3403,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.730852484703064,
      "rewards/margins": 1.766655683517456,
      "rewards/rejected": -3.4975085258483887,
      "step": 10020
    },
    {
      "epoch": 1.6839986581683999,
      "grad_norm": 1.7946767807006836,
      "learning_rate": 2.195571955719557e-05,
      "logits/chosen": 2.592480182647705,
      "logits/rejected": 2.7410435676574707,
      "logps/chosen": -204.54598999023438,
      "logps/rejected": -189.49807739257812,
      "loss": 0.4083,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0487165451049805,
      "rewards/margins": 1.4878431558609009,
      "rewards/rejected": -3.5365593433380127,
      "step": 10040
    },
    {
      "epoch": 1.6873532371687352,
      "grad_norm": 3.143670082092285,
      "learning_rate": 2.1899809907189984e-05,
      "logits/chosen": 2.3512706756591797,
      "logits/rejected": 2.6598458290100098,
      "logps/chosen": -210.60366821289062,
      "logps/rejected": -193.130615234375,
      "loss": 0.4057,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4401161670684814,
      "rewards/margins": 1.6697582006454468,
      "rewards/rejected": -3.1098742485046387,
      "step": 10060
    },
    {
      "epoch": 1.6907078161690707,
      "grad_norm": 3.8511276245117188,
      "learning_rate": 2.184390025718439e-05,
      "logits/chosen": 2.5646908283233643,
      "logits/rejected": 2.8557684421539307,
      "logps/chosen": -209.5847625732422,
      "logps/rejected": -205.57931518554688,
      "loss": 0.5646,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6965032815933228,
      "rewards/margins": 1.1374382972717285,
      "rewards/rejected": -2.833941698074341,
      "step": 10080
    },
    {
      "epoch": 1.6940623951694063,
      "grad_norm": 8.059562683105469,
      "learning_rate": 2.1787990607178802e-05,
      "logits/chosen": 2.3931305408477783,
      "logits/rejected": 2.6518707275390625,
      "logps/chosen": -205.5920867919922,
      "logps/rejected": -190.94273376464844,
      "loss": 0.4696,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.386340856552124,
      "rewards/margins": 1.23993980884552,
      "rewards/rejected": -2.6262805461883545,
      "step": 10100
    },
    {
      "epoch": 1.6974169741697418,
      "grad_norm": 2.6016316413879395,
      "learning_rate": 2.173208095717321e-05,
      "logits/chosen": 2.521221399307251,
      "logits/rejected": 2.843168258666992,
      "logps/chosen": -221.02230834960938,
      "logps/rejected": -201.47129821777344,
      "loss": 0.4261,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.4635518789291382,
      "rewards/margins": 1.5094983577728271,
      "rewards/rejected": -2.973050117492676,
      "step": 10120
    },
    {
      "epoch": 1.700771553170077,
      "grad_norm": 2.4480061531066895,
      "learning_rate": 2.1676171307167616e-05,
      "logits/chosen": 2.5836853981018066,
      "logits/rejected": 2.8650577068328857,
      "logps/chosen": -212.23556518554688,
      "logps/rejected": -194.89791870117188,
      "loss": 0.4077,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.393019437789917,
      "rewards/margins": 1.461147427558899,
      "rewards/rejected": -2.8541669845581055,
      "step": 10140
    },
    {
      "epoch": 1.7041261321704126,
      "grad_norm": 4.710577487945557,
      "learning_rate": 2.162026165716203e-05,
      "logits/chosen": 2.6586105823516846,
      "logits/rejected": 2.89863920211792,
      "logps/chosen": -224.9989013671875,
      "logps/rejected": -200.81861877441406,
      "loss": 0.542,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4054914712905884,
      "rewards/margins": 1.4689900875091553,
      "rewards/rejected": -2.874481678009033,
      "step": 10160
    },
    {
      "epoch": 1.707480711170748,
      "grad_norm": 4.89068078994751,
      "learning_rate": 2.1564352007156434e-05,
      "logits/chosen": 2.4707248210906982,
      "logits/rejected": 2.731060743331909,
      "logps/chosen": -216.8341827392578,
      "logps/rejected": -201.5024871826172,
      "loss": 0.5083,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7625923156738281,
      "rewards/margins": 1.2526696920394897,
      "rewards/rejected": -3.0152621269226074,
      "step": 10180
    },
    {
      "epoch": 1.7108352901710835,
      "grad_norm": 0.7582474946975708,
      "learning_rate": 2.1508442357150846e-05,
      "logits/chosen": 2.8056721687316895,
      "logits/rejected": 2.9890706539154053,
      "logps/chosen": -210.30142211914062,
      "logps/rejected": -206.1205291748047,
      "loss": 0.5135,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3084416389465332,
      "rewards/margins": 1.3258492946624756,
      "rewards/rejected": -2.634291172027588,
      "step": 10200
    },
    {
      "epoch": 1.714189869171419,
      "grad_norm": 0.5000349879264832,
      "learning_rate": 2.1452532707145255e-05,
      "logits/chosen": 2.6890149116516113,
      "logits/rejected": 2.85526967048645,
      "logps/chosen": -189.9394989013672,
      "logps/rejected": -172.8307647705078,
      "loss": 0.4651,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0743032693862915,
      "rewards/margins": 1.2542667388916016,
      "rewards/rejected": -2.3285701274871826,
      "step": 10220
    },
    {
      "epoch": 1.7175444481717546,
      "grad_norm": 2.0284969806671143,
      "learning_rate": 2.1396623057139664e-05,
      "logits/chosen": 2.661864757537842,
      "logits/rejected": 2.957125425338745,
      "logps/chosen": -193.9101104736328,
      "logps/rejected": -195.99716186523438,
      "loss": 0.4027,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9937198758125305,
      "rewards/margins": 1.2989612817764282,
      "rewards/rejected": -2.2926812171936035,
      "step": 10240
    },
    {
      "epoch": 1.7208990271720899,
      "grad_norm": 3.6688437461853027,
      "learning_rate": 2.1340713407134073e-05,
      "logits/chosen": 2.8611416816711426,
      "logits/rejected": 3.0370612144470215,
      "logps/chosen": -194.18405151367188,
      "logps/rejected": -197.9063720703125,
      "loss": 0.4512,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.185100793838501,
      "rewards/margins": 1.1653006076812744,
      "rewards/rejected": -2.3504014015197754,
      "step": 10260
    },
    {
      "epoch": 1.7242536061724254,
      "grad_norm": 1.4841885566711426,
      "learning_rate": 2.1284803757128482e-05,
      "logits/chosen": 2.520246982574463,
      "logits/rejected": 2.7809884548187256,
      "logps/chosen": -199.25831604003906,
      "logps/rejected": -181.9646453857422,
      "loss": 0.3451,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.115838646888733,
      "rewards/margins": 1.5670442581176758,
      "rewards/rejected": -2.682882785797119,
      "step": 10280
    },
    {
      "epoch": 1.7276081851727607,
      "grad_norm": 5.616297245025635,
      "learning_rate": 2.122889410712289e-05,
      "logits/chosen": 2.7341692447662354,
      "logits/rejected": 2.9741997718811035,
      "logps/chosen": -199.56005859375,
      "logps/rejected": -191.0012664794922,
      "loss": 0.4228,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3763755559921265,
      "rewards/margins": 1.41377592086792,
      "rewards/rejected": -2.790151596069336,
      "step": 10300
    },
    {
      "epoch": 1.7309627641730962,
      "grad_norm": 3.0863537788391113,
      "learning_rate": 2.11729844571173e-05,
      "logits/chosen": 2.486675977706909,
      "logits/rejected": 2.6735923290252686,
      "logps/chosen": -191.0929412841797,
      "logps/rejected": -189.29446411132812,
      "loss": 0.519,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4631366729736328,
      "rewards/margins": 1.0122627019882202,
      "rewards/rejected": -2.4753994941711426,
      "step": 10320
    },
    {
      "epoch": 1.7343173431734318,
      "grad_norm": 7.433493614196777,
      "learning_rate": 2.111707480711171e-05,
      "logits/chosen": 2.6927313804626465,
      "logits/rejected": 2.9984195232391357,
      "logps/chosen": -215.58438110351562,
      "logps/rejected": -200.9446563720703,
      "loss": 0.4061,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.2083470821380615,
      "rewards/margins": 1.5305871963500977,
      "rewards/rejected": -2.73893404006958,
      "step": 10340
    },
    {
      "epoch": 1.7376719221737673,
      "grad_norm": 5.612776279449463,
      "learning_rate": 2.1061165157106118e-05,
      "logits/chosen": 2.7177793979644775,
      "logits/rejected": 2.8304996490478516,
      "logps/chosen": -207.74545288085938,
      "logps/rejected": -206.40682983398438,
      "loss": 0.4124,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.091567873954773,
      "rewards/margins": 1.338943600654602,
      "rewards/rejected": -2.430511713027954,
      "step": 10360
    },
    {
      "epoch": 1.7410265011741026,
      "grad_norm": 4.551675796508789,
      "learning_rate": 2.1005255507100527e-05,
      "logits/chosen": 2.628039836883545,
      "logits/rejected": 2.832914352416992,
      "logps/chosen": -211.3330535888672,
      "logps/rejected": -183.62197875976562,
      "loss": 0.4045,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9280215501785278,
      "rewards/margins": 1.312353491783142,
      "rewards/rejected": -2.24037504196167,
      "step": 10380
    },
    {
      "epoch": 1.7443810801744382,
      "grad_norm": 3.0948872566223145,
      "learning_rate": 2.0949345857094936e-05,
      "logits/chosen": 2.7058093547821045,
      "logits/rejected": 2.9172141551971436,
      "logps/chosen": -191.91873168945312,
      "logps/rejected": -185.34359741210938,
      "loss": 0.4315,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1932035684585571,
      "rewards/margins": 1.3013538122177124,
      "rewards/rejected": -2.4945573806762695,
      "step": 10400
    },
    {
      "epoch": 1.7477356591747735,
      "grad_norm": 2.6948509216308594,
      "learning_rate": 2.0893436207089344e-05,
      "logits/chosen": 2.6775805950164795,
      "logits/rejected": 2.9464476108551025,
      "logps/chosen": -205.2174530029297,
      "logps/rejected": -209.6732177734375,
      "loss": 0.3802,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.2021368741989136,
      "rewards/margins": 1.4001110792160034,
      "rewards/rejected": -2.602247714996338,
      "step": 10420
    },
    {
      "epoch": 1.751090238175109,
      "grad_norm": 2.4899795055389404,
      "learning_rate": 2.0837526557083753e-05,
      "logits/chosen": 2.6016814708709717,
      "logits/rejected": 2.8613455295562744,
      "logps/chosen": -207.0958709716797,
      "logps/rejected": -188.0742950439453,
      "loss": 0.4384,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3694407939910889,
      "rewards/margins": 1.406604290008545,
      "rewards/rejected": -2.776045322418213,
      "step": 10440
    },
    {
      "epoch": 1.7544448171754445,
      "grad_norm": 2.3988254070281982,
      "learning_rate": 2.0781616907078162e-05,
      "logits/chosen": 2.7802634239196777,
      "logits/rejected": 2.9727463722229004,
      "logps/chosen": -213.12869262695312,
      "logps/rejected": -204.47984313964844,
      "loss": 0.4856,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.455868124961853,
      "rewards/margins": 1.0931520462036133,
      "rewards/rejected": -2.549020290374756,
      "step": 10460
    },
    {
      "epoch": 1.75779939617578,
      "grad_norm": 3.002678632736206,
      "learning_rate": 2.072570725707257e-05,
      "logits/chosen": 2.7111904621124268,
      "logits/rejected": 3.051623821258545,
      "logps/chosen": -208.96902465820312,
      "logps/rejected": -196.87420654296875,
      "loss": 0.3231,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.2438390254974365,
      "rewards/margins": 1.6309032440185547,
      "rewards/rejected": -2.874742031097412,
      "step": 10480
    },
    {
      "epoch": 1.7611539751761154,
      "grad_norm": 6.219916343688965,
      "learning_rate": 2.0669797607066984e-05,
      "logits/chosen": 2.9000084400177,
      "logits/rejected": 3.0301599502563477,
      "logps/chosen": -206.7827606201172,
      "logps/rejected": -204.169189453125,
      "loss": 0.5071,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7421915531158447,
      "rewards/margins": 1.2917683124542236,
      "rewards/rejected": -3.0339598655700684,
      "step": 10500
    },
    {
      "epoch": 1.7645085541764507,
      "grad_norm": 5.135387420654297,
      "learning_rate": 2.061388795706139e-05,
      "logits/chosen": 2.6605422496795654,
      "logits/rejected": 2.959545373916626,
      "logps/chosen": -213.66677856445312,
      "logps/rejected": -211.0428009033203,
      "loss": 0.4675,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0031384229660034,
      "rewards/margins": 1.4179280996322632,
      "rewards/rejected": -2.4210667610168457,
      "step": 10520
    },
    {
      "epoch": 1.7678631331767862,
      "grad_norm": 3.602743148803711,
      "learning_rate": 2.05579783070558e-05,
      "logits/chosen": 2.8782877922058105,
      "logits/rejected": 3.1008825302124023,
      "logps/chosen": -210.44558715820312,
      "logps/rejected": -199.47874450683594,
      "loss": 0.4385,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.9953411221504211,
      "rewards/margins": 1.4300498962402344,
      "rewards/rejected": -2.4253907203674316,
      "step": 10540
    },
    {
      "epoch": 1.7712177121771218,
      "grad_norm": 3.1821014881134033,
      "learning_rate": 2.0502068657050207e-05,
      "logits/chosen": 2.8532967567443848,
      "logits/rejected": 3.008716106414795,
      "logps/chosen": -212.83224487304688,
      "logps/rejected": -201.64828491210938,
      "loss": 0.4061,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.154598593711853,
      "rewards/margins": 1.3732690811157227,
      "rewards/rejected": -2.527867555618286,
      "step": 10560
    },
    {
      "epoch": 1.7745722911774573,
      "grad_norm": 2.8786227703094482,
      "learning_rate": 2.0446159007044616e-05,
      "logits/chosen": 2.629490375518799,
      "logits/rejected": 3.0141854286193848,
      "logps/chosen": -216.78256225585938,
      "logps/rejected": -204.0247039794922,
      "loss": 0.3372,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.5685023069381714,
      "rewards/margins": 1.572049856185913,
      "rewards/rejected": -3.140552282333374,
      "step": 10580
    },
    {
      "epoch": 1.7779268701777928,
      "grad_norm": 5.167510509490967,
      "learning_rate": 2.0390249357039025e-05,
      "logits/chosen": 2.856935501098633,
      "logits/rejected": 3.187497615814209,
      "logps/chosen": -205.3535614013672,
      "logps/rejected": -186.0238494873047,
      "loss": 0.426,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.536643147468567,
      "rewards/margins": 1.5212829113006592,
      "rewards/rejected": -3.0579259395599365,
      "step": 10600
    },
    {
      "epoch": 1.7812814491781281,
      "grad_norm": 1.9032329320907593,
      "learning_rate": 2.0334339707033434e-05,
      "logits/chosen": 2.721328020095825,
      "logits/rejected": 3.036681652069092,
      "logps/chosen": -212.8115692138672,
      "logps/rejected": -200.8623046875,
      "loss": 0.3913,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.5898809432983398,
      "rewards/margins": 1.7002521753311157,
      "rewards/rejected": -3.290132999420166,
      "step": 10620
    },
    {
      "epoch": 1.7846360281784635,
      "grad_norm": 3.9671788215637207,
      "learning_rate": 2.0278430057027846e-05,
      "logits/chosen": 2.677082061767578,
      "logits/rejected": 2.88651180267334,
      "logps/chosen": -193.70852661132812,
      "logps/rejected": -186.7689971923828,
      "loss": 0.4437,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5715914964675903,
      "rewards/margins": 1.1342079639434814,
      "rewards/rejected": -2.7057995796203613,
      "step": 10640
    },
    {
      "epoch": 1.787990607178799,
      "grad_norm": 1.718463659286499,
      "learning_rate": 2.022252040702225e-05,
      "logits/chosen": 2.7612860202789307,
      "logits/rejected": 2.918700695037842,
      "logps/chosen": -221.7063446044922,
      "logps/rejected": -215.1638641357422,
      "loss": 0.5212,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2723052501678467,
      "rewards/margins": 1.178531289100647,
      "rewards/rejected": -2.450836658477783,
      "step": 10660
    },
    {
      "epoch": 1.7913451861791345,
      "grad_norm": 2.638620376586914,
      "learning_rate": 2.0166610757016664e-05,
      "logits/chosen": 3.122248888015747,
      "logits/rejected": 3.1751761436462402,
      "logps/chosen": -212.4850311279297,
      "logps/rejected": -203.79373168945312,
      "loss": 0.5414,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9534809589385986,
      "rewards/margins": 0.858725905418396,
      "rewards/rejected": -2.812206983566284,
      "step": 10680
    },
    {
      "epoch": 1.79469976517947,
      "grad_norm": 2.3595423698425293,
      "learning_rate": 2.011070110701107e-05,
      "logits/chosen": 2.7670767307281494,
      "logits/rejected": 3.114912509918213,
      "logps/chosen": -203.808837890625,
      "logps/rejected": -192.2161865234375,
      "loss": 0.4093,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4221022129058838,
      "rewards/margins": 1.5609837770462036,
      "rewards/rejected": -2.9830856323242188,
      "step": 10700
    },
    {
      "epoch": 1.7980543441798056,
      "grad_norm": 1.857913613319397,
      "learning_rate": 2.005479145700548e-05,
      "logits/chosen": 2.8266732692718506,
      "logits/rejected": 3.1002607345581055,
      "logps/chosen": -205.1363067626953,
      "logps/rejected": -188.9333038330078,
      "loss": 0.3648,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.4642678499221802,
      "rewards/margins": 1.604636788368225,
      "rewards/rejected": -3.068904399871826,
      "step": 10720
    },
    {
      "epoch": 1.801408923180141,
      "grad_norm": 4.405735492706299,
      "learning_rate": 1.999888180699989e-05,
      "logits/chosen": 2.847353458404541,
      "logits/rejected": 2.9985861778259277,
      "logps/chosen": -205.2554931640625,
      "logps/rejected": -202.21939086914062,
      "loss": 0.4817,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4657405614852905,
      "rewards/margins": 1.260972261428833,
      "rewards/rejected": -2.726712942123413,
      "step": 10740
    },
    {
      "epoch": 1.8047635021804762,
      "grad_norm": 1.8033016920089722,
      "learning_rate": 1.99429721569943e-05,
      "logits/chosen": 2.744340181350708,
      "logits/rejected": 2.9462621212005615,
      "logps/chosen": -208.97705078125,
      "logps/rejected": -207.9198455810547,
      "loss": 0.4523,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3372782468795776,
      "rewards/margins": 1.341252088546753,
      "rewards/rejected": -2.67853045463562,
      "step": 10760
    },
    {
      "epoch": 1.8081180811808117,
      "grad_norm": 3.6747350692749023,
      "learning_rate": 1.9889857989488984e-05,
      "logits/chosen": 2.591064453125,
      "logits/rejected": 3.0120770931243896,
      "logps/chosen": -203.48922729492188,
      "logps/rejected": -205.8983612060547,
      "loss": 0.3569,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.5981743335723877,
      "rewards/margins": 1.5955660343170166,
      "rewards/rejected": -3.1937406063079834,
      "step": 10780
    },
    {
      "epoch": 1.8114726601811473,
      "grad_norm": 4.767332077026367,
      "learning_rate": 1.9833948339483397e-05,
      "logits/chosen": 2.8492980003356934,
      "logits/rejected": 3.1030449867248535,
      "logps/chosen": -201.5897674560547,
      "logps/rejected": -201.32827758789062,
      "loss": 0.4861,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7621967792510986,
      "rewards/margins": 1.4542646408081055,
      "rewards/rejected": -3.216461658477783,
      "step": 10800
    },
    {
      "epoch": 1.8148272391814828,
      "grad_norm": 4.48643159866333,
      "learning_rate": 1.9778038689477806e-05,
      "logits/chosen": 2.777355670928955,
      "logits/rejected": 3.061497926712036,
      "logps/chosen": -198.26856994628906,
      "logps/rejected": -184.3069610595703,
      "loss": 0.4598,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3174004554748535,
      "rewards/margins": 1.4145872592926025,
      "rewards/rejected": -2.731987714767456,
      "step": 10820
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 2.0535552501678467,
      "learning_rate": 1.9722129039472215e-05,
      "logits/chosen": 2.720022678375244,
      "logits/rejected": 3.015416383743286,
      "logps/chosen": -205.55410766601562,
      "logps/rejected": -200.88540649414062,
      "loss": 0.483,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5421998500823975,
      "rewards/margins": 1.3167707920074463,
      "rewards/rejected": -2.8589704036712646,
      "step": 10840
    },
    {
      "epoch": 1.8215363971821537,
      "grad_norm": 1.0056205987930298,
      "learning_rate": 1.9666219389466623e-05,
      "logits/chosen": 2.7050516605377197,
      "logits/rejected": 2.920609951019287,
      "logps/chosen": -205.061767578125,
      "logps/rejected": -204.25440979003906,
      "loss": 0.4386,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1581895351409912,
      "rewards/margins": 1.4157402515411377,
      "rewards/rejected": -2.573929786682129,
      "step": 10860
    },
    {
      "epoch": 1.824890976182489,
      "grad_norm": 2.8952059745788574,
      "learning_rate": 1.9610309739461032e-05,
      "logits/chosen": 2.6243767738342285,
      "logits/rejected": 2.906459331512451,
      "logps/chosen": -209.60476684570312,
      "logps/rejected": -211.2181854248047,
      "loss": 0.4278,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3492741584777832,
      "rewards/margins": 1.5746127367019653,
      "rewards/rejected": -2.923886775970459,
      "step": 10880
    },
    {
      "epoch": 1.8282455551828245,
      "grad_norm": 5.008426189422607,
      "learning_rate": 1.955440008945544e-05,
      "logits/chosen": 2.7981879711151123,
      "logits/rejected": 3.134547710418701,
      "logps/chosen": -221.52053833007812,
      "logps/rejected": -203.9038543701172,
      "loss": 0.3773,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3247202634811401,
      "rewards/margins": 1.5457276105880737,
      "rewards/rejected": -2.870448350906372,
      "step": 10900
    },
    {
      "epoch": 1.83160013418316,
      "grad_norm": 4.966320991516113,
      "learning_rate": 1.949849043944985e-05,
      "logits/chosen": 2.845670700073242,
      "logits/rejected": 3.002254009246826,
      "logps/chosen": -204.59628295898438,
      "logps/rejected": -189.25253295898438,
      "loss": 0.4514,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.514984369277954,
      "rewards/margins": 1.386095643043518,
      "rewards/rejected": -2.9010796546936035,
      "step": 10920
    },
    {
      "epoch": 1.8349547131834956,
      "grad_norm": 3.477530002593994,
      "learning_rate": 1.944258078944426e-05,
      "logits/chosen": 2.917149305343628,
      "logits/rejected": 3.035916566848755,
      "logps/chosen": -203.34066772460938,
      "logps/rejected": -193.81900024414062,
      "loss": 0.4705,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4155361652374268,
      "rewards/margins": 1.3348981142044067,
      "rewards/rejected": -2.750434160232544,
      "step": 10940
    },
    {
      "epoch": 1.8383092921838309,
      "grad_norm": 1.8173593282699585,
      "learning_rate": 1.9386671139438668e-05,
      "logits/chosen": 2.761570453643799,
      "logits/rejected": 2.913635492324829,
      "logps/chosen": -203.93325805664062,
      "logps/rejected": -202.72694396972656,
      "loss": 0.4837,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3127424716949463,
      "rewards/margins": 1.3852310180664062,
      "rewards/rejected": -2.6979734897613525,
      "step": 10960
    },
    {
      "epoch": 1.8416638711841664,
      "grad_norm": 4.162115573883057,
      "learning_rate": 1.9330761489433077e-05,
      "logits/chosen": 2.631608009338379,
      "logits/rejected": 2.8047282695770264,
      "logps/chosen": -209.8160858154297,
      "logps/rejected": -201.8409881591797,
      "loss": 0.4604,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.0518176555633545,
      "rewards/margins": 1.2993074655532837,
      "rewards/rejected": -2.3511250019073486,
      "step": 10980
    },
    {
      "epoch": 1.8450184501845017,
      "grad_norm": 2.680849075317383,
      "learning_rate": 1.9274851839427486e-05,
      "logits/chosen": 2.5295803546905518,
      "logits/rejected": 2.9880785942077637,
      "logps/chosen": -192.43087768554688,
      "logps/rejected": -191.6362762451172,
      "loss": 0.3971,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3405026197433472,
      "rewards/margins": 1.4327205419540405,
      "rewards/rejected": -2.773223400115967,
      "step": 11000
    },
    {
      "epoch": 1.8483730291848373,
      "grad_norm": 2.5412609577178955,
      "learning_rate": 1.9218942189421895e-05,
      "logits/chosen": 2.6539559364318848,
      "logits/rejected": 2.860867977142334,
      "logps/chosen": -201.04904174804688,
      "logps/rejected": -205.1194610595703,
      "loss": 0.5094,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7587999105453491,
      "rewards/margins": 1.0957266092300415,
      "rewards/rejected": -2.8545260429382324,
      "step": 11020
    },
    {
      "epoch": 1.8517276081851728,
      "grad_norm": 2.8277580738067627,
      "learning_rate": 1.9163032539416304e-05,
      "logits/chosen": 2.617565155029297,
      "logits/rejected": 2.946368455886841,
      "logps/chosen": -203.3637237548828,
      "logps/rejected": -202.07559204101562,
      "loss": 0.3659,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.2739962339401245,
      "rewards/margins": 1.5281203985214233,
      "rewards/rejected": -2.802116870880127,
      "step": 11040
    },
    {
      "epoch": 1.8550821871855083,
      "grad_norm": 3.467813491821289,
      "learning_rate": 1.9107122889410713e-05,
      "logits/chosen": 2.641864776611328,
      "logits/rejected": 2.8440463542938232,
      "logps/chosen": -201.3390350341797,
      "logps/rejected": -197.76821899414062,
      "loss": 0.3827,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3894413709640503,
      "rewards/margins": 1.6136398315429688,
      "rewards/rejected": -3.0030810832977295,
      "step": 11060
    },
    {
      "epoch": 1.8584367661858436,
      "grad_norm": 1.1867471933364868,
      "learning_rate": 1.905121323940512e-05,
      "logits/chosen": 2.5807113647460938,
      "logits/rejected": 2.9002766609191895,
      "logps/chosen": -197.19366455078125,
      "logps/rejected": -183.87570190429688,
      "loss": 0.4552,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5316120386123657,
      "rewards/margins": 1.5364896059036255,
      "rewards/rejected": -3.068101644515991,
      "step": 11080
    },
    {
      "epoch": 1.8617913451861792,
      "grad_norm": 4.338637828826904,
      "learning_rate": 1.8995303589399534e-05,
      "logits/chosen": 2.6206178665161133,
      "logits/rejected": 2.914214611053467,
      "logps/chosen": -204.51625061035156,
      "logps/rejected": -191.7139129638672,
      "loss": 0.441,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5557247400283813,
      "rewards/margins": 1.406458854675293,
      "rewards/rejected": -2.9621834754943848,
      "step": 11100
    },
    {
      "epoch": 1.8651459241865145,
      "grad_norm": 4.138955593109131,
      "learning_rate": 1.893939393939394e-05,
      "logits/chosen": 2.6149814128875732,
      "logits/rejected": 2.848411798477173,
      "logps/chosen": -199.5867919921875,
      "logps/rejected": -187.3831787109375,
      "loss": 0.4814,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3718715906143188,
      "rewards/margins": 1.4188926219940186,
      "rewards/rejected": -2.790764331817627,
      "step": 11120
    },
    {
      "epoch": 1.86850050318685,
      "grad_norm": 2.8812527656555176,
      "learning_rate": 1.888348428938835e-05,
      "logits/chosen": 2.7498021125793457,
      "logits/rejected": 3.0242037773132324,
      "logps/chosen": -220.8092803955078,
      "logps/rejected": -202.57150268554688,
      "loss": 0.4718,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1148247718811035,
      "rewards/margins": 1.4735329151153564,
      "rewards/rejected": -2.588357448577881,
      "step": 11140
    },
    {
      "epoch": 1.8718550821871855,
      "grad_norm": 5.947351455688477,
      "learning_rate": 1.8827574639382757e-05,
      "logits/chosen": 2.581777811050415,
      "logits/rejected": 2.791377544403076,
      "logps/chosen": -193.70703125,
      "logps/rejected": -194.28799438476562,
      "loss": 0.5383,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.456295132637024,
      "rewards/margins": 1.3590290546417236,
      "rewards/rejected": -2.815323829650879,
      "step": 11160
    },
    {
      "epoch": 1.875209661187521,
      "grad_norm": 5.279738903045654,
      "learning_rate": 1.8771664989377166e-05,
      "logits/chosen": 2.8915886878967285,
      "logits/rejected": 2.95771861076355,
      "logps/chosen": -203.7301483154297,
      "logps/rejected": -202.2803497314453,
      "loss": 0.5274,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6169341802597046,
      "rewards/margins": 1.1977847814559937,
      "rewards/rejected": -2.8147189617156982,
      "step": 11180
    },
    {
      "epoch": 1.8785642401878564,
      "grad_norm": 4.223840713500977,
      "learning_rate": 1.871575533937158e-05,
      "logits/chosen": 2.412238359451294,
      "logits/rejected": 2.579721689224243,
      "logps/chosen": -200.8999481201172,
      "logps/rejected": -197.1099853515625,
      "loss": 0.5647,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3047783374786377,
      "rewards/margins": 1.404343843460083,
      "rewards/rejected": -2.7091221809387207,
      "step": 11200
    },
    {
      "epoch": 1.881918819188192,
      "grad_norm": 3.089883327484131,
      "learning_rate": 1.8659845689365984e-05,
      "logits/chosen": 2.5464119911193848,
      "logits/rejected": 2.6305034160614014,
      "logps/chosen": -198.02865600585938,
      "logps/rejected": -201.23590087890625,
      "loss": 0.6297,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5471134185791016,
      "rewards/margins": 0.9169846773147583,
      "rewards/rejected": -2.4640979766845703,
      "step": 11220
    },
    {
      "epoch": 1.8852733981885272,
      "grad_norm": 2.932925224304199,
      "learning_rate": 1.8603936039360396e-05,
      "logits/chosen": 2.5939059257507324,
      "logits/rejected": 2.9129438400268555,
      "logps/chosen": -211.69558715820312,
      "logps/rejected": -187.3138427734375,
      "loss": 0.4312,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5876154899597168,
      "rewards/margins": 1.4233771562576294,
      "rewards/rejected": -3.0109927654266357,
      "step": 11240
    },
    {
      "epoch": 1.8886279771888628,
      "grad_norm": 5.987842559814453,
      "learning_rate": 1.8548026389354802e-05,
      "logits/chosen": 2.641594171524048,
      "logits/rejected": 2.9020516872406006,
      "logps/chosen": -207.952880859375,
      "logps/rejected": -200.0771026611328,
      "loss": 0.5074,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.735914945602417,
      "rewards/margins": 1.072585105895996,
      "rewards/rejected": -2.808500051498413,
      "step": 11260
    },
    {
      "epoch": 1.8919825561891983,
      "grad_norm": 3.2732105255126953,
      "learning_rate": 1.8492116739349214e-05,
      "logits/chosen": 2.5380988121032715,
      "logits/rejected": 2.8003740310668945,
      "logps/chosen": -209.6057586669922,
      "logps/rejected": -206.94775390625,
      "loss": 0.4258,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6070263385772705,
      "rewards/margins": 1.463896632194519,
      "rewards/rejected": -3.070922613143921,
      "step": 11280
    },
    {
      "epoch": 1.8953371351895338,
      "grad_norm": 2.8196537494659424,
      "learning_rate": 1.843620708934362e-05,
      "logits/chosen": 2.5152010917663574,
      "logits/rejected": 2.731452226638794,
      "logps/chosen": -209.2985382080078,
      "logps/rejected": -193.0224609375,
      "loss": 0.3871,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6260483264923096,
      "rewards/margins": 1.4029741287231445,
      "rewards/rejected": -3.029022216796875,
      "step": 11300
    },
    {
      "epoch": 1.8986917141898692,
      "grad_norm": 6.018666744232178,
      "learning_rate": 1.8380297439338032e-05,
      "logits/chosen": 2.5896449089050293,
      "logits/rejected": 2.832639455795288,
      "logps/chosen": -219.34945678710938,
      "logps/rejected": -203.34568786621094,
      "loss": 0.3965,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.249492883682251,
      "rewards/margins": 1.4249248504638672,
      "rewards/rejected": -2.6744179725646973,
      "step": 11320
    },
    {
      "epoch": 1.9020462931902047,
      "grad_norm": 3.4977195262908936,
      "learning_rate": 1.832438778933244e-05,
      "logits/chosen": 2.339787483215332,
      "logits/rejected": 2.627784252166748,
      "logps/chosen": -208.0589599609375,
      "logps/rejected": -194.05349731445312,
      "loss": 0.4075,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5406931638717651,
      "rewards/margins": 1.6479082107543945,
      "rewards/rejected": -3.18860125541687,
      "step": 11340
    },
    {
      "epoch": 1.90540087219054,
      "grad_norm": 2.0622620582580566,
      "learning_rate": 1.826847813932685e-05,
      "logits/chosen": 2.592808723449707,
      "logits/rejected": 2.7830281257629395,
      "logps/chosen": -194.18077087402344,
      "logps/rejected": -185.47178649902344,
      "loss": 0.4589,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.628064513206482,
      "rewards/margins": 1.2990621328353882,
      "rewards/rejected": -2.92712664604187,
      "step": 11360
    },
    {
      "epoch": 1.9087554511908755,
      "grad_norm": 2.264758825302124,
      "learning_rate": 1.821256848932126e-05,
      "logits/chosen": 2.657346248626709,
      "logits/rejected": 2.727656841278076,
      "logps/chosen": -198.60769653320312,
      "logps/rejected": -199.2715301513672,
      "loss": 0.5552,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9834213256835938,
      "rewards/margins": 1.093402624130249,
      "rewards/rejected": -3.0768237113952637,
      "step": 11380
    },
    {
      "epoch": 1.912110030191211,
      "grad_norm": 4.140563488006592,
      "learning_rate": 1.8156658839315664e-05,
      "logits/chosen": 2.666464328765869,
      "logits/rejected": 2.743473529815674,
      "logps/chosen": -217.3455810546875,
      "logps/rejected": -217.188232421875,
      "loss": 0.4384,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8012678623199463,
      "rewards/margins": 1.2014471292495728,
      "rewards/rejected": -3.0027148723602295,
      "step": 11400
    },
    {
      "epoch": 1.9154646091915466,
      "grad_norm": 1.6280159950256348,
      "learning_rate": 1.8100749189310077e-05,
      "logits/chosen": 2.515453815460205,
      "logits/rejected": 2.651045799255371,
      "logps/chosen": -209.701171875,
      "logps/rejected": -205.44723510742188,
      "loss": 0.4135,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.600442886352539,
      "rewards/margins": 1.4165772199630737,
      "rewards/rejected": -3.0170199871063232,
      "step": 11420
    },
    {
      "epoch": 1.918819188191882,
      "grad_norm": 3.9881949424743652,
      "learning_rate": 1.8044839539304485e-05,
      "logits/chosen": 2.779371738433838,
      "logits/rejected": 2.9757132530212402,
      "logps/chosen": -224.96923828125,
      "logps/rejected": -215.4716796875,
      "loss": 0.376,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9059035778045654,
      "rewards/margins": 1.438507080078125,
      "rewards/rejected": -3.3444106578826904,
      "step": 11440
    },
    {
      "epoch": 1.9221737671922172,
      "grad_norm": 2.6147665977478027,
      "learning_rate": 1.7988929889298894e-05,
      "logits/chosen": 2.508488416671753,
      "logits/rejected": 2.701113224029541,
      "logps/chosen": -215.0072479248047,
      "logps/rejected": -203.74896240234375,
      "loss": 0.5039,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.131399393081665,
      "rewards/margins": 1.2124327421188354,
      "rewards/rejected": -3.343832015991211,
      "step": 11460
    },
    {
      "epoch": 1.9255283461925528,
      "grad_norm": 6.579815864562988,
      "learning_rate": 1.7933020239293303e-05,
      "logits/chosen": 2.606816053390503,
      "logits/rejected": 2.849050283432007,
      "logps/chosen": -207.9679412841797,
      "logps/rejected": -212.40902709960938,
      "loss": 0.5096,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.129668712615967,
      "rewards/margins": 1.3177220821380615,
      "rewards/rejected": -3.4473907947540283,
      "step": 11480
    },
    {
      "epoch": 1.9288829251928883,
      "grad_norm": 5.9812211990356445,
      "learning_rate": 1.7877110589287712e-05,
      "logits/chosen": 2.301074504852295,
      "logits/rejected": 2.497659683227539,
      "logps/chosen": -209.82943725585938,
      "logps/rejected": -215.43984985351562,
      "loss": 0.5937,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.3179383277893066,
      "rewards/margins": 0.9579257965087891,
      "rewards/rejected": -3.275864362716675,
      "step": 11500
    },
    {
      "epoch": 1.9322375041932238,
      "grad_norm": 4.631689071655273,
      "learning_rate": 1.782120093928212e-05,
      "logits/chosen": 2.5444631576538086,
      "logits/rejected": 2.764681577682495,
      "logps/chosen": -220.929443359375,
      "logps/rejected": -216.4975128173828,
      "loss": 0.4611,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7457389831542969,
      "rewards/margins": 1.205243468284607,
      "rewards/rejected": -2.9509825706481934,
      "step": 11520
    },
    {
      "epoch": 1.9355920831935594,
      "grad_norm": 2.380862236022949,
      "learning_rate": 1.776529128927653e-05,
      "logits/chosen": 2.5878188610076904,
      "logits/rejected": 2.7957653999328613,
      "logps/chosen": -215.66055297851562,
      "logps/rejected": -208.8245086669922,
      "loss": 0.4852,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7898643016815186,
      "rewards/margins": 1.288266897201538,
      "rewards/rejected": -3.0781311988830566,
      "step": 11540
    },
    {
      "epoch": 1.9389466621938947,
      "grad_norm": 4.355412006378174,
      "learning_rate": 1.770938163927094e-05,
      "logits/chosen": 2.5532429218292236,
      "logits/rejected": 2.699798345565796,
      "logps/chosen": -207.97293090820312,
      "logps/rejected": -202.24417114257812,
      "loss": 0.467,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.39919912815094,
      "rewards/margins": 1.0985512733459473,
      "rewards/rejected": -2.4977505207061768,
      "step": 11560
    },
    {
      "epoch": 1.94230124119423,
      "grad_norm": 3.5938901901245117,
      "learning_rate": 1.7653471989265348e-05,
      "logits/chosen": 2.793376922607422,
      "logits/rejected": 3.0678536891937256,
      "logps/chosen": -201.8268280029297,
      "logps/rejected": -192.8931427001953,
      "loss": 0.3876,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.734653115272522,
      "rewards/margins": 1.525813341140747,
      "rewards/rejected": -3.2604663372039795,
      "step": 11580
    },
    {
      "epoch": 1.9456558201945655,
      "grad_norm": 1.98228120803833,
      "learning_rate": 1.7597562339259757e-05,
      "logits/chosen": 2.6918179988861084,
      "logits/rejected": 2.844679355621338,
      "logps/chosen": -214.76272583007812,
      "logps/rejected": -203.11614990234375,
      "loss": 0.4028,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2662779092788696,
      "rewards/margins": 1.5030931234359741,
      "rewards/rejected": -2.7693707942962646,
      "step": 11600
    },
    {
      "epoch": 1.949010399194901,
      "grad_norm": 2.9886038303375244,
      "learning_rate": 1.7541652689254166e-05,
      "logits/chosen": 2.6613833904266357,
      "logits/rejected": 2.9664008617401123,
      "logps/chosen": -219.8482666015625,
      "logps/rejected": -205.94979858398438,
      "loss": 0.3624,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.1179267168045044,
      "rewards/margins": 1.4094352722167969,
      "rewards/rejected": -2.527362108230591,
      "step": 11620
    },
    {
      "epoch": 1.9523649781952366,
      "grad_norm": 0.8564455509185791,
      "learning_rate": 1.7485743039248575e-05,
      "logits/chosen": 2.736640214920044,
      "logits/rejected": 3.022918224334717,
      "logps/chosen": -225.3103790283203,
      "logps/rejected": -214.561279296875,
      "loss": 0.4299,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.0986262559890747,
      "rewards/margins": 1.4159259796142578,
      "rewards/rejected": -2.514552354812622,
      "step": 11640
    },
    {
      "epoch": 1.9557195571955721,
      "grad_norm": 2.5636446475982666,
      "learning_rate": 1.7429833389242984e-05,
      "logits/chosen": 2.520904064178467,
      "logits/rejected": 2.714540958404541,
      "logps/chosen": -203.58128356933594,
      "logps/rejected": -200.30447387695312,
      "loss": 0.4531,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3279235363006592,
      "rewards/margins": 1.1533114910125732,
      "rewards/rejected": -2.4812350273132324,
      "step": 11660
    },
    {
      "epoch": 1.9590741361959074,
      "grad_norm": 3.2133305072784424,
      "learning_rate": 1.7373923739237392e-05,
      "logits/chosen": 2.627642869949341,
      "logits/rejected": 2.8593859672546387,
      "logps/chosen": -197.28457641601562,
      "logps/rejected": -196.2393035888672,
      "loss": 0.4479,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1837420463562012,
      "rewards/margins": 1.543114185333252,
      "rewards/rejected": -2.726855993270874,
      "step": 11680
    },
    {
      "epoch": 1.9624287151962427,
      "grad_norm": 3.937763214111328,
      "learning_rate": 1.73180140892318e-05,
      "logits/chosen": 2.6079776287078857,
      "logits/rejected": 2.8746001720428467,
      "logps/chosen": -197.77810668945312,
      "logps/rejected": -196.79226684570312,
      "loss": 0.4029,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.0325348377227783,
      "rewards/margins": 1.4839403629302979,
      "rewards/rejected": -2.516475200653076,
      "step": 11700
    },
    {
      "epoch": 1.9657832941965783,
      "grad_norm": 1.8883880376815796,
      "learning_rate": 1.7262104439226214e-05,
      "logits/chosen": 2.647050142288208,
      "logits/rejected": 2.831631660461426,
      "logps/chosen": -219.20578002929688,
      "logps/rejected": -208.935302734375,
      "loss": 0.4567,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5492017269134521,
      "rewards/margins": 1.3267256021499634,
      "rewards/rejected": -2.875927448272705,
      "step": 11720
    },
    {
      "epoch": 1.9691378731969138,
      "grad_norm": 3.400331497192383,
      "learning_rate": 1.720619478922062e-05,
      "logits/chosen": 2.6814751625061035,
      "logits/rejected": 2.8603463172912598,
      "logps/chosen": -200.18980407714844,
      "logps/rejected": -207.3199462890625,
      "loss": 0.4009,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.355684518814087,
      "rewards/margins": 1.3565694093704224,
      "rewards/rejected": -2.712254047393799,
      "step": 11740
    },
    {
      "epoch": 1.9724924521972493,
      "grad_norm": 3.566375970840454,
      "learning_rate": 1.715028513921503e-05,
      "logits/chosen": 2.5900955200195312,
      "logits/rejected": 2.860806703567505,
      "logps/chosen": -218.25326538085938,
      "logps/rejected": -197.6920928955078,
      "loss": 0.4693,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3293120861053467,
      "rewards/margins": 1.261643648147583,
      "rewards/rejected": -2.590955972671509,
      "step": 11760
    },
    {
      "epoch": 1.9758470311975849,
      "grad_norm": 3.930243730545044,
      "learning_rate": 1.7094375489209437e-05,
      "logits/chosen": 2.597280979156494,
      "logits/rejected": 2.9602396488189697,
      "logps/chosen": -203.57264709472656,
      "logps/rejected": -198.63650512695312,
      "loss": 0.4465,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6599632501602173,
      "rewards/margins": 1.4190187454223633,
      "rewards/rejected": -3.078981876373291,
      "step": 11780
    },
    {
      "epoch": 1.9792016101979202,
      "grad_norm": 3.5298924446105957,
      "learning_rate": 1.703846583920385e-05,
      "logits/chosen": 2.5155656337738037,
      "logits/rejected": 2.7377800941467285,
      "logps/chosen": -207.7029571533203,
      "logps/rejected": -189.9972381591797,
      "loss": 0.5257,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5931578874588013,
      "rewards/margins": 1.1935726404190063,
      "rewards/rejected": -2.7867305278778076,
      "step": 11800
    },
    {
      "epoch": 1.9825561891982555,
      "grad_norm": 1.3885197639465332,
      "learning_rate": 1.6982556189198255e-05,
      "logits/chosen": 2.7906646728515625,
      "logits/rejected": 2.978667736053467,
      "logps/chosen": -223.64755249023438,
      "logps/rejected": -213.0089874267578,
      "loss": 0.485,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7231467962265015,
      "rewards/margins": 1.1530388593673706,
      "rewards/rejected": -2.876185655593872,
      "step": 11820
    },
    {
      "epoch": 1.985910768198591,
      "grad_norm": 5.560853004455566,
      "learning_rate": 1.6926646539192664e-05,
      "logits/chosen": 2.478708505630493,
      "logits/rejected": 2.8178153038024902,
      "logps/chosen": -208.17770385742188,
      "logps/rejected": -222.41647338867188,
      "loss": 0.4183,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7333284616470337,
      "rewards/margins": 1.414400339126587,
      "rewards/rejected": -3.14772891998291,
      "step": 11840
    },
    {
      "epoch": 1.9892653471989266,
      "grad_norm": 2.686267137527466,
      "learning_rate": 1.6870736889187076e-05,
      "logits/chosen": 2.626532793045044,
      "logits/rejected": 2.8889269828796387,
      "logps/chosen": -199.86190795898438,
      "logps/rejected": -184.42208862304688,
      "loss": 0.4705,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.051534414291382,
      "rewards/margins": 1.1821273565292358,
      "rewards/rejected": -3.2336621284484863,
      "step": 11860
    },
    {
      "epoch": 1.992619926199262,
      "grad_norm": 4.844263553619385,
      "learning_rate": 1.681482723918148e-05,
      "logits/chosen": 2.656094551086426,
      "logits/rejected": 2.8143858909606934,
      "logps/chosen": -209.94619750976562,
      "logps/rejected": -206.91629028320312,
      "loss": 0.5384,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.465341567993164,
      "rewards/margins": 1.0723702907562256,
      "rewards/rejected": -2.5377116203308105,
      "step": 11880
    },
    {
      "epoch": 1.9959745051995974,
      "grad_norm": 3.0626578330993652,
      "learning_rate": 1.6758917589175894e-05,
      "logits/chosen": 2.545567035675049,
      "logits/rejected": 2.8028817176818848,
      "logps/chosen": -209.53567504882812,
      "logps/rejected": -210.2661895751953,
      "loss": 0.4093,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4789021015167236,
      "rewards/margins": 1.4226030111312866,
      "rewards/rejected": -2.901505470275879,
      "step": 11900
    },
    {
      "epoch": 1.999329084199933,
      "grad_norm": 2.3582684993743896,
      "learning_rate": 1.67030079391703e-05,
      "logits/chosen": 2.633913040161133,
      "logits/rejected": 2.9456024169921875,
      "logps/chosen": -212.1994171142578,
      "logps/rejected": -213.3050537109375,
      "loss": 0.4317,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8353443145751953,
      "rewards/margins": 1.3851823806762695,
      "rewards/rejected": -3.220526933670044,
      "step": 11920
    },
    {
      "epoch": 2.0026836632002682,
      "grad_norm": 2.9020040035247803,
      "learning_rate": 1.6647098289164712e-05,
      "logits/chosen": 2.6868884563446045,
      "logits/rejected": 2.9097466468811035,
      "logps/chosen": -207.9815216064453,
      "logps/rejected": -210.4921875,
      "loss": 0.3099,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.9042737483978271,
      "rewards/margins": 1.9162832498550415,
      "rewards/rejected": -3.8205573558807373,
      "step": 11940
    },
    {
      "epoch": 2.006038242200604,
      "grad_norm": 1.1602731943130493,
      "learning_rate": 1.659118863915912e-05,
      "logits/chosen": 2.5623090267181396,
      "logits/rejected": 2.965089797973633,
      "logps/chosen": -186.635498046875,
      "logps/rejected": -189.5491943359375,
      "loss": 0.263,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.5111305713653564,
      "rewards/margins": 2.0917742252349854,
      "rewards/rejected": -3.602904796600342,
      "step": 11960
    },
    {
      "epoch": 2.0093928212009393,
      "grad_norm": 3.344815492630005,
      "learning_rate": 1.653527898915353e-05,
      "logits/chosen": 2.6240458488464355,
      "logits/rejected": 3.005195379257202,
      "logps/chosen": -206.7838592529297,
      "logps/rejected": -205.10739135742188,
      "loss": 0.2706,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.8701318502426147,
      "rewards/margins": 2.119171619415283,
      "rewards/rejected": -3.9893035888671875,
      "step": 11980
    },
    {
      "epoch": 2.012747400201275,
      "grad_norm": 3.2736611366271973,
      "learning_rate": 1.647936933914794e-05,
      "logits/chosen": 2.603940486907959,
      "logits/rejected": 2.8319430351257324,
      "logps/chosen": -205.0341796875,
      "logps/rejected": -209.3900604248047,
      "loss": 0.2802,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.9008255004882812,
      "rewards/margins": 1.7102025747299194,
      "rewards/rejected": -3.6110281944274902,
      "step": 12000
    },
    {
      "epoch": 2.0161019792016104,
      "grad_norm": 0.3738170862197876,
      "learning_rate": 1.6423459689142347e-05,
      "logits/chosen": 2.463078022003174,
      "logits/rejected": 2.730968475341797,
      "logps/chosen": -209.4690704345703,
      "logps/rejected": -206.2896270751953,
      "loss": 0.2826,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.8541663885116577,
      "rewards/margins": 1.8108928203582764,
      "rewards/rejected": -3.6650595664978027,
      "step": 12020
    },
    {
      "epoch": 2.0194565582019455,
      "grad_norm": 6.097513198852539,
      "learning_rate": 1.6367550039136756e-05,
      "logits/chosen": 2.7252116203308105,
      "logits/rejected": 2.8989367485046387,
      "logps/chosen": -204.52584838867188,
      "logps/rejected": -211.9304656982422,
      "loss": 0.3842,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.013319492340088,
      "rewards/margins": 1.4438679218292236,
      "rewards/rejected": -3.4571871757507324,
      "step": 12040
    },
    {
      "epoch": 2.022811137202281,
      "grad_norm": 2.200322151184082,
      "learning_rate": 1.6311640389131165e-05,
      "logits/chosen": 2.670381546020508,
      "logits/rejected": 3.0887210369110107,
      "logps/chosen": -208.49032592773438,
      "logps/rejected": -206.46316528320312,
      "loss": 0.2118,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -1.5781878232955933,
      "rewards/margins": 2.3579633235931396,
      "rewards/rejected": -3.9361510276794434,
      "step": 12060
    },
    {
      "epoch": 2.0261657162026165,
      "grad_norm": 3.4048354625701904,
      "learning_rate": 1.6255730739125574e-05,
      "logits/chosen": 2.63042950630188,
      "logits/rejected": 2.84704852104187,
      "logps/chosen": -203.59573364257812,
      "logps/rejected": -204.81503295898438,
      "loss": 0.3308,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9703925848007202,
      "rewards/margins": 1.7516762018203735,
      "rewards/rejected": -3.7220687866210938,
      "step": 12080
    },
    {
      "epoch": 2.029520295202952,
      "grad_norm": 5.7344489097595215,
      "learning_rate": 1.6199821089119983e-05,
      "logits/chosen": 2.487597942352295,
      "logits/rejected": 2.678758382797241,
      "logps/chosen": -208.3325958251953,
      "logps/rejected": -216.81320190429688,
      "loss": 0.3217,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9625076055526733,
      "rewards/margins": 1.888517141342163,
      "rewards/rejected": -3.851025342941284,
      "step": 12100
    },
    {
      "epoch": 2.0328748742032876,
      "grad_norm": 0.997012197971344,
      "learning_rate": 1.6143911439114392e-05,
      "logits/chosen": 2.586270570755005,
      "logits/rejected": 2.8349149227142334,
      "logps/chosen": -215.61331176757812,
      "logps/rejected": -203.68846130371094,
      "loss": 0.2959,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.859925627708435,
      "rewards/margins": 1.7908046245574951,
      "rewards/rejected": -3.650730609893799,
      "step": 12120
    },
    {
      "epoch": 2.036229453203623,
      "grad_norm": 2.13704252243042,
      "learning_rate": 1.60880017891088e-05,
      "logits/chosen": 2.490813970565796,
      "logits/rejected": 2.8792898654937744,
      "logps/chosen": -230.75390625,
      "logps/rejected": -202.5989990234375,
      "loss": 0.2467,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.842638611793518,
      "rewards/margins": 2.100430488586426,
      "rewards/rejected": -3.9430694580078125,
      "step": 12140
    },
    {
      "epoch": 2.0395840322039582,
      "grad_norm": 1.4090321063995361,
      "learning_rate": 1.603209213910321e-05,
      "logits/chosen": 2.371032238006592,
      "logits/rejected": 2.609729290008545,
      "logps/chosen": -206.98226928710938,
      "logps/rejected": -217.86715698242188,
      "loss": 0.3967,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2020838260650635,
      "rewards/margins": 1.7216047048568726,
      "rewards/rejected": -3.9236884117126465,
      "step": 12160
    },
    {
      "epoch": 2.0429386112042938,
      "grad_norm": 1.6314691305160522,
      "learning_rate": 1.597618248909762e-05,
      "logits/chosen": 2.444016933441162,
      "logits/rejected": 2.6709885597229004,
      "logps/chosen": -222.41439819335938,
      "logps/rejected": -246.4531707763672,
      "loss": 0.2533,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.055510997772217,
      "rewards/margins": 2.2194113731384277,
      "rewards/rejected": -4.2749223709106445,
      "step": 12180
    },
    {
      "epoch": 2.0462931902046293,
      "grad_norm": 0.7341145277023315,
      "learning_rate": 1.5920272839092028e-05,
      "logits/chosen": 2.414412021636963,
      "logits/rejected": 2.643493890762329,
      "logps/chosen": -215.5511474609375,
      "logps/rejected": -217.13931274414062,
      "loss": 0.2546,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.091632604598999,
      "rewards/margins": 1.932727575302124,
      "rewards/rejected": -4.024360179901123,
      "step": 12200
    },
    {
      "epoch": 2.049647769204965,
      "grad_norm": 3.2061569690704346,
      "learning_rate": 1.5864363189086437e-05,
      "logits/chosen": 2.4263672828674316,
      "logits/rejected": 2.8129844665527344,
      "logps/chosen": -205.93319702148438,
      "logps/rejected": -201.66812133789062,
      "loss": 0.3026,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.33504056930542,
      "rewards/margins": 1.9886459112167358,
      "rewards/rejected": -4.3236870765686035,
      "step": 12220
    },
    {
      "epoch": 2.0530023482053004,
      "grad_norm": 2.3534255027770996,
      "learning_rate": 1.580845353908085e-05,
      "logits/chosen": 2.381521701812744,
      "logits/rejected": 2.586909055709839,
      "logps/chosen": -214.027587890625,
      "logps/rejected": -223.2900848388672,
      "loss": 0.2883,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.9636356830596924,
      "rewards/margins": 1.8926423788070679,
      "rewards/rejected": -3.8562779426574707,
      "step": 12240
    },
    {
      "epoch": 2.056356927205636,
      "grad_norm": 1.076102614402771,
      "learning_rate": 1.5752543889075254e-05,
      "logits/chosen": 2.457343578338623,
      "logits/rejected": 2.9068057537078857,
      "logps/chosen": -217.7945556640625,
      "logps/rejected": -199.8261260986328,
      "loss": 0.2714,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.2317564487457275,
      "rewards/margins": 2.1371426582336426,
      "rewards/rejected": -4.368899345397949,
      "step": 12260
    },
    {
      "epoch": 2.059711506205971,
      "grad_norm": 3.659116268157959,
      "learning_rate": 1.5696634239069663e-05,
      "logits/chosen": 2.534167766571045,
      "logits/rejected": 2.734152317047119,
      "logps/chosen": -218.53085327148438,
      "logps/rejected": -220.7458038330078,
      "loss": 0.3393,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.0993149280548096,
      "rewards/margins": 1.583595871925354,
      "rewards/rejected": -3.682910919189453,
      "step": 12280
    },
    {
      "epoch": 2.0630660852063065,
      "grad_norm": 6.700272083282471,
      "learning_rate": 1.5640724589064072e-05,
      "logits/chosen": 2.375499725341797,
      "logits/rejected": 2.6189582347869873,
      "logps/chosen": -199.70742797851562,
      "logps/rejected": -205.76077270507812,
      "loss": 0.3104,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2333693504333496,
      "rewards/margins": 2.014315128326416,
      "rewards/rejected": -4.247684478759766,
      "step": 12300
    },
    {
      "epoch": 2.066420664206642,
      "grad_norm": 1.6763442754745483,
      "learning_rate": 1.558481493905848e-05,
      "logits/chosen": 2.3374416828155518,
      "logits/rejected": 2.7438180446624756,
      "logps/chosen": -205.5355224609375,
      "logps/rejected": -195.66281127929688,
      "loss": 0.2833,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.821668267250061,
      "rewards/margins": 2.089362382888794,
      "rewards/rejected": -3.9110305309295654,
      "step": 12320
    },
    {
      "epoch": 2.0697752432069776,
      "grad_norm": 1.7931498289108276,
      "learning_rate": 1.5528905289052894e-05,
      "logits/chosen": 2.382445812225342,
      "logits/rejected": 2.7190029621124268,
      "logps/chosen": -215.2855682373047,
      "logps/rejected": -209.3388214111328,
      "loss": 0.2939,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.178450107574463,
      "rewards/margins": 1.9608066082000732,
      "rewards/rejected": -4.139256954193115,
      "step": 12340
    },
    {
      "epoch": 2.073129822207313,
      "grad_norm": 3.0827150344848633,
      "learning_rate": 1.54729956390473e-05,
      "logits/chosen": 2.486983299255371,
      "logits/rejected": 2.8460707664489746,
      "logps/chosen": -216.58078002929688,
      "logps/rejected": -209.45263671875,
      "loss": 0.2947,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.0369622707366943,
      "rewards/margins": 2.0876660346984863,
      "rewards/rejected": -4.12462854385376,
      "step": 12360
    },
    {
      "epoch": 2.076484401207648,
      "grad_norm": 1.7117544412612915,
      "learning_rate": 1.541708598904171e-05,
      "logits/chosen": 2.3880746364593506,
      "logits/rejected": 2.6829376220703125,
      "logps/chosen": -222.1835479736328,
      "logps/rejected": -218.9138641357422,
      "loss": 0.3422,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.0928168296813965,
      "rewards/margins": 2.2529218196868896,
      "rewards/rejected": -4.345738887786865,
      "step": 12380
    },
    {
      "epoch": 2.0798389802079837,
      "grad_norm": 2.6430444717407227,
      "learning_rate": 1.5361176339036117e-05,
      "logits/chosen": 2.644779682159424,
      "logits/rejected": 3.0631191730499268,
      "logps/chosen": -215.84603881835938,
      "logps/rejected": -210.84249877929688,
      "loss": 0.2657,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.080435037612915,
      "rewards/margins": 2.161174774169922,
      "rewards/rejected": -4.241610050201416,
      "step": 12400
    },
    {
      "epoch": 2.0831935592083193,
      "grad_norm": 2.574577808380127,
      "learning_rate": 1.530526668903053e-05,
      "logits/chosen": 2.670076370239258,
      "logits/rejected": 2.870136022567749,
      "logps/chosen": -222.4231719970703,
      "logps/rejected": -225.7505340576172,
      "loss": 0.3605,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.172184467315674,
      "rewards/margins": 1.8521862030029297,
      "rewards/rejected": -4.0243706703186035,
      "step": 12420
    },
    {
      "epoch": 2.086548138208655,
      "grad_norm": 2.651746988296509,
      "learning_rate": 1.5249357039024936e-05,
      "logits/chosen": 2.2537121772766113,
      "logits/rejected": 2.4674556255340576,
      "logps/chosen": -208.7537841796875,
      "logps/rejected": -204.53482055664062,
      "loss": 0.3184,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.017519474029541,
      "rewards/margins": 1.7642974853515625,
      "rewards/rejected": -3.7818171977996826,
      "step": 12440
    },
    {
      "epoch": 2.0899027172089903,
      "grad_norm": 3.505215644836426,
      "learning_rate": 1.5193447389019347e-05,
      "logits/chosen": 2.4706666469573975,
      "logits/rejected": 2.821232318878174,
      "logps/chosen": -215.6307373046875,
      "logps/rejected": -194.8341827392578,
      "loss": 0.3022,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.9941976070404053,
      "rewards/margins": 1.9142825603485107,
      "rewards/rejected": -3.908480167388916,
      "step": 12460
    },
    {
      "epoch": 2.093257296209326,
      "grad_norm": 1.5230439901351929,
      "learning_rate": 1.5137537739013754e-05,
      "logits/chosen": 2.4558768272399902,
      "logits/rejected": 2.662473201751709,
      "logps/chosen": -195.7609405517578,
      "logps/rejected": -202.68804931640625,
      "loss": 0.4284,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.240262508392334,
      "rewards/margins": 1.50034499168396,
      "rewards/rejected": -3.740607738494873,
      "step": 12480
    },
    {
      "epoch": 2.0966118752096614,
      "grad_norm": 2.3115248680114746,
      "learning_rate": 1.5081628089008163e-05,
      "logits/chosen": 2.699017286300659,
      "logits/rejected": 2.7867939472198486,
      "logps/chosen": -224.3721923828125,
      "logps/rejected": -227.7612762451172,
      "loss": 0.2399,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.635854721069336,
      "rewards/margins": 2.02453875541687,
      "rewards/rejected": -3.660393476486206,
      "step": 12500
    },
    {
      "epoch": 2.0999664542099965,
      "grad_norm": 2.3050642013549805,
      "learning_rate": 1.5025718439002574e-05,
      "logits/chosen": 2.459026336669922,
      "logits/rejected": 2.771322250366211,
      "logps/chosen": -203.38607788085938,
      "logps/rejected": -201.16513061523438,
      "loss": 0.21,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.4454559087753296,
      "rewards/margins": 2.294100522994995,
      "rewards/rejected": -3.7395565509796143,
      "step": 12520
    },
    {
      "epoch": 2.103321033210332,
      "grad_norm": 2.1031713485717773,
      "learning_rate": 1.4969808788996981e-05,
      "logits/chosen": 2.5861897468566895,
      "logits/rejected": 2.6841166019439697,
      "logps/chosen": -211.63571166992188,
      "logps/rejected": -211.3906707763672,
      "loss": 0.2889,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.8524925708770752,
      "rewards/margins": 1.861908197402954,
      "rewards/rejected": -3.7144007682800293,
      "step": 12540
    },
    {
      "epoch": 2.1066756122106676,
      "grad_norm": 1.2963398694992065,
      "learning_rate": 1.4913899138991392e-05,
      "logits/chosen": 2.506218194961548,
      "logits/rejected": 2.796591281890869,
      "logps/chosen": -206.5015106201172,
      "logps/rejected": -200.3276824951172,
      "loss": 0.2916,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.0842597484588623,
      "rewards/margins": 1.9978358745574951,
      "rewards/rejected": -4.082095623016357,
      "step": 12560
    },
    {
      "epoch": 2.110030191211003,
      "grad_norm": 3.093430757522583,
      "learning_rate": 1.4857989488985799e-05,
      "logits/chosen": 2.37977933883667,
      "logits/rejected": 2.565574884414673,
      "logps/chosen": -218.6142578125,
      "logps/rejected": -214.3378448486328,
      "loss": 0.3122,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1884281635284424,
      "rewards/margins": 1.9368242025375366,
      "rewards/rejected": -4.125252723693848,
      "step": 12580
    },
    {
      "epoch": 2.1133847702113386,
      "grad_norm": 2.955641984939575,
      "learning_rate": 1.480207983898021e-05,
      "logits/chosen": 2.395895004272461,
      "logits/rejected": 2.7158284187316895,
      "logps/chosen": -221.3905792236328,
      "logps/rejected": -222.69302368164062,
      "loss": 0.2292,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -2.200052261352539,
      "rewards/margins": 2.208282709121704,
      "rewards/rejected": -4.408334732055664,
      "step": 12600
    },
    {
      "epoch": 2.1167393492116737,
      "grad_norm": 0.48441827297210693,
      "learning_rate": 1.4746170188974617e-05,
      "logits/chosen": 2.2796082496643066,
      "logits/rejected": 2.616830825805664,
      "logps/chosen": -208.2842254638672,
      "logps/rejected": -205.5529327392578,
      "loss": 0.2782,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7206001281738281,
      "rewards/margins": 2.1565005779266357,
      "rewards/rejected": -3.877100706100464,
      "step": 12620
    },
    {
      "epoch": 2.1200939282120093,
      "grad_norm": 3.9840497970581055,
      "learning_rate": 1.4690260538969027e-05,
      "logits/chosen": 2.4160542488098145,
      "logits/rejected": 2.557896137237549,
      "logps/chosen": -216.73489379882812,
      "logps/rejected": -225.29525756835938,
      "loss": 0.2607,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.674740195274353,
      "rewards/margins": 2.2414612770080566,
      "rewards/rejected": -3.91620135307312,
      "step": 12640
    },
    {
      "epoch": 2.123448507212345,
      "grad_norm": 4.988081932067871,
      "learning_rate": 1.4634350888963436e-05,
      "logits/chosen": 2.3335092067718506,
      "logits/rejected": 2.6245853900909424,
      "logps/chosen": -224.798583984375,
      "logps/rejected": -222.3765869140625,
      "loss": 0.2324,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6120452880859375,
      "rewards/margins": 2.261028528213501,
      "rewards/rejected": -3.8730742931365967,
      "step": 12660
    },
    {
      "epoch": 2.1268030862126803,
      "grad_norm": 2.9709384441375732,
      "learning_rate": 1.4578441238957847e-05,
      "logits/chosen": 2.138627767562866,
      "logits/rejected": 2.4332690238952637,
      "logps/chosen": -199.06820678710938,
      "logps/rejected": -200.95254516601562,
      "loss": 0.3004,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.1097846031188965,
      "rewards/margins": 1.7833560705184937,
      "rewards/rejected": -3.8931407928466797,
      "step": 12680
    },
    {
      "epoch": 2.130157665213016,
      "grad_norm": 2.372605085372925,
      "learning_rate": 1.4522531588952254e-05,
      "logits/chosen": 2.3234150409698486,
      "logits/rejected": 2.54567289352417,
      "logps/chosen": -202.27725219726562,
      "logps/rejected": -225.233642578125,
      "loss": 0.3053,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2128043174743652,
      "rewards/margins": 2.1392271518707275,
      "rewards/rejected": -4.352031230926514,
      "step": 12700
    },
    {
      "epoch": 2.1335122442133514,
      "grad_norm": 1.277143120765686,
      "learning_rate": 1.4466621938946661e-05,
      "logits/chosen": 2.339092969894409,
      "logits/rejected": 2.721623420715332,
      "logps/chosen": -206.2726593017578,
      "logps/rejected": -205.4839630126953,
      "loss": 0.2212,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.0680928230285645,
      "rewards/margins": 2.2821109294891357,
      "rewards/rejected": -4.350203514099121,
      "step": 12720
    },
    {
      "epoch": 2.1368668232136865,
      "grad_norm": 1.4806010723114014,
      "learning_rate": 1.4410712288941072e-05,
      "logits/chosen": 2.0265679359436035,
      "logits/rejected": 2.3943521976470947,
      "logps/chosen": -218.4769287109375,
      "logps/rejected": -201.08554077148438,
      "loss": 0.3236,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.958636999130249,
      "rewards/margins": 2.0840275287628174,
      "rewards/rejected": -4.042665004730225,
      "step": 12740
    },
    {
      "epoch": 2.140221402214022,
      "grad_norm": 1.230622410774231,
      "learning_rate": 1.435480263893548e-05,
      "logits/chosen": 2.2049145698547363,
      "logits/rejected": 2.4595823287963867,
      "logps/chosen": -207.83935546875,
      "logps/rejected": -222.413330078125,
      "loss": 0.2878,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.3589961528778076,
      "rewards/margins": 1.716538667678833,
      "rewards/rejected": -4.075534820556641,
      "step": 12760
    },
    {
      "epoch": 2.1435759812143576,
      "grad_norm": 1.2771234512329102,
      "learning_rate": 1.4298892988929891e-05,
      "logits/chosen": 2.2101590633392334,
      "logits/rejected": 2.539386749267578,
      "logps/chosen": -208.7332763671875,
      "logps/rejected": -213.36288452148438,
      "loss": 0.2081,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8144874572753906,
      "rewards/margins": 2.492600202560425,
      "rewards/rejected": -4.3070878982543945,
      "step": 12780
    },
    {
      "epoch": 2.146930560214693,
      "grad_norm": 1.3384567499160767,
      "learning_rate": 1.4242983338924299e-05,
      "logits/chosen": 2.2863826751708984,
      "logits/rejected": 2.6291046142578125,
      "logps/chosen": -206.8459014892578,
      "logps/rejected": -200.32765197753906,
      "loss": 0.3057,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.812931537628174,
      "rewards/margins": 2.0328433513641357,
      "rewards/rejected": -4.8457746505737305,
      "step": 12800
    },
    {
      "epoch": 2.1502851392150286,
      "grad_norm": 0.6770272850990295,
      "learning_rate": 1.418707368891871e-05,
      "logits/chosen": 2.220215320587158,
      "logits/rejected": 2.481806516647339,
      "logps/chosen": -199.06948852539062,
      "logps/rejected": -199.94874572753906,
      "loss": 0.2876,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1424601078033447,
      "rewards/margins": 1.9797852039337158,
      "rewards/rejected": -4.122244834899902,
      "step": 12820
    },
    {
      "epoch": 2.153639718215364,
      "grad_norm": 1.7405526638031006,
      "learning_rate": 1.4131164038913116e-05,
      "logits/chosen": 2.4509236812591553,
      "logits/rejected": 2.6295888423919678,
      "logps/chosen": -214.88815307617188,
      "logps/rejected": -215.84130859375,
      "loss": 0.3178,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.223140239715576,
      "rewards/margins": 2.0900251865386963,
      "rewards/rejected": -4.313165187835693,
      "step": 12840
    },
    {
      "epoch": 2.1569942972156992,
      "grad_norm": 8.408438682556152,
      "learning_rate": 1.4075254388907527e-05,
      "logits/chosen": 2.423919439315796,
      "logits/rejected": 2.513899564743042,
      "logps/chosen": -234.06912231445312,
      "logps/rejected": -224.4705047607422,
      "loss": 0.3994,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.375274658203125,
      "rewards/margins": 1.6134856939315796,
      "rewards/rejected": -3.988759994506836,
      "step": 12860
    },
    {
      "epoch": 2.1603488762160348,
      "grad_norm": 2.1416616439819336,
      "learning_rate": 1.4019344738901934e-05,
      "logits/chosen": 2.2675747871398926,
      "logits/rejected": 2.5055270195007324,
      "logps/chosen": -223.3692626953125,
      "logps/rejected": -228.2563018798828,
      "loss": 0.2538,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -1.9458739757537842,
      "rewards/margins": 2.1087775230407715,
      "rewards/rejected": -4.054651260375977,
      "step": 12880
    },
    {
      "epoch": 2.1637034552163703,
      "grad_norm": 2.2513444423675537,
      "learning_rate": 1.3963435088896345e-05,
      "logits/chosen": 2.4821341037750244,
      "logits/rejected": 2.6691484451293945,
      "logps/chosen": -219.024658203125,
      "logps/rejected": -220.23422241210938,
      "loss": 0.2904,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.593660831451416,
      "rewards/margins": 2.14435076713562,
      "rewards/rejected": -4.738011837005615,
      "step": 12900
    },
    {
      "epoch": 2.167058034216706,
      "grad_norm": 1.4387457370758057,
      "learning_rate": 1.3907525438890754e-05,
      "logits/chosen": 2.444275379180908,
      "logits/rejected": 2.7061266899108887,
      "logps/chosen": -212.8905792236328,
      "logps/rejected": -224.6775665283203,
      "loss": 0.3703,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.522664785385132,
      "rewards/margins": 2.1513938903808594,
      "rewards/rejected": -4.67405891418457,
      "step": 12920
    },
    {
      "epoch": 2.1704126132170414,
      "grad_norm": 2.1050515174865723,
      "learning_rate": 1.3851615788885161e-05,
      "logits/chosen": 2.2593741416931152,
      "logits/rejected": 2.428334951400757,
      "logps/chosen": -203.4480743408203,
      "logps/rejected": -210.70529174804688,
      "loss": 0.3001,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.4625561237335205,
      "rewards/margins": 1.9058231115341187,
      "rewards/rejected": -4.36837911605835,
      "step": 12940
    },
    {
      "epoch": 2.173767192217377,
      "grad_norm": 5.286204814910889,
      "learning_rate": 1.3795706138879572e-05,
      "logits/chosen": 2.283752679824829,
      "logits/rejected": 2.606532335281372,
      "logps/chosen": -212.4867401123047,
      "logps/rejected": -224.3969268798828,
      "loss": 0.2723,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.450287342071533,
      "rewards/margins": 2.38272762298584,
      "rewards/rejected": -4.833014965057373,
      "step": 12960
    },
    {
      "epoch": 2.177121771217712,
      "grad_norm": 2.9754786491394043,
      "learning_rate": 1.3739796488873979e-05,
      "logits/chosen": 2.0906195640563965,
      "logits/rejected": 2.3175556659698486,
      "logps/chosen": -218.7533721923828,
      "logps/rejected": -209.5888671875,
      "loss": 0.3646,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.49432635307312,
      "rewards/margins": 2.0192008018493652,
      "rewards/rejected": -4.513526916503906,
      "step": 12980
    },
    {
      "epoch": 2.1804763502180475,
      "grad_norm": 3.884646415710449,
      "learning_rate": 1.368388683886839e-05,
      "logits/chosen": 2.0565083026885986,
      "logits/rejected": 2.402829647064209,
      "logps/chosen": -234.3339385986328,
      "logps/rejected": -221.4455108642578,
      "loss": 0.3128,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.9165027141571045,
      "rewards/margins": 1.994518518447876,
      "rewards/rejected": -4.9110212326049805,
      "step": 13000
    },
    {
      "epoch": 2.183830929218383,
      "grad_norm": 4.283308982849121,
      "learning_rate": 1.3627977188862798e-05,
      "logits/chosen": 2.1709492206573486,
      "logits/rejected": 2.4233460426330566,
      "logps/chosen": -222.51571655273438,
      "logps/rejected": -219.75289916992188,
      "loss": 0.298,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.620573043823242,
      "rewards/margins": 2.1080989837646484,
      "rewards/rejected": -4.728672027587891,
      "step": 13020
    },
    {
      "epoch": 2.1871855082187186,
      "grad_norm": 1.0936685800552368,
      "learning_rate": 1.3572067538857209e-05,
      "logits/chosen": 2.2083868980407715,
      "logits/rejected": 2.4691171646118164,
      "logps/chosen": -223.17697143554688,
      "logps/rejected": -210.7135009765625,
      "loss": 0.2716,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.7884113788604736,
      "rewards/margins": 2.0796947479248047,
      "rewards/rejected": -4.868105888366699,
      "step": 13040
    },
    {
      "epoch": 2.190540087219054,
      "grad_norm": 8.088676452636719,
      "learning_rate": 1.3516157888851616e-05,
      "logits/chosen": 2.0963120460510254,
      "logits/rejected": 2.3862318992614746,
      "logps/chosen": -212.9944305419922,
      "logps/rejected": -223.955810546875,
      "loss": 0.2947,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.4005513191223145,
      "rewards/margins": 2.187943458557129,
      "rewards/rejected": -4.588494777679443,
      "step": 13060
    },
    {
      "epoch": 2.1938946662193897,
      "grad_norm": 0.9613835215568542,
      "learning_rate": 1.3460248238846027e-05,
      "logits/chosen": 2.162116527557373,
      "logits/rejected": 2.5660526752471924,
      "logps/chosen": -211.91201782226562,
      "logps/rejected": -206.45925903320312,
      "loss": 0.1909,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -2.0235087871551514,
      "rewards/margins": 2.69807767868042,
      "rewards/rejected": -4.72158670425415,
      "step": 13080
    },
    {
      "epoch": 2.1972492452197248,
      "grad_norm": 1.90341317653656,
      "learning_rate": 1.3404338588840434e-05,
      "logits/chosen": 2.1997785568237305,
      "logits/rejected": 2.5009381771087646,
      "logps/chosen": -216.1743621826172,
      "logps/rejected": -228.9052276611328,
      "loss": 0.2456,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.3060169219970703,
      "rewards/margins": 2.1590120792388916,
      "rewards/rejected": -4.465029239654541,
      "step": 13100
    },
    {
      "epoch": 2.2006038242200603,
      "grad_norm": 2.1363162994384766,
      "learning_rate": 1.3348428938834845e-05,
      "logits/chosen": 2.0549445152282715,
      "logits/rejected": 2.2137367725372314,
      "logps/chosen": -217.70889282226562,
      "logps/rejected": -227.3766632080078,
      "loss": 0.2517,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.8200695514678955,
      "rewards/margins": 2.2650375366210938,
      "rewards/rejected": -5.085107326507568,
      "step": 13120
    },
    {
      "epoch": 2.203958403220396,
      "grad_norm": 2.4114108085632324,
      "learning_rate": 1.3292519288829252e-05,
      "logits/chosen": 2.3300368785858154,
      "logits/rejected": 2.7098138332366943,
      "logps/chosen": -230.8890380859375,
      "logps/rejected": -223.2312469482422,
      "loss": 0.3287,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.9039969444274902,
      "rewards/margins": 2.252978801727295,
      "rewards/rejected": -5.156975746154785,
      "step": 13140
    },
    {
      "epoch": 2.2073129822207314,
      "grad_norm": 2.8874058723449707,
      "learning_rate": 1.323660963882366e-05,
      "logits/chosen": 2.063551664352417,
      "logits/rejected": 2.5858089923858643,
      "logps/chosen": -219.07595825195312,
      "logps/rejected": -205.6938934326172,
      "loss": 0.3193,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.53733491897583,
      "rewards/margins": 1.930809736251831,
      "rewards/rejected": -4.468144416809082,
      "step": 13160
    },
    {
      "epoch": 2.210667561221067,
      "grad_norm": 3.5044009685516357,
      "learning_rate": 1.3180699988818071e-05,
      "logits/chosen": 2.376610279083252,
      "logits/rejected": 2.6353936195373535,
      "logps/chosen": -212.43228149414062,
      "logps/rejected": -228.379150390625,
      "loss": 0.2879,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.9449260234832764,
      "rewards/margins": 2.0843753814697266,
      "rewards/rejected": -5.029301643371582,
      "step": 13180
    },
    {
      "epoch": 2.2140221402214024,
      "grad_norm": 2.9904980659484863,
      "learning_rate": 1.3124790338812479e-05,
      "logits/chosen": 2.1831085681915283,
      "logits/rejected": 2.619884729385376,
      "logps/chosen": -225.32412719726562,
      "logps/rejected": -231.3718719482422,
      "loss": 0.2685,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.563863515853882,
      "rewards/margins": 2.441906452178955,
      "rewards/rejected": -5.005769729614258,
      "step": 13200
    },
    {
      "epoch": 2.2173767192217375,
      "grad_norm": 2.6148059368133545,
      "learning_rate": 1.306888068880689e-05,
      "logits/chosen": 2.3002474308013916,
      "logits/rejected": 2.6477808952331543,
      "logps/chosen": -223.53128051757812,
      "logps/rejected": -217.31411743164062,
      "loss": 0.2464,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.6035914421081543,
      "rewards/margins": 2.4523181915283203,
      "rewards/rejected": -5.055909633636475,
      "step": 13220
    },
    {
      "epoch": 2.220731298222073,
      "grad_norm": 5.58095121383667,
      "learning_rate": 1.3012971038801296e-05,
      "logits/chosen": 2.0528931617736816,
      "logits/rejected": 2.4272079467773438,
      "logps/chosen": -215.90377807617188,
      "logps/rejected": -220.8319091796875,
      "loss": 0.2722,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.8719944953918457,
      "rewards/margins": 2.192185163497925,
      "rewards/rejected": -5.06417989730835,
      "step": 13240
    },
    {
      "epoch": 2.2240858772224086,
      "grad_norm": 3.839238405227661,
      "learning_rate": 1.2957061388795707e-05,
      "logits/chosen": 2.0197601318359375,
      "logits/rejected": 2.381357192993164,
      "logps/chosen": -216.8910675048828,
      "logps/rejected": -217.18655395507812,
      "loss": 0.348,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.415252208709717,
      "rewards/margins": 1.8228203058242798,
      "rewards/rejected": -4.238072395324707,
      "step": 13260
    },
    {
      "epoch": 2.227440456222744,
      "grad_norm": 5.674498081207275,
      "learning_rate": 1.2901151738790116e-05,
      "logits/chosen": 2.043041229248047,
      "logits/rejected": 2.4049856662750244,
      "logps/chosen": -229.10104370117188,
      "logps/rejected": -212.2437286376953,
      "loss": 0.2789,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.6109297275543213,
      "rewards/margins": 2.088287591934204,
      "rewards/rejected": -4.699217319488525,
      "step": 13280
    },
    {
      "epoch": 2.2307950352230796,
      "grad_norm": 5.067447662353516,
      "learning_rate": 1.2845242088784527e-05,
      "logits/chosen": 2.1589198112487793,
      "logits/rejected": 2.4838051795959473,
      "logps/chosen": -230.30380249023438,
      "logps/rejected": -227.2685089111328,
      "loss": 0.2322,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.998578429222107,
      "rewards/margins": 2.2135326862335205,
      "rewards/rejected": -4.212111473083496,
      "step": 13300
    },
    {
      "epoch": 2.2341496142234147,
      "grad_norm": 4.557471752166748,
      "learning_rate": 1.2789332438778934e-05,
      "logits/chosen": 2.2039847373962402,
      "logits/rejected": 2.402886390686035,
      "logps/chosen": -229.2569580078125,
      "logps/rejected": -224.66873168945312,
      "loss": 0.3774,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.0302605628967285,
      "rewards/margins": 1.7167460918426514,
      "rewards/rejected": -3.74700665473938,
      "step": 13320
    },
    {
      "epoch": 2.2375041932237503,
      "grad_norm": 5.024401664733887,
      "learning_rate": 1.2733422788773344e-05,
      "logits/chosen": 2.377483606338501,
      "logits/rejected": 2.595890522003174,
      "logps/chosen": -213.6867218017578,
      "logps/rejected": -218.87661743164062,
      "loss": 0.4603,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.5530459880828857,
      "rewards/margins": 1.5903278589248657,
      "rewards/rejected": -4.143373966217041,
      "step": 13340
    },
    {
      "epoch": 2.240858772224086,
      "grad_norm": 3.445697546005249,
      "learning_rate": 1.2680308621268031e-05,
      "logits/chosen": 2.336355686187744,
      "logits/rejected": 2.779975414276123,
      "logps/chosen": -215.12939453125,
      "logps/rejected": -205.2620849609375,
      "loss": 0.2677,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.9454755783081055,
      "rewards/margins": 2.34187650680542,
      "rewards/rejected": -4.287352561950684,
      "step": 13360
    },
    {
      "epoch": 2.2442133512244213,
      "grad_norm": 4.161665439605713,
      "learning_rate": 1.2624398971262442e-05,
      "logits/chosen": 2.2419309616088867,
      "logits/rejected": 2.5228774547576904,
      "logps/chosen": -212.81094360351562,
      "logps/rejected": -216.45962524414062,
      "loss": 0.2645,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.1984639167785645,
      "rewards/margins": 2.023653745651245,
      "rewards/rejected": -4.2221174240112305,
      "step": 13380
    },
    {
      "epoch": 2.247567930224757,
      "grad_norm": 1.0949369668960571,
      "learning_rate": 1.2568489321256849e-05,
      "logits/chosen": 2.3165793418884277,
      "logits/rejected": 2.6557841300964355,
      "logps/chosen": -202.59689331054688,
      "logps/rejected": -205.00634765625,
      "loss": 0.2669,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.212568759918213,
      "rewards/margins": 1.9987980127334595,
      "rewards/rejected": -4.211366653442383,
      "step": 13400
    },
    {
      "epoch": 2.2509225092250924,
      "grad_norm": 2.0221359729766846,
      "learning_rate": 1.251257967125126e-05,
      "logits/chosen": 2.238537073135376,
      "logits/rejected": 2.468864917755127,
      "logps/chosen": -215.38131713867188,
      "logps/rejected": -227.8547821044922,
      "loss": 0.3507,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.237419605255127,
      "rewards/margins": 1.664899468421936,
      "rewards/rejected": -3.9023194313049316,
      "step": 13420
    },
    {
      "epoch": 2.254277088225428,
      "grad_norm": 5.003190040588379,
      "learning_rate": 1.2456670021245667e-05,
      "logits/chosen": 2.2868237495422363,
      "logits/rejected": 2.545135021209717,
      "logps/chosen": -228.81210327148438,
      "logps/rejected": -226.38525390625,
      "loss": 0.28,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.0415329933166504,
      "rewards/margins": 2.14699649810791,
      "rewards/rejected": -4.188529014587402,
      "step": 13440
    },
    {
      "epoch": 2.257631667225763,
      "grad_norm": 3.5032095909118652,
      "learning_rate": 1.2400760371240076e-05,
      "logits/chosen": 2.19303297996521,
      "logits/rejected": 2.408271074295044,
      "logps/chosen": -227.6130828857422,
      "logps/rejected": -221.34658813476562,
      "loss": 0.3757,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.5882363319396973,
      "rewards/margins": 1.8809512853622437,
      "rewards/rejected": -4.4691877365112305,
      "step": 13460
    },
    {
      "epoch": 2.2609862462260986,
      "grad_norm": 0.2723020613193512,
      "learning_rate": 1.2344850721234486e-05,
      "logits/chosen": 2.2222092151641846,
      "logits/rejected": 2.5965564250946045,
      "logps/chosen": -219.231689453125,
      "logps/rejected": -213.92538452148438,
      "loss": 0.2839,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.5159130096435547,
      "rewards/margins": 2.2533135414123535,
      "rewards/rejected": -4.769227027893066,
      "step": 13480
    },
    {
      "epoch": 2.264340825226434,
      "grad_norm": 1.5792930126190186,
      "learning_rate": 1.2288941071228895e-05,
      "logits/chosen": 2.254263401031494,
      "logits/rejected": 2.4773669242858887,
      "logps/chosen": -216.8585968017578,
      "logps/rejected": -227.7375030517578,
      "loss": 0.3975,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.656339645385742,
      "rewards/margins": 1.9497826099395752,
      "rewards/rejected": -4.606122016906738,
      "step": 13500
    },
    {
      "epoch": 2.2676954042267696,
      "grad_norm": 2.0125932693481445,
      "learning_rate": 1.2233031421223304e-05,
      "logits/chosen": 2.1279890537261963,
      "logits/rejected": 2.327348470687866,
      "logps/chosen": -225.6619415283203,
      "logps/rejected": -222.6226043701172,
      "loss": 0.302,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.534698724746704,
      "rewards/margins": 2.1680941581726074,
      "rewards/rejected": -4.702792644500732,
      "step": 13520
    },
    {
      "epoch": 2.271049983227105,
      "grad_norm": 1.236785650253296,
      "learning_rate": 1.2177121771217713e-05,
      "logits/chosen": 2.2173471450805664,
      "logits/rejected": 2.5666556358337402,
      "logps/chosen": -224.021728515625,
      "logps/rejected": -232.1976776123047,
      "loss": 0.2087,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.3828179836273193,
      "rewards/margins": 2.5558180809020996,
      "rewards/rejected": -4.938636779785156,
      "step": 13540
    },
    {
      "epoch": 2.2744045622274403,
      "grad_norm": 6.241024017333984,
      "learning_rate": 1.2121212121212122e-05,
      "logits/chosen": 2.233135938644409,
      "logits/rejected": 2.492107391357422,
      "logps/chosen": -227.46322631835938,
      "logps/rejected": -228.366455078125,
      "loss": 0.3259,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.2289206981658936,
      "rewards/margins": 1.9806663990020752,
      "rewards/rejected": -5.209587097167969,
      "step": 13560
    },
    {
      "epoch": 2.277759141227776,
      "grad_norm": 6.342057704925537,
      "learning_rate": 1.2065302471206531e-05,
      "logits/chosen": 2.353353977203369,
      "logits/rejected": 2.6845784187316895,
      "logps/chosen": -228.1591033935547,
      "logps/rejected": -212.2520294189453,
      "loss": 0.3608,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.308452606201172,
      "rewards/margins": 2.061845064163208,
      "rewards/rejected": -5.370297908782959,
      "step": 13580
    },
    {
      "epoch": 2.2811137202281113,
      "grad_norm": 2.0903830528259277,
      "learning_rate": 1.200939282120094e-05,
      "logits/chosen": 2.189020872116089,
      "logits/rejected": 2.6370670795440674,
      "logps/chosen": -227.6988525390625,
      "logps/rejected": -211.3489990234375,
      "loss": 0.3313,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.6634721755981445,
      "rewards/margins": 2.1475868225097656,
      "rewards/rejected": -4.81105899810791,
      "step": 13600
    },
    {
      "epoch": 2.284468299228447,
      "grad_norm": 5.073988437652588,
      "learning_rate": 1.1953483171195349e-05,
      "logits/chosen": 2.1502716541290283,
      "logits/rejected": 2.239457368850708,
      "logps/chosen": -238.6303253173828,
      "logps/rejected": -254.80197143554688,
      "loss": 0.4137,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.5110840797424316,
      "rewards/margins": 1.940673828125,
      "rewards/rejected": -4.45175838470459,
      "step": 13620
    },
    {
      "epoch": 2.2878228782287824,
      "grad_norm": 2.036043167114258,
      "learning_rate": 1.1897573521189758e-05,
      "logits/chosen": 2.2891769409179688,
      "logits/rejected": 2.6687488555908203,
      "logps/chosen": -223.75650024414062,
      "logps/rejected": -222.17575073242188,
      "loss": 0.3716,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.605180501937866,
      "rewards/margins": 2.1636223793029785,
      "rewards/rejected": -4.768803119659424,
      "step": 13640
    },
    {
      "epoch": 2.291177457229118,
      "grad_norm": 4.1999406814575195,
      "learning_rate": 1.1841663871184167e-05,
      "logits/chosen": 2.2623541355133057,
      "logits/rejected": 2.6990647315979004,
      "logps/chosen": -228.8136749267578,
      "logps/rejected": -215.71554565429688,
      "loss": 0.2835,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.5572571754455566,
      "rewards/margins": 2.0681750774383545,
      "rewards/rejected": -4.62543249130249,
      "step": 13660
    },
    {
      "epoch": 2.2945320362294535,
      "grad_norm": 2.209429979324341,
      "learning_rate": 1.1785754221178575e-05,
      "logits/chosen": 2.2913475036621094,
      "logits/rejected": 2.694035530090332,
      "logps/chosen": -227.4637908935547,
      "logps/rejected": -222.0719757080078,
      "loss": 0.2735,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.5326075553894043,
      "rewards/margins": 2.2818169593811035,
      "rewards/rejected": -4.814424991607666,
      "step": 13680
    },
    {
      "epoch": 2.2978866152297885,
      "grad_norm": 3.493194818496704,
      "learning_rate": 1.1729844571172984e-05,
      "logits/chosen": 2.1349353790283203,
      "logits/rejected": 2.4674270153045654,
      "logps/chosen": -216.0707550048828,
      "logps/rejected": -216.48434448242188,
      "loss": 0.2546,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.602663993835449,
      "rewards/margins": 2.2827908992767334,
      "rewards/rejected": -4.885455131530762,
      "step": 13700
    },
    {
      "epoch": 2.301241194230124,
      "grad_norm": 2.174938678741455,
      "learning_rate": 1.1673934921167393e-05,
      "logits/chosen": 2.284425973892212,
      "logits/rejected": 2.607370376586914,
      "logps/chosen": -206.32571411132812,
      "logps/rejected": -209.0684051513672,
      "loss": 0.2723,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3726556301116943,
      "rewards/margins": 2.2204089164733887,
      "rewards/rejected": -4.593064308166504,
      "step": 13720
    },
    {
      "epoch": 2.3045957732304596,
      "grad_norm": 7.56169319152832,
      "learning_rate": 1.1618025271161804e-05,
      "logits/chosen": 2.269536256790161,
      "logits/rejected": 2.6124911308288574,
      "logps/chosen": -217.55508422851562,
      "logps/rejected": -213.28628540039062,
      "loss": 0.3937,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.800855875015259,
      "rewards/margins": 2.163479804992676,
      "rewards/rejected": -4.9643354415893555,
      "step": 13740
    },
    {
      "epoch": 2.307950352230795,
      "grad_norm": 2.2475225925445557,
      "learning_rate": 1.1562115621156213e-05,
      "logits/chosen": 2.3296358585357666,
      "logits/rejected": 2.6899406909942627,
      "logps/chosen": -211.1718292236328,
      "logps/rejected": -208.3193359375,
      "loss": 0.2954,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.4749374389648438,
      "rewards/margins": 2.276984453201294,
      "rewards/rejected": -4.7519211769104,
      "step": 13760
    },
    {
      "epoch": 2.3113049312311307,
      "grad_norm": 4.290184497833252,
      "learning_rate": 1.1506205971150622e-05,
      "logits/chosen": 2.301021099090576,
      "logits/rejected": 2.71905517578125,
      "logps/chosen": -239.5631561279297,
      "logps/rejected": -228.7513427734375,
      "loss": 0.2986,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3100221157073975,
      "rewards/margins": 2.087337017059326,
      "rewards/rejected": -4.3973588943481445,
      "step": 13780
    },
    {
      "epoch": 2.3146595102314658,
      "grad_norm": 3.0809381008148193,
      "learning_rate": 1.145029632114503e-05,
      "logits/chosen": 2.484968423843384,
      "logits/rejected": 2.74971079826355,
      "logps/chosen": -212.31332397460938,
      "logps/rejected": -207.37918090820312,
      "loss": 0.2945,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.855090618133545,
      "rewards/margins": 2.123971700668335,
      "rewards/rejected": -4.979062080383301,
      "step": 13800
    },
    {
      "epoch": 2.3180140892318013,
      "grad_norm": 4.942359924316406,
      "learning_rate": 1.139438667113944e-05,
      "logits/chosen": 2.365983724594116,
      "logits/rejected": 2.6052441596984863,
      "logps/chosen": -230.6475830078125,
      "logps/rejected": -223.54922485351562,
      "loss": 0.2593,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.7940263748168945,
      "rewards/margins": 2.063771963119507,
      "rewards/rejected": -4.8577985763549805,
      "step": 13820
    },
    {
      "epoch": 2.321368668232137,
      "grad_norm": 3.2974021434783936,
      "learning_rate": 1.1338477021133847e-05,
      "logits/chosen": 2.6044652462005615,
      "logits/rejected": 2.783517360687256,
      "logps/chosen": -216.8273468017578,
      "logps/rejected": -224.52554321289062,
      "loss": 0.4536,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.932044744491577,
      "rewards/margins": 1.7358672618865967,
      "rewards/rejected": -4.667912006378174,
      "step": 13840
    },
    {
      "epoch": 2.3247232472324724,
      "grad_norm": 0.9019806981086731,
      "learning_rate": 1.1282567371128257e-05,
      "logits/chosen": 2.5113673210144043,
      "logits/rejected": 2.7437338829040527,
      "logps/chosen": -217.3173370361328,
      "logps/rejected": -218.4562225341797,
      "loss": 0.2548,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.382519245147705,
      "rewards/margins": 2.2504169940948486,
      "rewards/rejected": -4.632936954498291,
      "step": 13860
    },
    {
      "epoch": 2.328077826232808,
      "grad_norm": 5.638179302215576,
      "learning_rate": 1.1226657721122666e-05,
      "logits/chosen": 2.3843226432800293,
      "logits/rejected": 2.597115993499756,
      "logps/chosen": -216.11380004882812,
      "logps/rejected": -217.4591064453125,
      "loss": 0.3327,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.360704183578491,
      "rewards/margins": 2.120656967163086,
      "rewards/rejected": -4.4813618659973145,
      "step": 13880
    },
    {
      "epoch": 2.3314324052331434,
      "grad_norm": 3.293984889984131,
      "learning_rate": 1.1170748071117075e-05,
      "logits/chosen": 2.266446352005005,
      "logits/rejected": 2.647432804107666,
      "logps/chosen": -223.3043212890625,
      "logps/rejected": -219.03128051757812,
      "loss": 0.2536,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.2827389240264893,
      "rewards/margins": 2.308490753173828,
      "rewards/rejected": -4.591230392456055,
      "step": 13900
    },
    {
      "epoch": 2.3347869842334785,
      "grad_norm": 2.8309884071350098,
      "learning_rate": 1.1114838421111484e-05,
      "logits/chosen": 2.4739575386047363,
      "logits/rejected": 2.682467222213745,
      "logps/chosen": -238.8488311767578,
      "logps/rejected": -233.1522979736328,
      "loss": 0.3046,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.1751484870910645,
      "rewards/margins": 2.195692539215088,
      "rewards/rejected": -4.370841026306152,
      "step": 13920
    },
    {
      "epoch": 2.338141563233814,
      "grad_norm": 1.0381754636764526,
      "learning_rate": 1.1058928771105893e-05,
      "logits/chosen": 2.119502544403076,
      "logits/rejected": 2.5377864837646484,
      "logps/chosen": -219.4392547607422,
      "logps/rejected": -217.19296264648438,
      "loss": 0.2645,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.1641671657562256,
      "rewards/margins": 2.164618730545044,
      "rewards/rejected": -4.3287858963012695,
      "step": 13940
    },
    {
      "epoch": 2.3414961422341496,
      "grad_norm": 3.767268180847168,
      "learning_rate": 1.1003019121100302e-05,
      "logits/chosen": 2.230128049850464,
      "logits/rejected": 2.550252914428711,
      "logps/chosen": -210.19094848632812,
      "logps/rejected": -209.07846069335938,
      "loss": 0.2852,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.437230348587036,
      "rewards/margins": 2.1263718605041504,
      "rewards/rejected": -4.563601970672607,
      "step": 13960
    },
    {
      "epoch": 2.344850721234485,
      "grad_norm": 5.71238899230957,
      "learning_rate": 1.0947109471094711e-05,
      "logits/chosen": 2.3614883422851562,
      "logits/rejected": 2.6191329956054688,
      "logps/chosen": -222.6926727294922,
      "logps/rejected": -216.770751953125,
      "loss": 0.3116,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.027358293533325,
      "rewards/margins": 2.3818674087524414,
      "rewards/rejected": -4.409225940704346,
      "step": 13980
    },
    {
      "epoch": 2.3482053002348207,
      "grad_norm": 2.5978658199310303,
      "learning_rate": 1.0891199821089122e-05,
      "logits/chosen": 2.114908456802368,
      "logits/rejected": 2.5134401321411133,
      "logps/chosen": -221.5494384765625,
      "logps/rejected": -218.17922973632812,
      "loss": 0.3076,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9135879278182983,
      "rewards/margins": 2.33944034576416,
      "rewards/rejected": -4.25302791595459,
      "step": 14000
    },
    {
      "epoch": 2.3515598792351557,
      "grad_norm": 1.772088646888733,
      "learning_rate": 1.083529017108353e-05,
      "logits/chosen": 2.326992988586426,
      "logits/rejected": 2.599810838699341,
      "logps/chosen": -227.68283081054688,
      "logps/rejected": -226.75820922851562,
      "loss": 0.2716,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.4026763439178467,
      "rewards/margins": 2.1997671127319336,
      "rewards/rejected": -4.602443695068359,
      "step": 14020
    },
    {
      "epoch": 2.3549144582354913,
      "grad_norm": 8.211204528808594,
      "learning_rate": 1.077938052107794e-05,
      "logits/chosen": 2.228858470916748,
      "logits/rejected": 2.4495997428894043,
      "logps/chosen": -215.8786163330078,
      "logps/rejected": -215.3609619140625,
      "loss": 0.3097,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.3111510276794434,
      "rewards/margins": 2.3281443119049072,
      "rewards/rejected": -4.6392951011657715,
      "step": 14040
    },
    {
      "epoch": 2.358269037235827,
      "grad_norm": 5.955894947052002,
      "learning_rate": 1.0723470871072347e-05,
      "logits/chosen": 2.281769275665283,
      "logits/rejected": 2.6595404148101807,
      "logps/chosen": -219.3789520263672,
      "logps/rejected": -225.9717559814453,
      "loss": 0.2415,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.0181102752685547,
      "rewards/margins": 2.520272731781006,
      "rewards/rejected": -4.5383830070495605,
      "step": 14060
    },
    {
      "epoch": 2.3616236162361623,
      "grad_norm": 1.303340196609497,
      "learning_rate": 1.0667561221066755e-05,
      "logits/chosen": 2.1314616203308105,
      "logits/rejected": 2.436837673187256,
      "logps/chosen": -219.57315063476562,
      "logps/rejected": -225.33236694335938,
      "loss": 0.239,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.0464189052581787,
      "rewards/margins": 2.2606024742126465,
      "rewards/rejected": -4.307021141052246,
      "step": 14080
    },
    {
      "epoch": 2.364978195236498,
      "grad_norm": 1.9194822311401367,
      "learning_rate": 1.0611651571061164e-05,
      "logits/chosen": 1.983635663986206,
      "logits/rejected": 2.2891886234283447,
      "logps/chosen": -213.32711791992188,
      "logps/rejected": -227.62582397460938,
      "loss": 0.3049,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.544666051864624,
      "rewards/margins": 2.213609457015991,
      "rewards/rejected": -4.758275508880615,
      "step": 14100
    },
    {
      "epoch": 2.3683327742368334,
      "grad_norm": 1.6082454919815063,
      "learning_rate": 1.0555741921055575e-05,
      "logits/chosen": 2.3376011848449707,
      "logits/rejected": 2.7736597061157227,
      "logps/chosen": -233.7479248046875,
      "logps/rejected": -212.0670928955078,
      "loss": 0.2584,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.2884433269500732,
      "rewards/margins": 2.254027843475342,
      "rewards/rejected": -4.542471408843994,
      "step": 14120
    },
    {
      "epoch": 2.371687353237169,
      "grad_norm": 4.898983955383301,
      "learning_rate": 1.0499832271049984e-05,
      "logits/chosen": 2.4355509281158447,
      "logits/rejected": 2.7335171699523926,
      "logps/chosen": -226.6654815673828,
      "logps/rejected": -242.4091796875,
      "loss": 0.2844,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.384284496307373,
      "rewards/margins": 2.3198320865631104,
      "rewards/rejected": -4.704115867614746,
      "step": 14140
    },
    {
      "epoch": 2.375041932237504,
      "grad_norm": 3.1298344135284424,
      "learning_rate": 1.0443922621044393e-05,
      "logits/chosen": 2.2538490295410156,
      "logits/rejected": 2.651817798614502,
      "logps/chosen": -219.15261840820312,
      "logps/rejected": -214.24032592773438,
      "loss": 0.3187,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.543494701385498,
      "rewards/margins": 2.1644318103790283,
      "rewards/rejected": -4.7079267501831055,
      "step": 14160
    },
    {
      "epoch": 2.3783965112378396,
      "grad_norm": 1.884395718574524,
      "learning_rate": 1.0388012971038802e-05,
      "logits/chosen": 2.463097333908081,
      "logits/rejected": 2.6561293601989746,
      "logps/chosen": -220.62551879882812,
      "logps/rejected": -233.0539093017578,
      "loss": 0.2904,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.831913948059082,
      "rewards/margins": 2.108351469039917,
      "rewards/rejected": -4.94026517868042,
      "step": 14180
    },
    {
      "epoch": 2.381751090238175,
      "grad_norm": 2.7058486938476562,
      "learning_rate": 1.033210332103321e-05,
      "logits/chosen": 2.119629144668579,
      "logits/rejected": 2.411006450653076,
      "logps/chosen": -200.98960876464844,
      "logps/rejected": -216.2721405029297,
      "loss": 0.3425,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.633784055709839,
      "rewards/margins": 2.173450469970703,
      "rewards/rejected": -4.807234764099121,
      "step": 14200
    },
    {
      "epoch": 2.3851056692385106,
      "grad_norm": 2.8048551082611084,
      "learning_rate": 1.027619367102762e-05,
      "logits/chosen": 2.3178417682647705,
      "logits/rejected": 2.6246085166931152,
      "logps/chosen": -206.95169067382812,
      "logps/rejected": -202.9675750732422,
      "loss": 0.271,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.603619337081909,
      "rewards/margins": 2.2294702529907227,
      "rewards/rejected": -4.833089351654053,
      "step": 14220
    },
    {
      "epoch": 2.388460248238846,
      "grad_norm": 5.294882774353027,
      "learning_rate": 1.0220284021022029e-05,
      "logits/chosen": 2.2222259044647217,
      "logits/rejected": 2.6534528732299805,
      "logps/chosen": -224.8264617919922,
      "logps/rejected": -215.8171844482422,
      "loss": 0.2749,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1797032356262207,
      "rewards/margins": 2.178790807723999,
      "rewards/rejected": -4.358493804931641,
      "step": 14240
    },
    {
      "epoch": 2.3918148272391813,
      "grad_norm": 3.325488328933716,
      "learning_rate": 1.0164374371016439e-05,
      "logits/chosen": 2.3374199867248535,
      "logits/rejected": 2.7427258491516113,
      "logps/chosen": -213.07373046875,
      "logps/rejected": -233.8677215576172,
      "loss": 0.3091,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.3354973793029785,
      "rewards/margins": 2.4042766094207764,
      "rewards/rejected": -4.739773750305176,
      "step": 14260
    },
    {
      "epoch": 2.395169406239517,
      "grad_norm": 3.460247755050659,
      "learning_rate": 1.0108464721010846e-05,
      "logits/chosen": 2.082890510559082,
      "logits/rejected": 2.4650256633758545,
      "logps/chosen": -218.53146362304688,
      "logps/rejected": -211.4123992919922,
      "loss": 0.3064,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.6334593296051025,
      "rewards/margins": 1.8600813150405884,
      "rewards/rejected": -4.4935407638549805,
      "step": 14280
    },
    {
      "epoch": 2.3985239852398523,
      "grad_norm": 1.1534309387207031,
      "learning_rate": 1.0052555071005255e-05,
      "logits/chosen": 2.131349802017212,
      "logits/rejected": 2.496243953704834,
      "logps/chosen": -212.4478302001953,
      "logps/rejected": -215.63330078125,
      "loss": 0.2761,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.2613439559936523,
      "rewards/margins": 2.1028013229370117,
      "rewards/rejected": -4.364144802093506,
      "step": 14300
    },
    {
      "epoch": 2.401878564240188,
      "grad_norm": 1.980510950088501,
      "learning_rate": 9.996645420999664e-06,
      "logits/chosen": 2.5077502727508545,
      "logits/rejected": 2.6757302284240723,
      "logps/chosen": -221.53683471679688,
      "logps/rejected": -200.17202758789062,
      "loss": 0.3515,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.5535013675689697,
      "rewards/margins": 1.8650157451629639,
      "rewards/rejected": -4.418517112731934,
      "step": 14320
    },
    {
      "epoch": 2.4052331432405234,
      "grad_norm": 9.380234718322754,
      "learning_rate": 9.940735770994073e-06,
      "logits/chosen": 2.2304110527038574,
      "logits/rejected": 2.5943264961242676,
      "logps/chosen": -222.73745727539062,
      "logps/rejected": -231.7953643798828,
      "loss": 0.3223,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.909306287765503,
      "rewards/margins": 2.283482313156128,
      "rewards/rejected": -5.192788600921631,
      "step": 14340
    },
    {
      "epoch": 2.408587722240859,
      "grad_norm": 2.2671704292297363,
      "learning_rate": 9.884826120988484e-06,
      "logits/chosen": 2.435117721557617,
      "logits/rejected": 2.585291624069214,
      "logps/chosen": -224.30825805664062,
      "logps/rejected": -240.9456024169922,
      "loss": 0.2303,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.4573090076446533,
      "rewards/margins": 2.4485716819763184,
      "rewards/rejected": -4.905880928039551,
      "step": 14360
    },
    {
      "epoch": 2.4119423012411945,
      "grad_norm": 2.1353816986083984,
      "learning_rate": 9.828916470982893e-06,
      "logits/chosen": 2.319439172744751,
      "logits/rejected": 2.578625440597534,
      "logps/chosen": -216.482666015625,
      "logps/rejected": -223.77096557617188,
      "loss": 0.2837,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.7796342372894287,
      "rewards/margins": 2.5813956260681152,
      "rewards/rejected": -5.361029624938965,
      "step": 14380
    },
    {
      "epoch": 2.4152968802415296,
      "grad_norm": 5.220946311950684,
      "learning_rate": 9.773006820977302e-06,
      "logits/chosen": 2.268704891204834,
      "logits/rejected": 2.6391279697418213,
      "logps/chosen": -203.3865203857422,
      "logps/rejected": -214.4481658935547,
      "loss": 0.3682,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.805107593536377,
      "rewards/margins": 2.1807069778442383,
      "rewards/rejected": -4.985814094543457,
      "step": 14400
    },
    {
      "epoch": 2.418651459241865,
      "grad_norm": 0.2052410989999771,
      "learning_rate": 9.71709717097171e-06,
      "logits/chosen": 2.26460337638855,
      "logits/rejected": 2.5317256450653076,
      "logps/chosen": -223.0745849609375,
      "logps/rejected": -225.18130493164062,
      "loss": 0.2556,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.3473079204559326,
      "rewards/margins": 2.374725103378296,
      "rewards/rejected": -4.7220330238342285,
      "step": 14420
    },
    {
      "epoch": 2.4220060382422006,
      "grad_norm": 2.8899216651916504,
      "learning_rate": 9.66118752096612e-06,
      "logits/chosen": 2.431349754333496,
      "logits/rejected": 2.6569089889526367,
      "logps/chosen": -233.7433319091797,
      "logps/rejected": -237.662353515625,
      "loss": 0.2645,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.7933249473571777,
      "rewards/margins": 2.3059370517730713,
      "rewards/rejected": -5.099262237548828,
      "step": 14440
    },
    {
      "epoch": 2.425360617242536,
      "grad_norm": 1.2083649635314941,
      "learning_rate": 9.605277870960528e-06,
      "logits/chosen": 2.3508660793304443,
      "logits/rejected": 2.5915958881378174,
      "logps/chosen": -219.3940887451172,
      "logps/rejected": -229.00070190429688,
      "loss": 0.2951,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.8467984199523926,
      "rewards/margins": 2.3714232444763184,
      "rewards/rejected": -5.218221187591553,
      "step": 14460
    },
    {
      "epoch": 2.4287151962428717,
      "grad_norm": 3.5214037895202637,
      "learning_rate": 9.549368220954937e-06,
      "logits/chosen": 2.248387098312378,
      "logits/rejected": 2.6037192344665527,
      "logps/chosen": -202.57095336914062,
      "logps/rejected": -214.3651123046875,
      "loss": 0.2699,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.5337841510772705,
      "rewards/margins": 2.5264174938201904,
      "rewards/rejected": -5.060201644897461,
      "step": 14480
    },
    {
      "epoch": 2.4320697752432068,
      "grad_norm": 0.6938855648040771,
      "learning_rate": 9.493458570949346e-06,
      "logits/chosen": 2.346677303314209,
      "logits/rejected": 2.585073947906494,
      "logps/chosen": -225.2798614501953,
      "logps/rejected": -237.6986083984375,
      "loss": 0.2719,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.917569398880005,
      "rewards/margins": 2.2411413192749023,
      "rewards/rejected": -5.158710956573486,
      "step": 14500
    },
    {
      "epoch": 2.4354243542435423,
      "grad_norm": 9.276928901672363,
      "learning_rate": 9.437548920943755e-06,
      "logits/chosen": 2.336672067642212,
      "logits/rejected": 2.5066933631896973,
      "logps/chosen": -217.5900115966797,
      "logps/rejected": -224.03726196289062,
      "loss": 0.3406,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.6981091499328613,
      "rewards/margins": 2.1242334842681885,
      "rewards/rejected": -4.822342872619629,
      "step": 14520
    },
    {
      "epoch": 2.438778933243878,
      "grad_norm": 2.0213937759399414,
      "learning_rate": 9.381639270938164e-06,
      "logits/chosen": 2.091887950897217,
      "logits/rejected": 2.3387699127197266,
      "logps/chosen": -209.97988891601562,
      "logps/rejected": -211.1070098876953,
      "loss": 0.3331,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.876296281814575,
      "rewards/margins": 2.107496976852417,
      "rewards/rejected": -4.983793258666992,
      "step": 14540
    },
    {
      "epoch": 2.4421335122442134,
      "grad_norm": 3.0027668476104736,
      "learning_rate": 9.325729620932573e-06,
      "logits/chosen": 2.0114023685455322,
      "logits/rejected": 2.2007079124450684,
      "logps/chosen": -213.50625610351562,
      "logps/rejected": -214.3229522705078,
      "loss": 0.3259,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.5088443756103516,
      "rewards/margins": 2.062819480895996,
      "rewards/rejected": -4.571663856506348,
      "step": 14560
    },
    {
      "epoch": 2.445488091244549,
      "grad_norm": 1.9746302366256714,
      "learning_rate": 9.269819970926982e-06,
      "logits/chosen": 2.298004150390625,
      "logits/rejected": 2.5281691551208496,
      "logps/chosen": -219.44009399414062,
      "logps/rejected": -227.2270050048828,
      "loss": 0.3872,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.031013011932373,
      "rewards/margins": 1.8392912149429321,
      "rewards/rejected": -4.870304584503174,
      "step": 14580
    },
    {
      "epoch": 2.4488426702448844,
      "grad_norm": 1.8595672845840454,
      "learning_rate": 9.21391032092139e-06,
      "logits/chosen": 2.202019691467285,
      "logits/rejected": 2.5327625274658203,
      "logps/chosen": -226.9512939453125,
      "logps/rejected": -229.0369110107422,
      "loss": 0.2723,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.2677886486053467,
      "rewards/margins": 2.3934199810028076,
      "rewards/rejected": -5.661208152770996,
      "step": 14600
    },
    {
      "epoch": 2.4521972492452195,
      "grad_norm": 3.332765817642212,
      "learning_rate": 9.158000670915801e-06,
      "logits/chosen": 2.0443577766418457,
      "logits/rejected": 2.3757123947143555,
      "logps/chosen": -225.257080078125,
      "logps/rejected": -228.153076171875,
      "loss": 0.304,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.8853487968444824,
      "rewards/margins": 2.227565050125122,
      "rewards/rejected": -5.112913608551025,
      "step": 14620
    },
    {
      "epoch": 2.455551828245555,
      "grad_norm": 1.4178454875946045,
      "learning_rate": 9.10209102091021e-06,
      "logits/chosen": 2.053144931793213,
      "logits/rejected": 2.451803207397461,
      "logps/chosen": -216.43014526367188,
      "logps/rejected": -222.52175903320312,
      "loss": 0.26,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.0592901706695557,
      "rewards/margins": 2.529006242752075,
      "rewards/rejected": -5.588295936584473,
      "step": 14640
    },
    {
      "epoch": 2.4589064072458906,
      "grad_norm": 4.255051136016846,
      "learning_rate": 9.04618137090462e-06,
      "logits/chosen": 2.3400630950927734,
      "logits/rejected": 2.3506951332092285,
      "logps/chosen": -214.732666015625,
      "logps/rejected": -237.2305145263672,
      "loss": 0.3274,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.0310277938842773,
      "rewards/margins": 2.128286361694336,
      "rewards/rejected": -5.159314155578613,
      "step": 14660
    },
    {
      "epoch": 2.462260986246226,
      "grad_norm": 1.883339285850525,
      "learning_rate": 8.990271720899028e-06,
      "logits/chosen": 2.223630905151367,
      "logits/rejected": 2.3626463413238525,
      "logps/chosen": -208.669677734375,
      "logps/rejected": -221.8690643310547,
      "loss": 0.3037,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.1390902996063232,
      "rewards/margins": 2.0303292274475098,
      "rewards/rejected": -5.169419765472412,
      "step": 14680
    },
    {
      "epoch": 2.4656155652465617,
      "grad_norm": 8.047774314880371,
      "learning_rate": 8.934362070893437e-06,
      "logits/chosen": 2.247732639312744,
      "logits/rejected": 2.5057835578918457,
      "logps/chosen": -231.8492431640625,
      "logps/rejected": -226.87680053710938,
      "loss": 0.3516,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.0741703510284424,
      "rewards/margins": 1.9431324005126953,
      "rewards/rejected": -5.017302513122559,
      "step": 14700
    },
    {
      "epoch": 2.468970144246897,
      "grad_norm": 0.563035786151886,
      "learning_rate": 8.878452420887844e-06,
      "logits/chosen": 2.17136287689209,
      "logits/rejected": 2.53029203414917,
      "logps/chosen": -215.3232421875,
      "logps/rejected": -216.7597198486328,
      "loss": 0.3669,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.147818088531494,
      "rewards/margins": 2.095163345336914,
      "rewards/rejected": -5.242981910705566,
      "step": 14720
    },
    {
      "epoch": 2.4723247232472323,
      "grad_norm": 5.572517395019531,
      "learning_rate": 8.822542770882255e-06,
      "logits/chosen": 2.411006450653076,
      "logits/rejected": 2.5092122554779053,
      "logps/chosen": -223.8794403076172,
      "logps/rejected": -241.204833984375,
      "loss": 0.2697,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.187715530395508,
      "rewards/margins": 2.2251462936401367,
      "rewards/rejected": -5.412861347198486,
      "step": 14740
    },
    {
      "epoch": 2.475679302247568,
      "grad_norm": 2.2019710540771484,
      "learning_rate": 8.766633120876664e-06,
      "logits/chosen": 2.2885589599609375,
      "logits/rejected": 2.654703378677368,
      "logps/chosen": -222.7882080078125,
      "logps/rejected": -233.63015747070312,
      "loss": 0.2812,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.846778392791748,
      "rewards/margins": 2.1940383911132812,
      "rewards/rejected": -5.040816783905029,
      "step": 14760
    },
    {
      "epoch": 2.4790338812479034,
      "grad_norm": 2.435976028442383,
      "learning_rate": 8.710723470871073e-06,
      "logits/chosen": 2.413994550704956,
      "logits/rejected": 2.4882349967956543,
      "logps/chosen": -229.7747802734375,
      "logps/rejected": -232.95443725585938,
      "loss": 0.2991,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.0209641456604004,
      "rewards/margins": 2.0634665489196777,
      "rewards/rejected": -5.084430694580078,
      "step": 14780
    },
    {
      "epoch": 2.482388460248239,
      "grad_norm": 2.6232008934020996,
      "learning_rate": 8.654813820865482e-06,
      "logits/chosen": 2.3816323280334473,
      "logits/rejected": 2.676663875579834,
      "logps/chosen": -227.9505615234375,
      "logps/rejected": -227.6196746826172,
      "loss": 0.3329,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.6806552410125732,
      "rewards/margins": 2.1779112815856934,
      "rewards/rejected": -4.858566761016846,
      "step": 14800
    },
    {
      "epoch": 2.4857430392485744,
      "grad_norm": 2.893667221069336,
      "learning_rate": 8.59890417085989e-06,
      "logits/chosen": 2.361624240875244,
      "logits/rejected": 2.649646043777466,
      "logps/chosen": -235.7958984375,
      "logps/rejected": -225.5065155029297,
      "loss": 0.3473,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.057969570159912,
      "rewards/margins": 1.9545705318450928,
      "rewards/rejected": -5.012539863586426,
      "step": 14820
    },
    {
      "epoch": 2.48909761824891,
      "grad_norm": 3.7791264057159424,
      "learning_rate": 8.5429945208543e-06,
      "logits/chosen": 2.075188159942627,
      "logits/rejected": 2.257023334503174,
      "logps/chosen": -220.16293334960938,
      "logps/rejected": -217.6977081298828,
      "loss": 0.305,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.826812267303467,
      "rewards/margins": 1.9062588214874268,
      "rewards/rejected": -4.733071327209473,
      "step": 14840
    },
    {
      "epoch": 2.492452197249245,
      "grad_norm": 4.744650363922119,
      "learning_rate": 8.487084870848708e-06,
      "logits/chosen": 2.311176061630249,
      "logits/rejected": 2.671140670776367,
      "logps/chosen": -218.1395263671875,
      "logps/rejected": -236.7777557373047,
      "loss": 0.3537,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.171858549118042,
      "rewards/margins": 2.1082406044006348,
      "rewards/rejected": -5.280098915100098,
      "step": 14860
    },
    {
      "epoch": 2.4958067762495806,
      "grad_norm": 3.75923752784729,
      "learning_rate": 8.431175220843119e-06,
      "logits/chosen": 2.3674697875976562,
      "logits/rejected": 2.66007137298584,
      "logps/chosen": -222.3753204345703,
      "logps/rejected": -217.5573272705078,
      "loss": 0.3056,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.079674005508423,
      "rewards/margins": 2.1819255352020264,
      "rewards/rejected": -5.261599540710449,
      "step": 14880
    },
    {
      "epoch": 2.499161355249916,
      "grad_norm": 3.2614736557006836,
      "learning_rate": 8.375265570837528e-06,
      "logits/chosen": 2.0640437602996826,
      "logits/rejected": 2.4345130920410156,
      "logps/chosen": -219.81442260742188,
      "logps/rejected": -224.0507049560547,
      "loss": 0.2168,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.9823780059814453,
      "rewards/margins": 2.522498369216919,
      "rewards/rejected": -5.504876136779785,
      "step": 14900
    },
    {
      "epoch": 2.5025159342502517,
      "grad_norm": 4.149655818939209,
      "learning_rate": 8.319355920831937e-06,
      "logits/chosen": 2.11918306350708,
      "logits/rejected": 2.425980567932129,
      "logps/chosen": -217.82470703125,
      "logps/rejected": -231.92562866210938,
      "loss": 0.3079,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.914288282394409,
      "rewards/margins": 2.302978038787842,
      "rewards/rejected": -5.217265605926514,
      "step": 14920
    },
    {
      "epoch": 2.505870513250587,
      "grad_norm": 2.6073191165924072,
      "learning_rate": 8.263446270826344e-06,
      "logits/chosen": 2.2789254188537598,
      "logits/rejected": 2.431770086288452,
      "logps/chosen": -219.8181915283203,
      "logps/rejected": -226.05496215820312,
      "loss": 0.4302,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.582498073577881,
      "rewards/margins": 1.791316270828247,
      "rewards/rejected": -5.373814582824707,
      "step": 14940
    },
    {
      "epoch": 2.5092250922509223,
      "grad_norm": 0.28033336997032166,
      "learning_rate": 8.207536620820753e-06,
      "logits/chosen": 2.242122173309326,
      "logits/rejected": 2.545584201812744,
      "logps/chosen": -208.20468139648438,
      "logps/rejected": -212.20547485351562,
      "loss": 0.2639,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.912416934967041,
      "rewards/margins": 2.495029926300049,
      "rewards/rejected": -5.40744686126709,
      "step": 14960
    },
    {
      "epoch": 2.512579671251258,
      "grad_norm": 2.858478307723999,
      "learning_rate": 8.151626970815162e-06,
      "logits/chosen": 2.0260839462280273,
      "logits/rejected": 2.377413511276245,
      "logps/chosen": -229.33676147460938,
      "logps/rejected": -217.89547729492188,
      "loss": 0.281,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.024481773376465,
      "rewards/margins": 2.058117151260376,
      "rewards/rejected": -5.082598686218262,
      "step": 14980
    },
    {
      "epoch": 2.5159342502515933,
      "grad_norm": 0.27245044708251953,
      "learning_rate": 8.095717320809572e-06,
      "logits/chosen": 2.3978333473205566,
      "logits/rejected": 2.6517348289489746,
      "logps/chosen": -234.8845672607422,
      "logps/rejected": -238.2650909423828,
      "loss": 0.3261,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.882672071456909,
      "rewards/margins": 1.9950494766235352,
      "rewards/rejected": -4.877721309661865,
      "step": 15000
    },
    {
      "epoch": 2.519288829251929,
      "grad_norm": 1.6845437288284302,
      "learning_rate": 8.039807670803981e-06,
      "logits/chosen": 2.2837867736816406,
      "logits/rejected": 2.5968375205993652,
      "logps/chosen": -233.2221221923828,
      "logps/rejected": -232.39529418945312,
      "loss": 0.2856,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.0070056915283203,
      "rewards/margins": 2.15014386177063,
      "rewards/rejected": -5.157149314880371,
      "step": 15020
    },
    {
      "epoch": 2.5226434082522644,
      "grad_norm": 5.411908149719238,
      "learning_rate": 7.98389802079839e-06,
      "logits/chosen": 1.9746967554092407,
      "logits/rejected": 2.2210404872894287,
      "logps/chosen": -220.1624298095703,
      "logps/rejected": -245.86239624023438,
      "loss": 0.2312,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.182129144668579,
      "rewards/margins": 2.3571152687072754,
      "rewards/rejected": -5.539244174957275,
      "step": 15040
    },
    {
      "epoch": 2.5259979872526,
      "grad_norm": 5.698423862457275,
      "learning_rate": 7.9279883707928e-06,
      "logits/chosen": 1.8893730640411377,
      "logits/rejected": 2.288104772567749,
      "logps/chosen": -210.73660278320312,
      "logps/rejected": -212.02096557617188,
      "loss": 0.3297,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.314242124557495,
      "rewards/margins": 2.1406352519989014,
      "rewards/rejected": -5.4548773765563965,
      "step": 15060
    },
    {
      "epoch": 2.5293525662529355,
      "grad_norm": 3.40191912651062,
      "learning_rate": 7.872078720787208e-06,
      "logits/chosen": 2.136490821838379,
      "logits/rejected": 2.56689453125,
      "logps/chosen": -221.88113403320312,
      "logps/rejected": -215.82064819335938,
      "loss": 0.2652,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.55764102935791,
      "rewards/margins": 2.326932191848755,
      "rewards/rejected": -4.884572982788086,
      "step": 15080
    },
    {
      "epoch": 2.5327071452532706,
      "grad_norm": 2.225102424621582,
      "learning_rate": 7.816169070781617e-06,
      "logits/chosen": 2.126979112625122,
      "logits/rejected": 2.481126070022583,
      "logps/chosen": -227.299560546875,
      "logps/rejected": -228.9939727783203,
      "loss": 0.2039,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.72056245803833,
      "rewards/margins": 2.4585342407226562,
      "rewards/rejected": -5.179096698760986,
      "step": 15100
    },
    {
      "epoch": 2.536061724253606,
      "grad_norm": 3.3700008392333984,
      "learning_rate": 7.760259420776026e-06,
      "logits/chosen": 2.2810885906219482,
      "logits/rejected": 2.4330005645751953,
      "logps/chosen": -219.09933471679688,
      "logps/rejected": -217.8694610595703,
      "loss": 0.2862,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.9770009517669678,
      "rewards/margins": 2.013597249984741,
      "rewards/rejected": -4.990598201751709,
      "step": 15120
    },
    {
      "epoch": 2.5394163032539416,
      "grad_norm": 4.413935661315918,
      "learning_rate": 7.704349770770437e-06,
      "logits/chosen": 2.159950017929077,
      "logits/rejected": 2.399028778076172,
      "logps/chosen": -217.55502319335938,
      "logps/rejected": -219.760498046875,
      "loss": 0.3252,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.876866102218628,
      "rewards/margins": 1.9953529834747314,
      "rewards/rejected": -4.872219085693359,
      "step": 15140
    },
    {
      "epoch": 2.542770882254277,
      "grad_norm": 2.780512571334839,
      "learning_rate": 7.648440120764844e-06,
      "logits/chosen": 2.25284743309021,
      "logits/rejected": 2.694692373275757,
      "logps/chosen": -218.0556640625,
      "logps/rejected": -226.3470458984375,
      "loss": 0.2449,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.6859309673309326,
      "rewards/margins": 2.3886160850524902,
      "rewards/rejected": -5.074547290802002,
      "step": 15160
    },
    {
      "epoch": 2.5461254612546127,
      "grad_norm": 1.2548251152038574,
      "learning_rate": 7.592530470759253e-06,
      "logits/chosen": 2.1513655185699463,
      "logits/rejected": 2.61845064163208,
      "logps/chosen": -227.0581512451172,
      "logps/rejected": -233.88656616210938,
      "loss": 0.3405,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.977327823638916,
      "rewards/margins": 2.0276269912719727,
      "rewards/rejected": -5.0049543380737305,
      "step": 15180
    },
    {
      "epoch": 2.549480040254948,
      "grad_norm": 1.12458336353302,
      "learning_rate": 7.536620820753662e-06,
      "logits/chosen": 2.289623975753784,
      "logits/rejected": 2.742920398712158,
      "logps/chosen": -225.6122283935547,
      "logps/rejected": -213.10165405273438,
      "loss": 0.2937,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.7875473499298096,
      "rewards/margins": 2.130232810974121,
      "rewards/rejected": -4.917779922485352,
      "step": 15200
    },
    {
      "epoch": 2.5528346192552833,
      "grad_norm": 2.2801265716552734,
      "learning_rate": 7.480711170748071e-06,
      "logits/chosen": 2.1419436931610107,
      "logits/rejected": 2.4840102195739746,
      "logps/chosen": -212.27371215820312,
      "logps/rejected": -223.0791778564453,
      "loss": 0.2754,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.7710702419281006,
      "rewards/margins": 2.0729618072509766,
      "rewards/rejected": -4.844031810760498,
      "step": 15220
    },
    {
      "epoch": 2.556189198255619,
      "grad_norm": 9.398368835449219,
      "learning_rate": 7.42480152074248e-06,
      "logits/chosen": 2.1089587211608887,
      "logits/rejected": 2.4028730392456055,
      "logps/chosen": -221.7052459716797,
      "logps/rejected": -228.63525390625,
      "loss": 0.2932,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.696791887283325,
      "rewards/margins": 2.30501127243042,
      "rewards/rejected": -5.001802921295166,
      "step": 15240
    },
    {
      "epoch": 2.5595437772559544,
      "grad_norm": 1.1929309368133545,
      "learning_rate": 7.368891870736889e-06,
      "logits/chosen": 2.18384051322937,
      "logits/rejected": 2.507350444793701,
      "logps/chosen": -219.13943481445312,
      "logps/rejected": -218.30322265625,
      "loss": 0.3319,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.8215343952178955,
      "rewards/margins": 2.3695099353790283,
      "rewards/rejected": -5.191044330596924,
      "step": 15260
    },
    {
      "epoch": 2.56289835625629,
      "grad_norm": 1.5556179285049438,
      "learning_rate": 7.312982220731299e-06,
      "logits/chosen": 2.081852912902832,
      "logits/rejected": 2.6215546131134033,
      "logps/chosen": -213.2369384765625,
      "logps/rejected": -202.46763610839844,
      "loss": 0.234,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.660677433013916,
      "rewards/margins": 2.8291046619415283,
      "rewards/rejected": -5.489782333374023,
      "step": 15280
    },
    {
      "epoch": 2.5662529352566255,
      "grad_norm": 3.2901804447174072,
      "learning_rate": 7.257072570725708e-06,
      "logits/chosen": 2.106522798538208,
      "logits/rejected": 2.5169951915740967,
      "logps/chosen": -194.68101501464844,
      "logps/rejected": -214.8332061767578,
      "loss": 0.1751,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.4833006858825684,
      "rewards/margins": 2.764829397201538,
      "rewards/rejected": -5.248129844665527,
      "step": 15300
    },
    {
      "epoch": 2.569607514256961,
      "grad_norm": 8.10143756866455,
      "learning_rate": 7.201162920720117e-06,
      "logits/chosen": 2.1148972511291504,
      "logits/rejected": 2.422746181488037,
      "logps/chosen": -227.21084594726562,
      "logps/rejected": -227.2710418701172,
      "loss": 0.3292,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.783052921295166,
      "rewards/margins": 1.9138774871826172,
      "rewards/rejected": -4.696930408477783,
      "step": 15320
    },
    {
      "epoch": 2.572962093257296,
      "grad_norm": 7.79780387878418,
      "learning_rate": 7.145253270714526e-06,
      "logits/chosen": 2.1319961547851562,
      "logits/rejected": 2.4904048442840576,
      "logps/chosen": -218.5167694091797,
      "logps/rejected": -218.5008544921875,
      "loss": 0.2982,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.7057323455810547,
      "rewards/margins": 2.0919299125671387,
      "rewards/rejected": -4.797662258148193,
      "step": 15340
    },
    {
      "epoch": 2.5763166722576316,
      "grad_norm": 1.5066721439361572,
      "learning_rate": 7.0893436207089355e-06,
      "logits/chosen": 2.151416301727295,
      "logits/rejected": 2.441037654876709,
      "logps/chosen": -218.8023223876953,
      "logps/rejected": -227.202880859375,
      "loss": 0.21,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.640770435333252,
      "rewards/margins": 2.6818385124206543,
      "rewards/rejected": -5.3226094245910645,
      "step": 15360
    },
    {
      "epoch": 2.579671251257967,
      "grad_norm": 3.2066168785095215,
      "learning_rate": 7.033433970703343e-06,
      "logits/chosen": 2.1302428245544434,
      "logits/rejected": 2.545693874359131,
      "logps/chosen": -229.2940673828125,
      "logps/rejected": -211.9299774169922,
      "loss": 0.2424,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.869307518005371,
      "rewards/margins": 2.371216297149658,
      "rewards/rejected": -5.240523338317871,
      "step": 15380
    },
    {
      "epoch": 2.5830258302583027,
      "grad_norm": 2.5879290103912354,
      "learning_rate": 6.9775243206977525e-06,
      "logits/chosen": 2.062852621078491,
      "logits/rejected": 2.3475213050842285,
      "logps/chosen": -226.233642578125,
      "logps/rejected": -220.83505249023438,
      "loss": 0.2807,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.1040117740631104,
      "rewards/margins": 2.110832452774048,
      "rewards/rejected": -5.21484375,
      "step": 15400
    },
    {
      "epoch": 2.5863804092586378,
      "grad_norm": 3.0957627296447754,
      "learning_rate": 6.9216146706921614e-06,
      "logits/chosen": 2.002610921859741,
      "logits/rejected": 2.2735683917999268,
      "logps/chosen": -209.3827667236328,
      "logps/rejected": -222.4093780517578,
      "loss": 0.195,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.8663671016693115,
      "rewards/margins": 2.3250908851623535,
      "rewards/rejected": -5.191457748413086,
      "step": 15420
    },
    {
      "epoch": 2.5897349882589733,
      "grad_norm": 5.9529032707214355,
      "learning_rate": 6.86570502068657e-06,
      "logits/chosen": 2.1668317317962646,
      "logits/rejected": 2.5748419761657715,
      "logps/chosen": -201.48648071289062,
      "logps/rejected": -207.7415008544922,
      "loss": 0.2864,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.212796688079834,
      "rewards/margins": 2.399552583694458,
      "rewards/rejected": -5.612349510192871,
      "step": 15440
    },
    {
      "epoch": 2.593089567259309,
      "grad_norm": 1.0601589679718018,
      "learning_rate": 6.80979537068098e-06,
      "logits/chosen": 2.2056353092193604,
      "logits/rejected": 2.584106206893921,
      "logps/chosen": -221.5289764404297,
      "logps/rejected": -221.65396118164062,
      "loss": 0.2863,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.8500008583068848,
      "rewards/margins": 2.5111186504364014,
      "rewards/rejected": -5.361119747161865,
      "step": 15460
    },
    {
      "epoch": 2.5964441462596444,
      "grad_norm": 2.9615652561187744,
      "learning_rate": 6.753885720675389e-06,
      "logits/chosen": 2.3557891845703125,
      "logits/rejected": 2.702000141143799,
      "logps/chosen": -224.32479858398438,
      "logps/rejected": -229.65969848632812,
      "loss": 0.3128,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.4765071868896484,
      "rewards/margins": 2.1799821853637695,
      "rewards/rejected": -5.656489372253418,
      "step": 15480
    },
    {
      "epoch": 2.59979872525998,
      "grad_norm": 6.966286659240723,
      "learning_rate": 6.697976070669798e-06,
      "logits/chosen": 2.1014533042907715,
      "logits/rejected": 2.46175479888916,
      "logps/chosen": -218.0922088623047,
      "logps/rejected": -212.44577026367188,
      "loss": 0.2387,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.3323841094970703,
      "rewards/margins": 2.5068373680114746,
      "rewards/rejected": -5.839221954345703,
      "step": 15500
    },
    {
      "epoch": 2.6031533042603154,
      "grad_norm": 9.994613647460938,
      "learning_rate": 6.642066420664207e-06,
      "logits/chosen": 2.1959784030914307,
      "logits/rejected": 2.36141300201416,
      "logps/chosen": -216.3162841796875,
      "logps/rejected": -221.68905639648438,
      "loss": 0.3102,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.1205830574035645,
      "rewards/margins": 2.0015556812286377,
      "rewards/rejected": -5.122138977050781,
      "step": 15520
    },
    {
      "epoch": 2.606507883260651,
      "grad_norm": 1.8064523935317993,
      "learning_rate": 6.586156770658617e-06,
      "logits/chosen": 2.0375173091888428,
      "logits/rejected": 2.387648105621338,
      "logps/chosen": -223.95394897460938,
      "logps/rejected": -225.8160858154297,
      "loss": 0.2315,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.3914170265197754,
      "rewards/margins": 2.4662811756134033,
      "rewards/rejected": -5.8576979637146,
      "step": 15540
    },
    {
      "epoch": 2.6098624622609865,
      "grad_norm": 8.918169021606445,
      "learning_rate": 6.5302471206530256e-06,
      "logits/chosen": 2.0956974029541016,
      "logits/rejected": 2.3361477851867676,
      "logps/chosen": -243.2032470703125,
      "logps/rejected": -237.31979370117188,
      "loss": 0.4328,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.454521894454956,
      "rewards/margins": 2.012193202972412,
      "rewards/rejected": -5.466715335845947,
      "step": 15560
    },
    {
      "epoch": 2.6132170412613216,
      "grad_norm": 3.1234660148620605,
      "learning_rate": 6.4743374706474345e-06,
      "logits/chosen": 1.955234169960022,
      "logits/rejected": 2.1922106742858887,
      "logps/chosen": -225.79043579101562,
      "logps/rejected": -235.02206420898438,
      "loss": 0.2681,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.046483039855957,
      "rewards/margins": 2.0026822090148926,
      "rewards/rejected": -5.049164772033691,
      "step": 15580
    },
    {
      "epoch": 2.616571620261657,
      "grad_norm": 2.467576026916504,
      "learning_rate": 6.4184278206418425e-06,
      "logits/chosen": 2.29538631439209,
      "logits/rejected": 2.4652695655822754,
      "logps/chosen": -244.1722869873047,
      "logps/rejected": -248.13577270507812,
      "loss": 0.2433,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.0759165287017822,
      "rewards/margins": 2.688171148300171,
      "rewards/rejected": -5.764088153839111,
      "step": 15600
    },
    {
      "epoch": 2.6199261992619927,
      "grad_norm": 2.801546335220337,
      "learning_rate": 6.3625181706362515e-06,
      "logits/chosen": 2.1501379013061523,
      "logits/rejected": 2.4973392486572266,
      "logps/chosen": -232.5785675048828,
      "logps/rejected": -234.3361358642578,
      "loss": 0.3416,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.74542236328125,
      "rewards/margins": 1.8986259698867798,
      "rewards/rejected": -5.64404821395874,
      "step": 15620
    },
    {
      "epoch": 2.623280778262328,
      "grad_norm": 1.1218633651733398,
      "learning_rate": 6.30660852063066e-06,
      "logits/chosen": 1.9220062494277954,
      "logits/rejected": 2.2829205989837646,
      "logps/chosen": -221.65768432617188,
      "logps/rejected": -230.32492065429688,
      "loss": 0.2573,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.4123268127441406,
      "rewards/margins": 2.443542242050171,
      "rewards/rejected": -5.855869770050049,
      "step": 15640
    },
    {
      "epoch": 2.6266353572626633,
      "grad_norm": 7.996606826782227,
      "learning_rate": 6.25069887062507e-06,
      "logits/chosen": 2.020564556121826,
      "logits/rejected": 2.407987117767334,
      "logps/chosen": -236.76968383789062,
      "logps/rejected": -237.4559326171875,
      "loss": 0.2334,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.095140218734741,
      "rewards/margins": 2.6088385581970215,
      "rewards/rejected": -5.7039794921875,
      "step": 15660
    },
    {
      "epoch": 2.629989936262999,
      "grad_norm": 1.370733618736267,
      "learning_rate": 6.194789220619479e-06,
      "logits/chosen": 2.1591169834136963,
      "logits/rejected": 2.385971784591675,
      "logps/chosen": -241.21859741210938,
      "logps/rejected": -253.66506958007812,
      "loss": 0.25,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.4478187561035156,
      "rewards/margins": 2.4159252643585205,
      "rewards/rejected": -5.863743305206299,
      "step": 15680
    },
    {
      "epoch": 2.6333445152633344,
      "grad_norm": 7.44163703918457,
      "learning_rate": 6.138879570613888e-06,
      "logits/chosen": 2.0519580841064453,
      "logits/rejected": 2.4374775886535645,
      "logps/chosen": -235.7771453857422,
      "logps/rejected": -217.0628204345703,
      "loss": 0.4229,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.6079087257385254,
      "rewards/margins": 2.0402121543884277,
      "rewards/rejected": -5.648120880126953,
      "step": 15700
    },
    {
      "epoch": 2.63669909426367,
      "grad_norm": 6.82700777053833,
      "learning_rate": 6.082969920608298e-06,
      "logits/chosen": 2.095024347305298,
      "logits/rejected": 2.3944525718688965,
      "logps/chosen": -213.8292999267578,
      "logps/rejected": -212.56704711914062,
      "loss": 0.3125,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.3589253425598145,
      "rewards/margins": 2.0653481483459473,
      "rewards/rejected": -5.424273490905762,
      "step": 15720
    },
    {
      "epoch": 2.6400536732640054,
      "grad_norm": 4.221988677978516,
      "learning_rate": 6.027060270602707e-06,
      "logits/chosen": 2.0981719493865967,
      "logits/rejected": 2.361149787902832,
      "logps/chosen": -207.4888458251953,
      "logps/rejected": -212.075439453125,
      "loss": 0.3843,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.364067792892456,
      "rewards/margins": 2.2886390686035156,
      "rewards/rejected": -5.652707576751709,
      "step": 15740
    },
    {
      "epoch": 2.643408252264341,
      "grad_norm": 0.8081954717636108,
      "learning_rate": 5.971150620597115e-06,
      "logits/chosen": 1.8931804895401,
      "logits/rejected": 2.3526203632354736,
      "logps/chosen": -219.19155883789062,
      "logps/rejected": -226.7624969482422,
      "loss": 0.1841,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.6377079486846924,
      "rewards/margins": 2.7223777770996094,
      "rewards/rejected": -5.360085964202881,
      "step": 15760
    },
    {
      "epoch": 2.6467628312646765,
      "grad_norm": 2.661365270614624,
      "learning_rate": 5.9152409705915245e-06,
      "logits/chosen": 2.0951194763183594,
      "logits/rejected": 2.338243246078491,
      "logps/chosen": -231.1755828857422,
      "logps/rejected": -223.5063934326172,
      "loss": 0.3384,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.8653342723846436,
      "rewards/margins": 1.9301897287368774,
      "rewards/rejected": -4.795524597167969,
      "step": 15780
    },
    {
      "epoch": 2.6501174102650116,
      "grad_norm": 1.9825515747070312,
      "learning_rate": 5.859331320585933e-06,
      "logits/chosen": 2.23728609085083,
      "logits/rejected": 2.390479803085327,
      "logps/chosen": -225.7233428955078,
      "logps/rejected": -248.24755859375,
      "loss": 0.417,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.148012638092041,
      "rewards/margins": 2.093352794647217,
      "rewards/rejected": -5.241365909576416,
      "step": 15800
    },
    {
      "epoch": 2.653471989265347,
      "grad_norm": 3.1586601734161377,
      "learning_rate": 5.803421670580342e-06,
      "logits/chosen": 2.0860023498535156,
      "logits/rejected": 2.2310824394226074,
      "logps/chosen": -222.08535766601562,
      "logps/rejected": -233.9508819580078,
      "loss": 0.2609,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.2421162128448486,
      "rewards/margins": 2.3510196208953857,
      "rewards/rejected": -5.593135833740234,
      "step": 15820
    },
    {
      "epoch": 2.6568265682656826,
      "grad_norm": 2.2693958282470703,
      "learning_rate": 5.747512020574751e-06,
      "logits/chosen": 1.8805614709854126,
      "logits/rejected": 2.3398213386535645,
      "logps/chosen": -221.717529296875,
      "logps/rejected": -220.1809844970703,
      "loss": 0.2857,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.094010829925537,
      "rewards/margins": 2.2845828533172607,
      "rewards/rejected": -5.378593921661377,
      "step": 15840
    },
    {
      "epoch": 2.660181147266018,
      "grad_norm": 5.996692180633545,
      "learning_rate": 5.691602370569161e-06,
      "logits/chosen": 2.010985851287842,
      "logits/rejected": 2.4228291511535645,
      "logps/chosen": -210.69082641601562,
      "logps/rejected": -228.99966430664062,
      "loss": 0.1757,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.9633255004882812,
      "rewards/margins": 2.971677541732788,
      "rewards/rejected": -5.935003757476807,
      "step": 15860
    },
    {
      "epoch": 2.6635357262663537,
      "grad_norm": 8.45685863494873,
      "learning_rate": 5.635692720563569e-06,
      "logits/chosen": 2.213296413421631,
      "logits/rejected": 2.4580178260803223,
      "logps/chosen": -223.9372100830078,
      "logps/rejected": -217.01632690429688,
      "loss": 0.3449,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.309652328491211,
      "rewards/margins": 2.0917418003082275,
      "rewards/rejected": -5.401393890380859,
      "step": 15880
    },
    {
      "epoch": 2.666890305266689,
      "grad_norm": 2.2898035049438477,
      "learning_rate": 5.579783070557979e-06,
      "logits/chosen": 2.017834186553955,
      "logits/rejected": 2.3984062671661377,
      "logps/chosen": -210.8733673095703,
      "logps/rejected": -207.0010986328125,
      "loss": 0.3358,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.0110816955566406,
      "rewards/margins": 2.184464931488037,
      "rewards/rejected": -5.195546627044678,
      "step": 15900
    },
    {
      "epoch": 2.6702448842670243,
      "grad_norm": 0.9787893891334534,
      "learning_rate": 5.523873420552388e-06,
      "logits/chosen": 2.3703951835632324,
      "logits/rejected": 2.7029151916503906,
      "logps/chosen": -228.0711212158203,
      "logps/rejected": -221.44381713867188,
      "loss": 0.3272,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.9568965435028076,
      "rewards/margins": 2.1721935272216797,
      "rewards/rejected": -5.129090309143066,
      "step": 15920
    },
    {
      "epoch": 2.67359946326736,
      "grad_norm": 2.0715630054473877,
      "learning_rate": 5.467963770546797e-06,
      "logits/chosen": 2.1521477699279785,
      "logits/rejected": 2.4878790378570557,
      "logps/chosen": -230.21792602539062,
      "logps/rejected": -231.2927703857422,
      "loss": 0.2508,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.818876028060913,
      "rewards/margins": 2.754271984100342,
      "rewards/rejected": -5.573147773742676,
      "step": 15940
    },
    {
      "epoch": 2.6769540422676954,
      "grad_norm": 1.8300713300704956,
      "learning_rate": 5.412054120541206e-06,
      "logits/chosen": 2.266221046447754,
      "logits/rejected": 2.51155161857605,
      "logps/chosen": -214.3106689453125,
      "logps/rejected": -204.91781616210938,
      "loss": 0.2794,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.6926071643829346,
      "rewards/margins": 2.422529458999634,
      "rewards/rejected": -5.115137100219727,
      "step": 15960
    },
    {
      "epoch": 2.680308621268031,
      "grad_norm": 2.6323935985565186,
      "learning_rate": 5.358939953035894e-06,
      "logits/chosen": 2.283614158630371,
      "logits/rejected": 2.671329975128174,
      "logps/chosen": -217.411865234375,
      "logps/rejected": -221.683349609375,
      "loss": 0.3546,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.8027095794677734,
      "rewards/margins": 2.0791642665863037,
      "rewards/rejected": -4.881874084472656,
      "step": 15980
    },
    {
      "epoch": 2.6836632002683665,
      "grad_norm": 10.62785530090332,
      "learning_rate": 5.303030303030304e-06,
      "logits/chosen": 2.0795958042144775,
      "logits/rejected": 2.4205780029296875,
      "logps/chosen": -222.3964385986328,
      "logps/rejected": -234.89682006835938,
      "loss": 0.2363,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -2.7846155166625977,
      "rewards/margins": 2.557804584503174,
      "rewards/rejected": -5.3424201011657715,
      "step": 16000
    },
    {
      "epoch": 2.687017779268702,
      "grad_norm": 1.46440851688385,
      "learning_rate": 5.247120653024713e-06,
      "logits/chosen": 2.1129021644592285,
      "logits/rejected": 2.4265646934509277,
      "logps/chosen": -209.35379028320312,
      "logps/rejected": -205.05380249023438,
      "loss": 0.3179,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.822880744934082,
      "rewards/margins": 2.075495958328247,
      "rewards/rejected": -4.898376941680908,
      "step": 16020
    },
    {
      "epoch": 2.690372358269037,
      "grad_norm": 2.764213800430298,
      "learning_rate": 5.191211003019121e-06,
      "logits/chosen": 2.148049831390381,
      "logits/rejected": 2.6061460971832275,
      "logps/chosen": -248.11508178710938,
      "logps/rejected": -237.4519500732422,
      "loss": 0.2738,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.6465823650360107,
      "rewards/margins": 2.320255756378174,
      "rewards/rejected": -4.9668378829956055,
      "step": 16040
    },
    {
      "epoch": 2.6937269372693726,
      "grad_norm": 6.644765377044678,
      "learning_rate": 5.13530135301353e-06,
      "logits/chosen": 2.475795269012451,
      "logits/rejected": 2.810211658477783,
      "logps/chosen": -225.81674194335938,
      "logps/rejected": -227.0778045654297,
      "loss": 0.3256,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.8888192176818848,
      "rewards/margins": 2.110408306121826,
      "rewards/rejected": -4.999227523803711,
      "step": 16060
    },
    {
      "epoch": 2.697081516269708,
      "grad_norm": 1.9985568523406982,
      "learning_rate": 5.079391703007939e-06,
      "logits/chosen": 2.3425188064575195,
      "logits/rejected": 2.6449666023254395,
      "logps/chosen": -233.5438995361328,
      "logps/rejected": -233.71029663085938,
      "loss": 0.2595,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.544351577758789,
      "rewards/margins": 2.3154163360595703,
      "rewards/rejected": -4.859767913818359,
      "step": 16080
    },
    {
      "epoch": 2.7004360952700437,
      "grad_norm": 1.5661916732788086,
      "learning_rate": 5.023482053002348e-06,
      "logits/chosen": 2.202491044998169,
      "logits/rejected": 2.5043373107910156,
      "logps/chosen": -229.9780731201172,
      "logps/rejected": -216.132080078125,
      "loss": 0.3188,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.391455888748169,
      "rewards/margins": 2.3395097255706787,
      "rewards/rejected": -4.730965614318848,
      "step": 16100
    },
    {
      "epoch": 2.7037906742703792,
      "grad_norm": 2.2347536087036133,
      "learning_rate": 4.967572402996758e-06,
      "logits/chosen": 2.4042458534240723,
      "logits/rejected": 2.6824769973754883,
      "logps/chosen": -208.5693817138672,
      "logps/rejected": -218.6754913330078,
      "loss": 0.3181,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.059274673461914,
      "rewards/margins": 2.1280529499053955,
      "rewards/rejected": -5.187327861785889,
      "step": 16120
    },
    {
      "epoch": 2.7071452532707143,
      "grad_norm": 2.653728723526001,
      "learning_rate": 4.911662752991167e-06,
      "logits/chosen": 2.3615963459014893,
      "logits/rejected": 2.6412882804870605,
      "logps/chosen": -209.68246459960938,
      "logps/rejected": -207.2457275390625,
      "loss": 0.2967,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.6958248615264893,
      "rewards/margins": 2.07185697555542,
      "rewards/rejected": -4.76768159866333,
      "step": 16140
    },
    {
      "epoch": 2.71049983227105,
      "grad_norm": 6.535830497741699,
      "learning_rate": 4.855753102985575e-06,
      "logits/chosen": 2.3246021270751953,
      "logits/rejected": 2.5847182273864746,
      "logps/chosen": -211.38818359375,
      "logps/rejected": -224.39578247070312,
      "loss": 0.3362,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.92067289352417,
      "rewards/margins": 2.31353497505188,
      "rewards/rejected": -5.234208106994629,
      "step": 16160
    },
    {
      "epoch": 2.7138544112713854,
      "grad_norm": 2.997615098953247,
      "learning_rate": 4.799843452979985e-06,
      "logits/chosen": 2.1482746601104736,
      "logits/rejected": 2.6623992919921875,
      "logps/chosen": -223.67880249023438,
      "logps/rejected": -209.840087890625,
      "loss": 0.3272,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.1054744720458984,
      "rewards/margins": 2.3261630535125732,
      "rewards/rejected": -5.431637763977051,
      "step": 16180
    },
    {
      "epoch": 2.717208990271721,
      "grad_norm": 5.799169063568115,
      "learning_rate": 4.743933802974394e-06,
      "logits/chosen": 2.29339337348938,
      "logits/rejected": 2.7083115577697754,
      "logps/chosen": -213.5828094482422,
      "logps/rejected": -214.8198699951172,
      "loss": 0.2308,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.910271167755127,
      "rewards/margins": 2.3478055000305176,
      "rewards/rejected": -5.2580766677856445,
      "step": 16200
    },
    {
      "epoch": 2.7205635692720564,
      "grad_norm": 6.451234340667725,
      "learning_rate": 4.688024152968803e-06,
      "logits/chosen": 2.3821940422058105,
      "logits/rejected": 2.733597993850708,
      "logps/chosen": -213.84793090820312,
      "logps/rejected": -218.9766082763672,
      "loss": 0.2658,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.935012102127075,
      "rewards/margins": 2.3978240489959717,
      "rewards/rejected": -5.332835674285889,
      "step": 16220
    },
    {
      "epoch": 2.723918148272392,
      "grad_norm": 4.106689453125,
      "learning_rate": 4.6321145029632115e-06,
      "logits/chosen": 2.1664977073669434,
      "logits/rejected": 2.4263222217559814,
      "logps/chosen": -229.9299774169922,
      "logps/rejected": -223.92764282226562,
      "loss": 0.2663,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.788215160369873,
      "rewards/margins": 2.413769006729126,
      "rewards/rejected": -5.201984405517578,
      "step": 16240
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 3.3822505474090576,
      "learning_rate": 4.5762048529576204e-06,
      "logits/chosen": 2.295708179473877,
      "logits/rejected": 2.5581469535827637,
      "logps/chosen": -219.26748657226562,
      "logps/rejected": -228.0113525390625,
      "loss": 0.1846,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.282639741897583,
      "rewards/margins": 2.698845386505127,
      "rewards/rejected": -5.981484889984131,
      "step": 16260
    },
    {
      "epoch": 2.7306273062730626,
      "grad_norm": 2.7032854557037354,
      "learning_rate": 4.520295202952029e-06,
      "logits/chosen": 2.290618896484375,
      "logits/rejected": 2.5932393074035645,
      "logps/chosen": -220.4052734375,
      "logps/rejected": -207.39120483398438,
      "loss": 0.3007,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.184765100479126,
      "rewards/margins": 1.9593693017959595,
      "rewards/rejected": -5.144134044647217,
      "step": 16280
    },
    {
      "epoch": 2.733981885273398,
      "grad_norm": 1.9347141981124878,
      "learning_rate": 4.464385552946439e-06,
      "logits/chosen": 2.152087450027466,
      "logits/rejected": 2.5936145782470703,
      "logps/chosen": -212.7353057861328,
      "logps/rejected": -194.32040405273438,
      "loss": 0.2652,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.0271947383880615,
      "rewards/margins": 2.236208200454712,
      "rewards/rejected": -5.263402938842773,
      "step": 16300
    },
    {
      "epoch": 2.7373364642737337,
      "grad_norm": 4.019633769989014,
      "learning_rate": 4.408475902940848e-06,
      "logits/chosen": 2.079009532928467,
      "logits/rejected": 2.378551483154297,
      "logps/chosen": -206.57504272460938,
      "logps/rejected": -213.3996124267578,
      "loss": 0.3839,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.7706496715545654,
      "rewards/margins": 2.001279830932617,
      "rewards/rejected": -4.771929740905762,
      "step": 16320
    },
    {
      "epoch": 2.740691043274069,
      "grad_norm": 6.350766181945801,
      "learning_rate": 4.352566252935257e-06,
      "logits/chosen": 2.370567798614502,
      "logits/rejected": 2.615828275680542,
      "logps/chosen": -213.1338348388672,
      "logps/rejected": -208.33944702148438,
      "loss": 0.3126,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.1700072288513184,
      "rewards/margins": 2.108337879180908,
      "rewards/rejected": -5.278344631195068,
      "step": 16340
    },
    {
      "epoch": 2.7440456222744043,
      "grad_norm": 8.52958869934082,
      "learning_rate": 4.296656602929666e-06,
      "logits/chosen": 2.182462692260742,
      "logits/rejected": 2.427983522415161,
      "logps/chosen": -203.7586212158203,
      "logps/rejected": -208.50888061523438,
      "loss": 0.3826,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.334789991378784,
      "rewards/margins": 1.829197645187378,
      "rewards/rejected": -5.163987636566162,
      "step": 16360
    },
    {
      "epoch": 2.74740020127474,
      "grad_norm": 2.5838210582733154,
      "learning_rate": 4.240746952924075e-06,
      "logits/chosen": 2.027345657348633,
      "logits/rejected": 2.3346261978149414,
      "logps/chosen": -223.2301483154297,
      "logps/rejected": -227.2598114013672,
      "loss": 0.3474,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.0448315143585205,
      "rewards/margins": 2.3677334785461426,
      "rewards/rejected": -5.412564754486084,
      "step": 16380
    },
    {
      "epoch": 2.7507547802750754,
      "grad_norm": 3.249972343444824,
      "learning_rate": 4.184837302918484e-06,
      "logits/chosen": 1.992653489112854,
      "logits/rejected": 2.369938850402832,
      "logps/chosen": -203.46652221679688,
      "logps/rejected": -212.55899047851562,
      "loss": 0.2219,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.250335216522217,
      "rewards/margins": 2.422602891921997,
      "rewards/rejected": -5.672938346862793,
      "step": 16400
    },
    {
      "epoch": 2.754109359275411,
      "grad_norm": 4.482507228851318,
      "learning_rate": 4.128927652912893e-06,
      "logits/chosen": 2.0566179752349854,
      "logits/rejected": 2.3182740211486816,
      "logps/chosen": -217.7155303955078,
      "logps/rejected": -247.46890258789062,
      "loss": 0.2517,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.9321024417877197,
      "rewards/margins": 2.722224712371826,
      "rewards/rejected": -5.654326915740967,
      "step": 16420
    },
    {
      "epoch": 2.7574639382757464,
      "grad_norm": 1.3003602027893066,
      "learning_rate": 4.073018002907302e-06,
      "logits/chosen": 2.114659547805786,
      "logits/rejected": 2.5447773933410645,
      "logps/chosen": -217.73306274414062,
      "logps/rejected": -213.2670440673828,
      "loss": 0.2923,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.4300179481506348,
      "rewards/margins": 2.4552383422851562,
      "rewards/rejected": -5.885256767272949,
      "step": 16440
    },
    {
      "epoch": 2.760818517276082,
      "grad_norm": 4.3273844718933105,
      "learning_rate": 4.017108352901711e-06,
      "logits/chosen": 2.1504931449890137,
      "logits/rejected": 2.276942729949951,
      "logps/chosen": -201.2663116455078,
      "logps/rejected": -224.49600219726562,
      "loss": 0.3664,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.9130773544311523,
      "rewards/margins": 1.9432907104492188,
      "rewards/rejected": -4.856368064880371,
      "step": 16460
    },
    {
      "epoch": 2.7641730962764175,
      "grad_norm": 5.8512678146362305,
      "learning_rate": 3.961198702896119e-06,
      "logits/chosen": 2.0888047218322754,
      "logits/rejected": 2.456747531890869,
      "logps/chosen": -234.30294799804688,
      "logps/rejected": -223.0177764892578,
      "loss": 0.252,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.032130002975464,
      "rewards/margins": 2.4426050186157227,
      "rewards/rejected": -5.474736213684082,
      "step": 16480
    },
    {
      "epoch": 2.767527675276753,
      "grad_norm": 2.3632476329803467,
      "learning_rate": 3.905289052890529e-06,
      "logits/chosen": 2.3454203605651855,
      "logits/rejected": 2.534301519393921,
      "logps/chosen": -227.0555419921875,
      "logps/rejected": -229.2587432861328,
      "loss": 0.3701,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.8647377490997314,
      "rewards/margins": 1.9420194625854492,
      "rewards/rejected": -4.806757926940918,
      "step": 16500
    },
    {
      "epoch": 2.770882254277088,
      "grad_norm": 1.7627806663513184,
      "learning_rate": 3.849379402884938e-06,
      "logits/chosen": 2.427314281463623,
      "logits/rejected": 2.6556339263916016,
      "logps/chosen": -213.34375,
      "logps/rejected": -217.6614990234375,
      "loss": 0.3777,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.235046863555908,
      "rewards/margins": 1.9128086566925049,
      "rewards/rejected": -5.147855281829834,
      "step": 16520
    },
    {
      "epoch": 2.7742368332774237,
      "grad_norm": 5.5344672203063965,
      "learning_rate": 3.7934697528793474e-06,
      "logits/chosen": 2.2578976154327393,
      "logits/rejected": 2.6670188903808594,
      "logps/chosen": -220.1119384765625,
      "logps/rejected": -222.5962371826172,
      "loss": 0.2158,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.7314352989196777,
      "rewards/margins": 2.571326732635498,
      "rewards/rejected": -5.302762031555176,
      "step": 16540
    },
    {
      "epoch": 2.777591412277759,
      "grad_norm": 1.1389925479888916,
      "learning_rate": 3.7375601028737563e-06,
      "logits/chosen": 2.02895450592041,
      "logits/rejected": 2.4233791828155518,
      "logps/chosen": -217.7256622314453,
      "logps/rejected": -235.9239501953125,
      "loss": 0.2062,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -3.163661479949951,
      "rewards/margins": 2.5770318508148193,
      "rewards/rejected": -5.740693092346191,
      "step": 16560
    },
    {
      "epoch": 2.7809459912780947,
      "grad_norm": 7.842658519744873,
      "learning_rate": 3.6816504528681657e-06,
      "logits/chosen": 2.2030766010284424,
      "logits/rejected": 2.6493992805480957,
      "logps/chosen": -234.20925903320312,
      "logps/rejected": -237.3217315673828,
      "loss": 0.2927,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.9796016216278076,
      "rewards/margins": 2.5178964138031006,
      "rewards/rejected": -5.497498035430908,
      "step": 16580
    },
    {
      "epoch": 2.78430057027843,
      "grad_norm": 8.459599494934082,
      "learning_rate": 3.625740802862574e-06,
      "logits/chosen": 2.2106947898864746,
      "logits/rejected": 2.6065866947174072,
      "logps/chosen": -220.37930297851562,
      "logps/rejected": -216.68807983398438,
      "loss": 0.3123,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.372408390045166,
      "rewards/margins": 2.300799608230591,
      "rewards/rejected": -5.673207759857178,
      "step": 16600
    },
    {
      "epoch": 2.7876551492787653,
      "grad_norm": 1.9382233619689941,
      "learning_rate": 3.569831152856983e-06,
      "logits/chosen": 2.1343021392822266,
      "logits/rejected": 2.294029474258423,
      "logps/chosen": -211.60501098632812,
      "logps/rejected": -224.64511108398438,
      "loss": 0.317,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.0841403007507324,
      "rewards/margins": 1.7663519382476807,
      "rewards/rejected": -4.850492000579834,
      "step": 16620
    },
    {
      "epoch": 2.791009728279101,
      "grad_norm": 8.82517147064209,
      "learning_rate": 3.5139215028513924e-06,
      "logits/chosen": 2.2515907287597656,
      "logits/rejected": 2.3599510192871094,
      "logps/chosen": -224.46005249023438,
      "logps/rejected": -226.9329376220703,
      "loss": 0.2527,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.291238307952881,
      "rewards/margins": 2.077375650405884,
      "rewards/rejected": -5.36861515045166,
      "step": 16640
    },
    {
      "epoch": 2.7943643072794364,
      "grad_norm": 6.655052185058594,
      "learning_rate": 3.4580118528458013e-06,
      "logits/chosen": 2.382784843444824,
      "logits/rejected": 2.891425848007202,
      "logps/chosen": -240.9080352783203,
      "logps/rejected": -221.11404418945312,
      "loss": 0.2929,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.8784899711608887,
      "rewards/margins": 2.4534988403320312,
      "rewards/rejected": -5.33198881149292,
      "step": 16660
    },
    {
      "epoch": 2.797718886279772,
      "grad_norm": 2.352111339569092,
      "learning_rate": 3.4021022028402107e-06,
      "logits/chosen": 2.0095956325531006,
      "logits/rejected": 2.317455291748047,
      "logps/chosen": -210.0966339111328,
      "logps/rejected": -206.9834442138672,
      "loss": 0.2514,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.7268974781036377,
      "rewards/margins": 2.407503366470337,
      "rewards/rejected": -5.134400367736816,
      "step": 16680
    },
    {
      "epoch": 2.8010734652801075,
      "grad_norm": 3.8210291862487793,
      "learning_rate": 3.346192552834619e-06,
      "logits/chosen": 2.071516275405884,
      "logits/rejected": 2.399357318878174,
      "logps/chosen": -231.54098510742188,
      "logps/rejected": -242.87893676757812,
      "loss": 0.203,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.5169663429260254,
      "rewards/margins": 2.6766204833984375,
      "rewards/rejected": -5.193586826324463,
      "step": 16700
    },
    {
      "epoch": 2.804428044280443,
      "grad_norm": 2.0222277641296387,
      "learning_rate": 3.290282902829028e-06,
      "logits/chosen": 2.368417739868164,
      "logits/rejected": 2.769566297531128,
      "logps/chosen": -228.962890625,
      "logps/rejected": -209.3704071044922,
      "loss": 0.2853,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.4377808570861816,
      "rewards/margins": 2.2407374382019043,
      "rewards/rejected": -5.678518295288086,
      "step": 16720
    },
    {
      "epoch": 2.807782623280778,
      "grad_norm": 1.5331069231033325,
      "learning_rate": 3.2343732528234374e-06,
      "logits/chosen": 2.2085471153259277,
      "logits/rejected": 2.675410032272339,
      "logps/chosen": -224.1543731689453,
      "logps/rejected": -235.5788116455078,
      "loss": 0.2552,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.4790542125701904,
      "rewards/margins": 2.4027252197265625,
      "rewards/rejected": -5.881779193878174,
      "step": 16740
    },
    {
      "epoch": 2.8111372022811136,
      "grad_norm": 1.7065788507461548,
      "learning_rate": 3.1784636028178468e-06,
      "logits/chosen": 2.2775473594665527,
      "logits/rejected": 2.595346450805664,
      "logps/chosen": -234.4472198486328,
      "logps/rejected": -214.56533813476562,
      "loss": 0.2784,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -3.1372416019439697,
      "rewards/margins": 2.1925747394561768,
      "rewards/rejected": -5.329816818237305,
      "step": 16760
    },
    {
      "epoch": 2.814491781281449,
      "grad_norm": 4.686037540435791,
      "learning_rate": 3.1225539528122553e-06,
      "logits/chosen": 2.132769823074341,
      "logits/rejected": 2.259711742401123,
      "logps/chosen": -231.7158203125,
      "logps/rejected": -239.1415557861328,
      "loss": 0.3991,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.233553647994995,
      "rewards/margins": 1.941009283065796,
      "rewards/rejected": -5.174563407897949,
      "step": 16780
    },
    {
      "epoch": 2.8178463602817847,
      "grad_norm": 2.6798951625823975,
      "learning_rate": 3.0666443028066646e-06,
      "logits/chosen": 2.3169028759002686,
      "logits/rejected": 2.4750895500183105,
      "logps/chosen": -233.7366485595703,
      "logps/rejected": -235.4228973388672,
      "loss": 0.3342,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.0036487579345703,
      "rewards/margins": 2.0225346088409424,
      "rewards/rejected": -5.026183128356934,
      "step": 16800
    },
    {
      "epoch": 2.8212009392821202,
      "grad_norm": 2.7031307220458984,
      "learning_rate": 3.010734652801074e-06,
      "logits/chosen": 2.22697114944458,
      "logits/rejected": 2.487767219543457,
      "logps/chosen": -230.8826904296875,
      "logps/rejected": -229.97982788085938,
      "loss": 0.2931,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.052467107772827,
      "rewards/margins": 2.4077582359313965,
      "rewards/rejected": -5.4602251052856445,
      "step": 16820
    },
    {
      "epoch": 2.8245555182824553,
      "grad_norm": 3.1475555896759033,
      "learning_rate": 2.9548250027954824e-06,
      "logits/chosen": 2.208188772201538,
      "logits/rejected": 2.6378962993621826,
      "logps/chosen": -250.3994903564453,
      "logps/rejected": -228.1487579345703,
      "loss": 0.4317,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.978527069091797,
      "rewards/margins": 2.280907154083252,
      "rewards/rejected": -5.259434700012207,
      "step": 16840
    },
    {
      "epoch": 2.827910097282791,
      "grad_norm": 7.4943695068359375,
      "learning_rate": 2.8989153527898918e-06,
      "logits/chosen": 2.330644130706787,
      "logits/rejected": 2.7269489765167236,
      "logps/chosen": -219.81112670898438,
      "logps/rejected": -212.998046875,
      "loss": 0.2814,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.89316987991333,
      "rewards/margins": 2.618436574935913,
      "rewards/rejected": -5.511606216430664,
      "step": 16860
    },
    {
      "epoch": 2.8312646762831264,
      "grad_norm": 1.3414608240127563,
      "learning_rate": 2.8430057027843007e-06,
      "logits/chosen": 2.2133986949920654,
      "logits/rejected": 2.405210256576538,
      "logps/chosen": -223.8961944580078,
      "logps/rejected": -238.97207641601562,
      "loss": 0.3028,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.874423027038574,
      "rewards/margins": 1.9686033725738525,
      "rewards/rejected": -4.843026161193848,
      "step": 16880
    },
    {
      "epoch": 2.834619255283462,
      "grad_norm": 4.993396282196045,
      "learning_rate": 2.7870960527787096e-06,
      "logits/chosen": 2.3283958435058594,
      "logits/rejected": 2.5363683700561523,
      "logps/chosen": -213.71713256835938,
      "logps/rejected": -224.0811309814453,
      "loss": 0.387,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.3093833923339844,
      "rewards/margins": 1.7701606750488281,
      "rewards/rejected": -5.0795440673828125,
      "step": 16900
    },
    {
      "epoch": 2.8379738342837975,
      "grad_norm": 2.6519017219543457,
      "learning_rate": 2.731186402773119e-06,
      "logits/chosen": 2.255064010620117,
      "logits/rejected": 2.6260385513305664,
      "logps/chosen": -218.28677368164062,
      "logps/rejected": -222.32559204101562,
      "loss": 0.2295,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.8271241188049316,
      "rewards/margins": 2.62196683883667,
      "rewards/rejected": -5.44909143447876,
      "step": 16920
    },
    {
      "epoch": 2.841328413284133,
      "grad_norm": 10.775538444519043,
      "learning_rate": 2.6752767527675275e-06,
      "logits/chosen": 2.2954261302948,
      "logits/rejected": 2.3612723350524902,
      "logps/chosen": -213.30517578125,
      "logps/rejected": -222.8955841064453,
      "loss": 0.3653,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.97172474861145,
      "rewards/margins": 2.0223147869110107,
      "rewards/rejected": -4.994040012359619,
      "step": 16940
    },
    {
      "epoch": 2.8446829922844685,
      "grad_norm": 7.879827499389648,
      "learning_rate": 2.619367102761937e-06,
      "logits/chosen": 2.103379011154175,
      "logits/rejected": 2.3572006225585938,
      "logps/chosen": -204.9468994140625,
      "logps/rejected": -204.27871704101562,
      "loss": 0.3827,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.2923686504364014,
      "rewards/margins": 1.8092931509017944,
      "rewards/rejected": -5.1016621589660645,
      "step": 16960
    },
    {
      "epoch": 2.8480375712848036,
      "grad_norm": 2.1221039295196533,
      "learning_rate": 2.563457452756346e-06,
      "logits/chosen": 2.1817104816436768,
      "logits/rejected": 2.4583897590637207,
      "logps/chosen": -220.0471954345703,
      "logps/rejected": -225.23471069335938,
      "loss": 0.3196,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.7733781337738037,
      "rewards/margins": 2.0356152057647705,
      "rewards/rejected": -4.808993339538574,
      "step": 16980
    },
    {
      "epoch": 2.851392150285139,
      "grad_norm": 3.459368944168091,
      "learning_rate": 2.5075478027507546e-06,
      "logits/chosen": 1.8959672451019287,
      "logits/rejected": 2.269874334335327,
      "logps/chosen": -218.5106201171875,
      "logps/rejected": -223.894775390625,
      "loss": 0.288,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.7190654277801514,
      "rewards/margins": 2.3039755821228027,
      "rewards/rejected": -5.023041725158691,
      "step": 17000
    },
    {
      "epoch": 2.8547467292854747,
      "grad_norm": 4.063632011413574,
      "learning_rate": 2.451638152745164e-06,
      "logits/chosen": 2.031242847442627,
      "logits/rejected": 2.421891689300537,
      "logps/chosen": -223.5740966796875,
      "logps/rejected": -237.49691772460938,
      "loss": 0.2769,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.275172472000122,
      "rewards/margins": 2.7704055309295654,
      "rewards/rejected": -6.045578956604004,
      "step": 17020
    },
    {
      "epoch": 2.85810130828581,
      "grad_norm": 3.535374879837036,
      "learning_rate": 2.395728502739573e-06,
      "logits/chosen": 2.178136110305786,
      "logits/rejected": 2.6176795959472656,
      "logps/chosen": -246.9913330078125,
      "logps/rejected": -230.26431274414062,
      "loss": 0.2849,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.0243732929229736,
      "rewards/margins": 2.2370731830596924,
      "rewards/rejected": -5.261446475982666,
      "step": 17040
    },
    {
      "epoch": 2.8614558872861457,
      "grad_norm": 1.7638554573059082,
      "learning_rate": 2.339818852733982e-06,
      "logits/chosen": 2.1536197662353516,
      "logits/rejected": 2.5344393253326416,
      "logps/chosen": -229.99710083007812,
      "logps/rejected": -239.73526000976562,
      "loss": 0.1987,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -3.2060635089874268,
      "rewards/margins": 2.523897409439087,
      "rewards/rejected": -5.729961395263672,
      "step": 17060
    },
    {
      "epoch": 2.864810466286481,
      "grad_norm": 7.206869602203369,
      "learning_rate": 2.283909202728391e-06,
      "logits/chosen": 2.306478977203369,
      "logits/rejected": 2.5240731239318848,
      "logps/chosen": -241.5635986328125,
      "logps/rejected": -252.2966766357422,
      "loss": 0.2522,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.2728359699249268,
      "rewards/margins": 2.358809232711792,
      "rewards/rejected": -5.631645202636719,
      "step": 17080
    },
    {
      "epoch": 2.8681650452868164,
      "grad_norm": 0.7616440057754517,
      "learning_rate": 2.2279995527228e-06,
      "logits/chosen": 1.9384864568710327,
      "logits/rejected": 2.301243543624878,
      "logps/chosen": -220.525634765625,
      "logps/rejected": -229.7890625,
      "loss": 0.3222,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.970526933670044,
      "rewards/margins": 2.1249606609344482,
      "rewards/rejected": -5.09548807144165,
      "step": 17100
    },
    {
      "epoch": 2.871519624287152,
      "grad_norm": 1.5288238525390625,
      "learning_rate": 2.172089902717209e-06,
      "logits/chosen": 2.235013723373413,
      "logits/rejected": 2.462029218673706,
      "logps/chosen": -222.32656860351562,
      "logps/rejected": -241.4478302001953,
      "loss": 0.2226,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.2798893451690674,
      "rewards/margins": 2.6973073482513428,
      "rewards/rejected": -5.977196216583252,
      "step": 17120
    },
    {
      "epoch": 2.8748742032874874,
      "grad_norm": 3.3563547134399414,
      "learning_rate": 2.1161802527116183e-06,
      "logits/chosen": 2.3312201499938965,
      "logits/rejected": 2.6893210411071777,
      "logps/chosen": -219.0833282470703,
      "logps/rejected": -217.621826171875,
      "loss": 0.2243,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.9621427059173584,
      "rewards/margins": 2.6313416957855225,
      "rewards/rejected": -5.593483924865723,
      "step": 17140
    },
    {
      "epoch": 2.878228782287823,
      "grad_norm": 3.7119204998016357,
      "learning_rate": 2.060270602706027e-06,
      "logits/chosen": 2.1344122886657715,
      "logits/rejected": 2.308337688446045,
      "logps/chosen": -223.46170043945312,
      "logps/rejected": -237.4285125732422,
      "loss": 0.2889,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.2910282611846924,
      "rewards/margins": 2.2044615745544434,
      "rewards/rejected": -5.495490074157715,
      "step": 17160
    },
    {
      "epoch": 2.8815833612881585,
      "grad_norm": 2.383998155593872,
      "learning_rate": 2.004360952700436e-06,
      "logits/chosen": 2.202573299407959,
      "logits/rejected": 2.4855377674102783,
      "logps/chosen": -228.902099609375,
      "logps/rejected": -230.18789672851562,
      "loss": 0.196,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.8111186027526855,
      "rewards/margins": 2.553682327270508,
      "rewards/rejected": -5.364800930023193,
      "step": 17180
    },
    {
      "epoch": 2.884937940288494,
      "grad_norm": 7.31025505065918,
      "learning_rate": 1.9484513026948455e-06,
      "logits/chosen": 2.130849838256836,
      "logits/rejected": 2.397843837738037,
      "logps/chosen": -221.23727416992188,
      "logps/rejected": -227.70492553710938,
      "loss": 0.3045,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.872516632080078,
      "rewards/margins": 2.299806594848633,
      "rewards/rejected": -5.172323226928711,
      "step": 17200
    },
    {
      "epoch": 2.888292519288829,
      "grad_norm": 5.607447624206543,
      "learning_rate": 1.8925416526892542e-06,
      "logits/chosen": 2.313453197479248,
      "logits/rejected": 2.5644822120666504,
      "logps/chosen": -218.40640258789062,
      "logps/rejected": -220.9708709716797,
      "loss": 0.3851,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.9635515213012695,
      "rewards/margins": 2.0665154457092285,
      "rewards/rejected": -5.030066967010498,
      "step": 17220
    },
    {
      "epoch": 2.8916470982891647,
      "grad_norm": 0.7110040187835693,
      "learning_rate": 1.8366320026836633e-06,
      "logits/chosen": 2.1183907985687256,
      "logits/rejected": 2.335793972015381,
      "logps/chosen": -218.67715454101562,
      "logps/rejected": -219.75979614257812,
      "loss": 0.3609,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.050551176071167,
      "rewards/margins": 1.9584085941314697,
      "rewards/rejected": -5.008959770202637,
      "step": 17240
    },
    {
      "epoch": 2.8950016772895,
      "grad_norm": 0.7780256271362305,
      "learning_rate": 1.7807223526780725e-06,
      "logits/chosen": 2.2545371055603027,
      "logits/rejected": 2.7476603984832764,
      "logps/chosen": -239.913818359375,
      "logps/rejected": -228.672119140625,
      "loss": 0.1944,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.80169939994812,
      "rewards/margins": 2.6092512607574463,
      "rewards/rejected": -5.410950660705566,
      "step": 17260
    },
    {
      "epoch": 2.8983562562898357,
      "grad_norm": 2.0421969890594482,
      "learning_rate": 1.7248127026724812e-06,
      "logits/chosen": 2.3022217750549316,
      "logits/rejected": 2.5923590660095215,
      "logps/chosen": -231.64962768554688,
      "logps/rejected": -220.76834106445312,
      "loss": 0.2663,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -3.0444793701171875,
      "rewards/margins": 2.4995503425598145,
      "rewards/rejected": -5.544029235839844,
      "step": 17280
    },
    {
      "epoch": 2.901710835290171,
      "grad_norm": 11.014618873596191,
      "learning_rate": 1.6689030526668905e-06,
      "logits/chosen": 2.2626030445098877,
      "logits/rejected": 2.4009037017822266,
      "logps/chosen": -228.63198852539062,
      "logps/rejected": -239.31472778320312,
      "loss": 0.3989,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.2078304290771484,
      "rewards/margins": 1.903924584388733,
      "rewards/rejected": -5.111754894256592,
      "step": 17300
    },
    {
      "epoch": 2.9050654142905064,
      "grad_norm": 1.3764077425003052,
      "learning_rate": 1.6129934026612996e-06,
      "logits/chosen": 1.914284348487854,
      "logits/rejected": 2.400237560272217,
      "logps/chosen": -220.6291046142578,
      "logps/rejected": -232.9436492919922,
      "loss": 0.2346,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -3.1989572048187256,
      "rewards/margins": 2.2435736656188965,
      "rewards/rejected": -5.442531108856201,
      "step": 17320
    },
    {
      "epoch": 2.908419993290842,
      "grad_norm": 4.600604057312012,
      "learning_rate": 1.5570837526557083e-06,
      "logits/chosen": 2.0879688262939453,
      "logits/rejected": 2.3131420612335205,
      "logps/chosen": -229.24642944335938,
      "logps/rejected": -216.80947875976562,
      "loss": 0.3645,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -3.5055270195007324,
      "rewards/margins": 1.8707301616668701,
      "rewards/rejected": -5.376256942749023,
      "step": 17340
    },
    {
      "epoch": 2.9117745722911774,
      "grad_norm": 5.098952770233154,
      "learning_rate": 1.5011741026501175e-06,
      "logits/chosen": 2.247544050216675,
      "logits/rejected": 2.3781895637512207,
      "logps/chosen": -229.0404052734375,
      "logps/rejected": -233.45419311523438,
      "loss": 0.2378,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.852835178375244,
      "rewards/margins": 2.3922877311706543,
      "rewards/rejected": -5.245123386383057,
      "step": 17360
    },
    {
      "epoch": 2.915129151291513,
      "grad_norm": 2.4004414081573486,
      "learning_rate": 1.4452644526445266e-06,
      "logits/chosen": 2.123284101486206,
      "logits/rejected": 2.5086686611175537,
      "logps/chosen": -218.06777954101562,
      "logps/rejected": -220.888916015625,
      "loss": 0.2033,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.374227523803711,
      "rewards/margins": 2.644097089767456,
      "rewards/rejected": -5.018324851989746,
      "step": 17380
    },
    {
      "epoch": 2.9184837302918485,
      "grad_norm": 2.212812900543213,
      "learning_rate": 1.3893548026389355e-06,
      "logits/chosen": 2.1347837448120117,
      "logits/rejected": 2.482247829437256,
      "logps/chosen": -225.08432006835938,
      "logps/rejected": -234.1053009033203,
      "loss": 0.5093,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.7547831535339355,
      "rewards/margins": 1.9991413354873657,
      "rewards/rejected": -5.75392484664917,
      "step": 17400
    },
    {
      "epoch": 2.921838309292184,
      "grad_norm": 3.702192544937134,
      "learning_rate": 1.3334451526333444e-06,
      "logits/chosen": 2.204420804977417,
      "logits/rejected": 2.513123035430908,
      "logps/chosen": -230.99038696289062,
      "logps/rejected": -228.1239776611328,
      "loss": 0.2659,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -3.1828484535217285,
      "rewards/margins": 2.1893463134765625,
      "rewards/rejected": -5.372194766998291,
      "step": 17420
    },
    {
      "epoch": 2.9251928882925196,
      "grad_norm": 1.9462642669677734,
      "learning_rate": 1.2775355026277536e-06,
      "logits/chosen": 2.2303338050842285,
      "logits/rejected": 2.4910311698913574,
      "logps/chosen": -232.55117797851562,
      "logps/rejected": -236.2613067626953,
      "loss": 0.3207,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.777980089187622,
      "rewards/margins": 2.2574639320373535,
      "rewards/rejected": -5.035443305969238,
      "step": 17440
    },
    {
      "epoch": 2.9285474672928546,
      "grad_norm": 9.89486312866211,
      "learning_rate": 1.2216258526221627e-06,
      "logits/chosen": 1.9238531589508057,
      "logits/rejected": 2.2452330589294434,
      "logps/chosen": -218.14559936523438,
      "logps/rejected": -224.8616180419922,
      "loss": 0.2941,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -3.025087833404541,
      "rewards/margins": 2.2001185417175293,
      "rewards/rejected": -5.225205898284912,
      "step": 17460
    },
    {
      "epoch": 2.93190204629319,
      "grad_norm": 5.14877986907959,
      "learning_rate": 1.1657162026165716e-06,
      "logits/chosen": 2.3597474098205566,
      "logits/rejected": 2.661830425262451,
      "logps/chosen": -219.1681671142578,
      "logps/rejected": -218.6982879638672,
      "loss": 0.2767,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.8262321949005127,
      "rewards/margins": 2.1367969512939453,
      "rewards/rejected": -4.963029384613037,
      "step": 17480
    },
    {
      "epoch": 2.9352566252935257,
      "grad_norm": 1.5046535730361938,
      "learning_rate": 1.1098065526109805e-06,
      "logits/chosen": 2.266122341156006,
      "logits/rejected": 2.572783946990967,
      "logps/chosen": -233.346435546875,
      "logps/rejected": -238.1828155517578,
      "loss": 0.3586,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.3776309490203857,
      "rewards/margins": 2.1692047119140625,
      "rewards/rejected": -5.546835899353027,
      "step": 17500
    }
  ],
  "logging_steps": 20,
  "max_steps": 17886,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
