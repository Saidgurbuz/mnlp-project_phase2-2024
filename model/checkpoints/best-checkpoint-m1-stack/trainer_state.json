{
  "best_metric": 0.5116240978240967,
  "best_model_checkpoint": "checkpoints/microsoft/Phi-3-mini-4k-instructm1-stackexchange/checkpoint-10000",
  "epoch": 1.7651731340648995,
  "eval_steps": 5000,
  "global_step": 30000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0011767820893765998,
      "grad_norm": 1.5254461765289307,
      "learning_rate": 4.9982347749338044e-05,
      "logits/chosen": 3.900395631790161,
      "logits/rejected": 3.8402252197265625,
      "logps/chosen": -360.44085693359375,
      "logps/rejected": -242.47372436523438,
      "loss": 0.6939,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.02048586495220661,
      "rewards/margins": -0.001155562698841095,
      "rewards/rejected": 0.021641425788402557,
      "step": 20
    },
    {
      "epoch": 0.0023535641787531996,
      "grad_norm": 1.9697396755218506,
      "learning_rate": 4.996371481808375e-05,
      "logits/chosen": 3.9402613639831543,
      "logits/rejected": 3.8616766929626465,
      "logps/chosen": -388.2665100097656,
      "logps/rejected": -323.2774353027344,
      "loss": 0.6933,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.12331090122461319,
      "rewards/margins": 0.00843190960586071,
      "rewards/rejected": 0.11487899720668793,
      "step": 40
    },
    {
      "epoch": 0.003530346268129799,
      "grad_norm": 1.7668659687042236,
      "learning_rate": 4.994410120623713e-05,
      "logits/chosen": 3.9183807373046875,
      "logits/rejected": 3.8901054859161377,
      "logps/chosen": -351.0728454589844,
      "logps/rejected": -300.46942138671875,
      "loss": 0.6964,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.1941693127155304,
      "rewards/margins": 0.00594489136710763,
      "rewards/rejected": 0.1882244199514389,
      "step": 60
    },
    {
      "epoch": 0.004707128357506399,
      "grad_norm": 1.5599195957183838,
      "learning_rate": 4.9924487594390514e-05,
      "logits/chosen": 3.9653072357177734,
      "logits/rejected": 3.6991043090820312,
      "logps/chosen": -377.24822998046875,
      "logps/rejected": -284.22637939453125,
      "loss": 0.6688,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.2467104196548462,
      "rewards/margins": 0.10124526172876358,
      "rewards/rejected": 0.1454651653766632,
      "step": 80
    },
    {
      "epoch": 0.0058839104468829985,
      "grad_norm": 1.3308852910995483,
      "learning_rate": 4.990487398254389e-05,
      "logits/chosen": 3.5815696716308594,
      "logits/rejected": 3.633587598800659,
      "logps/chosen": -405.48541259765625,
      "logps/rejected": -285.0711975097656,
      "loss": 0.6443,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.5704617500305176,
      "rewards/margins": 0.2501431703567505,
      "rewards/rejected": 0.3203186094760895,
      "step": 100
    },
    {
      "epoch": 0.007060692536259598,
      "grad_norm": 12.129755973815918,
      "learning_rate": 4.9885260370697266e-05,
      "logits/chosen": 3.834022045135498,
      "logits/rejected": 3.882880449295044,
      "logps/chosen": -372.14984130859375,
      "logps/rejected": -299.31488037109375,
      "loss": 0.7005,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.41529351472854614,
      "rewards/margins": 0.058628808706998825,
      "rewards/rejected": 0.3566647171974182,
      "step": 120
    },
    {
      "epoch": 0.008237474625636197,
      "grad_norm": 1.9748419523239136,
      "learning_rate": 4.986564675885064e-05,
      "logits/chosen": 3.7730154991149902,
      "logits/rejected": 3.7289671897888184,
      "logps/chosen": -375.16021728515625,
      "logps/rejected": -255.29873657226562,
      "loss": 0.6035,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.5462189316749573,
      "rewards/margins": 0.2810196876525879,
      "rewards/rejected": 0.2651991844177246,
      "step": 140
    },
    {
      "epoch": 0.009414256715012798,
      "grad_norm": 3.4173877239227295,
      "learning_rate": 4.9846033147004025e-05,
      "logits/chosen": 3.9152164459228516,
      "logits/rejected": 3.8350863456726074,
      "logps/chosen": -392.8147888183594,
      "logps/rejected": -260.2391662597656,
      "loss": 0.6098,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.9560530781745911,
      "rewards/margins": 0.44232016801834106,
      "rewards/rejected": 0.51373291015625,
      "step": 160
    },
    {
      "epoch": 0.010591038804389398,
      "grad_norm": 2.101566791534424,
      "learning_rate": 4.98264195351574e-05,
      "logits/chosen": 3.916400194168091,
      "logits/rejected": 3.8646912574768066,
      "logps/chosen": -371.033447265625,
      "logps/rejected": -282.98931884765625,
      "loss": 0.6297,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.9030427932739258,
      "rewards/margins": 0.30241239070892334,
      "rewards/rejected": 0.6006304025650024,
      "step": 180
    },
    {
      "epoch": 0.011767820893765997,
      "grad_norm": 9.50378131866455,
      "learning_rate": 4.980876728449544e-05,
      "logits/chosen": 4.025866508483887,
      "logits/rejected": 3.956840991973877,
      "logps/chosen": -400.8894958496094,
      "logps/rejected": -344.3956298828125,
      "loss": 0.6601,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.86541748046875,
      "rewards/margins": 0.2336219847202301,
      "rewards/rejected": 0.6317955851554871,
      "step": 200
    },
    {
      "epoch": 0.012944602983142596,
      "grad_norm": 2.233403444290161,
      "learning_rate": 4.978915367264882e-05,
      "logits/chosen": 3.910517454147339,
      "logits/rejected": 3.945924758911133,
      "logps/chosen": -358.63330078125,
      "logps/rejected": -255.28500366210938,
      "loss": 0.5691,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.8379963636398315,
      "rewards/margins": 0.41442403197288513,
      "rewards/rejected": 0.4235723614692688,
      "step": 220
    },
    {
      "epoch": 0.014121385072519196,
      "grad_norm": 1.7410368919372559,
      "learning_rate": 4.97695400608022e-05,
      "logits/chosen": 3.903799533843994,
      "logits/rejected": 3.8625686168670654,
      "logps/chosen": -332.7555236816406,
      "logps/rejected": -251.5962371826172,
      "loss": 0.6827,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.9066424369812012,
      "rewards/margins": 0.3188055455684662,
      "rewards/rejected": 0.5878368616104126,
      "step": 240
    },
    {
      "epoch": 0.015298167161895797,
      "grad_norm": 1.8304293155670166,
      "learning_rate": 4.9750907129547907e-05,
      "logits/chosen": 4.130089282989502,
      "logits/rejected": 4.150957107543945,
      "logps/chosen": -383.9068908691406,
      "logps/rejected": -307.9795837402344,
      "loss": 0.6326,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.9683011174201965,
      "rewards/margins": 0.3992183804512024,
      "rewards/rejected": 0.5690826773643494,
      "step": 260
    },
    {
      "epoch": 0.016474949251272394,
      "grad_norm": 1.9163124561309814,
      "learning_rate": 4.973129351770129e-05,
      "logits/chosen": 4.007089614868164,
      "logits/rejected": 3.8110275268554688,
      "logps/chosen": -424.3692321777344,
      "logps/rejected": -312.9939270019531,
      "loss": 0.569,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.8750608563423157,
      "rewards/margins": 0.5883294343948364,
      "rewards/rejected": 0.28673145174980164,
      "step": 280
    },
    {
      "epoch": 0.017651731340648995,
      "grad_norm": 2.091113567352295,
      "learning_rate": 4.9711679905854665e-05,
      "logits/chosen": 3.7061893939971924,
      "logits/rejected": 3.580970048904419,
      "logps/chosen": -338.0245666503906,
      "logps/rejected": -272.24444580078125,
      "loss": 0.5756,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.4752654433250427,
      "rewards/margins": 0.40292495489120483,
      "rewards/rejected": 0.07234050333499908,
      "step": 300
    },
    {
      "epoch": 0.018828513430025597,
      "grad_norm": 0.9327049851417542,
      "learning_rate": 4.969206629400804e-05,
      "logits/chosen": 4.0285539627075195,
      "logits/rejected": 3.9013915061950684,
      "logps/chosen": -391.6291198730469,
      "logps/rejected": -292.1979675292969,
      "loss": 0.4953,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": 0.4818529188632965,
      "rewards/margins": 0.6874235272407532,
      "rewards/rejected": -0.20557065308094025,
      "step": 320
    },
    {
      "epoch": 0.020005295519402194,
      "grad_norm": 2.402803659439087,
      "learning_rate": 4.9672452682161424e-05,
      "logits/chosen": 3.8268790245056152,
      "logits/rejected": 3.7688775062561035,
      "logps/chosen": -364.4779968261719,
      "logps/rejected": -318.02392578125,
      "loss": 0.473,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.45787858963012695,
      "rewards/margins": 0.9425182342529297,
      "rewards/rejected": -0.4846397042274475,
      "step": 340
    },
    {
      "epoch": 0.021182077608778795,
      "grad_norm": 1.6775134801864624,
      "learning_rate": 4.96528390703148e-05,
      "logits/chosen": 3.8257102966308594,
      "logits/rejected": 3.667287826538086,
      "logps/chosen": -370.01275634765625,
      "logps/rejected": -314.2824401855469,
      "loss": 0.652,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.09044554829597473,
      "rewards/margins": 0.7044962644577026,
      "rewards/rejected": -0.7949417233467102,
      "step": 360
    },
    {
      "epoch": 0.022358859698155393,
      "grad_norm": 2.8350586891174316,
      "learning_rate": 4.963322545846818e-05,
      "logits/chosen": 3.7369561195373535,
      "logits/rejected": 3.7751832008361816,
      "logps/chosen": -372.616943359375,
      "logps/rejected": -331.5437927246094,
      "loss": 0.6007,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.0641636848449707,
      "rewards/margins": 0.6223805546760559,
      "rewards/rejected": -0.55821692943573,
      "step": 380
    },
    {
      "epoch": 0.023535641787531994,
      "grad_norm": 2.017735481262207,
      "learning_rate": 4.961361184662156e-05,
      "logits/chosen": 4.153414249420166,
      "logits/rejected": 4.08019495010376,
      "logps/chosen": -342.8172302246094,
      "logps/rejected": -271.3729248046875,
      "loss": 0.4882,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.4404563307762146,
      "rewards/margins": 0.8139389157295227,
      "rewards/rejected": -0.3734826147556305,
      "step": 400
    },
    {
      "epoch": 0.024712423876908595,
      "grad_norm": 3.6527152061462402,
      "learning_rate": 4.9593998234774935e-05,
      "logits/chosen": 3.5079917907714844,
      "logits/rejected": 3.6696619987487793,
      "logps/chosen": -343.101318359375,
      "logps/rejected": -298.9163513183594,
      "loss": 0.6435,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.3289462625980377,
      "rewards/margins": 0.5772636532783508,
      "rewards/rejected": -0.2483173906803131,
      "step": 420
    },
    {
      "epoch": 0.025889205966285193,
      "grad_norm": 3.520559072494507,
      "learning_rate": 4.957438462292832e-05,
      "logits/chosen": 3.7533633708953857,
      "logits/rejected": 3.6913509368896484,
      "logps/chosen": -374.0718688964844,
      "logps/rejected": -300.1485595703125,
      "loss": 0.5111,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.4300743639469147,
      "rewards/margins": 0.7572190761566162,
      "rewards/rejected": -0.32714468240737915,
      "step": 440
    },
    {
      "epoch": 0.027065988055661794,
      "grad_norm": 5.592657566070557,
      "learning_rate": 4.9554771011081694e-05,
      "logits/chosen": 3.7846133708953857,
      "logits/rejected": 3.636369228363037,
      "logps/chosen": -340.8485412597656,
      "logps/rejected": -253.0006866455078,
      "loss": 0.5389,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.45587700605392456,
      "rewards/margins": 0.8077176213264465,
      "rewards/rejected": -0.3518405854701996,
      "step": 460
    },
    {
      "epoch": 0.02824277014503839,
      "grad_norm": 2.213132619857788,
      "learning_rate": 4.953515739923507e-05,
      "logits/chosen": 3.859320878982544,
      "logits/rejected": 3.818814516067505,
      "logps/chosen": -362.09869384765625,
      "logps/rejected": -243.79470825195312,
      "loss": 0.5015,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.15797922015190125,
      "rewards/margins": 0.8651782274246216,
      "rewards/rejected": -0.707198977470398,
      "step": 480
    },
    {
      "epoch": 0.029419552234414992,
      "grad_norm": 2.7466812133789062,
      "learning_rate": 4.951554378738845e-05,
      "logits/chosen": 3.891167163848877,
      "logits/rejected": 3.765198230743408,
      "logps/chosen": -398.6227111816406,
      "logps/rejected": -302.10772705078125,
      "loss": 0.481,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": 0.6767946481704712,
      "rewards/margins": 1.6680930852890015,
      "rewards/rejected": -0.9912985563278198,
      "step": 500
    },
    {
      "epoch": 0.030596334323791594,
      "grad_norm": 10.260536193847656,
      "learning_rate": 4.949593017554183e-05,
      "logits/chosen": 4.076114654541016,
      "logits/rejected": 3.906811475753784,
      "logps/chosen": -396.928466796875,
      "logps/rejected": -352.97210693359375,
      "loss": 0.6371,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.2834536135196686,
      "rewards/margins": 0.8419520258903503,
      "rewards/rejected": -1.1254055500030518,
      "step": 520
    },
    {
      "epoch": 0.03177311641316819,
      "grad_norm": 2.4830644130706787,
      "learning_rate": 4.9476316563695205e-05,
      "logits/chosen": 4.072566032409668,
      "logits/rejected": 4.033658981323242,
      "logps/chosen": -380.2648620605469,
      "logps/rejected": -286.54852294921875,
      "loss": 0.4961,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.6752105355262756,
      "rewards/margins": 1.1726411581039429,
      "rewards/rejected": -0.4974307417869568,
      "step": 540
    },
    {
      "epoch": 0.03294989850254479,
      "grad_norm": 2.5974762439727783,
      "learning_rate": 4.945670295184859e-05,
      "logits/chosen": 3.9953932762145996,
      "logits/rejected": 3.8423068523406982,
      "logps/chosen": -391.73583984375,
      "logps/rejected": -291.5584716796875,
      "loss": 0.5109,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.8004420399665833,
      "rewards/margins": 1.2213577032089233,
      "rewards/rejected": -0.4209156632423401,
      "step": 560
    },
    {
      "epoch": 0.03412668059192139,
      "grad_norm": 1.7080241441726685,
      "learning_rate": 4.9437089340001964e-05,
      "logits/chosen": 3.819143295288086,
      "logits/rejected": 3.7761147022247314,
      "logps/chosen": -358.1265563964844,
      "logps/rejected": -243.6231689453125,
      "loss": 0.7245,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 1.0529745817184448,
      "rewards/margins": 0.8881276249885559,
      "rewards/rejected": 0.16484704613685608,
      "step": 580
    },
    {
      "epoch": 0.03530346268129799,
      "grad_norm": 3.574545383453369,
      "learning_rate": 4.941747572815535e-05,
      "logits/chosen": 4.139566421508789,
      "logits/rejected": 4.035101413726807,
      "logps/chosen": -366.63189697265625,
      "logps/rejected": -289.80548095703125,
      "loss": 0.5214,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.577386736869812,
      "rewards/margins": 1.0600764751434326,
      "rewards/rejected": -0.48268961906433105,
      "step": 600
    },
    {
      "epoch": 0.03648024477067459,
      "grad_norm": 2.205604314804077,
      "learning_rate": 4.9397862116308716e-05,
      "logits/chosen": 4.130000114440918,
      "logits/rejected": 4.005960941314697,
      "logps/chosen": -340.24713134765625,
      "logps/rejected": -279.7795104980469,
      "loss": 0.6107,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.37436020374298096,
      "rewards/margins": 0.7005017995834351,
      "rewards/rejected": -1.074862003326416,
      "step": 620
    },
    {
      "epoch": 0.03765702686005119,
      "grad_norm": 2.76129412651062,
      "learning_rate": 4.93782485044621e-05,
      "logits/chosen": 3.4516398906707764,
      "logits/rejected": 3.318244457244873,
      "logps/chosen": -325.1761779785156,
      "logps/rejected": -274.773193359375,
      "loss": 0.4676,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7520124316215515,
      "rewards/margins": 1.309231162071228,
      "rewards/rejected": -2.061243772506714,
      "step": 640
    },
    {
      "epoch": 0.03883380894942779,
      "grad_norm": 11.018401145935059,
      "learning_rate": 4.935863489261548e-05,
      "logits/chosen": 4.113995552062988,
      "logits/rejected": 4.061814308166504,
      "logps/chosen": -409.7859802246094,
      "logps/rejected": -301.8441162109375,
      "loss": 0.5461,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.3927362561225891,
      "rewards/margins": 1.454493761062622,
      "rewards/rejected": -1.8472301959991455,
      "step": 660
    },
    {
      "epoch": 0.04001059103880439,
      "grad_norm": 1.2953948974609375,
      "learning_rate": 4.933902128076886e-05,
      "logits/chosen": 3.710878372192383,
      "logits/rejected": 3.695716142654419,
      "logps/chosen": -334.6805419921875,
      "logps/rejected": -264.6780700683594,
      "loss": 0.563,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.00876966118812561,
      "rewards/margins": 1.0767815113067627,
      "rewards/rejected": -1.0680118799209595,
      "step": 680
    },
    {
      "epoch": 0.041187373128180986,
      "grad_norm": 0.8281885385513306,
      "learning_rate": 4.9319407668922234e-05,
      "logits/chosen": 3.762863874435425,
      "logits/rejected": 3.622788906097412,
      "logps/chosen": -353.91802978515625,
      "logps/rejected": -286.88372802734375,
      "loss": 0.5924,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.47983860969543457,
      "rewards/margins": 1.1396396160125732,
      "rewards/rejected": -0.6598011255264282,
      "step": 700
    },
    {
      "epoch": 0.04236415521755759,
      "grad_norm": 4.776910305023193,
      "learning_rate": 4.9299794057075616e-05,
      "logits/chosen": 3.921567916870117,
      "logits/rejected": 3.7394046783447266,
      "logps/chosen": -370.81866455078125,
      "logps/rejected": -284.4834899902344,
      "loss": 0.4319,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.23730364441871643,
      "rewards/margins": 1.5752575397491455,
      "rewards/rejected": -1.81256103515625,
      "step": 720
    },
    {
      "epoch": 0.04354093730693419,
      "grad_norm": 8.162681579589844,
      "learning_rate": 4.928018044522899e-05,
      "logits/chosen": 3.8015167713165283,
      "logits/rejected": 3.749706268310547,
      "logps/chosen": -389.46527099609375,
      "logps/rejected": -320.925048828125,
      "loss": 0.9128,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.247753381729126,
      "rewards/margins": 0.9361881017684937,
      "rewards/rejected": -2.183941602706909,
      "step": 740
    },
    {
      "epoch": 0.044717719396310786,
      "grad_norm": 4.4951066970825195,
      "learning_rate": 4.926056683338237e-05,
      "logits/chosen": 3.888648271560669,
      "logits/rejected": 3.9926249980926514,
      "logps/chosen": -416.9427795410156,
      "logps/rejected": -360.1051025390625,
      "loss": 0.6041,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7696967124938965,
      "rewards/margins": 1.007421851158142,
      "rewards/rejected": -1.7771186828613281,
      "step": 760
    },
    {
      "epoch": 0.04589450148568739,
      "grad_norm": 5.278325080871582,
      "learning_rate": 4.9240953221535745e-05,
      "logits/chosen": 3.944300889968872,
      "logits/rejected": 4.001398086547852,
      "logps/chosen": -434.34149169921875,
      "logps/rejected": -325.01251220703125,
      "loss": 0.6002,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3501035273075104,
      "rewards/margins": 1.2332847118377686,
      "rewards/rejected": -1.5833882093429565,
      "step": 780
    },
    {
      "epoch": 0.04707128357506399,
      "grad_norm": 1.6958730220794678,
      "learning_rate": 4.922133960968913e-05,
      "logits/chosen": 3.6944797039031982,
      "logits/rejected": 3.6487317085266113,
      "logps/chosen": -364.77081298828125,
      "logps/rejected": -247.51992797851562,
      "loss": 0.6011,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.2680078446865082,
      "rewards/margins": 1.2830983400344849,
      "rewards/rejected": -1.5511062145233154,
      "step": 800
    },
    {
      "epoch": 0.048248065664440586,
      "grad_norm": 4.3562541007995605,
      "learning_rate": 4.920172599784251e-05,
      "logits/chosen": 4.092978000640869,
      "logits/rejected": 4.1068267822265625,
      "logps/chosen": -420.54364013671875,
      "logps/rejected": -337.3465270996094,
      "loss": 0.5035,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.23965664207935333,
      "rewards/margins": 1.5945289134979248,
      "rewards/rejected": -1.354872465133667,
      "step": 820
    },
    {
      "epoch": 0.04942484775381719,
      "grad_norm": 4.943789482116699,
      "learning_rate": 4.918211238599588e-05,
      "logits/chosen": 4.1860551834106445,
      "logits/rejected": 4.046498775482178,
      "logps/chosen": -382.2222595214844,
      "logps/rejected": -316.89996337890625,
      "loss": 0.5477,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.2570818066596985,
      "rewards/margins": 1.5199143886566162,
      "rewards/rejected": -1.7769962549209595,
      "step": 840
    },
    {
      "epoch": 0.05060162984319379,
      "grad_norm": 5.688907146453857,
      "learning_rate": 4.916249877414926e-05,
      "logits/chosen": 4.20327091217041,
      "logits/rejected": 4.186867713928223,
      "logps/chosen": -399.4376525878906,
      "logps/rejected": -324.53271484375,
      "loss": 0.6563,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.3120248019695282,
      "rewards/margins": 1.3329837322235107,
      "rewards/rejected": -1.6450084447860718,
      "step": 860
    },
    {
      "epoch": 0.051778411932570385,
      "grad_norm": 1.356244683265686,
      "learning_rate": 4.914288516230264e-05,
      "logits/chosen": 3.8484184741973877,
      "logits/rejected": 3.8800246715545654,
      "logps/chosen": -372.0093994140625,
      "logps/rejected": -322.9435119628906,
      "loss": 0.5232,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.48931360244750977,
      "rewards/margins": 1.2362161874771118,
      "rewards/rejected": -1.725529670715332,
      "step": 880
    },
    {
      "epoch": 0.05295519402194698,
      "grad_norm": 1.8186016082763672,
      "learning_rate": 4.912327155045602e-05,
      "logits/chosen": 3.7387402057647705,
      "logits/rejected": 3.543851852416992,
      "logps/chosen": -352.4692077636719,
      "logps/rejected": -298.968505859375,
      "loss": 0.5654,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4856582581996918,
      "rewards/margins": 1.6062490940093994,
      "rewards/rejected": -2.091907262802124,
      "step": 900
    },
    {
      "epoch": 0.05413197611132359,
      "grad_norm": 2.4463133811950684,
      "learning_rate": 4.91036579386094e-05,
      "logits/chosen": 3.7734375,
      "logits/rejected": 3.857956647872925,
      "logps/chosen": -432.7862243652344,
      "logps/rejected": -372.23797607421875,
      "loss": 0.5854,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7406041026115417,
      "rewards/margins": 1.4785432815551758,
      "rewards/rejected": -2.2191474437713623,
      "step": 920
    },
    {
      "epoch": 0.055308758200700185,
      "grad_norm": 2.736973285675049,
      "learning_rate": 4.908404432676277e-05,
      "logits/chosen": 3.988248348236084,
      "logits/rejected": 3.930492401123047,
      "logps/chosen": -372.42840576171875,
      "logps/rejected": -272.6148986816406,
      "loss": 0.5094,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.05474688857793808,
      "rewards/margins": 1.3170722723007202,
      "rewards/rejected": -1.371819257736206,
      "step": 940
    },
    {
      "epoch": 0.05648554029007678,
      "grad_norm": 1.4485270977020264,
      "learning_rate": 4.9064430714916156e-05,
      "logits/chosen": 3.727174758911133,
      "logits/rejected": 3.7471976280212402,
      "logps/chosen": -340.0306091308594,
      "logps/rejected": -275.3135070800781,
      "loss": 0.6254,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.2342185527086258,
      "rewards/margins": 1.2083375453948975,
      "rewards/rejected": -0.9741190075874329,
      "step": 960
    },
    {
      "epoch": 0.05766232237945339,
      "grad_norm": 3.713315725326538,
      "learning_rate": 4.904481710306953e-05,
      "logits/chosen": 4.630952835083008,
      "logits/rejected": 4.405138969421387,
      "logps/chosen": -446.93341064453125,
      "logps/rejected": -308.22991943359375,
      "loss": 0.4588,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0358780100941658,
      "rewards/margins": 1.6702337265014648,
      "rewards/rejected": -1.7061119079589844,
      "step": 980
    },
    {
      "epoch": 0.058839104468829985,
      "grad_norm": 1.8806114196777344,
      "learning_rate": 4.902520349122291e-05,
      "logits/chosen": 4.133631706237793,
      "logits/rejected": 4.138179302215576,
      "logps/chosen": -393.4853820800781,
      "logps/rejected": -308.95025634765625,
      "loss": 0.6467,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5368205308914185,
      "rewards/margins": 1.215238332748413,
      "rewards/rejected": -1.752058744430542,
      "step": 1000
    },
    {
      "epoch": 0.06001588655820658,
      "grad_norm": 3.793015956878662,
      "learning_rate": 4.900558987937629e-05,
      "logits/chosen": 3.953676223754883,
      "logits/rejected": 3.868178129196167,
      "logps/chosen": -379.8621520996094,
      "logps/rejected": -271.8783874511719,
      "loss": 0.5443,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1715949773788452,
      "rewards/margins": 1.2141220569610596,
      "rewards/rejected": -2.3857171535491943,
      "step": 1020
    },
    {
      "epoch": 0.06119266864758319,
      "grad_norm": 2.0467801094055176,
      "learning_rate": 4.898597626752967e-05,
      "logits/chosen": 4.050430774688721,
      "logits/rejected": 3.8657774925231934,
      "logps/chosen": -362.581787109375,
      "logps/rejected": -289.40423583984375,
      "loss": 0.6418,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5338000655174255,
      "rewards/margins": 1.2113792896270752,
      "rewards/rejected": -1.7451794147491455,
      "step": 1040
    },
    {
      "epoch": 0.062369450736959785,
      "grad_norm": 2.3004302978515625,
      "learning_rate": 4.896636265568304e-05,
      "logits/chosen": 4.347959041595459,
      "logits/rejected": 4.191531658172607,
      "logps/chosen": -436.72998046875,
      "logps/rejected": -292.93011474609375,
      "loss": 0.4789,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.10037461668252945,
      "rewards/margins": 1.8533389568328857,
      "rewards/rejected": -1.9537136554718018,
      "step": 1060
    },
    {
      "epoch": 0.06354623282633638,
      "grad_norm": 1.5299452543258667,
      "learning_rate": 4.8946749043836426e-05,
      "logits/chosen": 4.3108720779418945,
      "logits/rejected": 4.047286033630371,
      "logps/chosen": -390.0726318359375,
      "logps/rejected": -314.5362854003906,
      "loss": 0.6477,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4459100365638733,
      "rewards/margins": 1.2388843297958374,
      "rewards/rejected": -1.6847944259643555,
      "step": 1080
    },
    {
      "epoch": 0.06472301491571299,
      "grad_norm": 0.6241890788078308,
      "learning_rate": 4.89271354319898e-05,
      "logits/chosen": 3.951432704925537,
      "logits/rejected": 4.056035041809082,
      "logps/chosen": -360.0296630859375,
      "logps/rejected": -283.8064880371094,
      "loss": 0.454,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.0030016303062438965,
      "rewards/margins": 1.6558592319488525,
      "rewards/rejected": -1.6588609218597412,
      "step": 1100
    },
    {
      "epoch": 0.06589979700508958,
      "grad_norm": 2.2283122539520264,
      "learning_rate": 4.8907521820143185e-05,
      "logits/chosen": 3.8497097492218018,
      "logits/rejected": 3.7161452770233154,
      "logps/chosen": -382.31103515625,
      "logps/rejected": -334.86590576171875,
      "loss": 0.6896,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.5125923156738281,
      "rewards/margins": 1.3908063173294067,
      "rewards/rejected": -1.9033987522125244,
      "step": 1120
    },
    {
      "epoch": 0.06707657909446618,
      "grad_norm": 0.6517332792282104,
      "learning_rate": 4.888790820829656e-05,
      "logits/chosen": 3.8320515155792236,
      "logits/rejected": 3.758655071258545,
      "logps/chosen": -415.9683532714844,
      "logps/rejected": -288.14312744140625,
      "loss": 0.5499,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7394172549247742,
      "rewards/margins": 1.75783371925354,
      "rewards/rejected": -2.497251033782959,
      "step": 1140
    },
    {
      "epoch": 0.06825336118384279,
      "grad_norm": 3.827998399734497,
      "learning_rate": 4.886829459644994e-05,
      "logits/chosen": 3.5229644775390625,
      "logits/rejected": 3.4693922996520996,
      "logps/chosen": -336.84320068359375,
      "logps/rejected": -258.86016845703125,
      "loss": 0.6243,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6742600202560425,
      "rewards/margins": 1.2576825618743896,
      "rewards/rejected": -1.9319425821304321,
      "step": 1160
    },
    {
      "epoch": 0.06943014327321938,
      "grad_norm": 1.1400065422058105,
      "learning_rate": 4.884868098460332e-05,
      "logits/chosen": 3.9860928058624268,
      "logits/rejected": 3.803433895111084,
      "logps/chosen": -371.8504943847656,
      "logps/rejected": -314.41851806640625,
      "loss": 0.4951,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.702863872051239,
      "rewards/margins": 1.8372390270233154,
      "rewards/rejected": -2.5401031970977783,
      "step": 1180
    },
    {
      "epoch": 0.07060692536259598,
      "grad_norm": 2.0643599033355713,
      "learning_rate": 4.8829067372756696e-05,
      "logits/chosen": 4.066655158996582,
      "logits/rejected": 4.06344747543335,
      "logps/chosen": -404.74859619140625,
      "logps/rejected": -287.55413818359375,
      "loss": 0.4003,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.21836185455322266,
      "rewards/margins": 2.05254864692688,
      "rewards/rejected": -1.8341869115829468,
      "step": 1200
    },
    {
      "epoch": 0.07178370745197259,
      "grad_norm": 3.1075053215026855,
      "learning_rate": 4.880945376091007e-05,
      "logits/chosen": 3.876721143722534,
      "logits/rejected": 3.836027145385742,
      "logps/chosen": -338.28521728515625,
      "logps/rejected": -299.5325622558594,
      "loss": 0.5077,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.011394500732421875,
      "rewards/margins": 2.12357759475708,
      "rewards/rejected": -2.134972095489502,
      "step": 1220
    },
    {
      "epoch": 0.07296048954134918,
      "grad_norm": 4.065100193023682,
      "learning_rate": 4.8789840149063454e-05,
      "logits/chosen": 3.864931106567383,
      "logits/rejected": 4.029473781585693,
      "logps/chosen": -380.7056579589844,
      "logps/rejected": -295.25408935546875,
      "loss": 0.4788,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": 0.11575277894735336,
      "rewards/margins": 1.806401014328003,
      "rewards/rejected": -1.6906483173370361,
      "step": 1240
    },
    {
      "epoch": 0.07413727163072578,
      "grad_norm": 2.1405067443847656,
      "learning_rate": 4.877022653721683e-05,
      "logits/chosen": 4.057973861694336,
      "logits/rejected": 4.092267990112305,
      "logps/chosen": -367.4293212890625,
      "logps/rejected": -299.33184814453125,
      "loss": 0.6101,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.2760372459888458,
      "rewards/margins": 1.6152598857879639,
      "rewards/rejected": -1.8912973403930664,
      "step": 1260
    },
    {
      "epoch": 0.07531405372010239,
      "grad_norm": 1.0469231605529785,
      "learning_rate": 4.8750612925370207e-05,
      "logits/chosen": 3.8919835090637207,
      "logits/rejected": 3.7626471519470215,
      "logps/chosen": -363.9228820800781,
      "logps/rejected": -267.483154296875,
      "loss": 0.5831,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.11745505034923553,
      "rewards/margins": 1.1768543720245361,
      "rewards/rejected": -1.0593993663787842,
      "step": 1280
    },
    {
      "epoch": 0.07649083580947898,
      "grad_norm": 3.877296209335327,
      "learning_rate": 4.873099931352359e-05,
      "logits/chosen": 4.159276962280273,
      "logits/rejected": 4.003535270690918,
      "logps/chosen": -424.67333984375,
      "logps/rejected": -337.9639892578125,
      "loss": 0.5227,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.03569822385907173,
      "rewards/margins": 2.344306468963623,
      "rewards/rejected": -2.308608055114746,
      "step": 1300
    },
    {
      "epoch": 0.07766761789885558,
      "grad_norm": 3.2871451377868652,
      "learning_rate": 4.8711385701676965e-05,
      "logits/chosen": 4.07987642288208,
      "logits/rejected": 3.83612322807312,
      "logps/chosen": -375.74578857421875,
      "logps/rejected": -280.37701416015625,
      "loss": 0.4477,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 1.0654293298721313,
      "rewards/margins": 2.116647481918335,
      "rewards/rejected": -1.0512182712554932,
      "step": 1320
    },
    {
      "epoch": 0.07884439998823217,
      "grad_norm": 0.8289132714271545,
      "learning_rate": 4.869177208983035e-05,
      "logits/chosen": 4.358994007110596,
      "logits/rejected": 4.4066481590271,
      "logps/chosen": -398.2413635253906,
      "logps/rejected": -351.8776550292969,
      "loss": 0.6444,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.4975655674934387,
      "rewards/margins": 1.3301708698272705,
      "rewards/rejected": -0.8326053619384766,
      "step": 1340
    },
    {
      "epoch": 0.08002118207760878,
      "grad_norm": 1.7669556140899658,
      "learning_rate": 4.867215847798372e-05,
      "logits/chosen": 4.119915962219238,
      "logits/rejected": 3.9688949584960938,
      "logps/chosen": -380.0735168457031,
      "logps/rejected": -275.1328430175781,
      "loss": 0.5708,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 1.1664178371429443,
      "rewards/margins": 2.0821971893310547,
      "rewards/rejected": -0.9157794713973999,
      "step": 1360
    },
    {
      "epoch": 0.08119796416698538,
      "grad_norm": 6.221396446228027,
      "learning_rate": 4.86525448661371e-05,
      "logits/chosen": 4.085162162780762,
      "logits/rejected": 4.016648292541504,
      "logps/chosen": -384.82281494140625,
      "logps/rejected": -282.16973876953125,
      "loss": 0.487,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.49687400460243225,
      "rewards/margins": 1.8914905786514282,
      "rewards/rejected": -1.3946166038513184,
      "step": 1380
    },
    {
      "epoch": 0.08237474625636197,
      "grad_norm": 3.4379055500030518,
      "learning_rate": 4.863293125429048e-05,
      "logits/chosen": 4.09078311920166,
      "logits/rejected": 3.9754836559295654,
      "logps/chosen": -365.2721862792969,
      "logps/rejected": -252.31802368164062,
      "loss": 0.6302,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.4281492829322815,
      "rewards/margins": 1.6243658065795898,
      "rewards/rejected": -1.196216344833374,
      "step": 1400
    },
    {
      "epoch": 0.08355152834573858,
      "grad_norm": 9.69139575958252,
      "learning_rate": 4.861331764244386e-05,
      "logits/chosen": 4.116997718811035,
      "logits/rejected": 4.141288757324219,
      "logps/chosen": -356.0020446777344,
      "logps/rejected": -298.0810852050781,
      "loss": 0.528,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.007353079505264759,
      "rewards/margins": 1.4515355825424194,
      "rewards/rejected": -1.4588886499404907,
      "step": 1420
    },
    {
      "epoch": 0.08472831043511518,
      "grad_norm": 1.7543267011642456,
      "learning_rate": 4.8593704030597235e-05,
      "logits/chosen": 4.038998126983643,
      "logits/rejected": 4.045985221862793,
      "logps/chosen": -358.8923645019531,
      "logps/rejected": -287.6695251464844,
      "loss": 0.5359,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.34944698214530945,
      "rewards/margins": 1.5857384204864502,
      "rewards/rejected": -1.935185432434082,
      "step": 1440
    },
    {
      "epoch": 0.08590509252449177,
      "grad_norm": 3.6868820190429688,
      "learning_rate": 4.857409041875062e-05,
      "logits/chosen": 3.7333054542541504,
      "logits/rejected": 3.720386505126953,
      "logps/chosen": -326.03424072265625,
      "logps/rejected": -256.2337341308594,
      "loss": 0.5639,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.2532469630241394,
      "rewards/margins": 1.0632433891296387,
      "rewards/rejected": -1.3164904117584229,
      "step": 1460
    },
    {
      "epoch": 0.08708187461386838,
      "grad_norm": 2.1689131259918213,
      "learning_rate": 4.8554476806903994e-05,
      "logits/chosen": 4.1072468757629395,
      "logits/rejected": 3.9746978282928467,
      "logps/chosen": -369.6243591308594,
      "logps/rejected": -326.53839111328125,
      "loss": 0.5169,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.18181248009204865,
      "rewards/margins": 1.360001802444458,
      "rewards/rejected": -1.5418144464492798,
      "step": 1480
    },
    {
      "epoch": 0.08825865670324498,
      "grad_norm": 2.1101863384246826,
      "learning_rate": 4.853486319505737e-05,
      "logits/chosen": 4.2869462966918945,
      "logits/rejected": 4.1977715492248535,
      "logps/chosen": -380.012939453125,
      "logps/rejected": -274.3448486328125,
      "loss": 0.4825,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.2233424186706543,
      "rewards/margins": 1.95769464969635,
      "rewards/rejected": -1.7343523502349854,
      "step": 1500
    },
    {
      "epoch": 0.08943543879262157,
      "grad_norm": 1.5386244058609009,
      "learning_rate": 4.8515249583210746e-05,
      "logits/chosen": 3.8916244506835938,
      "logits/rejected": 3.8724265098571777,
      "logps/chosen": -338.6315612792969,
      "logps/rejected": -261.75677490234375,
      "loss": 0.6985,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.4222044050693512,
      "rewards/margins": 1.5545060634613037,
      "rewards/rejected": -1.132301926612854,
      "step": 1520
    },
    {
      "epoch": 0.09061222088199818,
      "grad_norm": 1.0063254833221436,
      "learning_rate": 4.849563597136413e-05,
      "logits/chosen": 4.196977615356445,
      "logits/rejected": 4.166285991668701,
      "logps/chosen": -429.08013916015625,
      "logps/rejected": -302.9004821777344,
      "loss": 0.4391,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.42521756887435913,
      "rewards/margins": 1.9403550624847412,
      "rewards/rejected": -1.5151374340057373,
      "step": 1540
    },
    {
      "epoch": 0.09178900297137478,
      "grad_norm": 2.4083456993103027,
      "learning_rate": 4.847602235951751e-05,
      "logits/chosen": 3.939509630203247,
      "logits/rejected": 3.8934569358825684,
      "logps/chosen": -344.13330078125,
      "logps/rejected": -314.7292785644531,
      "loss": 0.4386,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.3266738951206207,
      "rewards/margins": 2.359527349472046,
      "rewards/rejected": -2.686201572418213,
      "step": 1560
    },
    {
      "epoch": 0.09296578506075137,
      "grad_norm": 5.57644510269165,
      "learning_rate": 4.845640874767088e-05,
      "logits/chosen": 3.8275208473205566,
      "logits/rejected": 3.8457672595977783,
      "logps/chosen": -348.56939697265625,
      "logps/rejected": -317.90631103515625,
      "loss": 0.728,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6176920533180237,
      "rewards/margins": 1.4364006519317627,
      "rewards/rejected": -2.0540924072265625,
      "step": 1580
    },
    {
      "epoch": 0.09414256715012798,
      "grad_norm": 2.602362871170044,
      "learning_rate": 4.8436795135824264e-05,
      "logits/chosen": 3.949450969696045,
      "logits/rejected": 3.792273759841919,
      "logps/chosen": -408.5367126464844,
      "logps/rejected": -272.3811340332031,
      "loss": 0.5144,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1052049398422241,
      "rewards/margins": 2.0918331146240234,
      "rewards/rejected": -3.197038173675537,
      "step": 1600
    },
    {
      "epoch": 0.09531934923950458,
      "grad_norm": 1.9985949993133545,
      "learning_rate": 4.841718152397765e-05,
      "logits/chosen": 3.740194320678711,
      "logits/rejected": 3.6763389110565186,
      "logps/chosen": -355.57086181640625,
      "logps/rejected": -293.66961669921875,
      "loss": 0.4324,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.3771389424800873,
      "rewards/margins": 1.7459936141967773,
      "rewards/rejected": -2.1231324672698975,
      "step": 1620
    },
    {
      "epoch": 0.09649613132888117,
      "grad_norm": 1.9039994478225708,
      "learning_rate": 4.839756791213102e-05,
      "logits/chosen": 4.122428894042969,
      "logits/rejected": 4.079632759094238,
      "logps/chosen": -410.5181579589844,
      "logps/rejected": -267.4759826660156,
      "loss": 0.4686,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.37848716974258423,
      "rewards/margins": 2.2282919883728027,
      "rewards/rejected": -1.8498046398162842,
      "step": 1640
    },
    {
      "epoch": 0.09767291341825778,
      "grad_norm": 1.775200605392456,
      "learning_rate": 4.83779543002844e-05,
      "logits/chosen": 3.8930423259735107,
      "logits/rejected": 3.8794097900390625,
      "logps/chosen": -345.6695861816406,
      "logps/rejected": -284.7189636230469,
      "loss": 0.5445,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.26914864778518677,
      "rewards/margins": 1.8251975774765015,
      "rewards/rejected": -2.094346523284912,
      "step": 1660
    },
    {
      "epoch": 0.09884969550763438,
      "grad_norm": 3.2777926921844482,
      "learning_rate": 4.8358340688437775e-05,
      "logits/chosen": 3.9893507957458496,
      "logits/rejected": 4.106879234313965,
      "logps/chosen": -349.6319274902344,
      "logps/rejected": -271.09625244140625,
      "loss": 0.5592,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.3327556550502777,
      "rewards/margins": 1.5559155941009521,
      "rewards/rejected": -1.8886711597442627,
      "step": 1680
    },
    {
      "epoch": 0.10002647759701097,
      "grad_norm": 2.2548916339874268,
      "learning_rate": 4.833872707659116e-05,
      "logits/chosen": 4.039695739746094,
      "logits/rejected": 4.018503665924072,
      "logps/chosen": -426.7120056152344,
      "logps/rejected": -333.89532470703125,
      "loss": 0.4816,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.15277937054634094,
      "rewards/margins": 1.9281282424926758,
      "rewards/rejected": -2.0809075832366943,
      "step": 1700
    },
    {
      "epoch": 0.10120325968638758,
      "grad_norm": 1.416834831237793,
      "learning_rate": 4.8319113464744534e-05,
      "logits/chosen": 4.083568572998047,
      "logits/rejected": 4.1008782386779785,
      "logps/chosen": -355.29071044921875,
      "logps/rejected": -273.45013427734375,
      "loss": 0.5104,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.774703860282898,
      "rewards/margins": 1.6281859874725342,
      "rewards/rejected": -2.4028899669647217,
      "step": 1720
    },
    {
      "epoch": 0.10238004177576417,
      "grad_norm": 2.519559383392334,
      "learning_rate": 4.829949985289791e-05,
      "logits/chosen": 3.9251582622528076,
      "logits/rejected": 3.8791098594665527,
      "logps/chosen": -393.4754333496094,
      "logps/rejected": -321.5624694824219,
      "loss": 0.6126,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8719097375869751,
      "rewards/margins": 1.8369629383087158,
      "rewards/rejected": -2.7088725566864014,
      "step": 1740
    },
    {
      "epoch": 0.10355682386514077,
      "grad_norm": 1.5407301187515259,
      "learning_rate": 4.827988624105129e-05,
      "logits/chosen": 3.766867160797119,
      "logits/rejected": 3.698660373687744,
      "logps/chosen": -385.54766845703125,
      "logps/rejected": -261.90765380859375,
      "loss": 0.5618,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8036373257637024,
      "rewards/margins": 1.862962007522583,
      "rewards/rejected": -2.6665995121002197,
      "step": 1760
    },
    {
      "epoch": 0.10473360595451738,
      "grad_norm": 2.7877023220062256,
      "learning_rate": 4.8260272629204675e-05,
      "logits/chosen": 4.214917182922363,
      "logits/rejected": 4.096793174743652,
      "logps/chosen": -422.08294677734375,
      "logps/rejected": -323.38775634765625,
      "loss": 0.4484,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0989834070205688,
      "rewards/margins": 1.6458498239517212,
      "rewards/rejected": -2.744833469390869,
      "step": 1780
    },
    {
      "epoch": 0.10591038804389397,
      "grad_norm": 1.4187086820602417,
      "learning_rate": 4.8240659017358045e-05,
      "logits/chosen": 3.6573619842529297,
      "logits/rejected": 3.682506561279297,
      "logps/chosen": -397.1757507324219,
      "logps/rejected": -328.8328857421875,
      "loss": 0.4959,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6483291387557983,
      "rewards/margins": 2.194045066833496,
      "rewards/rejected": -2.842374324798584,
      "step": 1800
    },
    {
      "epoch": 0.10708717013327057,
      "grad_norm": 5.067101001739502,
      "learning_rate": 4.822104540551143e-05,
      "logits/chosen": 4.039819717407227,
      "logits/rejected": 4.061232566833496,
      "logps/chosen": -432.48858642578125,
      "logps/rejected": -386.95281982421875,
      "loss": 0.5351,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.4446415901184082,
      "rewards/margins": 1.7392756938934326,
      "rewards/rejected": -3.1839168071746826,
      "step": 1820
    },
    {
      "epoch": 0.10826395222264718,
      "grad_norm": 3.4172353744506836,
      "learning_rate": 4.8201431793664803e-05,
      "logits/chosen": 4.164175987243652,
      "logits/rejected": 3.974109649658203,
      "logps/chosen": -379.4151306152344,
      "logps/rejected": -293.83856201171875,
      "loss": 0.5466,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6376293897628784,
      "rewards/margins": 1.7917299270629883,
      "rewards/rejected": -2.429359197616577,
      "step": 1840
    },
    {
      "epoch": 0.10944073431202377,
      "grad_norm": 1.1910754442214966,
      "learning_rate": 4.8181818181818186e-05,
      "logits/chosen": 4.027770042419434,
      "logits/rejected": 3.9223663806915283,
      "logps/chosen": -406.91192626953125,
      "logps/rejected": -275.7637023925781,
      "loss": 0.4509,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.4600227475166321,
      "rewards/margins": 1.8541091680526733,
      "rewards/rejected": -1.3940863609313965,
      "step": 1860
    },
    {
      "epoch": 0.11061751640140037,
      "grad_norm": 1.7347856760025024,
      "learning_rate": 4.816220456997156e-05,
      "logits/chosen": 3.792576551437378,
      "logits/rejected": 3.83526349067688,
      "logps/chosen": -325.9154052734375,
      "logps/rejected": -286.158447265625,
      "loss": 0.7124,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.1378260850906372,
      "rewards/margins": 1.0052659511566162,
      "rewards/rejected": -1.1430920362472534,
      "step": 1880
    },
    {
      "epoch": 0.11179429849077697,
      "grad_norm": 3.9973158836364746,
      "learning_rate": 4.814259095812494e-05,
      "logits/chosen": 3.8644843101501465,
      "logits/rejected": 3.7903053760528564,
      "logps/chosen": -372.46929931640625,
      "logps/rejected": -336.15087890625,
      "loss": 0.6205,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.4885362684726715,
      "rewards/margins": 1.9712212085723877,
      "rewards/rejected": -1.482684850692749,
      "step": 1900
    },
    {
      "epoch": 0.11297108058015357,
      "grad_norm": 1.3422211408615112,
      "learning_rate": 4.812297734627832e-05,
      "logits/chosen": 4.183838844299316,
      "logits/rejected": 4.132071495056152,
      "logps/chosen": -396.38397216796875,
      "logps/rejected": -310.6915283203125,
      "loss": 0.4825,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.05713465064764023,
      "rewards/margins": 1.6205732822418213,
      "rewards/rejected": -1.6777076721191406,
      "step": 1920
    },
    {
      "epoch": 0.11414786266953017,
      "grad_norm": 2.9984264373779297,
      "learning_rate": 4.81033637344317e-05,
      "logits/chosen": 3.9747185707092285,
      "logits/rejected": 3.9864935874938965,
      "logps/chosen": -329.4683532714844,
      "logps/rejected": -274.52838134765625,
      "loss": 0.6527,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.236349418759346,
      "rewards/margins": 1.4408423900604248,
      "rewards/rejected": -1.6771917343139648,
      "step": 1940
    },
    {
      "epoch": 0.11532464475890677,
      "grad_norm": 1.9515244960784912,
      "learning_rate": 4.808375012258507e-05,
      "logits/chosen": 4.202930927276611,
      "logits/rejected": 4.210437774658203,
      "logps/chosen": -376.1435546875,
      "logps/rejected": -277.08734130859375,
      "loss": 0.463,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.34083864092826843,
      "rewards/margins": 1.7335879802703857,
      "rewards/rejected": -2.0744268894195557,
      "step": 1960
    },
    {
      "epoch": 0.11650142684828337,
      "grad_norm": 2.5005621910095215,
      "learning_rate": 4.8064136510738456e-05,
      "logits/chosen": 4.145659446716309,
      "logits/rejected": 4.130236625671387,
      "logps/chosen": -358.0284729003906,
      "logps/rejected": -287.2637634277344,
      "loss": 0.784,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8719752430915833,
      "rewards/margins": 1.2517720460891724,
      "rewards/rejected": -2.1237473487854004,
      "step": 1980
    },
    {
      "epoch": 0.11767820893765997,
      "grad_norm": 4.832273006439209,
      "learning_rate": 4.804452289889183e-05,
      "logits/chosen": 4.1171674728393555,
      "logits/rejected": 4.147673606872559,
      "logps/chosen": -425.0638122558594,
      "logps/rejected": -328.5557861328125,
      "loss": 0.4806,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.45835843682289124,
      "rewards/margins": 2.1448588371276855,
      "rewards/rejected": -2.603217363357544,
      "step": 2000
    },
    {
      "epoch": 0.11885499102703657,
      "grad_norm": 0.45359155535697937,
      "learning_rate": 4.802490928704521e-05,
      "logits/chosen": 3.968201160430908,
      "logits/rejected": 3.9281623363494873,
      "logps/chosen": -409.09613037109375,
      "logps/rejected": -296.9620056152344,
      "loss": 0.4316,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.3193770945072174,
      "rewards/margins": 2.282968282699585,
      "rewards/rejected": -2.6023457050323486,
      "step": 2020
    },
    {
      "epoch": 0.12003177311641317,
      "grad_norm": 3.1514647006988525,
      "learning_rate": 4.800529567519859e-05,
      "logits/chosen": 3.816765546798706,
      "logits/rejected": 3.689749240875244,
      "logps/chosen": -381.748046875,
      "logps/rejected": -338.3741760253906,
      "loss": 0.5673,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7051134705543518,
      "rewards/margins": 1.7798388004302979,
      "rewards/rejected": -2.484952211380005,
      "step": 2040
    },
    {
      "epoch": 0.12120855520578977,
      "grad_norm": 1.8509624004364014,
      "learning_rate": 4.798568206335197e-05,
      "logits/chosen": 3.7660140991210938,
      "logits/rejected": 3.7160515785217285,
      "logps/chosen": -426.5193786621094,
      "logps/rejected": -325.4524841308594,
      "loss": 0.4891,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.6799224615097046,
      "rewards/margins": 2.1059513092041016,
      "rewards/rejected": -2.7858736515045166,
      "step": 2060
    },
    {
      "epoch": 0.12238533729516637,
      "grad_norm": 1.894199252128601,
      "learning_rate": 4.796606845150535e-05,
      "logits/chosen": 3.948035717010498,
      "logits/rejected": 3.799595594406128,
      "logps/chosen": -384.80169677734375,
      "logps/rejected": -299.7640380859375,
      "loss": 0.4598,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.062775731086731,
      "rewards/margins": 1.9457651376724243,
      "rewards/rejected": -3.008540630340576,
      "step": 2080
    },
    {
      "epoch": 0.12356211938454296,
      "grad_norm": 1.7811022996902466,
      "learning_rate": 4.7946454839658726e-05,
      "logits/chosen": 4.00213098526001,
      "logits/rejected": 3.843764066696167,
      "logps/chosen": -382.45526123046875,
      "logps/rejected": -296.6955871582031,
      "loss": 0.4584,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6946116089820862,
      "rewards/margins": 2.092528820037842,
      "rewards/rejected": -2.787140369415283,
      "step": 2100
    },
    {
      "epoch": 0.12473890147391957,
      "grad_norm": 1.6896454095840454,
      "learning_rate": 4.79268412278121e-05,
      "logits/chosen": 3.5953049659729004,
      "logits/rejected": 3.61559796333313,
      "logps/chosen": -404.7529602050781,
      "logps/rejected": -315.48895263671875,
      "loss": 0.6188,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.0604751110076904,
      "rewards/margins": 1.9390509128570557,
      "rewards/rejected": -2.999525547027588,
      "step": 2120
    },
    {
      "epoch": 0.12591568356329616,
      "grad_norm": 1.8810218572616577,
      "learning_rate": 4.7907227615965485e-05,
      "logits/chosen": 4.020689964294434,
      "logits/rejected": 3.8949673175811768,
      "logps/chosen": -349.023681640625,
      "logps/rejected": -328.6457824707031,
      "loss": 0.3874,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.3663981258869171,
      "rewards/margins": 2.3592724800109863,
      "rewards/rejected": -2.725670576095581,
      "step": 2140
    },
    {
      "epoch": 0.12709246565267276,
      "grad_norm": 4.166597843170166,
      "learning_rate": 4.788761400411886e-05,
      "logits/chosen": 3.6077933311462402,
      "logits/rejected": 3.712489366531372,
      "logps/chosen": -335.0087890625,
      "logps/rejected": -346.95916748046875,
      "loss": 0.6635,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4492450952529907,
      "rewards/margins": 1.3353092670440674,
      "rewards/rejected": -2.7845542430877686,
      "step": 2160
    },
    {
      "epoch": 0.12826924774204937,
      "grad_norm": 3.6546802520751953,
      "learning_rate": 4.786800039227224e-05,
      "logits/chosen": 4.1357293128967285,
      "logits/rejected": 4.107977867126465,
      "logps/chosen": -428.74169921875,
      "logps/rejected": -306.8629455566406,
      "loss": 0.5625,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8355877995491028,
      "rewards/margins": 1.9260385036468506,
      "rewards/rejected": -2.7616262435913086,
      "step": 2180
    },
    {
      "epoch": 0.12944602983142597,
      "grad_norm": 5.134012699127197,
      "learning_rate": 4.784838678042562e-05,
      "logits/chosen": 3.9624485969543457,
      "logits/rejected": 4.090671539306641,
      "logps/chosen": -362.91668701171875,
      "logps/rejected": -309.68048095703125,
      "loss": 0.5485,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6567251086235046,
      "rewards/margins": 1.3004188537597656,
      "rewards/rejected": -1.957143783569336,
      "step": 2200
    },
    {
      "epoch": 0.13062281192080258,
      "grad_norm": 1.3756879568099976,
      "learning_rate": 4.7828773168578996e-05,
      "logits/chosen": 3.8284785747528076,
      "logits/rejected": 3.761435031890869,
      "logps/chosen": -384.1830139160156,
      "logps/rejected": -293.78680419921875,
      "loss": 0.5822,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4092854857444763,
      "rewards/margins": 1.599195122718811,
      "rewards/rejected": -2.0084805488586426,
      "step": 2220
    },
    {
      "epoch": 0.13179959401017916,
      "grad_norm": 3.9612905979156494,
      "learning_rate": 4.780915955673237e-05,
      "logits/chosen": 3.8445823192596436,
      "logits/rejected": 3.9359183311462402,
      "logps/chosen": -318.8648986816406,
      "logps/rejected": -292.38140869140625,
      "loss": 0.5307,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5971136689186096,
      "rewards/margins": 1.341357946395874,
      "rewards/rejected": -1.9384715557098389,
      "step": 2240
    },
    {
      "epoch": 0.13297637609955576,
      "grad_norm": 2.391537666320801,
      "learning_rate": 4.7789545944885754e-05,
      "logits/chosen": 4.366172790527344,
      "logits/rejected": 4.217585563659668,
      "logps/chosen": -421.425537109375,
      "logps/rejected": -304.31689453125,
      "loss": 0.469,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.11694993078708649,
      "rewards/margins": 2.0484278202056885,
      "rewards/rejected": -2.165377616882324,
      "step": 2260
    },
    {
      "epoch": 0.13415315818893236,
      "grad_norm": 2.0951030254364014,
      "learning_rate": 4.776993233303913e-05,
      "logits/chosen": 3.9813525676727295,
      "logits/rejected": 3.849494457244873,
      "logps/chosen": -389.7234191894531,
      "logps/rejected": -301.11334228515625,
      "loss": 0.4442,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.39854249358177185,
      "rewards/margins": 2.71176815032959,
      "rewards/rejected": -2.313225269317627,
      "step": 2280
    },
    {
      "epoch": 0.13532994027830897,
      "grad_norm": 3.7435567378997803,
      "learning_rate": 4.775031872119251e-05,
      "logits/chosen": 4.515063762664795,
      "logits/rejected": 4.325621604919434,
      "logps/chosen": -423.45098876953125,
      "logps/rejected": -333.22076416015625,
      "loss": 0.563,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5964929461479187,
      "rewards/margins": 1.7203830480575562,
      "rewards/rejected": -2.316876173019409,
      "step": 2300
    },
    {
      "epoch": 0.13650672236768557,
      "grad_norm": 1.8274509906768799,
      "learning_rate": 4.773070510934588e-05,
      "logits/chosen": 4.0022430419921875,
      "logits/rejected": 3.8291797637939453,
      "logps/chosen": -423.8064880371094,
      "logps/rejected": -309.83709716796875,
      "loss": 0.5134,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.606514573097229,
      "rewards/margins": 1.6326287984848022,
      "rewards/rejected": -2.2391436100006104,
      "step": 2320
    },
    {
      "epoch": 0.13768350445706215,
      "grad_norm": 1.6579476594924927,
      "learning_rate": 4.7711091497499265e-05,
      "logits/chosen": 4.029296398162842,
      "logits/rejected": 3.9502224922180176,
      "logps/chosen": -421.0310974121094,
      "logps/rejected": -312.86981201171875,
      "loss": 0.5289,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8562808036804199,
      "rewards/margins": 1.4199825525283813,
      "rewards/rejected": -2.276263475418091,
      "step": 2340
    },
    {
      "epoch": 0.13886028654643875,
      "grad_norm": 3.6966044902801514,
      "learning_rate": 4.769147788565265e-05,
      "logits/chosen": 4.01786994934082,
      "logits/rejected": 3.9801228046417236,
      "logps/chosen": -374.5091857910156,
      "logps/rejected": -316.25469970703125,
      "loss": 0.5719,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.1930241584777832,
      "rewards/margins": 1.5436681509017944,
      "rewards/rejected": -2.736692428588867,
      "step": 2360
    },
    {
      "epoch": 0.14003706863581536,
      "grad_norm": 1.7946267127990723,
      "learning_rate": 4.7671864273806024e-05,
      "logits/chosen": 3.822019100189209,
      "logits/rejected": 3.8856735229492188,
      "logps/chosen": -336.4109191894531,
      "logps/rejected": -283.0655517578125,
      "loss": 0.459,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.3087937533855438,
      "rewards/margins": 1.826960802078247,
      "rewards/rejected": -2.1357545852661133,
      "step": 2380
    },
    {
      "epoch": 0.14121385072519196,
      "grad_norm": 0.44904595613479614,
      "learning_rate": 4.76522506619594e-05,
      "logits/chosen": 3.9469940662384033,
      "logits/rejected": 3.8910586833953857,
      "logps/chosen": -361.2853088378906,
      "logps/rejected": -286.9635925292969,
      "loss": 0.3975,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.3997423052787781,
      "rewards/margins": 2.0342981815338135,
      "rewards/rejected": -2.4340405464172363,
      "step": 2400
    },
    {
      "epoch": 0.14239063281456857,
      "grad_norm": 7.431148529052734,
      "learning_rate": 4.763263705011278e-05,
      "logits/chosen": 4.074143886566162,
      "logits/rejected": 4.070187568664551,
      "logps/chosen": -399.26361083984375,
      "logps/rejected": -330.9806213378906,
      "loss": 0.5339,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.1655040681362152,
      "rewards/margins": 2.255084753036499,
      "rewards/rejected": -2.08958101272583,
      "step": 2420
    },
    {
      "epoch": 0.14356741490394517,
      "grad_norm": 1.073145866394043,
      "learning_rate": 4.761302343826616e-05,
      "logits/chosen": 4.0657525062561035,
      "logits/rejected": 3.9600205421447754,
      "logps/chosen": -348.6988830566406,
      "logps/rejected": -295.422607421875,
      "loss": 0.4909,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.660010814666748,
      "rewards/margins": 1.6137796640396118,
      "rewards/rejected": -2.2737905979156494,
      "step": 2440
    },
    {
      "epoch": 0.14474419699332175,
      "grad_norm": 1.6694356203079224,
      "learning_rate": 4.7593409826419535e-05,
      "logits/chosen": 3.7916762828826904,
      "logits/rejected": 3.735034942626953,
      "logps/chosen": -402.23809814453125,
      "logps/rejected": -304.2998046875,
      "loss": 0.5233,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7787315249443054,
      "rewards/margins": 2.1382670402526855,
      "rewards/rejected": -2.9169986248016357,
      "step": 2460
    },
    {
      "epoch": 0.14592097908269835,
      "grad_norm": 2.0067355632781982,
      "learning_rate": 4.757379621457291e-05,
      "logits/chosen": 3.8799922466278076,
      "logits/rejected": 3.8846840858459473,
      "logps/chosen": -403.14788818359375,
      "logps/rejected": -291.3057556152344,
      "loss": 0.5082,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9353049397468567,
      "rewards/margins": 1.785783052444458,
      "rewards/rejected": -2.72108793258667,
      "step": 2480
    },
    {
      "epoch": 0.14709776117207496,
      "grad_norm": 1.196319341659546,
      "learning_rate": 4.7554182602726294e-05,
      "logits/chosen": 3.7090423107147217,
      "logits/rejected": 3.593419313430786,
      "logps/chosen": -365.7476806640625,
      "logps/rejected": -275.83721923828125,
      "loss": 0.5013,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8434950709342957,
      "rewards/margins": 1.4989467859268188,
      "rewards/rejected": -2.3424417972564697,
      "step": 2500
    },
    {
      "epoch": 0.14827454326145156,
      "grad_norm": 19.881752014160156,
      "learning_rate": 4.753456899087968e-05,
      "logits/chosen": 3.8537375926971436,
      "logits/rejected": 3.8264687061309814,
      "logps/chosen": -356.6422424316406,
      "logps/rejected": -277.05328369140625,
      "loss": 0.4828,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6511092185974121,
      "rewards/margins": 1.8352152109146118,
      "rewards/rejected": -2.4863243103027344,
      "step": 2520
    },
    {
      "epoch": 0.14945132535082817,
      "grad_norm": 4.543574333190918,
      "learning_rate": 4.7514955379033046e-05,
      "logits/chosen": 3.7416739463806152,
      "logits/rejected": 3.819483518600464,
      "logps/chosen": -365.3460693359375,
      "logps/rejected": -321.7981262207031,
      "loss": 0.5015,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2561267614364624,
      "rewards/margins": 1.8703672885894775,
      "rewards/rejected": -3.1264939308166504,
      "step": 2540
    },
    {
      "epoch": 0.15062810744020477,
      "grad_norm": 0.7309394478797913,
      "learning_rate": 4.749534176718643e-05,
      "logits/chosen": 3.4652371406555176,
      "logits/rejected": 3.503645658493042,
      "logps/chosen": -352.74078369140625,
      "logps/rejected": -302.9555969238281,
      "loss": 0.5141,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5255376696586609,
      "rewards/margins": 2.128343105316162,
      "rewards/rejected": -2.6538805961608887,
      "step": 2560
    },
    {
      "epoch": 0.15180488952958135,
      "grad_norm": 3.267874002456665,
      "learning_rate": 4.747572815533981e-05,
      "logits/chosen": 4.0678229331970215,
      "logits/rejected": 3.7986702919006348,
      "logps/chosen": -437.74530029296875,
      "logps/rejected": -258.236083984375,
      "loss": 0.4103,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.6240850687026978,
      "rewards/margins": 2.580141544342041,
      "rewards/rejected": -3.2042267322540283,
      "step": 2580
    },
    {
      "epoch": 0.15298167161895795,
      "grad_norm": 8.066899299621582,
      "learning_rate": 4.745611454349319e-05,
      "logits/chosen": 3.998067855834961,
      "logits/rejected": 3.9411799907684326,
      "logps/chosen": -404.69281005859375,
      "logps/rejected": -369.6488037109375,
      "loss": 0.5757,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8610019683837891,
      "rewards/margins": 1.781317949295044,
      "rewards/rejected": -2.642319917678833,
      "step": 2600
    },
    {
      "epoch": 0.15415845370833456,
      "grad_norm": 1.7350057363510132,
      "learning_rate": 4.7436500931646564e-05,
      "logits/chosen": 3.865856885910034,
      "logits/rejected": 3.913050889968872,
      "logps/chosen": -408.6334533691406,
      "logps/rejected": -288.4399719238281,
      "loss": 0.4139,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.16619105637073517,
      "rewards/margins": 2.814423084259033,
      "rewards/rejected": -2.980614185333252,
      "step": 2620
    },
    {
      "epoch": 0.15533523579771116,
      "grad_norm": 2.2089569568634033,
      "learning_rate": 4.741688731979994e-05,
      "logits/chosen": 3.8061447143554688,
      "logits/rejected": 3.66150164604187,
      "logps/chosen": -383.54412841796875,
      "logps/rejected": -297.5895690917969,
      "loss": 0.5776,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.127986192703247,
      "rewards/margins": 1.6677684783935547,
      "rewards/rejected": -2.795754909515381,
      "step": 2640
    },
    {
      "epoch": 0.15651201788708777,
      "grad_norm": 9.01259708404541,
      "learning_rate": 4.739727370795332e-05,
      "logits/chosen": 3.7203643321990967,
      "logits/rejected": 3.628911256790161,
      "logps/chosen": -353.27825927734375,
      "logps/rejected": -299.8863525390625,
      "loss": 0.521,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2008264064788818,
      "rewards/margins": 1.760784387588501,
      "rewards/rejected": -2.9616103172302246,
      "step": 2660
    },
    {
      "epoch": 0.15768879997646434,
      "grad_norm": 0.6178398132324219,
      "learning_rate": 4.73776600961067e-05,
      "logits/chosen": 3.7014973163604736,
      "logits/rejected": 3.709453582763672,
      "logps/chosen": -347.0692138671875,
      "logps/rejected": -257.94384765625,
      "loss": 0.4729,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6377609968185425,
      "rewards/margins": 2.162914991378784,
      "rewards/rejected": -2.800675868988037,
      "step": 2680
    },
    {
      "epoch": 0.15886558206584095,
      "grad_norm": 1.6235930919647217,
      "learning_rate": 4.7358046484260075e-05,
      "logits/chosen": 4.075919151306152,
      "logits/rejected": 3.8651745319366455,
      "logps/chosen": -385.7386474609375,
      "logps/rejected": -349.20880126953125,
      "loss": 0.4518,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.280698537826538,
      "rewards/margins": 2.162083148956299,
      "rewards/rejected": -3.442782163619995,
      "step": 2700
    },
    {
      "epoch": 0.16004236415521755,
      "grad_norm": 1.030633568763733,
      "learning_rate": 4.733843287241346e-05,
      "logits/chosen": 3.8811047077178955,
      "logits/rejected": 3.9779391288757324,
      "logps/chosen": -355.3014831542969,
      "logps/rejected": -309.659912109375,
      "loss": 0.6518,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2033579349517822,
      "rewards/margins": 1.9319469928741455,
      "rewards/rejected": -3.135305166244507,
      "step": 2720
    },
    {
      "epoch": 0.16121914624459416,
      "grad_norm": 1.249019980430603,
      "learning_rate": 4.731881926056684e-05,
      "logits/chosen": 3.615405559539795,
      "logits/rejected": 3.7168192863464355,
      "logps/chosen": -378.5979309082031,
      "logps/rejected": -304.1471862792969,
      "loss": 0.3732,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8235800862312317,
      "rewards/margins": 2.5712547302246094,
      "rewards/rejected": -3.3948349952697754,
      "step": 2740
    },
    {
      "epoch": 0.16239592833397076,
      "grad_norm": 0.7278867363929749,
      "learning_rate": 4.729920564872021e-05,
      "logits/chosen": 3.782099485397339,
      "logits/rejected": 3.780808925628662,
      "logps/chosen": -419.95928955078125,
      "logps/rejected": -349.2684631347656,
      "loss": 0.6141,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3414355516433716,
      "rewards/margins": 1.8000236749649048,
      "rewards/rejected": -3.1414592266082764,
      "step": 2760
    },
    {
      "epoch": 0.16357271042334737,
      "grad_norm": 0.9972284436225891,
      "learning_rate": 4.727959203687359e-05,
      "logits/chosen": 4.141464710235596,
      "logits/rejected": 3.9165854454040527,
      "logps/chosen": -389.2292785644531,
      "logps/rejected": -281.85113525390625,
      "loss": 0.6059,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.8829110860824585,
      "rewards/margins": 2.464700937271118,
      "rewards/rejected": -3.347611665725708,
      "step": 2780
    },
    {
      "epoch": 0.16474949251272394,
      "grad_norm": 1.6781500577926636,
      "learning_rate": 4.725997842502697e-05,
      "logits/chosen": 3.8878941535949707,
      "logits/rejected": 3.900819778442383,
      "logps/chosen": -376.5540466308594,
      "logps/rejected": -323.140380859375,
      "loss": 0.6493,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7908905744552612,
      "rewards/margins": 1.9483773708343506,
      "rewards/rejected": -2.7392680644989014,
      "step": 2800
    },
    {
      "epoch": 0.16592627460210055,
      "grad_norm": 3.503262519836426,
      "learning_rate": 4.724036481318035e-05,
      "logits/chosen": 3.9416370391845703,
      "logits/rejected": 3.9745922088623047,
      "logps/chosen": -371.66522216796875,
      "logps/rejected": -338.1304931640625,
      "loss": 0.737,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9266119003295898,
      "rewards/margins": 1.5165563821792603,
      "rewards/rejected": -2.4431681632995605,
      "step": 2820
    },
    {
      "epoch": 0.16710305669147715,
      "grad_norm": 2.1177163124084473,
      "learning_rate": 4.722075120133373e-05,
      "logits/chosen": 4.00523042678833,
      "logits/rejected": 4.02468729019165,
      "logps/chosen": -391.3067932128906,
      "logps/rejected": -285.3607482910156,
      "loss": 0.4435,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.733808696269989,
      "rewards/margins": 2.5503315925598145,
      "rewards/rejected": -3.2841403484344482,
      "step": 2840
    },
    {
      "epoch": 0.16827983878085376,
      "grad_norm": 0.6285840272903442,
      "learning_rate": 4.7201137589487103e-05,
      "logits/chosen": 3.848705768585205,
      "logits/rejected": 3.8689727783203125,
      "logps/chosen": -359.2933044433594,
      "logps/rejected": -310.63409423828125,
      "loss": 0.5105,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.1841944456100464,
      "rewards/margins": 2.214848041534424,
      "rewards/rejected": -2.030653715133667,
      "step": 2860
    },
    {
      "epoch": 0.16945662087023036,
      "grad_norm": 1.7541532516479492,
      "learning_rate": 4.7181523977640486e-05,
      "logits/chosen": 3.9501845836639404,
      "logits/rejected": 4.095211029052734,
      "logps/chosen": -399.2053527832031,
      "logps/rejected": -332.33416748046875,
      "loss": 0.5953,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.19079819321632385,
      "rewards/margins": 1.663017988204956,
      "rewards/rejected": -1.853816032409668,
      "step": 2880
    },
    {
      "epoch": 0.17063340295960697,
      "grad_norm": 1.6253618001937866,
      "learning_rate": 4.716191036579386e-05,
      "logits/chosen": 4.319411277770996,
      "logits/rejected": 4.146300315856934,
      "logps/chosen": -397.6328125,
      "logps/rejected": -322.115478515625,
      "loss": 0.5816,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.551072895526886,
      "rewards/margins": 1.6502166986465454,
      "rewards/rejected": -2.201289415359497,
      "step": 2900
    },
    {
      "epoch": 0.17181018504898354,
      "grad_norm": 1.501515507698059,
      "learning_rate": 4.714229675394724e-05,
      "logits/chosen": 4.014254570007324,
      "logits/rejected": 3.80754017829895,
      "logps/chosen": -399.4551696777344,
      "logps/rejected": -243.83132934570312,
      "loss": 0.5043,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.48151445388793945,
      "rewards/margins": 1.4742772579193115,
      "rewards/rejected": -1.955791711807251,
      "step": 2920
    },
    {
      "epoch": 0.17298696713836015,
      "grad_norm": 2.7179973125457764,
      "learning_rate": 4.712268314210062e-05,
      "logits/chosen": 4.05767822265625,
      "logits/rejected": 4.0473856925964355,
      "logps/chosen": -381.33905029296875,
      "logps/rejected": -304.91827392578125,
      "loss": 0.5456,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.525625467300415,
      "rewards/margins": 1.6836168766021729,
      "rewards/rejected": -2.209242343902588,
      "step": 2940
    },
    {
      "epoch": 0.17416374922773675,
      "grad_norm": 16.851253509521484,
      "learning_rate": 4.7103069530254e-05,
      "logits/chosen": 4.0658674240112305,
      "logits/rejected": 3.9137187004089355,
      "logps/chosen": -393.5731506347656,
      "logps/rejected": -310.8965148925781,
      "loss": 0.4862,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.5532479882240295,
      "rewards/margins": 2.4754204750061035,
      "rewards/rejected": -1.9221727848052979,
      "step": 2960
    },
    {
      "epoch": 0.17534053131711336,
      "grad_norm": 2.3020553588867188,
      "learning_rate": 4.708345591840737e-05,
      "logits/chosen": 3.8900959491729736,
      "logits/rejected": 4.059514999389648,
      "logps/chosen": -392.67730712890625,
      "logps/rejected": -310.76702880859375,
      "loss": 0.4398,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.13004758954048157,
      "rewards/margins": 1.777134656906128,
      "rewards/rejected": -1.6470870971679688,
      "step": 2980
    },
    {
      "epoch": 0.17651731340648996,
      "grad_norm": 1.7403392791748047,
      "learning_rate": 4.7063842306560756e-05,
      "logits/chosen": 4.236598014831543,
      "logits/rejected": 4.058546543121338,
      "logps/chosen": -380.40863037109375,
      "logps/rejected": -319.6398010253906,
      "loss": 0.5528,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.24121510982513428,
      "rewards/margins": 1.4548420906066895,
      "rewards/rejected": -1.6960573196411133,
      "step": 3000
    },
    {
      "epoch": 0.17769409549586657,
      "grad_norm": 1.5671454668045044,
      "learning_rate": 4.704422869471413e-05,
      "logits/chosen": 3.9400131702423096,
      "logits/rejected": 3.826140880584717,
      "logps/chosen": -373.90179443359375,
      "logps/rejected": -315.460693359375,
      "loss": 0.4907,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.024073749780654907,
      "rewards/margins": 1.98403000831604,
      "rewards/rejected": -1.959956169128418,
      "step": 3020
    },
    {
      "epoch": 0.17887087758524314,
      "grad_norm": 3.213282346725464,
      "learning_rate": 4.7024615082867515e-05,
      "logits/chosen": 3.900200366973877,
      "logits/rejected": 4.029318809509277,
      "logps/chosen": -357.3389587402344,
      "logps/rejected": -294.4122314453125,
      "loss": 0.6489,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.4149831235408783,
      "rewards/margins": 1.8897826671600342,
      "rewards/rejected": -2.3047661781311035,
      "step": 3040
    },
    {
      "epoch": 0.18004765967461975,
      "grad_norm": 1.2019089460372925,
      "learning_rate": 4.700500147102089e-05,
      "logits/chosen": 3.751481294631958,
      "logits/rejected": 3.65208101272583,
      "logps/chosen": -379.79937744140625,
      "logps/rejected": -306.9897766113281,
      "loss": 0.4181,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6570228338241577,
      "rewards/margins": 2.3291432857513428,
      "rewards/rejected": -2.98616623878479,
      "step": 3060
    },
    {
      "epoch": 0.18122444176399635,
      "grad_norm": 3.995742082595825,
      "learning_rate": 4.69863685397666e-05,
      "logits/chosen": 4.114032745361328,
      "logits/rejected": 4.046054363250732,
      "logps/chosen": -357.9629821777344,
      "logps/rejected": -312.66717529296875,
      "loss": 0.6262,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1558161973953247,
      "rewards/margins": 2.052168607711792,
      "rewards/rejected": -3.207984447479248,
      "step": 3080
    },
    {
      "epoch": 0.18240122385337296,
      "grad_norm": 5.059907913208008,
      "learning_rate": 4.696675492791998e-05,
      "logits/chosen": 4.055991172790527,
      "logits/rejected": 4.061542987823486,
      "logps/chosen": -379.3575134277344,
      "logps/rejected": -309.31610107421875,
      "loss": 0.5115,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6608930826187134,
      "rewards/margins": 1.9826371669769287,
      "rewards/rejected": -3.6435303688049316,
      "step": 3100
    },
    {
      "epoch": 0.18357800594274956,
      "grad_norm": 1.5037897825241089,
      "learning_rate": 4.6947141316073355e-05,
      "logits/chosen": 3.845303773880005,
      "logits/rejected": 3.8626372814178467,
      "logps/chosen": -342.08880615234375,
      "logps/rejected": -289.19879150390625,
      "loss": 0.4875,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9837366342544556,
      "rewards/margins": 1.8054158687591553,
      "rewards/rejected": -2.7891526222229004,
      "step": 3120
    },
    {
      "epoch": 0.18475478803212614,
      "grad_norm": 1.83905029296875,
      "learning_rate": 4.692752770422674e-05,
      "logits/chosen": 3.848691463470459,
      "logits/rejected": 3.8803162574768066,
      "logps/chosen": -372.3482666015625,
      "logps/rejected": -330.1871032714844,
      "loss": 0.452,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0652048587799072,
      "rewards/margins": 2.135664463043213,
      "rewards/rejected": -3.20086932182312,
      "step": 3140
    },
    {
      "epoch": 0.18593157012150274,
      "grad_norm": 1.5309900045394897,
      "learning_rate": 4.6907914092380114e-05,
      "logits/chosen": 3.4376754760742188,
      "logits/rejected": 3.3630073070526123,
      "logps/chosen": -365.2587585449219,
      "logps/rejected": -326.8480529785156,
      "loss": 0.6256,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2183278799057007,
      "rewards/margins": 1.788316011428833,
      "rewards/rejected": -3.006643772125244,
      "step": 3160
    },
    {
      "epoch": 0.18710835221087935,
      "grad_norm": 2.409414052963257,
      "learning_rate": 4.688830048053349e-05,
      "logits/chosen": 3.748581647872925,
      "logits/rejected": 3.8381965160369873,
      "logps/chosen": -395.8455810546875,
      "logps/rejected": -296.3940734863281,
      "loss": 0.5394,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.24126669764518738,
      "rewards/margins": 2.368264675140381,
      "rewards/rejected": -2.6095314025878906,
      "step": 3180
    },
    {
      "epoch": 0.18828513430025595,
      "grad_norm": 2.217036008834839,
      "learning_rate": 4.686868686868687e-05,
      "logits/chosen": 3.854353427886963,
      "logits/rejected": 3.7661056518554688,
      "logps/chosen": -405.45068359375,
      "logps/rejected": -308.02032470703125,
      "loss": 0.4948,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9585295915603638,
      "rewards/margins": 2.1083102226257324,
      "rewards/rejected": -3.0668396949768066,
      "step": 3200
    },
    {
      "epoch": 0.18946191638963256,
      "grad_norm": 1.340755581855774,
      "learning_rate": 4.684907325684025e-05,
      "logits/chosen": 4.017360210418701,
      "logits/rejected": 4.034041404724121,
      "logps/chosen": -374.3795471191406,
      "logps/rejected": -315.8192443847656,
      "loss": 0.5351,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5679519772529602,
      "rewards/margins": 1.8410422801971436,
      "rewards/rejected": -2.408994197845459,
      "step": 3220
    },
    {
      "epoch": 0.19063869847900916,
      "grad_norm": 3.3937337398529053,
      "learning_rate": 4.682945964499363e-05,
      "logits/chosen": 3.953167676925659,
      "logits/rejected": 3.7853827476501465,
      "logps/chosen": -419.8390197753906,
      "logps/rejected": -328.0956115722656,
      "loss": 0.7327,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1280076503753662,
      "rewards/margins": 1.5054550170898438,
      "rewards/rejected": -2.63346266746521,
      "step": 3240
    },
    {
      "epoch": 0.19181548056838574,
      "grad_norm": 9.095552444458008,
      "learning_rate": 4.680984603314701e-05,
      "logits/chosen": 4.387296199798584,
      "logits/rejected": 4.1911163330078125,
      "logps/chosen": -447.874755859375,
      "logps/rejected": -393.4856872558594,
      "loss": 0.5503,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.11630594730377197,
      "rewards/margins": 2.284052848815918,
      "rewards/rejected": -2.1677467823028564,
      "step": 3260
    },
    {
      "epoch": 0.19299226265776234,
      "grad_norm": 2.9371838569641113,
      "learning_rate": 4.6790232421300384e-05,
      "logits/chosen": 3.6145572662353516,
      "logits/rejected": 3.486940383911133,
      "logps/chosen": -377.43878173828125,
      "logps/rejected": -257.70330810546875,
      "loss": 0.4667,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.3199335038661957,
      "rewards/margins": 2.3406243324279785,
      "rewards/rejected": -2.020690679550171,
      "step": 3280
    },
    {
      "epoch": 0.19416904474713895,
      "grad_norm": 1.771064043045044,
      "learning_rate": 4.6770618809453766e-05,
      "logits/chosen": 3.696659564971924,
      "logits/rejected": 3.6951630115509033,
      "logps/chosen": -346.5843811035156,
      "logps/rejected": -311.5770568847656,
      "loss": 0.4637,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.09491325914859772,
      "rewards/margins": 1.9217445850372314,
      "rewards/rejected": -1.8268312215805054,
      "step": 3300
    },
    {
      "epoch": 0.19534582683651555,
      "grad_norm": 0.4820983111858368,
      "learning_rate": 4.675100519760714e-05,
      "logits/chosen": 3.72489595413208,
      "logits/rejected": 3.729358673095703,
      "logps/chosen": -346.9613342285156,
      "logps/rejected": -268.00787353515625,
      "loss": 0.4111,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.3704688847064972,
      "rewards/margins": 1.93817138671875,
      "rewards/rejected": -2.308640480041504,
      "step": 3320
    },
    {
      "epoch": 0.19652260892589216,
      "grad_norm": 4.756919860839844,
      "learning_rate": 4.673139158576052e-05,
      "logits/chosen": 3.768479824066162,
      "logits/rejected": 3.7160372734069824,
      "logps/chosen": -393.37506103515625,
      "logps/rejected": -350.8724670410156,
      "loss": 0.5306,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9237837791442871,
      "rewards/margins": 2.3753180503845215,
      "rewards/rejected": -3.2991020679473877,
      "step": 3340
    },
    {
      "epoch": 0.19769939101526876,
      "grad_norm": 12.815469741821289,
      "learning_rate": 4.67117779739139e-05,
      "logits/chosen": 3.681187868118286,
      "logits/rejected": 3.5199265480041504,
      "logps/chosen": -367.88519287109375,
      "logps/rejected": -304.68048095703125,
      "loss": 0.6061,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.02947199344635,
      "rewards/margins": 2.1283111572265625,
      "rewards/rejected": -3.157783031463623,
      "step": 3360
    },
    {
      "epoch": 0.19887617310464534,
      "grad_norm": 2.6970202922821045,
      "learning_rate": 4.669216436206728e-05,
      "logits/chosen": 3.7618186473846436,
      "logits/rejected": 3.656243085861206,
      "logps/chosen": -363.83306884765625,
      "logps/rejected": -285.88360595703125,
      "loss": 0.5822,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.8734505772590637,
      "rewards/margins": 1.6086342334747314,
      "rewards/rejected": -2.4820847511291504,
      "step": 3380
    },
    {
      "epoch": 0.20005295519402194,
      "grad_norm": 2.2216622829437256,
      "learning_rate": 4.667255075022065e-05,
      "logits/chosen": 3.8982529640197754,
      "logits/rejected": 3.711249589920044,
      "logps/chosen": -402.6278381347656,
      "logps/rejected": -293.2855224609375,
      "loss": 0.4852,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.04532743617892265,
      "rewards/margins": 2.1942901611328125,
      "rewards/rejected": -2.14896297454834,
      "step": 3400
    },
    {
      "epoch": 0.20122973728339855,
      "grad_norm": 1.340157151222229,
      "learning_rate": 4.6652937138374036e-05,
      "logits/chosen": 4.0126566886901855,
      "logits/rejected": 4.1691789627075195,
      "logps/chosen": -370.0653991699219,
      "logps/rejected": -349.99725341796875,
      "loss": 0.3883,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.07799895852804184,
      "rewards/margins": 2.61104154586792,
      "rewards/rejected": -2.689040422439575,
      "step": 3420
    },
    {
      "epoch": 0.20240651937277515,
      "grad_norm": 1.3417541980743408,
      "learning_rate": 4.663332352652741e-05,
      "logits/chosen": 3.9911696910858154,
      "logits/rejected": 3.932204008102417,
      "logps/chosen": -374.0650939941406,
      "logps/rejected": -311.4408874511719,
      "loss": 0.5723,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.28746289014816284,
      "rewards/margins": 1.9739049673080444,
      "rewards/rejected": -2.2613680362701416,
      "step": 3440
    },
    {
      "epoch": 0.20358330146215176,
      "grad_norm": 0.6481025218963623,
      "learning_rate": 4.6613709914680795e-05,
      "logits/chosen": 4.063925743103027,
      "logits/rejected": 3.9868476390838623,
      "logps/chosen": -379.4450378417969,
      "logps/rejected": -294.7895812988281,
      "loss": 0.4235,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.38405686616897583,
      "rewards/margins": 2.843754291534424,
      "rewards/rejected": -2.4596972465515137,
      "step": 3460
    },
    {
      "epoch": 0.20476008355152833,
      "grad_norm": 1.524705410003662,
      "learning_rate": 4.6594096302834164e-05,
      "logits/chosen": 4.052000045776367,
      "logits/rejected": 4.081376075744629,
      "logps/chosen": -375.2914123535156,
      "logps/rejected": -320.86395263671875,
      "loss": 0.4108,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.05519427731633186,
      "rewards/margins": 1.874200463294983,
      "rewards/rejected": -1.9293947219848633,
      "step": 3480
    },
    {
      "epoch": 0.20593686564090494,
      "grad_norm": 2.654597759246826,
      "learning_rate": 4.657448269098755e-05,
      "logits/chosen": 3.7125911712646484,
      "logits/rejected": 3.6060562133789062,
      "logps/chosen": -339.99444580078125,
      "logps/rejected": -269.4447937011719,
      "loss": 0.556,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.2072688341140747,
      "rewards/margins": 1.6769291162490845,
      "rewards/rejected": -1.8841979503631592,
      "step": 3500
    },
    {
      "epoch": 0.20711364773028154,
      "grad_norm": 4.5717878341674805,
      "learning_rate": 4.655486907914093e-05,
      "logits/chosen": 3.984213352203369,
      "logits/rejected": 3.8076655864715576,
      "logps/chosen": -395.2445373535156,
      "logps/rejected": -339.0816345214844,
      "loss": 0.4677,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.1296032965183258,
      "rewards/margins": 2.6978611946105957,
      "rewards/rejected": -2.8274641036987305,
      "step": 3520
    },
    {
      "epoch": 0.20829042981965815,
      "grad_norm": 1.0427591800689697,
      "learning_rate": 4.6535255467294306e-05,
      "logits/chosen": 4.182366847991943,
      "logits/rejected": 3.987466335296631,
      "logps/chosen": -422.64990234375,
      "logps/rejected": -306.0582580566406,
      "loss": 0.4155,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.18526297807693481,
      "rewards/margins": 2.318342924118042,
      "rewards/rejected": -2.503605842590332,
      "step": 3540
    },
    {
      "epoch": 0.20946721190903475,
      "grad_norm": 3.6797094345092773,
      "learning_rate": 4.651564185544768e-05,
      "logits/chosen": 3.984563112258911,
      "logits/rejected": 3.9811148643493652,
      "logps/chosen": -419.7337951660156,
      "logps/rejected": -343.01983642578125,
      "loss": 0.5809,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.23102860152721405,
      "rewards/margins": 2.1300930976867676,
      "rewards/rejected": -2.361121654510498,
      "step": 3560
    },
    {
      "epoch": 0.21064399399841136,
      "grad_norm": 1.6552131175994873,
      "learning_rate": 4.6496028243601065e-05,
      "logits/chosen": 3.8849551677703857,
      "logits/rejected": 3.7819695472717285,
      "logps/chosen": -375.49078369140625,
      "logps/rejected": -323.4497985839844,
      "loss": 0.5534,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.427961528301239,
      "rewards/margins": 2.1857056617736816,
      "rewards/rejected": -2.6136670112609863,
      "step": 3580
    },
    {
      "epoch": 0.21182077608778793,
      "grad_norm": 2.7265188694000244,
      "learning_rate": 4.647641463175444e-05,
      "logits/chosen": 3.4914374351501465,
      "logits/rejected": 3.7608535289764404,
      "logps/chosen": -309.5573425292969,
      "logps/rejected": -259.1494140625,
      "loss": 0.5468,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.491973876953125,
      "rewards/margins": 1.488115906715393,
      "rewards/rejected": -1.9800899028778076,
      "step": 3600
    },
    {
      "epoch": 0.21299755817716454,
      "grad_norm": 2.370591640472412,
      "learning_rate": 4.645680101990782e-05,
      "logits/chosen": 4.034953594207764,
      "logits/rejected": 3.9640018939971924,
      "logps/chosen": -365.2008056640625,
      "logps/rejected": -326.86126708984375,
      "loss": 0.5075,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8755391836166382,
      "rewards/margins": 1.7546793222427368,
      "rewards/rejected": -2.630218267440796,
      "step": 3620
    },
    {
      "epoch": 0.21417434026654114,
      "grad_norm": 1.566105604171753,
      "learning_rate": 4.643718740806119e-05,
      "logits/chosen": 3.7772717475891113,
      "logits/rejected": 3.8048110008239746,
      "logps/chosen": -346.79278564453125,
      "logps/rejected": -342.4468994140625,
      "loss": 0.6619,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.619310736656189,
      "rewards/margins": 2.189584255218506,
      "rewards/rejected": -2.8088951110839844,
      "step": 3640
    },
    {
      "epoch": 0.21535112235591775,
      "grad_norm": 6.243605136871338,
      "learning_rate": 4.6417573796214576e-05,
      "logits/chosen": 3.8919997215270996,
      "logits/rejected": 3.9233500957489014,
      "logps/chosen": -393.19500732421875,
      "logps/rejected": -322.9571228027344,
      "loss": 0.6317,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.364485740661621,
      "rewards/margins": 1.7244298458099365,
      "rewards/rejected": -3.0889158248901367,
      "step": 3660
    },
    {
      "epoch": 0.21652790444529435,
      "grad_norm": 0.5625620484352112,
      "learning_rate": 4.639796018436796e-05,
      "logits/chosen": 3.739521026611328,
      "logits/rejected": 3.8073432445526123,
      "logps/chosen": -359.3701477050781,
      "logps/rejected": -332.3946228027344,
      "loss": 0.6494,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.275281548500061,
      "rewards/margins": 1.5780901908874512,
      "rewards/rejected": -2.8533716201782227,
      "step": 3680
    },
    {
      "epoch": 0.21770468653467095,
      "grad_norm": 1.2594980001449585,
      "learning_rate": 4.637834657252133e-05,
      "logits/chosen": 3.5790436267852783,
      "logits/rejected": 3.699927806854248,
      "logps/chosen": -376.59747314453125,
      "logps/rejected": -296.4811096191406,
      "loss": 0.4609,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.45593976974487305,
      "rewards/margins": 1.878075361251831,
      "rewards/rejected": -2.334015130996704,
      "step": 3700
    },
    {
      "epoch": 0.21888146862404753,
      "grad_norm": 2.1755869388580322,
      "learning_rate": 4.635873296067471e-05,
      "logits/chosen": 3.6515705585479736,
      "logits/rejected": 3.656653881072998,
      "logps/chosen": -394.36785888671875,
      "logps/rejected": -325.00146484375,
      "loss": 0.5598,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6509502530097961,
      "rewards/margins": 1.9406874179840088,
      "rewards/rejected": -2.591637372970581,
      "step": 3720
    },
    {
      "epoch": 0.22005825071342414,
      "grad_norm": 1.6347625255584717,
      "learning_rate": 4.633911934882809e-05,
      "logits/chosen": 3.8660666942596436,
      "logits/rejected": 3.752737522125244,
      "logps/chosen": -394.2328796386719,
      "logps/rejected": -354.1099853515625,
      "loss": 0.4866,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.390730619430542,
      "rewards/margins": 1.8411823511123657,
      "rewards/rejected": -3.2319130897521973,
      "step": 3740
    },
    {
      "epoch": 0.22123503280280074,
      "grad_norm": 6.142799377441406,
      "learning_rate": 4.631950573698147e-05,
      "logits/chosen": 3.8184006214141846,
      "logits/rejected": 3.664576292037964,
      "logps/chosen": -365.70263671875,
      "logps/rejected": -279.52520751953125,
      "loss": 0.5763,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7602812647819519,
      "rewards/margins": 1.9247281551361084,
      "rewards/rejected": -2.685009479522705,
      "step": 3760
    },
    {
      "epoch": 0.22241181489217735,
      "grad_norm": 5.758858680725098,
      "learning_rate": 4.6299892125134846e-05,
      "logits/chosen": 3.932793378829956,
      "logits/rejected": 3.833380937576294,
      "logps/chosen": -392.84991455078125,
      "logps/rejected": -253.07373046875,
      "loss": 0.4826,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6016603708267212,
      "rewards/margins": 1.9473358392715454,
      "rewards/rejected": -2.5489959716796875,
      "step": 3780
    },
    {
      "epoch": 0.22358859698155395,
      "grad_norm": 14.253125190734863,
      "learning_rate": 4.628027851328822e-05,
      "logits/chosen": 3.8609070777893066,
      "logits/rejected": 3.8000786304473877,
      "logps/chosen": -396.9054870605469,
      "logps/rejected": -285.27923583984375,
      "loss": 0.5742,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.1221233606338501,
      "rewards/margins": 2.3496222496032715,
      "rewards/rejected": -2.471745252609253,
      "step": 3800
    },
    {
      "epoch": 0.22476537907093053,
      "grad_norm": 3.9244234561920166,
      "learning_rate": 4.6260664901441604e-05,
      "logits/chosen": 3.8135688304901123,
      "logits/rejected": 3.828408718109131,
      "logps/chosen": -343.29156494140625,
      "logps/rejected": -273.8038635253906,
      "loss": 0.6739,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.7662148475646973,
      "rewards/margins": 1.320824384689331,
      "rewards/rejected": -2.0870392322540283,
      "step": 3820
    },
    {
      "epoch": 0.22594216116030713,
      "grad_norm": 2.916790723800659,
      "learning_rate": 4.624105128959498e-05,
      "logits/chosen": 4.068106651306152,
      "logits/rejected": 3.8282253742218018,
      "logps/chosen": -371.7975769042969,
      "logps/rejected": -282.10858154296875,
      "loss": 0.4927,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.5291515588760376,
      "rewards/margins": 1.8085705041885376,
      "rewards/rejected": -2.3377223014831543,
      "step": 3840
    },
    {
      "epoch": 0.22711894324968374,
      "grad_norm": 1.6819818019866943,
      "learning_rate": 4.6221437677748356e-05,
      "logits/chosen": 4.168694972991943,
      "logits/rejected": 4.044835567474365,
      "logps/chosen": -381.67156982421875,
      "logps/rejected": -315.841796875,
      "loss": 0.641,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.353800505399704,
      "rewards/margins": 1.674403429031372,
      "rewards/rejected": -2.0282037258148193,
      "step": 3860
    },
    {
      "epoch": 0.22829572533906034,
      "grad_norm": 4.7785539627075195,
      "learning_rate": 4.620182406590174e-05,
      "logits/chosen": 4.05222225189209,
      "logits/rejected": 3.912022113800049,
      "logps/chosen": -386.9627380371094,
      "logps/rejected": -315.3544921875,
      "loss": 0.4607,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.07937918603420258,
      "rewards/margins": 1.7948329448699951,
      "rewards/rejected": -1.8742122650146484,
      "step": 3880
    },
    {
      "epoch": 0.22947250742843694,
      "grad_norm": 3.068640947341919,
      "learning_rate": 4.6182210454055115e-05,
      "logits/chosen": 3.843059539794922,
      "logits/rejected": 3.7988979816436768,
      "logps/chosen": -370.0342102050781,
      "logps/rejected": -309.1739807128906,
      "loss": 0.5778,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7302266359329224,
      "rewards/margins": 1.5152199268341064,
      "rewards/rejected": -2.2454464435577393,
      "step": 3900
    },
    {
      "epoch": 0.23064928951781355,
      "grad_norm": 4.122404098510742,
      "learning_rate": 4.616259684220849e-05,
      "logits/chosen": 3.7007975578308105,
      "logits/rejected": 3.6770026683807373,
      "logps/chosen": -376.42938232421875,
      "logps/rejected": -266.82293701171875,
      "loss": 0.784,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7777374982833862,
      "rewards/margins": 1.5926724672317505,
      "rewards/rejected": -2.3704099655151367,
      "step": 3920
    },
    {
      "epoch": 0.23182607160719013,
      "grad_norm": 0.9173489809036255,
      "learning_rate": 4.6142983230361874e-05,
      "logits/chosen": 4.169530391693115,
      "logits/rejected": 3.9272313117980957,
      "logps/chosen": -361.3434753417969,
      "logps/rejected": -313.00750732421875,
      "loss": 0.4682,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.18983909487724304,
      "rewards/margins": 1.8401587009429932,
      "rewards/rejected": -2.0299978256225586,
      "step": 3940
    },
    {
      "epoch": 0.23300285369656673,
      "grad_norm": 3.6109986305236816,
      "learning_rate": 4.612336961851525e-05,
      "logits/chosen": 4.084725379943848,
      "logits/rejected": 4.093364238739014,
      "logps/chosen": -377.0013732910156,
      "logps/rejected": -320.3575744628906,
      "loss": 0.5141,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6597668528556824,
      "rewards/margins": 1.575218915939331,
      "rewards/rejected": -2.234985828399658,
      "step": 3960
    },
    {
      "epoch": 0.23417963578594334,
      "grad_norm": 1.812408447265625,
      "learning_rate": 4.610375600666863e-05,
      "logits/chosen": 3.3960964679718018,
      "logits/rejected": 3.3688995838165283,
      "logps/chosen": -366.8317565917969,
      "logps/rejected": -298.6665344238281,
      "loss": 0.6146,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.80286705493927,
      "rewards/margins": 1.9163360595703125,
      "rewards/rejected": -2.719202995300293,
      "step": 3980
    },
    {
      "epoch": 0.23535641787531994,
      "grad_norm": 1.2039704322814941,
      "learning_rate": 4.608414239482201e-05,
      "logits/chosen": 3.885197162628174,
      "logits/rejected": 3.7340824604034424,
      "logps/chosen": -431.8900451660156,
      "logps/rejected": -303.7445373535156,
      "loss": 0.5524,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.6565124988555908,
      "rewards/margins": 2.029449939727783,
      "rewards/rejected": -2.685961961746216,
      "step": 4000
    },
    {
      "epoch": 0.23653319996469654,
      "grad_norm": 1.168357253074646,
      "learning_rate": 4.6064528782975385e-05,
      "logits/chosen": 3.9487242698669434,
      "logits/rejected": 3.934535264968872,
      "logps/chosen": -371.33160400390625,
      "logps/rejected": -330.32305908203125,
      "loss": 0.5352,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7026062607765198,
      "rewards/margins": 1.593214511871338,
      "rewards/rejected": -2.295820713043213,
      "step": 4020
    },
    {
      "epoch": 0.23770998205407315,
      "grad_norm": 2.47282075881958,
      "learning_rate": 4.604491517112877e-05,
      "logits/chosen": 3.872112274169922,
      "logits/rejected": 3.6570677757263184,
      "logps/chosen": -381.0318603515625,
      "logps/rejected": -312.7147216796875,
      "loss": 0.5493,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.101325511932373,
      "rewards/margins": 1.7711122035980225,
      "rewards/rejected": -2.8724377155303955,
      "step": 4040
    },
    {
      "epoch": 0.23888676414344973,
      "grad_norm": 2.179629325866699,
      "learning_rate": 4.6025301559282144e-05,
      "logits/chosen": 3.640777587890625,
      "logits/rejected": 3.65260648727417,
      "logps/chosen": -372.6716003417969,
      "logps/rejected": -318.20587158203125,
      "loss": 0.4931,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7606675028800964,
      "rewards/margins": 2.482287883758545,
      "rewards/rejected": -3.2429556846618652,
      "step": 4060
    },
    {
      "epoch": 0.24006354623282633,
      "grad_norm": 0.6821606755256653,
      "learning_rate": 4.600568794743552e-05,
      "logits/chosen": 4.0066022872924805,
      "logits/rejected": 3.98957896232605,
      "logps/chosen": -375.7389221191406,
      "logps/rejected": -306.85479736328125,
      "loss": 0.477,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.49587029218673706,
      "rewards/margins": 1.8527570962905884,
      "rewards/rejected": -2.3486275672912598,
      "step": 4080
    },
    {
      "epoch": 0.24124032832220293,
      "grad_norm": 2.3250162601470947,
      "learning_rate": 4.59860743355889e-05,
      "logits/chosen": 3.664116621017456,
      "logits/rejected": 3.6723244190216064,
      "logps/chosen": -351.3760681152344,
      "logps/rejected": -264.67230224609375,
      "loss": 0.5842,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.9273570775985718,
      "rewards/margins": 1.3321528434753418,
      "rewards/rejected": -2.259510040283203,
      "step": 4100
    },
    {
      "epoch": 0.24241711041157954,
      "grad_norm": 2.737543821334839,
      "learning_rate": 4.596646072374228e-05,
      "logits/chosen": 4.083239555358887,
      "logits/rejected": 3.9889602661132812,
      "logps/chosen": -372.7425537109375,
      "logps/rejected": -277.7660827636719,
      "loss": 0.4876,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9896017909049988,
      "rewards/margins": 2.0893142223358154,
      "rewards/rejected": -3.07891583442688,
      "step": 4120
    },
    {
      "epoch": 0.24359389250095614,
      "grad_norm": 5.003377437591553,
      "learning_rate": 4.5946847111895655e-05,
      "logits/chosen": 3.981369733810425,
      "logits/rejected": 3.8902740478515625,
      "logps/chosen": -368.9591369628906,
      "logps/rejected": -321.42132568359375,
      "loss": 0.5625,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7781158685684204,
      "rewards/margins": 2.4909605979919434,
      "rewards/rejected": -3.2690765857696533,
      "step": 4140
    },
    {
      "epoch": 0.24477067459033275,
      "grad_norm": 1.8926348686218262,
      "learning_rate": 4.592723350004904e-05,
      "logits/chosen": 3.725560426712036,
      "logits/rejected": 3.7282376289367676,
      "logps/chosen": -350.6560974121094,
      "logps/rejected": -316.302978515625,
      "loss": 0.455,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.09284450858831406,
      "rewards/margins": 2.9361536502838135,
      "rewards/rejected": -2.843308925628662,
      "step": 4160
    },
    {
      "epoch": 0.24594745667970933,
      "grad_norm": 1.6676329374313354,
      "learning_rate": 4.5907619888202414e-05,
      "logits/chosen": 3.872894287109375,
      "logits/rejected": 3.852083921432495,
      "logps/chosen": -375.9571228027344,
      "logps/rejected": -276.39654541015625,
      "loss": 0.5046,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5823355317115784,
      "rewards/margins": 1.8131811618804932,
      "rewards/rejected": -2.395516872406006,
      "step": 4180
    },
    {
      "epoch": 0.24712423876908593,
      "grad_norm": 0.8329097032546997,
      "learning_rate": 4.5888006276355797e-05,
      "logits/chosen": 3.888472080230713,
      "logits/rejected": 3.7899036407470703,
      "logps/chosen": -355.89874267578125,
      "logps/rejected": -268.1582946777344,
      "loss": 0.4813,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7746320962905884,
      "rewards/margins": 1.829742670059204,
      "rewards/rejected": -2.604374647140503,
      "step": 4200
    },
    {
      "epoch": 0.24830102085846253,
      "grad_norm": 1.511104941368103,
      "learning_rate": 4.5868392664509166e-05,
      "logits/chosen": 3.9172255992889404,
      "logits/rejected": 3.8333942890167236,
      "logps/chosen": -363.7930908203125,
      "logps/rejected": -272.0894470214844,
      "loss": 0.3335,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -0.5183709859848022,
      "rewards/margins": 2.0674259662628174,
      "rewards/rejected": -2.58579683303833,
      "step": 4220
    },
    {
      "epoch": 0.24947780294783914,
      "grad_norm": 0.2257886677980423,
      "learning_rate": 4.584877905266255e-05,
      "logits/chosen": 3.641267776489258,
      "logits/rejected": 3.71260142326355,
      "logps/chosen": -356.68255615234375,
      "logps/rejected": -287.1745300292969,
      "loss": 0.6019,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.8008033633232117,
      "rewards/margins": 1.379257082939148,
      "rewards/rejected": -2.180060386657715,
      "step": 4240
    },
    {
      "epoch": 0.2506545850372157,
      "grad_norm": 0.5686696171760559,
      "learning_rate": 4.582916544081593e-05,
      "logits/chosen": 3.842421770095825,
      "logits/rejected": 3.8234894275665283,
      "logps/chosen": -406.99407958984375,
      "logps/rejected": -289.40606689453125,
      "loss": 0.3259,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": 0.4382505416870117,
      "rewards/margins": 2.7290377616882324,
      "rewards/rejected": -2.2907872200012207,
      "step": 4260
    },
    {
      "epoch": 0.2518313671265923,
      "grad_norm": 1.8334697484970093,
      "learning_rate": 4.580955182896931e-05,
      "logits/chosen": 3.784946918487549,
      "logits/rejected": 3.880073070526123,
      "logps/chosen": -376.5481872558594,
      "logps/rejected": -295.79095458984375,
      "loss": 0.4863,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7034000158309937,
      "rewards/margins": 1.7247260808944702,
      "rewards/rejected": -2.428126096725464,
      "step": 4280
    },
    {
      "epoch": 0.2530081492159689,
      "grad_norm": 1.4082926511764526,
      "learning_rate": 4.5789938217122684e-05,
      "logits/chosen": 3.947366714477539,
      "logits/rejected": 3.813328504562378,
      "logps/chosen": -357.7833557128906,
      "logps/rejected": -256.4302673339844,
      "loss": 0.429,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.2724539339542389,
      "rewards/margins": 2.1764609813690186,
      "rewards/rejected": -2.4489150047302246,
      "step": 4300
    },
    {
      "epoch": 0.25418493130534553,
      "grad_norm": 2.819836139678955,
      "learning_rate": 4.5770324605276066e-05,
      "logits/chosen": 3.8904659748077393,
      "logits/rejected": 3.8561527729034424,
      "logps/chosen": -409.4525146484375,
      "logps/rejected": -268.3323974609375,
      "loss": 0.54,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.4625978469848633,
      "rewards/margins": 2.176909923553467,
      "rewards/rejected": -2.63950777053833,
      "step": 4320
    },
    {
      "epoch": 0.25536171339472213,
      "grad_norm": 13.713994979858398,
      "learning_rate": 4.575071099342944e-05,
      "logits/chosen": 3.7505831718444824,
      "logits/rejected": 3.8474020957946777,
      "logps/chosen": -366.52471923828125,
      "logps/rejected": -327.915771484375,
      "loss": 0.4419,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.47061848640441895,
      "rewards/margins": 2.3138999938964844,
      "rewards/rejected": -2.7845184803009033,
      "step": 4340
    },
    {
      "epoch": 0.25653849548409874,
      "grad_norm": 2.283039093017578,
      "learning_rate": 4.573109738158282e-05,
      "logits/chosen": 4.0774078369140625,
      "logits/rejected": 4.060842514038086,
      "logps/chosen": -366.05889892578125,
      "logps/rejected": -303.85345458984375,
      "loss": 0.4477,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9251823425292969,
      "rewards/margins": 1.9974219799041748,
      "rewards/rejected": -2.9226043224334717,
      "step": 4360
    },
    {
      "epoch": 0.25771527757347534,
      "grad_norm": 4.2626495361328125,
      "learning_rate": 4.5711483769736195e-05,
      "logits/chosen": 3.941023588180542,
      "logits/rejected": 3.869060516357422,
      "logps/chosen": -362.256591796875,
      "logps/rejected": -302.70733642578125,
      "loss": 0.5088,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6405221819877625,
      "rewards/margins": 2.2647528648376465,
      "rewards/rejected": -2.9052751064300537,
      "step": 4380
    },
    {
      "epoch": 0.25889205966285195,
      "grad_norm": 0.6342628598213196,
      "learning_rate": 4.569187015788958e-05,
      "logits/chosen": 4.011737823486328,
      "logits/rejected": 4.018604755401611,
      "logps/chosen": -388.0562744140625,
      "logps/rejected": -295.48822021484375,
      "loss": 0.4355,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.8853446841239929,
      "rewards/margins": 1.9650089740753174,
      "rewards/rejected": -2.850353479385376,
      "step": 4400
    },
    {
      "epoch": 0.26006884175222855,
      "grad_norm": 3.616238832473755,
      "learning_rate": 4.567225654604296e-05,
      "logits/chosen": 4.042046546936035,
      "logits/rejected": 4.059494972229004,
      "logps/chosen": -366.5600280761719,
      "logps/rejected": -288.83636474609375,
      "loss": 0.6201,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0010120868682861,
      "rewards/margins": 1.4688560962677002,
      "rewards/rejected": -2.4698681831359863,
      "step": 4420
    },
    {
      "epoch": 0.26124562384160516,
      "grad_norm": 0.44241079688072205,
      "learning_rate": 4.565264293419633e-05,
      "logits/chosen": 3.900494337081909,
      "logits/rejected": 3.7993080615997314,
      "logps/chosen": -368.43218994140625,
      "logps/rejected": -290.42498779296875,
      "loss": 0.627,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.2977260947227478,
      "rewards/margins": 2.1935036182403564,
      "rewards/rejected": -2.491229772567749,
      "step": 4440
    },
    {
      "epoch": 0.2624224059309817,
      "grad_norm": 3.847792387008667,
      "learning_rate": 4.563302932234971e-05,
      "logits/chosen": 3.9711289405822754,
      "logits/rejected": 3.98256254196167,
      "logps/chosen": -307.222900390625,
      "logps/rejected": -302.0344543457031,
      "loss": 0.5785,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.504607081413269,
      "rewards/margins": 1.4149787425994873,
      "rewards/rejected": -1.9195858240127563,
      "step": 4460
    },
    {
      "epoch": 0.2635991880203583,
      "grad_norm": 1.3070546388626099,
      "learning_rate": 4.5613415710503095e-05,
      "logits/chosen": 3.8885223865509033,
      "logits/rejected": 3.9099698066711426,
      "logps/chosen": -336.6740417480469,
      "logps/rejected": -263.01593017578125,
      "loss": 0.4194,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.027668654918670654,
      "rewards/margins": 2.11668062210083,
      "rewards/rejected": -2.1443493366241455,
      "step": 4480
    },
    {
      "epoch": 0.2647759701097349,
      "grad_norm": 10.807671546936035,
      "learning_rate": 4.559380209865647e-05,
      "logits/chosen": 4.070006370544434,
      "logits/rejected": 4.155968189239502,
      "logps/chosen": -315.9425354003906,
      "logps/rejected": -285.26214599609375,
      "loss": 0.6061,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7186495065689087,
      "rewards/margins": 1.55075204372406,
      "rewards/rejected": -2.269401788711548,
      "step": 4500
    },
    {
      "epoch": 0.2659527521991115,
      "grad_norm": 4.091713905334473,
      "learning_rate": 4.557418848680985e-05,
      "logits/chosen": 3.788825511932373,
      "logits/rejected": 3.8570926189422607,
      "logps/chosen": -377.39129638671875,
      "logps/rejected": -282.25860595703125,
      "loss": 0.6862,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.765266478061676,
      "rewards/margins": 1.471984624862671,
      "rewards/rejected": -2.2372512817382812,
      "step": 4520
    },
    {
      "epoch": 0.2671295342884881,
      "grad_norm": 2.3088793754577637,
      "learning_rate": 4.555457487496322e-05,
      "logits/chosen": 3.8644516468048096,
      "logits/rejected": 3.9575812816619873,
      "logps/chosen": -362.3299560546875,
      "logps/rejected": -295.7015380859375,
      "loss": 0.5852,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6596552729606628,
      "rewards/margins": 1.6836214065551758,
      "rewards/rejected": -2.3432767391204834,
      "step": 4540
    },
    {
      "epoch": 0.26830631637786473,
      "grad_norm": 1.4541971683502197,
      "learning_rate": 4.5534961263116606e-05,
      "logits/chosen": 4.080594062805176,
      "logits/rejected": 4.075314998626709,
      "logps/chosen": -427.69036865234375,
      "logps/rejected": -312.6279602050781,
      "loss": 0.3766,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.29134926199913025,
      "rewards/margins": 2.626899242401123,
      "rewards/rejected": -2.9182486534118652,
      "step": 4560
    },
    {
      "epoch": 0.26948309846724133,
      "grad_norm": 1.5538115501403809,
      "learning_rate": 4.551534765126998e-05,
      "logits/chosen": 3.935652256011963,
      "logits/rejected": 3.7203078269958496,
      "logps/chosen": -361.015380859375,
      "logps/rejected": -300.22906494140625,
      "loss": 0.465,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.3636208176612854,
      "rewards/margins": 2.2022268772125244,
      "rewards/rejected": -2.565847396850586,
      "step": 4580
    },
    {
      "epoch": 0.27065988055661794,
      "grad_norm": 1.7136598825454712,
      "learning_rate": 4.549573403942336e-05,
      "logits/chosen": 4.043416976928711,
      "logits/rejected": 3.9874885082244873,
      "logps/chosen": -395.5157470703125,
      "logps/rejected": -322.83233642578125,
      "loss": 0.489,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.07220068573951721,
      "rewards/margins": 2.3799655437469482,
      "rewards/rejected": -2.4521663188934326,
      "step": 4600
    },
    {
      "epoch": 0.27183666264599454,
      "grad_norm": 0.7680180072784424,
      "learning_rate": 4.547612042757674e-05,
      "logits/chosen": 3.667304515838623,
      "logits/rejected": 3.6738944053649902,
      "logps/chosen": -389.14892578125,
      "logps/rejected": -360.2791442871094,
      "loss": 0.4388,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.5568132996559143,
      "rewards/margins": 2.7634193897247314,
      "rewards/rejected": -3.32023286819458,
      "step": 4620
    },
    {
      "epoch": 0.27301344473537115,
      "grad_norm": 7.350926399230957,
      "learning_rate": 4.5456506815730124e-05,
      "logits/chosen": 3.9056758880615234,
      "logits/rejected": 3.7846240997314453,
      "logps/chosen": -368.29986572265625,
      "logps/rejected": -328.3833923339844,
      "loss": 0.612,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7833874821662903,
      "rewards/margins": 2.34627103805542,
      "rewards/rejected": -3.1296584606170654,
      "step": 4640
    },
    {
      "epoch": 0.27419022682474775,
      "grad_norm": 1.6049953699111938,
      "learning_rate": 4.543689320388349e-05,
      "logits/chosen": 3.4738972187042236,
      "logits/rejected": 3.507631301879883,
      "logps/chosen": -346.4712829589844,
      "logps/rejected": -265.1185607910156,
      "loss": 0.4623,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.4594552516937256,
      "rewards/margins": 2.4242260456085205,
      "rewards/rejected": -2.883680820465088,
      "step": 4660
    },
    {
      "epoch": 0.2753670089141243,
      "grad_norm": 0.7437319159507751,
      "learning_rate": 4.5417279592036876e-05,
      "logits/chosen": 3.595783233642578,
      "logits/rejected": 3.515763759613037,
      "logps/chosen": -362.82305908203125,
      "logps/rejected": -284.725341796875,
      "loss": 0.3502,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.11438135802745819,
      "rewards/margins": 2.5299606323242188,
      "rewards/rejected": -2.6443419456481934,
      "step": 4680
    },
    {
      "epoch": 0.2765437910035009,
      "grad_norm": 1.9823105335235596,
      "learning_rate": 4.539766598019025e-05,
      "logits/chosen": 3.8451385498046875,
      "logits/rejected": 3.824586868286133,
      "logps/chosen": -419.20599365234375,
      "logps/rejected": -349.30804443359375,
      "loss": 0.5627,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.28605905175209045,
      "rewards/margins": 2.2744736671447754,
      "rewards/rejected": -2.560532331466675,
      "step": 4700
    },
    {
      "epoch": 0.2777205730928775,
      "grad_norm": 0.8981407284736633,
      "learning_rate": 4.5378052368343635e-05,
      "logits/chosen": 4.125657081604004,
      "logits/rejected": 3.887185573577881,
      "logps/chosen": -411.32080078125,
      "logps/rejected": -276.3066711425781,
      "loss": 0.4333,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.01876882277429104,
      "rewards/margins": 2.73511004447937,
      "rewards/rejected": -2.7538790702819824,
      "step": 4720
    },
    {
      "epoch": 0.2788973551822541,
      "grad_norm": 1.1240659952163696,
      "learning_rate": 4.535843875649701e-05,
      "logits/chosen": 3.8259100914001465,
      "logits/rejected": 3.8165011405944824,
      "logps/chosen": -371.07525634765625,
      "logps/rejected": -313.9222717285156,
      "loss": 0.4723,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.03458500653505325,
      "rewards/margins": 2.0322301387786865,
      "rewards/rejected": -2.06681489944458,
      "step": 4740
    },
    {
      "epoch": 0.2800741372716307,
      "grad_norm": 0.29339954257011414,
      "learning_rate": 4.533882514465039e-05,
      "logits/chosen": 4.275204658508301,
      "logits/rejected": 4.211958885192871,
      "logps/chosen": -445.8816833496094,
      "logps/rejected": -350.8197326660156,
      "loss": 0.597,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.18898969888687134,
      "rewards/margins": 2.437711715698242,
      "rewards/rejected": -2.2487220764160156,
      "step": 4760
    },
    {
      "epoch": 0.2812509193610073,
      "grad_norm": 1.9004762172698975,
      "learning_rate": 4.531921153280377e-05,
      "logits/chosen": 4.053976058959961,
      "logits/rejected": 3.978041410446167,
      "logps/chosen": -353.45025634765625,
      "logps/rejected": -311.3339538574219,
      "loss": 0.4911,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.03819240257143974,
      "rewards/margins": 2.830242156982422,
      "rewards/rejected": -2.868434429168701,
      "step": 4780
    },
    {
      "epoch": 0.28242770145038393,
      "grad_norm": 1.591182827949524,
      "learning_rate": 4.5299597920957146e-05,
      "logits/chosen": 3.5070621967315674,
      "logits/rejected": 3.5940253734588623,
      "logps/chosen": -308.5200500488281,
      "logps/rejected": -296.73712158203125,
      "loss": 0.7133,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.701311469078064,
      "rewards/margins": 1.1055158376693726,
      "rewards/rejected": -1.8068273067474365,
      "step": 4800
    },
    {
      "epoch": 0.28360448353976053,
      "grad_norm": 0.7266954779624939,
      "learning_rate": 4.527998430911052e-05,
      "logits/chosen": 3.9400596618652344,
      "logits/rejected": 3.8423469066619873,
      "logps/chosen": -386.620361328125,
      "logps/rejected": -311.1239318847656,
      "loss": 0.4334,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0523807629942894,
      "rewards/margins": 2.7690436840057373,
      "rewards/rejected": -2.716662883758545,
      "step": 4820
    },
    {
      "epoch": 0.28478126562913714,
      "grad_norm": 0.9208925366401672,
      "learning_rate": 4.5260370697263904e-05,
      "logits/chosen": 3.7407710552215576,
      "logits/rejected": 3.698500871658325,
      "logps/chosen": -336.495849609375,
      "logps/rejected": -286.75225830078125,
      "loss": 0.5103,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6532922387123108,
      "rewards/margins": 1.8857784271240234,
      "rewards/rejected": -2.5390706062316895,
      "step": 4840
    },
    {
      "epoch": 0.28595804771851374,
      "grad_norm": 5.283653259277344,
      "learning_rate": 4.524075708541728e-05,
      "logits/chosen": 3.3800721168518066,
      "logits/rejected": 3.4719607830047607,
      "logps/chosen": -348.7921447753906,
      "logps/rejected": -277.6793518066406,
      "loss": 0.8267,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.18589012324810028,
      "rewards/margins": 0.9527108073234558,
      "rewards/rejected": -1.1386009454727173,
      "step": 4860
    },
    {
      "epoch": 0.28713482980789035,
      "grad_norm": 4.304108619689941,
      "learning_rate": 4.5221143473570656e-05,
      "logits/chosen": 3.963017702102661,
      "logits/rejected": 3.9131808280944824,
      "logps/chosen": -334.782958984375,
      "logps/rejected": -292.7922058105469,
      "loss": 0.44,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5179252624511719,
      "rewards/margins": 1.9355205297470093,
      "rewards/rejected": -2.45344614982605,
      "step": 4880
    },
    {
      "epoch": 0.28831161189726695,
      "grad_norm": 2.002436876296997,
      "learning_rate": 4.520152986172404e-05,
      "logits/chosen": 3.836770534515381,
      "logits/rejected": 3.7962913513183594,
      "logps/chosen": -368.6269836425781,
      "logps/rejected": -318.0236511230469,
      "loss": 0.5523,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.27479833364486694,
      "rewards/margins": 1.7433738708496094,
      "rewards/rejected": -2.018172025680542,
      "step": 4900
    },
    {
      "epoch": 0.2894883939866435,
      "grad_norm": 2.7627904415130615,
      "learning_rate": 4.5181916249877415e-05,
      "logits/chosen": 3.8395698070526123,
      "logits/rejected": 3.870361804962158,
      "logps/chosen": -344.26007080078125,
      "logps/rejected": -297.4288635253906,
      "loss": 0.5896,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.2975647449493408,
      "rewards/margins": 1.6813485622406006,
      "rewards/rejected": -1.9789135456085205,
      "step": 4920
    },
    {
      "epoch": 0.2906651760760201,
      "grad_norm": 3.1448476314544678,
      "learning_rate": 4.51623026380308e-05,
      "logits/chosen": 3.8777244091033936,
      "logits/rejected": 3.831697940826416,
      "logps/chosen": -419.09228515625,
      "logps/rejected": -270.1283874511719,
      "loss": 0.6024,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.6315062642097473,
      "rewards/margins": 2.4940083026885986,
      "rewards/rejected": -1.8625023365020752,
      "step": 4940
    },
    {
      "epoch": 0.2918419581653967,
      "grad_norm": 6.085812091827393,
      "learning_rate": 4.5142689026184174e-05,
      "logits/chosen": 3.968348264694214,
      "logits/rejected": 4.002958297729492,
      "logps/chosen": -355.7444763183594,
      "logps/rejected": -311.9701843261719,
      "loss": 0.5774,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6529649496078491,
      "rewards/margins": 1.344003677368164,
      "rewards/rejected": -1.9969686269760132,
      "step": 4960
    },
    {
      "epoch": 0.2930187402547733,
      "grad_norm": 1.2461680173873901,
      "learning_rate": 4.512307541433755e-05,
      "logits/chosen": 4.285794258117676,
      "logits/rejected": 4.184774398803711,
      "logps/chosen": -414.9651794433594,
      "logps/rejected": -321.74029541015625,
      "loss": 0.5451,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.20555345714092255,
      "rewards/margins": 2.2463366985321045,
      "rewards/rejected": -2.040783405303955,
      "step": 4980
    },
    {
      "epoch": 0.2941955223441499,
      "grad_norm": 1.4473812580108643,
      "learning_rate": 4.510346180249093e-05,
      "logits/chosen": 3.933858871459961,
      "logits/rejected": 3.8295905590057373,
      "logps/chosen": -342.867431640625,
      "logps/rejected": -295.9610290527344,
      "loss": 0.5219,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.634492039680481,
      "rewards/margins": 1.5870070457458496,
      "rewards/rejected": -2.221498966217041,
      "step": 5000
    },
    {
      "epoch": 0.2941955223441499,
      "eval_logits/chosen": 3.4395954608917236,
      "eval_logits/rejected": 3.453139305114746,
      "eval_logps/chosen": -364.1418151855469,
      "eval_logps/rejected": -324.09161376953125,
      "eval_loss": 0.520565927028656,
      "eval_rewards/accuracies": 0.7580529451370239,
      "eval_rewards/chosen": -0.9561174511909485,
      "eval_rewards/margins": 1.8297263383865356,
      "eval_rewards/rejected": -2.785843849182129,
      "eval_runtime": 3547.3585,
      "eval_samples_per_second": 3.151,
      "eval_steps_per_second": 3.151,
      "step": 5000
    },
    {
      "epoch": 0.2953723044335265,
      "grad_norm": 2.4880294799804688,
      "learning_rate": 4.508384819064431e-05,
      "logits/chosen": 3.791093349456787,
      "logits/rejected": 3.7678818702697754,
      "logps/chosen": -368.6669616699219,
      "logps/rejected": -322.44354248046875,
      "loss": 0.276,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.2998022735118866,
      "rewards/margins": 3.001532793045044,
      "rewards/rejected": -3.301335096359253,
      "step": 5020
    },
    {
      "epoch": 0.2965490865229031,
      "grad_norm": 1.188387393951416,
      "learning_rate": 4.5064234578797685e-05,
      "logits/chosen": 3.6626791954040527,
      "logits/rejected": 3.6338272094726562,
      "logps/chosen": -380.8639221191406,
      "logps/rejected": -333.67193603515625,
      "loss": 0.4753,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5812358856201172,
      "rewards/margins": 2.079810380935669,
      "rewards/rejected": -2.6610465049743652,
      "step": 5040
    },
    {
      "epoch": 0.29772586861227973,
      "grad_norm": 2.4926111698150635,
      "learning_rate": 4.504462096695107e-05,
      "logits/chosen": 3.616425037384033,
      "logits/rejected": 3.590660810470581,
      "logps/chosen": -373.04718017578125,
      "logps/rejected": -309.9325866699219,
      "loss": 0.5787,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8774175643920898,
      "rewards/margins": 2.2430970668792725,
      "rewards/rejected": -3.1205148696899414,
      "step": 5060
    },
    {
      "epoch": 0.29890265070165634,
      "grad_norm": 1.5216400623321533,
      "learning_rate": 4.5025007355104444e-05,
      "logits/chosen": 3.9083092212677,
      "logits/rejected": 3.978524684906006,
      "logps/chosen": -380.31915283203125,
      "logps/rejected": -373.9271545410156,
      "loss": 0.4573,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.41057783365249634,
      "rewards/margins": 2.5588738918304443,
      "rewards/rejected": -2.969451665878296,
      "step": 5080
    },
    {
      "epoch": 0.30007943279103294,
      "grad_norm": 1.2466539144515991,
      "learning_rate": 4.500539374325782e-05,
      "logits/chosen": 3.6344566345214844,
      "logits/rejected": 3.7075467109680176,
      "logps/chosen": -401.4488525390625,
      "logps/rejected": -301.2823181152344,
      "loss": 0.5164,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6157650351524353,
      "rewards/margins": 2.09724760055542,
      "rewards/rejected": -2.713012933731079,
      "step": 5100
    },
    {
      "epoch": 0.30125621488040955,
      "grad_norm": 1.171763300895691,
      "learning_rate": 4.49857801314112e-05,
      "logits/chosen": 3.8099656105041504,
      "logits/rejected": 3.6917622089385986,
      "logps/chosen": -377.4117736816406,
      "logps/rejected": -310.7364501953125,
      "loss": 0.5993,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7370834946632385,
      "rewards/margins": 2.205932140350342,
      "rewards/rejected": -2.9430155754089355,
      "step": 5120
    },
    {
      "epoch": 0.3024329969697861,
      "grad_norm": 0.759533166885376,
      "learning_rate": 4.496616651956458e-05,
      "logits/chosen": 3.7394347190856934,
      "logits/rejected": 3.8469581604003906,
      "logps/chosen": -404.04498291015625,
      "logps/rejected": -343.3771667480469,
      "loss": 0.5578,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6915034651756287,
      "rewards/margins": 1.9739633798599243,
      "rewards/rejected": -2.665466785430908,
      "step": 5140
    },
    {
      "epoch": 0.3036097790591627,
      "grad_norm": 0.5452690720558167,
      "learning_rate": 4.494655290771796e-05,
      "logits/chosen": 4.127898216247559,
      "logits/rejected": 4.0437774658203125,
      "logps/chosen": -377.0535888671875,
      "logps/rejected": -296.24365234375,
      "loss": 0.4962,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7992690801620483,
      "rewards/margins": 1.9137897491455078,
      "rewards/rejected": -2.7130589485168457,
      "step": 5160
    },
    {
      "epoch": 0.3047865611485393,
      "grad_norm": 1.8620060682296753,
      "learning_rate": 4.492693929587133e-05,
      "logits/chosen": 3.6631553173065186,
      "logits/rejected": 3.562699794769287,
      "logps/chosen": -374.7733459472656,
      "logps/rejected": -304.59124755859375,
      "loss": 0.6742,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0014535188674927,
      "rewards/margins": 1.447435975074768,
      "rewards/rejected": -2.4488894939422607,
      "step": 5180
    },
    {
      "epoch": 0.3059633432379159,
      "grad_norm": 1.306377649307251,
      "learning_rate": 4.4907325684024714e-05,
      "logits/chosen": 4.008425712585449,
      "logits/rejected": 3.937279224395752,
      "logps/chosen": -370.693115234375,
      "logps/rejected": -248.7536163330078,
      "loss": 0.3991,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.6313813924789429,
      "rewards/margins": 2.130983352661133,
      "rewards/rejected": -2.7623648643493652,
      "step": 5200
    },
    {
      "epoch": 0.3071401253272925,
      "grad_norm": 0.6295668482780457,
      "learning_rate": 4.4887712072178097e-05,
      "logits/chosen": 3.9660897254943848,
      "logits/rejected": 3.806278944015503,
      "logps/chosen": -390.70770263671875,
      "logps/rejected": -268.34222412109375,
      "loss": 0.3575,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": 0.2732008099555969,
      "rewards/margins": 2.3905186653137207,
      "rewards/rejected": -2.1173181533813477,
      "step": 5220
    },
    {
      "epoch": 0.3083169074166691,
      "grad_norm": 5.845119476318359,
      "learning_rate": 4.486809846033147e-05,
      "logits/chosen": 4.069488525390625,
      "logits/rejected": 3.9888687133789062,
      "logps/chosen": -362.2344970703125,
      "logps/rejected": -310.30047607421875,
      "loss": 0.7525,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.28989481925964355,
      "rewards/margins": 1.5250910520553589,
      "rewards/rejected": -1.814985990524292,
      "step": 5240
    },
    {
      "epoch": 0.3094936895060457,
      "grad_norm": 1.865014672279358,
      "learning_rate": 4.484848484848485e-05,
      "logits/chosen": 3.8895785808563232,
      "logits/rejected": 3.7393417358398438,
      "logps/chosen": -361.1651306152344,
      "logps/rejected": -271.2442321777344,
      "loss": 0.4419,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.12827381491661072,
      "rewards/margins": 2.1298859119415283,
      "rewards/rejected": -2.0016121864318848,
      "step": 5260
    },
    {
      "epoch": 0.3106704715954223,
      "grad_norm": 2.60064959526062,
      "learning_rate": 4.482887123663823e-05,
      "logits/chosen": 3.8746399879455566,
      "logits/rejected": 3.8889057636260986,
      "logps/chosen": -359.05804443359375,
      "logps/rejected": -291.7168884277344,
      "loss": 0.5981,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7025303840637207,
      "rewards/margins": 1.6195061206817627,
      "rewards/rejected": -2.3220362663269043,
      "step": 5280
    },
    {
      "epoch": 0.31184725368479893,
      "grad_norm": 2.9131088256835938,
      "learning_rate": 4.480925762479161e-05,
      "logits/chosen": 3.8423056602478027,
      "logits/rejected": 3.7947704792022705,
      "logps/chosen": -330.68218994140625,
      "logps/rejected": -279.22174072265625,
      "loss": 0.633,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.39788737893104553,
      "rewards/margins": 1.8612935543060303,
      "rewards/rejected": -2.259181261062622,
      "step": 5300
    },
    {
      "epoch": 0.31302403577417554,
      "grad_norm": 1.69281804561615,
      "learning_rate": 4.4789644012944984e-05,
      "logits/chosen": 3.96211314201355,
      "logits/rejected": 3.91546368598938,
      "logps/chosen": -368.55291748046875,
      "logps/rejected": -340.9021301269531,
      "loss": 0.5692,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.37419095635414124,
      "rewards/margins": 1.5473474264144897,
      "rewards/rejected": -1.9215385913848877,
      "step": 5320
    },
    {
      "epoch": 0.31420081786355214,
      "grad_norm": 1.3102837800979614,
      "learning_rate": 4.477003040109836e-05,
      "logits/chosen": 4.266538619995117,
      "logits/rejected": 4.1817169189453125,
      "logps/chosen": -367.34088134765625,
      "logps/rejected": -303.7972106933594,
      "loss": 0.4737,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.4504873752593994,
      "rewards/margins": 2.2177839279174805,
      "rewards/rejected": -2.66827130317688,
      "step": 5340
    },
    {
      "epoch": 0.3153775999529287,
      "grad_norm": 2.781527280807495,
      "learning_rate": 4.475041678925174e-05,
      "logits/chosen": 3.5813076496124268,
      "logits/rejected": 3.4707229137420654,
      "logps/chosen": -316.8355407714844,
      "logps/rejected": -260.20611572265625,
      "loss": 0.4079,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8100000619888306,
      "rewards/margins": 2.0756735801696777,
      "rewards/rejected": -2.8856735229492188,
      "step": 5360
    },
    {
      "epoch": 0.3165543820423053,
      "grad_norm": 2.2813937664031982,
      "learning_rate": 4.4730803177405125e-05,
      "logits/chosen": 3.705429792404175,
      "logits/rejected": 3.638617753982544,
      "logps/chosen": -328.9134826660156,
      "logps/rejected": -315.3653869628906,
      "loss": 0.5355,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.095696210861206,
      "rewards/margins": 1.9420267343521118,
      "rewards/rejected": -3.0377230644226074,
      "step": 5380
    },
    {
      "epoch": 0.3177311641316819,
      "grad_norm": 1.1846308708190918,
      "learning_rate": 4.4711189565558494e-05,
      "logits/chosen": 3.5994479656219482,
      "logits/rejected": 3.7600197792053223,
      "logps/chosen": -358.9570007324219,
      "logps/rejected": -292.067138671875,
      "loss": 0.6148,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0827088356018066,
      "rewards/margins": 1.6070293188095093,
      "rewards/rejected": -2.6897380352020264,
      "step": 5400
    },
    {
      "epoch": 0.3189079462210585,
      "grad_norm": 0.4293053150177002,
      "learning_rate": 4.469157595371188e-05,
      "logits/chosen": 3.8295845985412598,
      "logits/rejected": 3.7220776081085205,
      "logps/chosen": -393.17742919921875,
      "logps/rejected": -312.98333740234375,
      "loss": 0.7247,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.20734138786792755,
      "rewards/margins": 2.5679306983947754,
      "rewards/rejected": -2.3605892658233643,
      "step": 5420
    },
    {
      "epoch": 0.3200847283104351,
      "grad_norm": 3.7908432483673096,
      "learning_rate": 4.467196234186526e-05,
      "logits/chosen": 3.6393065452575684,
      "logits/rejected": 3.627856492996216,
      "logps/chosen": -420.3727111816406,
      "logps/rejected": -323.2429504394531,
      "loss": 0.58,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.1798001378774643,
      "rewards/margins": 1.7697088718414307,
      "rewards/rejected": -1.9495089054107666,
      "step": 5440
    },
    {
      "epoch": 0.3212615103998117,
      "grad_norm": 10.451855659484863,
      "learning_rate": 4.4652348730018636e-05,
      "logits/chosen": 3.8152241706848145,
      "logits/rejected": 3.8065669536590576,
      "logps/chosen": -359.3902893066406,
      "logps/rejected": -303.4555969238281,
      "loss": 0.5369,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6679446697235107,
      "rewards/margins": 1.822270154953003,
      "rewards/rejected": -2.4902148246765137,
      "step": 5460
    },
    {
      "epoch": 0.3224382924891883,
      "grad_norm": 1.1000409126281738,
      "learning_rate": 4.463273511817201e-05,
      "logits/chosen": 3.630199909210205,
      "logits/rejected": 3.718447208404541,
      "logps/chosen": -371.11151123046875,
      "logps/rejected": -291.827392578125,
      "loss": 0.4589,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9902308583259583,
      "rewards/margins": 2.0721232891082764,
      "rewards/rejected": -3.062354326248169,
      "step": 5480
    },
    {
      "epoch": 0.3236150745785649,
      "grad_norm": 2.8998303413391113,
      "learning_rate": 4.461312150632539e-05,
      "logits/chosen": 4.040562629699707,
      "logits/rejected": 4.073617458343506,
      "logps/chosen": -425.85009765625,
      "logps/rejected": -343.02947998046875,
      "loss": 0.6386,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9694474339485168,
      "rewards/margins": 1.906333565711975,
      "rewards/rejected": -2.8757808208465576,
      "step": 5500
    },
    {
      "epoch": 0.3247918566679415,
      "grad_norm": 3.7025325298309326,
      "learning_rate": 4.459350789447877e-05,
      "logits/chosen": 3.8885645866394043,
      "logits/rejected": 3.8072447776794434,
      "logps/chosen": -346.9313049316406,
      "logps/rejected": -298.52337646484375,
      "loss": 0.4706,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6290275454521179,
      "rewards/margins": 1.9395815134048462,
      "rewards/rejected": -2.5686089992523193,
      "step": 5520
    },
    {
      "epoch": 0.32596863875731813,
      "grad_norm": 0.664478063583374,
      "learning_rate": 4.457389428263215e-05,
      "logits/chosen": 3.9312591552734375,
      "logits/rejected": 3.8978142738342285,
      "logps/chosen": -405.65692138671875,
      "logps/rejected": -288.9471130371094,
      "loss": 0.4211,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.08906112611293793,
      "rewards/margins": 2.4771974086761475,
      "rewards/rejected": -2.388136386871338,
      "step": 5540
    },
    {
      "epoch": 0.32714542084669473,
      "grad_norm": 3.158036231994629,
      "learning_rate": 4.455428067078552e-05,
      "logits/chosen": 3.715132474899292,
      "logits/rejected": 3.680227756500244,
      "logps/chosen": -412.6014099121094,
      "logps/rejected": -323.0578918457031,
      "loss": 0.7313,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.2769163250923157,
      "rewards/margins": 1.5777570009231567,
      "rewards/rejected": -1.854673147201538,
      "step": 5560
    },
    {
      "epoch": 0.32832220293607134,
      "grad_norm": 1.7634153366088867,
      "learning_rate": 4.4534667058938906e-05,
      "logits/chosen": 4.228349685668945,
      "logits/rejected": 4.173091411590576,
      "logps/chosen": -409.2328186035156,
      "logps/rejected": -314.27471923828125,
      "loss": 0.3942,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.3566462993621826,
      "rewards/margins": 1.9577429294586182,
      "rewards/rejected": -2.31438946723938,
      "step": 5580
    },
    {
      "epoch": 0.3294989850254479,
      "grad_norm": 1.3821561336517334,
      "learning_rate": 4.451505344709229e-05,
      "logits/chosen": 4.228193759918213,
      "logits/rejected": 4.150616645812988,
      "logps/chosen": -383.2174987792969,
      "logps/rejected": -352.0435485839844,
      "loss": 0.544,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.8940447568893433,
      "rewards/margins": 1.6818244457244873,
      "rewards/rejected": -2.575869083404541,
      "step": 5600
    },
    {
      "epoch": 0.3306757671148245,
      "grad_norm": 1.7639061212539673,
      "learning_rate": 4.449543983524566e-05,
      "logits/chosen": 3.8591713905334473,
      "logits/rejected": 3.8292572498321533,
      "logps/chosen": -365.5003356933594,
      "logps/rejected": -286.65167236328125,
      "loss": 0.624,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.5124713182449341,
      "rewards/margins": 1.4222654104232788,
      "rewards/rejected": -1.9347368478775024,
      "step": 5620
    },
    {
      "epoch": 0.3318525492042011,
      "grad_norm": 3.1119863986968994,
      "learning_rate": 4.447582622339904e-05,
      "logits/chosen": 4.0420427322387695,
      "logits/rejected": 3.940218448638916,
      "logps/chosen": -376.29498291015625,
      "logps/rejected": -288.0831298828125,
      "loss": 0.5309,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.6711453795433044,
      "rewards/margins": 1.4210107326507568,
      "rewards/rejected": -2.092156171798706,
      "step": 5640
    },
    {
      "epoch": 0.3330293312935777,
      "grad_norm": 0.3605206608772278,
      "learning_rate": 4.445621261155242e-05,
      "logits/chosen": 3.7216262817382812,
      "logits/rejected": 3.856653928756714,
      "logps/chosen": -386.3352966308594,
      "logps/rejected": -328.7687072753906,
      "loss": 0.5281,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7531664967536926,
      "rewards/margins": 1.6401078701019287,
      "rewards/rejected": -2.3932743072509766,
      "step": 5660
    },
    {
      "epoch": 0.3342061133829543,
      "grad_norm": 1.7343690395355225,
      "learning_rate": 4.44365989997058e-05,
      "logits/chosen": 3.4930691719055176,
      "logits/rejected": 3.5833563804626465,
      "logps/chosen": -343.5676574707031,
      "logps/rejected": -310.730224609375,
      "loss": 0.6183,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.6706128120422363,
      "rewards/margins": 1.379608392715454,
      "rewards/rejected": -2.0502212047576904,
      "step": 5680
    },
    {
      "epoch": 0.3353828954723309,
      "grad_norm": 1.9195009469985962,
      "learning_rate": 4.4416985387859176e-05,
      "logits/chosen": 3.9290153980255127,
      "logits/rejected": 3.8733458518981934,
      "logps/chosen": -403.0855407714844,
      "logps/rejected": -310.6180114746094,
      "loss": 0.5223,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.48244166374206543,
      "rewards/margins": 2.3526134490966797,
      "rewards/rejected": -2.835055112838745,
      "step": 5700
    },
    {
      "epoch": 0.3365596775617075,
      "grad_norm": 0.6276792883872986,
      "learning_rate": 4.439737177601255e-05,
      "logits/chosen": 3.8955795764923096,
      "logits/rejected": 3.9943840503692627,
      "logps/chosen": -367.95697021484375,
      "logps/rejected": -319.0234680175781,
      "loss": 0.4075,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6101840734481812,
      "rewards/margins": 1.8257629871368408,
      "rewards/rejected": -2.4359469413757324,
      "step": 5720
    },
    {
      "epoch": 0.3377364596510841,
      "grad_norm": 2.283914566040039,
      "learning_rate": 4.4377758164165935e-05,
      "logits/chosen": 3.768125534057617,
      "logits/rejected": 3.87192964553833,
      "logps/chosen": -400.26824951171875,
      "logps/rejected": -310.28155517578125,
      "loss": 0.3105,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.04807731509208679,
      "rewards/margins": 2.585082530975342,
      "rewards/rejected": -2.633159637451172,
      "step": 5740
    },
    {
      "epoch": 0.3389132417404607,
      "grad_norm": 0.40602999925613403,
      "learning_rate": 4.435814455231931e-05,
      "logits/chosen": 3.8790862560272217,
      "logits/rejected": 3.9202969074249268,
      "logps/chosen": -392.3023681640625,
      "logps/rejected": -273.08746337890625,
      "loss": 0.3971,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.27050215005874634,
      "rewards/margins": 2.3778772354125977,
      "rewards/rejected": -2.6483795642852783,
      "step": 5760
    },
    {
      "epoch": 0.34009002382983733,
      "grad_norm": 3.4202561378479004,
      "learning_rate": 4.433853094047269e-05,
      "logits/chosen": 3.9906017780303955,
      "logits/rejected": 3.981217622756958,
      "logps/chosen": -364.87762451171875,
      "logps/rejected": -325.6111755371094,
      "loss": 0.5784,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.32689517736434937,
      "rewards/margins": 1.7115259170532227,
      "rewards/rejected": -2.038421154022217,
      "step": 5780
    },
    {
      "epoch": 0.34126680591921393,
      "grad_norm": 2.8818392753601074,
      "learning_rate": 4.431891732862607e-05,
      "logits/chosen": 3.682757616043091,
      "logits/rejected": 3.768362522125244,
      "logps/chosen": -369.08978271484375,
      "logps/rejected": -307.53033447265625,
      "loss": 0.4363,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.25357168912887573,
      "rewards/margins": 2.39662504196167,
      "rewards/rejected": -2.6501965522766113,
      "step": 5800
    },
    {
      "epoch": 0.3424435880085905,
      "grad_norm": 4.244569778442383,
      "learning_rate": 4.4299303716779446e-05,
      "logits/chosen": 3.751075029373169,
      "logits/rejected": 3.8176651000976562,
      "logps/chosen": -390.7714538574219,
      "logps/rejected": -350.02972412109375,
      "loss": 0.5159,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.3282216191291809,
      "rewards/margins": 2.204319715499878,
      "rewards/rejected": -2.532541275024414,
      "step": 5820
    },
    {
      "epoch": 0.3436203700979671,
      "grad_norm": 1.8751088380813599,
      "learning_rate": 4.427969010493283e-05,
      "logits/chosen": 3.8929362297058105,
      "logits/rejected": 3.831075668334961,
      "logps/chosen": -380.0155029296875,
      "logps/rejected": -289.40643310546875,
      "loss": 0.4115,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.4257870316505432,
      "rewards/margins": 2.4999401569366455,
      "rewards/rejected": -2.925727367401123,
      "step": 5840
    },
    {
      "epoch": 0.3447971521873437,
      "grad_norm": 2.382357358932495,
      "learning_rate": 4.4260076493086204e-05,
      "logits/chosen": 3.5967609882354736,
      "logits/rejected": 3.726151943206787,
      "logps/chosen": -337.35345458984375,
      "logps/rejected": -315.9678649902344,
      "loss": 0.4514,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.959058403968811,
      "rewards/margins": 2.232126474380493,
      "rewards/rejected": -3.1911847591400146,
      "step": 5860
    },
    {
      "epoch": 0.3459739342767203,
      "grad_norm": 3.5229411125183105,
      "learning_rate": 4.424046288123958e-05,
      "logits/chosen": 4.0231218338012695,
      "logits/rejected": 4.022984504699707,
      "logps/chosen": -397.84027099609375,
      "logps/rejected": -333.5237121582031,
      "loss": 0.5024,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8638870120048523,
      "rewards/margins": 2.060014009475708,
      "rewards/rejected": -2.923901319503784,
      "step": 5880
    },
    {
      "epoch": 0.3471507163660969,
      "grad_norm": 3.3867063522338867,
      "learning_rate": 4.422084926939296e-05,
      "logits/chosen": 3.630204439163208,
      "logits/rejected": 3.7219722270965576,
      "logps/chosen": -353.5252380371094,
      "logps/rejected": -305.9286193847656,
      "loss": 0.4842,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7660120725631714,
      "rewards/margins": 1.9813029766082764,
      "rewards/rejected": -2.7473151683807373,
      "step": 5900
    },
    {
      "epoch": 0.3483274984554735,
      "grad_norm": 12.77614688873291,
      "learning_rate": 4.420123565754634e-05,
      "logits/chosen": 3.6437199115753174,
      "logits/rejected": 3.7636146545410156,
      "logps/chosen": -346.77410888671875,
      "logps/rejected": -287.9988708496094,
      "loss": 0.5278,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6796813011169434,
      "rewards/margins": 2.0988268852233887,
      "rewards/rejected": -2.778508186340332,
      "step": 5920
    },
    {
      "epoch": 0.3495042805448501,
      "grad_norm": 0.9629377722740173,
      "learning_rate": 4.4181622045699715e-05,
      "logits/chosen": 3.8727505207061768,
      "logits/rejected": 3.8130478858947754,
      "logps/chosen": -372.2995910644531,
      "logps/rejected": -285.457275390625,
      "loss": 0.5852,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.9020236134529114,
      "rewards/margins": 1.7094876766204834,
      "rewards/rejected": -2.61151123046875,
      "step": 5940
    },
    {
      "epoch": 0.3506810626342267,
      "grad_norm": 1.1320704221725464,
      "learning_rate": 4.41620084338531e-05,
      "logits/chosen": 3.7233047485351562,
      "logits/rejected": 3.7034149169921875,
      "logps/chosen": -368.1529541015625,
      "logps/rejected": -265.4613342285156,
      "loss": 0.4078,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8032075762748718,
      "rewards/margins": 2.037928581237793,
      "rewards/rejected": -2.8411364555358887,
      "step": 5960
    },
    {
      "epoch": 0.3518578447236033,
      "grad_norm": 0.40536001324653625,
      "learning_rate": 4.4142394822006474e-05,
      "logits/chosen": 3.5598015785217285,
      "logits/rejected": 3.7828516960144043,
      "logps/chosen": -394.0317687988281,
      "logps/rejected": -296.167236328125,
      "loss": 0.4859,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.665027379989624,
      "rewards/margins": 1.8355003595352173,
      "rewards/rejected": -2.500527858734131,
      "step": 5980
    },
    {
      "epoch": 0.3530346268129799,
      "grad_norm": 1.5275994539260864,
      "learning_rate": 4.412278121015985e-05,
      "logits/chosen": 3.6023387908935547,
      "logits/rejected": 3.6784279346466064,
      "logps/chosen": -329.4845886230469,
      "logps/rejected": -279.8588562011719,
      "loss": 0.5106,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.687403678894043,
      "rewards/margins": 1.5175325870513916,
      "rewards/rejected": -2.2049362659454346,
      "step": 6000
    },
    {
      "epoch": 0.35421140890235653,
      "grad_norm": 2.8855979442596436,
      "learning_rate": 4.410316759831323e-05,
      "logits/chosen": 3.909217119216919,
      "logits/rejected": 3.8459229469299316,
      "logps/chosen": -393.6022644042969,
      "logps/rejected": -303.927490234375,
      "loss": 0.3953,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.05947868898510933,
      "rewards/margins": 2.2622056007385254,
      "rewards/rejected": -2.2027270793914795,
      "step": 6020
    },
    {
      "epoch": 0.35538819099173313,
      "grad_norm": 1.1258240938186646,
      "learning_rate": 4.408355398646661e-05,
      "logits/chosen": 3.997410535812378,
      "logits/rejected": 3.9100117683410645,
      "logps/chosen": -420.5667419433594,
      "logps/rejected": -349.56634521484375,
      "loss": 0.5562,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.4741913378238678,
      "rewards/margins": 2.502624034881592,
      "rewards/rejected": -2.976815700531006,
      "step": 6040
    },
    {
      "epoch": 0.3565649730811097,
      "grad_norm": 1.663320779800415,
      "learning_rate": 4.406394037461999e-05,
      "logits/chosen": 4.094570159912109,
      "logits/rejected": 3.951288938522339,
      "logps/chosen": -445.20184326171875,
      "logps/rejected": -302.0513610839844,
      "loss": 0.3718,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.6506838202476501,
      "rewards/margins": 2.384791851043701,
      "rewards/rejected": -3.035475969314575,
      "step": 6060
    },
    {
      "epoch": 0.3577417551704863,
      "grad_norm": 3.1803104877471924,
      "learning_rate": 4.404432676277337e-05,
      "logits/chosen": 3.7485013008117676,
      "logits/rejected": 3.8065738677978516,
      "logps/chosen": -375.9324645996094,
      "logps/rejected": -320.9659729003906,
      "loss": 0.5392,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7004510164260864,
      "rewards/margins": 1.9814459085464478,
      "rewards/rejected": -2.681896924972534,
      "step": 6080
    },
    {
      "epoch": 0.3589185372598629,
      "grad_norm": 1.6765685081481934,
      "learning_rate": 4.4024713150926744e-05,
      "logits/chosen": 3.7170443534851074,
      "logits/rejected": 3.872382402420044,
      "logps/chosen": -343.1884460449219,
      "logps/rejected": -292.92645263671875,
      "loss": 0.5513,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9366350173950195,
      "rewards/margins": 1.6341499090194702,
      "rewards/rejected": -2.5707850456237793,
      "step": 6100
    },
    {
      "epoch": 0.3600953193492395,
      "grad_norm": 2.266915798187256,
      "learning_rate": 4.400509953908013e-05,
      "logits/chosen": 3.4445090293884277,
      "logits/rejected": 3.4831290245056152,
      "logps/chosen": -403.72900390625,
      "logps/rejected": -316.2178649902344,
      "loss": 0.4662,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.6023406386375427,
      "rewards/margins": 2.6117584705352783,
      "rewards/rejected": -3.214099168777466,
      "step": 6120
    },
    {
      "epoch": 0.3612721014386161,
      "grad_norm": 0.7436463832855225,
      "learning_rate": 4.39854859272335e-05,
      "logits/chosen": 4.176050186157227,
      "logits/rejected": 4.0215983390808105,
      "logps/chosen": -399.01751708984375,
      "logps/rejected": -319.30206298828125,
      "loss": 0.3905,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.7382370233535767,
      "rewards/margins": 2.235842227935791,
      "rewards/rejected": -2.9740796089172363,
      "step": 6140
    },
    {
      "epoch": 0.3624488835279927,
      "grad_norm": 1.2385222911834717,
      "learning_rate": 4.396587231538688e-05,
      "logits/chosen": 4.113757610321045,
      "logits/rejected": 4.108339786529541,
      "logps/chosen": -438.6981506347656,
      "logps/rejected": -349.12359619140625,
      "loss": 0.4861,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1122825145721436,
      "rewards/margins": 2.189730405807495,
      "rewards/rejected": -3.3020129203796387,
      "step": 6160
    },
    {
      "epoch": 0.3636256656173693,
      "grad_norm": 1.9404209852218628,
      "learning_rate": 4.394625870354026e-05,
      "logits/chosen": 3.7006912231445312,
      "logits/rejected": 3.7130210399627686,
      "logps/chosen": -335.4095153808594,
      "logps/rejected": -250.0302734375,
      "loss": 0.5404,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.8513866662979126,
      "rewards/margins": 1.653874158859253,
      "rewards/rejected": -2.505260944366455,
      "step": 6180
    },
    {
      "epoch": 0.3648024477067459,
      "grad_norm": 1.0004856586456299,
      "learning_rate": 4.392664509169364e-05,
      "logits/chosen": 3.8553872108459473,
      "logits/rejected": 3.8790650367736816,
      "logps/chosen": -403.2759704589844,
      "logps/rejected": -345.6244201660156,
      "loss": 0.5204,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5661803483963013,
      "rewards/margins": 2.1013550758361816,
      "rewards/rejected": -2.6675353050231934,
      "step": 6200
    },
    {
      "epoch": 0.3659792297961225,
      "grad_norm": 2.482213020324707,
      "learning_rate": 4.3907031479847014e-05,
      "logits/chosen": 3.687382936477661,
      "logits/rejected": 3.8936798572540283,
      "logps/chosen": -335.4395751953125,
      "logps/rejected": -353.49713134765625,
      "loss": 0.708,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.9991250038146973,
      "rewards/margins": 1.6515051126480103,
      "rewards/rejected": -2.650630474090576,
      "step": 6220
    },
    {
      "epoch": 0.3671560118854991,
      "grad_norm": 2.8875131607055664,
      "learning_rate": 4.3887417868000397e-05,
      "logits/chosen": 3.732907772064209,
      "logits/rejected": 3.7239480018615723,
      "logps/chosen": -341.00299072265625,
      "logps/rejected": -296.73223876953125,
      "loss": 0.4542,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.4487374424934387,
      "rewards/margins": 2.0891194343566895,
      "rewards/rejected": -2.5378565788269043,
      "step": 6240
    },
    {
      "epoch": 0.3683327939748757,
      "grad_norm": 3.871368646621704,
      "learning_rate": 4.386780425615377e-05,
      "logits/chosen": 4.258243560791016,
      "logits/rejected": 4.147256374359131,
      "logps/chosen": -412.920654296875,
      "logps/rejected": -341.5549011230469,
      "loss": 0.4642,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9190303683280945,
      "rewards/margins": 2.4137139320373535,
      "rewards/rejected": -3.332744598388672,
      "step": 6260
    },
    {
      "epoch": 0.3695095760642523,
      "grad_norm": 1.321394681930542,
      "learning_rate": 4.3848190644307155e-05,
      "logits/chosen": 3.5896668434143066,
      "logits/rejected": 3.5816168785095215,
      "logps/chosen": -350.58984375,
      "logps/rejected": -305.56024169921875,
      "loss": 0.5526,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1496691703796387,
      "rewards/margins": 1.738159418106079,
      "rewards/rejected": -2.8878283500671387,
      "step": 6280
    },
    {
      "epoch": 0.3706863581536289,
      "grad_norm": 2.161771297454834,
      "learning_rate": 4.3828577032460525e-05,
      "logits/chosen": 3.888599395751953,
      "logits/rejected": 3.876636505126953,
      "logps/chosen": -364.1529541015625,
      "logps/rejected": -308.49847412109375,
      "loss": 0.4379,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.282486915588379,
      "rewards/margins": 1.900568962097168,
      "rewards/rejected": -3.183055877685547,
      "step": 6300
    },
    {
      "epoch": 0.3718631402430055,
      "grad_norm": 2.514068841934204,
      "learning_rate": 4.380896342061391e-05,
      "logits/chosen": 3.4824047088623047,
      "logits/rejected": 3.535867214202881,
      "logps/chosen": -365.391845703125,
      "logps/rejected": -296.0636291503906,
      "loss": 0.4721,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8632797002792358,
      "rewards/margins": 1.9855868816375732,
      "rewards/rejected": -2.8488667011260986,
      "step": 6320
    },
    {
      "epoch": 0.3730399223323821,
      "grad_norm": 5.409834861755371,
      "learning_rate": 4.378934980876729e-05,
      "logits/chosen": 3.5519185066223145,
      "logits/rejected": 3.6374523639678955,
      "logps/chosen": -396.8775939941406,
      "logps/rejected": -292.2284851074219,
      "loss": 0.5022,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1793427467346191,
      "rewards/margins": 1.7505035400390625,
      "rewards/rejected": -2.9298462867736816,
      "step": 6340
    },
    {
      "epoch": 0.3742167044217587,
      "grad_norm": 2.243864059448242,
      "learning_rate": 4.3769736196920666e-05,
      "logits/chosen": 3.2393558025360107,
      "logits/rejected": 3.4364166259765625,
      "logps/chosen": -324.86126708984375,
      "logps/rejected": -267.01806640625,
      "loss": 0.5454,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1370290517807007,
      "rewards/margins": 1.7535253763198853,
      "rewards/rejected": -2.890554428100586,
      "step": 6360
    },
    {
      "epoch": 0.3753934865111353,
      "grad_norm": 1.3118019104003906,
      "learning_rate": 4.375012258507404e-05,
      "logits/chosen": 3.8191158771514893,
      "logits/rejected": 3.943523406982422,
      "logps/chosen": -401.89898681640625,
      "logps/rejected": -298.25311279296875,
      "loss": 0.6266,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.8898981809616089,
      "rewards/margins": 1.49733567237854,
      "rewards/rejected": -2.3872337341308594,
      "step": 6380
    },
    {
      "epoch": 0.3765702686005119,
      "grad_norm": 1.626131534576416,
      "learning_rate": 4.3730508973227425e-05,
      "logits/chosen": 4.103299617767334,
      "logits/rejected": 4.026572227478027,
      "logps/chosen": -408.3140563964844,
      "logps/rejected": -288.14825439453125,
      "loss": 0.4782,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.47139009833335876,
      "rewards/margins": 2.4262561798095703,
      "rewards/rejected": -2.897646427154541,
      "step": 6400
    },
    {
      "epoch": 0.3777470506898885,
      "grad_norm": 4.653689384460449,
      "learning_rate": 4.37108953613808e-05,
      "logits/chosen": 3.9688963890075684,
      "logits/rejected": 3.886422634124756,
      "logps/chosen": -416.4383239746094,
      "logps/rejected": -304.5619812011719,
      "loss": 0.5216,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.3835797607898712,
      "rewards/margins": 1.6126117706298828,
      "rewards/rejected": -1.996191382408142,
      "step": 6420
    },
    {
      "epoch": 0.3789238327792651,
      "grad_norm": 0.6370656490325928,
      "learning_rate": 4.369128174953418e-05,
      "logits/chosen": 3.862260341644287,
      "logits/rejected": 3.7324631214141846,
      "logps/chosen": -345.5308532714844,
      "logps/rejected": -257.10675048828125,
      "loss": 0.4207,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.1510661244392395,
      "rewards/margins": 1.8750765323638916,
      "rewards/rejected": -2.0261425971984863,
      "step": 6440
    },
    {
      "epoch": 0.3801006148686417,
      "grad_norm": 1.0726449489593506,
      "learning_rate": 4.367166813768755e-05,
      "logits/chosen": 3.824639081954956,
      "logits/rejected": 3.9510257244110107,
      "logps/chosen": -409.84674072265625,
      "logps/rejected": -322.72210693359375,
      "loss": 0.3371,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": 0.4880766272544861,
      "rewards/margins": 2.37754487991333,
      "rewards/rejected": -1.8894679546356201,
      "step": 6460
    },
    {
      "epoch": 0.3812773969580183,
      "grad_norm": 1.1490589380264282,
      "learning_rate": 4.3652054525840936e-05,
      "logits/chosen": 4.117963790893555,
      "logits/rejected": 4.021010398864746,
      "logps/chosen": -411.53875732421875,
      "logps/rejected": -305.0238342285156,
      "loss": 0.4378,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.2970680892467499,
      "rewards/margins": 1.909630537033081,
      "rewards/rejected": -2.2066986560821533,
      "step": 6480
    },
    {
      "epoch": 0.38245417904739487,
      "grad_norm": 5.862971782684326,
      "learning_rate": 4.363244091399432e-05,
      "logits/chosen": 4.021271228790283,
      "logits/rejected": 3.996192216873169,
      "logps/chosen": -368.86383056640625,
      "logps/rejected": -313.80120849609375,
      "loss": 0.4904,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.38656848669052124,
      "rewards/margins": 2.0825085639953613,
      "rewards/rejected": -2.4690768718719482,
      "step": 6500
    },
    {
      "epoch": 0.3836309611367715,
      "grad_norm": 2.925367593765259,
      "learning_rate": 4.361282730214769e-05,
      "logits/chosen": 4.022738456726074,
      "logits/rejected": 4.030731201171875,
      "logps/chosen": -362.593994140625,
      "logps/rejected": -329.03216552734375,
      "loss": 0.5408,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8981642723083496,
      "rewards/margins": 1.9326307773590088,
      "rewards/rejected": -2.8307950496673584,
      "step": 6520
    },
    {
      "epoch": 0.3848077432261481,
      "grad_norm": 2.3391363620758057,
      "learning_rate": 4.359321369030107e-05,
      "logits/chosen": 4.028599262237549,
      "logits/rejected": 3.9747390747070312,
      "logps/chosen": -375.74560546875,
      "logps/rejected": -291.6775207519531,
      "loss": 0.4621,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0732640027999878,
      "rewards/margins": 2.1263370513916016,
      "rewards/rejected": -3.1996009349823,
      "step": 6540
    },
    {
      "epoch": 0.3859845253155247,
      "grad_norm": 3.122568368911743,
      "learning_rate": 4.3573600078454454e-05,
      "logits/chosen": 3.9587948322296143,
      "logits/rejected": 3.8275561332702637,
      "logps/chosen": -362.00128173828125,
      "logps/rejected": -291.13726806640625,
      "loss": 0.4099,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7997269630432129,
      "rewards/margins": 1.8758646249771118,
      "rewards/rejected": -2.675591468811035,
      "step": 6560
    },
    {
      "epoch": 0.3871613074049013,
      "grad_norm": 1.3926013708114624,
      "learning_rate": 4.355398646660783e-05,
      "logits/chosen": 4.246554374694824,
      "logits/rejected": 4.185428619384766,
      "logps/chosen": -399.3337097167969,
      "logps/rejected": -306.2196044921875,
      "loss": 0.4755,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.682901918888092,
      "rewards/margins": 2.4841487407684326,
      "rewards/rejected": -3.16705060005188,
      "step": 6580
    },
    {
      "epoch": 0.3883380894942779,
      "grad_norm": 1.4434312582015991,
      "learning_rate": 4.3534372854761206e-05,
      "logits/chosen": 4.1274895668029785,
      "logits/rejected": 4.091851711273193,
      "logps/chosen": -377.2879638671875,
      "logps/rejected": -293.6605529785156,
      "loss": 0.4531,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.32946938276290894,
      "rewards/margins": 1.9019429683685303,
      "rewards/rejected": -2.231412410736084,
      "step": 6600
    },
    {
      "epoch": 0.3895148715836545,
      "grad_norm": 2.3689663410186768,
      "learning_rate": 4.351475924291458e-05,
      "logits/chosen": 3.3644020557403564,
      "logits/rejected": 3.3449158668518066,
      "logps/chosen": -331.33013916015625,
      "logps/rejected": -276.9282531738281,
      "loss": 0.4354,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.1821504682302475,
      "rewards/margins": 2.5251963138580322,
      "rewards/rejected": -2.343045711517334,
      "step": 6620
    },
    {
      "epoch": 0.3906916536730311,
      "grad_norm": 0.7355430722236633,
      "learning_rate": 4.3495145631067965e-05,
      "logits/chosen": 4.037959098815918,
      "logits/rejected": 3.917928695678711,
      "logps/chosen": -379.26934814453125,
      "logps/rejected": -282.2528381347656,
      "loss": 0.6403,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.49045276641845703,
      "rewards/margins": 1.197903037071228,
      "rewards/rejected": -1.6883560419082642,
      "step": 6640
    },
    {
      "epoch": 0.3918684357624077,
      "grad_norm": 1.523672342300415,
      "learning_rate": 4.347553201922134e-05,
      "logits/chosen": 3.6536154747009277,
      "logits/rejected": 3.6124281883239746,
      "logps/chosen": -325.334716796875,
      "logps/rejected": -306.1634826660156,
      "loss": 0.4443,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.11690382659435272,
      "rewards/margins": 1.9827791452407837,
      "rewards/rejected": -2.0996830463409424,
      "step": 6660
    },
    {
      "epoch": 0.3930452178517843,
      "grad_norm": 1.5733110904693604,
      "learning_rate": 4.345591840737472e-05,
      "logits/chosen": 3.905949354171753,
      "logits/rejected": 3.95770525932312,
      "logps/chosen": -345.5780029296875,
      "logps/rejected": -285.07232666015625,
      "loss": 0.4376,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.18539470434188843,
      "rewards/margins": 1.9942901134490967,
      "rewards/rejected": -2.179685115814209,
      "step": 6680
    },
    {
      "epoch": 0.3942219999411609,
      "grad_norm": 0.6507959961891174,
      "learning_rate": 4.34363047955281e-05,
      "logits/chosen": 3.809091091156006,
      "logits/rejected": 3.7752041816711426,
      "logps/chosen": -363.26446533203125,
      "logps/rejected": -292.6475524902344,
      "loss": 0.4395,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.29719024896621704,
      "rewards/margins": 2.2943460941314697,
      "rewards/rejected": -2.591536283493042,
      "step": 6700
    },
    {
      "epoch": 0.3953987820305375,
      "grad_norm": 2.9473752975463867,
      "learning_rate": 4.341669118368148e-05,
      "logits/chosen": 3.8408637046813965,
      "logits/rejected": 3.7379684448242188,
      "logps/chosen": -400.9721984863281,
      "logps/rejected": -349.6376953125,
      "loss": 0.4452,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8146038055419922,
      "rewards/margins": 2.4644932746887207,
      "rewards/rejected": -3.279097080230713,
      "step": 6720
    },
    {
      "epoch": 0.39657556411991407,
      "grad_norm": 2.372077465057373,
      "learning_rate": 4.339707757183485e-05,
      "logits/chosen": 3.7980518341064453,
      "logits/rejected": 3.9224319458007812,
      "logps/chosen": -397.41497802734375,
      "logps/rejected": -337.21978759765625,
      "loss": 0.6207,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.1248235702514648,
      "rewards/margins": 1.6929104328155518,
      "rewards/rejected": -2.8177342414855957,
      "step": 6740
    },
    {
      "epoch": 0.3977523462092907,
      "grad_norm": 4.422814846038818,
      "learning_rate": 4.3377463959988235e-05,
      "logits/chosen": 3.6936233043670654,
      "logits/rejected": 3.684720277786255,
      "logps/chosen": -364.8277282714844,
      "logps/rejected": -315.33612060546875,
      "loss": 0.4442,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.764157772064209,
      "rewards/margins": 2.6376311779022217,
      "rewards/rejected": -3.4017891883850098,
      "step": 6760
    },
    {
      "epoch": 0.3989291282986673,
      "grad_norm": 6.882433891296387,
      "learning_rate": 4.335785034814161e-05,
      "logits/chosen": 3.6837379932403564,
      "logits/rejected": 3.7322611808776855,
      "logps/chosen": -364.24822998046875,
      "logps/rejected": -337.6784362792969,
      "loss": 0.4824,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.1643834114074707,
      "rewards/margins": 2.2795705795288086,
      "rewards/rejected": -3.4439537525177,
      "step": 6780
    },
    {
      "epoch": 0.4001059103880439,
      "grad_norm": 1.0700733661651611,
      "learning_rate": 4.3338236736294993e-05,
      "logits/chosen": 3.563620090484619,
      "logits/rejected": 3.514331817626953,
      "logps/chosen": -375.4443359375,
      "logps/rejected": -329.98602294921875,
      "loss": 0.5309,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2525475025177002,
      "rewards/margins": 2.0504043102264404,
      "rewards/rejected": -3.3029518127441406,
      "step": 6800
    },
    {
      "epoch": 0.4012826924774205,
      "grad_norm": 1.0525083541870117,
      "learning_rate": 4.331862312444837e-05,
      "logits/chosen": 3.7747421264648438,
      "logits/rejected": 3.730682373046875,
      "logps/chosen": -368.01739501953125,
      "logps/rejected": -292.66094970703125,
      "loss": 0.4884,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1146929264068604,
      "rewards/margins": 1.8339273929595947,
      "rewards/rejected": -2.948620080947876,
      "step": 6820
    },
    {
      "epoch": 0.4024594745667971,
      "grad_norm": 1.0203986167907715,
      "learning_rate": 4.3299009512601746e-05,
      "logits/chosen": 3.9396889209747314,
      "logits/rejected": 3.8597233295440674,
      "logps/chosen": -398.8213195800781,
      "logps/rejected": -344.06097412109375,
      "loss": 0.4262,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5317849516868591,
      "rewards/margins": 2.7599873542785645,
      "rewards/rejected": -3.2917723655700684,
      "step": 6840
    },
    {
      "epoch": 0.4036362566561737,
      "grad_norm": 2.4175095558166504,
      "learning_rate": 4.327939590075513e-05,
      "logits/chosen": 3.8315556049346924,
      "logits/rejected": 3.6883387565612793,
      "logps/chosen": -367.29290771484375,
      "logps/rejected": -315.46331787109375,
      "loss": 0.3506,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.5631893277168274,
      "rewards/margins": 2.7440741062164307,
      "rewards/rejected": -3.307263135910034,
      "step": 6860
    },
    {
      "epoch": 0.4048130387455503,
      "grad_norm": 0.957709550857544,
      "learning_rate": 4.3259782288908504e-05,
      "logits/chosen": 3.754948377609253,
      "logits/rejected": 3.779627561569214,
      "logps/chosen": -392.10675048828125,
      "logps/rejected": -294.82952880859375,
      "loss": 0.5746,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6504583954811096,
      "rewards/margins": 2.536006450653076,
      "rewards/rejected": -3.186464786529541,
      "step": 6880
    },
    {
      "epoch": 0.4059898208349269,
      "grad_norm": 2.2311930656433105,
      "learning_rate": 4.3241149357654216e-05,
      "logits/chosen": 3.9108123779296875,
      "logits/rejected": 3.8325462341308594,
      "logps/chosen": -419.19866943359375,
      "logps/rejected": -361.5098876953125,
      "loss": 0.5678,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2914607524871826,
      "rewards/margins": 2.569657802581787,
      "rewards/rejected": -3.861118793487549,
      "step": 6900
    },
    {
      "epoch": 0.4071666029243035,
      "grad_norm": 1.1270307302474976,
      "learning_rate": 4.322153574580759e-05,
      "logits/chosen": 3.418222427368164,
      "logits/rejected": 3.331204652786255,
      "logps/chosen": -352.321044921875,
      "logps/rejected": -299.7467956542969,
      "loss": 0.7099,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.2664515972137451,
      "rewards/margins": 2.1089487075805664,
      "rewards/rejected": -3.3754000663757324,
      "step": 6920
    },
    {
      "epoch": 0.4083433850136801,
      "grad_norm": 2.886934518814087,
      "learning_rate": 4.320192213396097e-05,
      "logits/chosen": 3.951441526412964,
      "logits/rejected": 3.796988010406494,
      "logps/chosen": -432.165771484375,
      "logps/rejected": -351.16998291015625,
      "loss": 0.6553,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.9385792016983032,
      "rewards/margins": 1.905297040939331,
      "rewards/rejected": -2.843876361846924,
      "step": 6940
    },
    {
      "epoch": 0.40952016710305666,
      "grad_norm": 1.77916419506073,
      "learning_rate": 4.318230852211435e-05,
      "logits/chosen": 4.048036098480225,
      "logits/rejected": 3.9944190979003906,
      "logps/chosen": -398.70172119140625,
      "logps/rejected": -330.1722717285156,
      "loss": 0.526,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1128638982772827,
      "rewards/margins": 2.0593862533569336,
      "rewards/rejected": -3.172250509262085,
      "step": 6960
    },
    {
      "epoch": 0.41069694919243327,
      "grad_norm": 2.26693058013916,
      "learning_rate": 4.316269491026773e-05,
      "logits/chosen": 3.972367525100708,
      "logits/rejected": 3.809685468673706,
      "logps/chosen": -456.48199462890625,
      "logps/rejected": -349.802978515625,
      "loss": 0.5174,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.46041393280029297,
      "rewards/margins": 2.1215012073516846,
      "rewards/rejected": -2.5819149017333984,
      "step": 6980
    },
    {
      "epoch": 0.4118737312818099,
      "grad_norm": 1.2289382219314575,
      "learning_rate": 4.31430812984211e-05,
      "logits/chosen": 3.8684394359588623,
      "logits/rejected": 3.7544302940368652,
      "logps/chosen": -424.9632263183594,
      "logps/rejected": -280.7428283691406,
      "loss": 0.4434,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.2939726710319519,
      "rewards/margins": 2.5583488941192627,
      "rewards/rejected": -2.8523213863372803,
      "step": 7000
    },
    {
      "epoch": 0.4130505133711865,
      "grad_norm": 2.3317294120788574,
      "learning_rate": 4.3123467686574486e-05,
      "logits/chosen": 3.7543234825134277,
      "logits/rejected": 3.740917205810547,
      "logps/chosen": -342.8333740234375,
      "logps/rejected": -252.74496459960938,
      "loss": 0.5426,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.43368011713027954,
      "rewards/margins": 1.819162130355835,
      "rewards/rejected": -2.252842426300049,
      "step": 7020
    },
    {
      "epoch": 0.4142272954605631,
      "grad_norm": 1.8402942419052124,
      "learning_rate": 4.310385407472786e-05,
      "logits/chosen": 3.9483604431152344,
      "logits/rejected": 3.994882106781006,
      "logps/chosen": -346.96044921875,
      "logps/rejected": -286.49603271484375,
      "loss": 0.4197,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.0521119050681591,
      "rewards/margins": 2.5130269527435303,
      "rewards/rejected": -2.4609150886535645,
      "step": 7040
    },
    {
      "epoch": 0.4154040775499397,
      "grad_norm": 2.7921195030212402,
      "learning_rate": 4.3084240462881245e-05,
      "logits/chosen": 4.151788711547852,
      "logits/rejected": 4.0509562492370605,
      "logps/chosen": -382.763427734375,
      "logps/rejected": -336.1974792480469,
      "loss": 0.7084,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5203946232795715,
      "rewards/margins": 1.7499363422393799,
      "rewards/rejected": -2.2703309059143066,
      "step": 7060
    },
    {
      "epoch": 0.4165808596393163,
      "grad_norm": 10.096364974975586,
      "learning_rate": 4.3064626851034614e-05,
      "logits/chosen": 4.0393385887146,
      "logits/rejected": 4.016718864440918,
      "logps/chosen": -421.1334533691406,
      "logps/rejected": -344.3695373535156,
      "loss": 0.4206,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5240753889083862,
      "rewards/margins": 2.506018877029419,
      "rewards/rejected": -3.0300939083099365,
      "step": 7080
    },
    {
      "epoch": 0.4177576417286929,
      "grad_norm": 2.2367799282073975,
      "learning_rate": 4.3045013239188e-05,
      "logits/chosen": 4.2083845138549805,
      "logits/rejected": 4.229189872741699,
      "logps/chosen": -425.2315368652344,
      "logps/rejected": -367.371337890625,
      "loss": 0.5749,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.35422423481941223,
      "rewards/margins": 2.377108097076416,
      "rewards/rejected": -2.731332302093506,
      "step": 7100
    },
    {
      "epoch": 0.4189344238180695,
      "grad_norm": 0.19303879141807556,
      "learning_rate": 4.302539962734138e-05,
      "logits/chosen": 4.005551338195801,
      "logits/rejected": 3.8324050903320312,
      "logps/chosen": -386.14947509765625,
      "logps/rejected": -324.49114990234375,
      "loss": 0.5275,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8435310125350952,
      "rewards/margins": 2.126539707183838,
      "rewards/rejected": -2.9700706005096436,
      "step": 7120
    },
    {
      "epoch": 0.4201112059074461,
      "grad_norm": 1.491182804107666,
      "learning_rate": 4.3005786015494756e-05,
      "logits/chosen": 3.8613827228546143,
      "logits/rejected": 3.866738796234131,
      "logps/chosen": -371.8357238769531,
      "logps/rejected": -306.76422119140625,
      "loss": 0.5606,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0487101078033447,
      "rewards/margins": 1.5570639371871948,
      "rewards/rejected": -2.605774164199829,
      "step": 7140
    },
    {
      "epoch": 0.4212879879968227,
      "grad_norm": 1.3451242446899414,
      "learning_rate": 4.298617240364813e-05,
      "logits/chosen": 4.076267719268799,
      "logits/rejected": 3.9941067695617676,
      "logps/chosen": -417.605224609375,
      "logps/rejected": -313.1178283691406,
      "loss": 0.5349,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7207165956497192,
      "rewards/margins": 1.699430227279663,
      "rewards/rejected": -2.4201467037200928,
      "step": 7160
    },
    {
      "epoch": 0.4224647700861993,
      "grad_norm": 2.388561248779297,
      "learning_rate": 4.2966558791801515e-05,
      "logits/chosen": 4.201601982116699,
      "logits/rejected": 3.9934890270233154,
      "logps/chosen": -400.48291015625,
      "logps/rejected": -252.5781707763672,
      "loss": 0.5019,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5990439653396606,
      "rewards/margins": 1.7439908981323242,
      "rewards/rejected": -2.3430347442626953,
      "step": 7180
    },
    {
      "epoch": 0.42364155217557586,
      "grad_norm": 0.34887751936912537,
      "learning_rate": 4.294694517995489e-05,
      "logits/chosen": 3.8290467262268066,
      "logits/rejected": 3.934372663497925,
      "logps/chosen": -392.9451904296875,
      "logps/rejected": -310.850341796875,
      "loss": 0.4438,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.14278480410575867,
      "rewards/margins": 2.2449283599853516,
      "rewards/rejected": -2.1021437644958496,
      "step": 7200
    },
    {
      "epoch": 0.42481833426495247,
      "grad_norm": 1.3792451620101929,
      "learning_rate": 4.292733156810827e-05,
      "logits/chosen": 4.051878929138184,
      "logits/rejected": 4.001675605773926,
      "logps/chosen": -356.6993103027344,
      "logps/rejected": -314.2523498535156,
      "loss": 0.5366,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.4906521737575531,
      "rewards/margins": 1.376802921295166,
      "rewards/rejected": -1.8674551248550415,
      "step": 7220
    },
    {
      "epoch": 0.4259951163543291,
      "grad_norm": 1.457850694656372,
      "learning_rate": 4.290771795626164e-05,
      "logits/chosen": 4.093168258666992,
      "logits/rejected": 3.8741886615753174,
      "logps/chosen": -373.5075988769531,
      "logps/rejected": -313.8340759277344,
      "loss": 0.4472,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.49386066198349,
      "rewards/margins": 1.7967605590820312,
      "rewards/rejected": -2.290621280670166,
      "step": 7240
    },
    {
      "epoch": 0.4271718984437057,
      "grad_norm": 2.4148056507110596,
      "learning_rate": 4.2888104344415026e-05,
      "logits/chosen": 3.841036558151245,
      "logits/rejected": 3.9627997875213623,
      "logps/chosen": -344.3138122558594,
      "logps/rejected": -323.4467468261719,
      "loss": 0.3574,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.6036252379417419,
      "rewards/margins": 1.894942045211792,
      "rewards/rejected": -2.4985671043395996,
      "step": 7260
    },
    {
      "epoch": 0.4283486805330823,
      "grad_norm": 3.4956982135772705,
      "learning_rate": 4.286849073256841e-05,
      "logits/chosen": 3.666581392288208,
      "logits/rejected": 3.718944549560547,
      "logps/chosen": -334.388427734375,
      "logps/rejected": -299.582275390625,
      "loss": 0.5173,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.7157667279243469,
      "rewards/margins": 1.9443943500518799,
      "rewards/rejected": -2.660160779953003,
      "step": 7280
    },
    {
      "epoch": 0.4295254626224589,
      "grad_norm": 1.24484384059906,
      "learning_rate": 4.284887712072178e-05,
      "logits/chosen": 4.092446804046631,
      "logits/rejected": 4.001906871795654,
      "logps/chosen": -395.5599670410156,
      "logps/rejected": -296.1177978515625,
      "loss": 0.3086,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.10427647829055786,
      "rewards/margins": 2.3352572917938232,
      "rewards/rejected": -2.4395337104797363,
      "step": 7300
    },
    {
      "epoch": 0.4307022447118355,
      "grad_norm": 1.9922703504562378,
      "learning_rate": 4.282926350887516e-05,
      "logits/chosen": 3.731292247772217,
      "logits/rejected": 3.797102451324463,
      "logps/chosen": -339.5762939453125,
      "logps/rejected": -282.4747619628906,
      "loss": 0.5747,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.6164346933364868,
      "rewards/margins": 1.603801965713501,
      "rewards/rejected": -2.2202365398406982,
      "step": 7320
    },
    {
      "epoch": 0.4318790268012121,
      "grad_norm": 0.5851308703422546,
      "learning_rate": 4.2809649897028543e-05,
      "logits/chosen": 3.704907178878784,
      "logits/rejected": 3.6737639904022217,
      "logps/chosen": -374.52691650390625,
      "logps/rejected": -316.085205078125,
      "loss": 0.4776,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5119150876998901,
      "rewards/margins": 2.1368069648742676,
      "rewards/rejected": -2.648721933364868,
      "step": 7340
    },
    {
      "epoch": 0.4330558088905887,
      "grad_norm": 2.272986650466919,
      "learning_rate": 4.279003628518192e-05,
      "logits/chosen": 3.8753502368927,
      "logits/rejected": 3.9819836616516113,
      "logps/chosen": -342.55224609375,
      "logps/rejected": -339.40484619140625,
      "loss": 0.4725,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9830689430236816,
      "rewards/margins": 2.2616961002349854,
      "rewards/rejected": -3.244765043258667,
      "step": 7360
    },
    {
      "epoch": 0.4342325909799653,
      "grad_norm": 1.4950209856033325,
      "learning_rate": 4.2770422673335296e-05,
      "logits/chosen": 3.783181667327881,
      "logits/rejected": 3.67596435546875,
      "logps/chosen": -375.20391845703125,
      "logps/rejected": -332.1134338378906,
      "loss": 0.4885,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6914247274398804,
      "rewards/margins": 2.3223297595977783,
      "rewards/rejected": -3.013754367828369,
      "step": 7380
    },
    {
      "epoch": 0.4354093730693419,
      "grad_norm": 22.958417892456055,
      "learning_rate": 4.275080906148867e-05,
      "logits/chosen": 4.028186321258545,
      "logits/rejected": 3.9050917625427246,
      "logps/chosen": -447.6368103027344,
      "logps/rejected": -333.70513916015625,
      "loss": 0.4282,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2052438259124756,
      "rewards/margins": 2.451699733734131,
      "rewards/rejected": -3.6569435596466064,
      "step": 7400
    },
    {
      "epoch": 0.43658615515871846,
      "grad_norm": 1.8577083349227905,
      "learning_rate": 4.2731195449642054e-05,
      "logits/chosen": 4.099614143371582,
      "logits/rejected": 3.993246555328369,
      "logps/chosen": -406.45330810546875,
      "logps/rejected": -389.90679931640625,
      "loss": 0.4564,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.252428650856018,
      "rewards/margins": 2.205376386642456,
      "rewards/rejected": -3.4578049182891846,
      "step": 7420
    },
    {
      "epoch": 0.43776293724809506,
      "grad_norm": 1.4075114727020264,
      "learning_rate": 4.271158183779543e-05,
      "logits/chosen": 3.7257561683654785,
      "logits/rejected": 3.6766154766082764,
      "logps/chosen": -395.2548522949219,
      "logps/rejected": -337.03106689453125,
      "loss": 0.6703,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.929356575012207,
      "rewards/margins": 2.786877155303955,
      "rewards/rejected": -3.716233730316162,
      "step": 7440
    },
    {
      "epoch": 0.43893971933747167,
      "grad_norm": 1.4466416835784912,
      "learning_rate": 4.2691968225948806e-05,
      "logits/chosen": 3.6386032104492188,
      "logits/rejected": 3.8049216270446777,
      "logps/chosen": -389.9204406738281,
      "logps/rejected": -314.8612976074219,
      "loss": 0.4745,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7209795713424683,
      "rewards/margins": 2.3650588989257812,
      "rewards/rejected": -3.086038827896118,
      "step": 7460
    },
    {
      "epoch": 0.4401165014268483,
      "grad_norm": 2.507573366165161,
      "learning_rate": 4.267235461410219e-05,
      "logits/chosen": 3.7788748741149902,
      "logits/rejected": 3.8214333057403564,
      "logps/chosen": -361.67791748046875,
      "logps/rejected": -320.17230224609375,
      "loss": 0.5189,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5729620456695557,
      "rewards/margins": 2.438383102416992,
      "rewards/rejected": -3.011345148086548,
      "step": 7480
    },
    {
      "epoch": 0.4412932835162249,
      "grad_norm": 2.160327196121216,
      "learning_rate": 4.265274100225557e-05,
      "logits/chosen": 4.017796039581299,
      "logits/rejected": 3.973170518875122,
      "logps/chosen": -373.44439697265625,
      "logps/rejected": -360.3879089355469,
      "loss": 0.6185,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.0531558990478516,
      "rewards/margins": 1.865540862083435,
      "rewards/rejected": -2.918696880340576,
      "step": 7500
    },
    {
      "epoch": 0.4424700656056015,
      "grad_norm": 2.8472352027893066,
      "learning_rate": 4.263312739040894e-05,
      "logits/chosen": 3.844303846359253,
      "logits/rejected": 3.737255573272705,
      "logps/chosen": -327.7882385253906,
      "logps/rejected": -303.2442626953125,
      "loss": 0.5087,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9825644493103027,
      "rewards/margins": 1.6294368505477905,
      "rewards/rejected": -2.6120009422302246,
      "step": 7520
    },
    {
      "epoch": 0.4436468476949781,
      "grad_norm": 2.1523964405059814,
      "learning_rate": 4.2613513778562324e-05,
      "logits/chosen": 3.625561237335205,
      "logits/rejected": 3.569777727127075,
      "logps/chosen": -358.76434326171875,
      "logps/rejected": -296.6949768066406,
      "loss": 0.4322,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.978124737739563,
      "rewards/margins": 2.0148496627807617,
      "rewards/rejected": -2.9929747581481934,
      "step": 7540
    },
    {
      "epoch": 0.4448236297843547,
      "grad_norm": 0.5722784996032715,
      "learning_rate": 4.25939001667157e-05,
      "logits/chosen": 4.027224540710449,
      "logits/rejected": 3.822537660598755,
      "logps/chosen": -446.22613525390625,
      "logps/rejected": -337.37652587890625,
      "loss": 0.5092,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3031820058822632,
      "rewards/margins": 1.9458105564117432,
      "rewards/rejected": -3.248992443084717,
      "step": 7560
    },
    {
      "epoch": 0.4460004118737313,
      "grad_norm": 2.23628830909729,
      "learning_rate": 4.257428655486908e-05,
      "logits/chosen": 3.9725120067596436,
      "logits/rejected": 3.8350837230682373,
      "logps/chosen": -414.3978576660156,
      "logps/rejected": -314.51055908203125,
      "loss": 0.47,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0360546112060547,
      "rewards/margins": 2.5039167404174805,
      "rewards/rejected": -3.539971113204956,
      "step": 7580
    },
    {
      "epoch": 0.4471771939631079,
      "grad_norm": 1.9510217905044556,
      "learning_rate": 4.255467294302246e-05,
      "logits/chosen": 4.147244453430176,
      "logits/rejected": 4.018971920013428,
      "logps/chosen": -402.30157470703125,
      "logps/rejected": -331.374267578125,
      "loss": 0.4269,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7317391037940979,
      "rewards/margins": 2.444124937057495,
      "rewards/rejected": -3.1758639812469482,
      "step": 7600
    },
    {
      "epoch": 0.4483539760524845,
      "grad_norm": 17.313459396362305,
      "learning_rate": 4.2535059331175835e-05,
      "logits/chosen": 3.958874464035034,
      "logits/rejected": 3.908662796020508,
      "logps/chosen": -409.7950744628906,
      "logps/rejected": -348.36932373046875,
      "loss": 0.6929,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6568295359611511,
      "rewards/margins": 1.8569679260253906,
      "rewards/rejected": -2.5137972831726074,
      "step": 7620
    },
    {
      "epoch": 0.44953075814186105,
      "grad_norm": 40.66537857055664,
      "learning_rate": 4.251544571932922e-05,
      "logits/chosen": 3.9240822792053223,
      "logits/rejected": 4.076077461242676,
      "logps/chosen": -414.86077880859375,
      "logps/rejected": -301.6517639160156,
      "loss": 0.5285,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9997243881225586,
      "rewards/margins": 2.0706286430358887,
      "rewards/rejected": -3.0703530311584473,
      "step": 7640
    },
    {
      "epoch": 0.45070754023123766,
      "grad_norm": 0.3397332727909088,
      "learning_rate": 4.2495832107482594e-05,
      "logits/chosen": 3.869938611984253,
      "logits/rejected": 3.848029613494873,
      "logps/chosen": -404.43878173828125,
      "logps/rejected": -310.9168701171875,
      "loss": 0.2984,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.8652554750442505,
      "rewards/margins": 2.719273090362549,
      "rewards/rejected": -3.5845284461975098,
      "step": 7660
    },
    {
      "epoch": 0.45188432232061426,
      "grad_norm": 3.732489824295044,
      "learning_rate": 4.247621849563597e-05,
      "logits/chosen": 3.8397083282470703,
      "logits/rejected": 3.8047797679901123,
      "logps/chosen": -358.0828857421875,
      "logps/rejected": -284.25396728515625,
      "loss": 0.5878,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7282069325447083,
      "rewards/margins": 1.9965565204620361,
      "rewards/rejected": -2.7247633934020996,
      "step": 7680
    },
    {
      "epoch": 0.45306110440999087,
      "grad_norm": 1.8091126680374146,
      "learning_rate": 4.245660488378935e-05,
      "logits/chosen": 4.056513786315918,
      "logits/rejected": 4.153885841369629,
      "logps/chosen": -408.9240417480469,
      "logps/rejected": -313.82611083984375,
      "loss": 0.3644,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.28702038526535034,
      "rewards/margins": 2.9959282875061035,
      "rewards/rejected": -3.2829489707946777,
      "step": 7700
    },
    {
      "epoch": 0.45423788649936747,
      "grad_norm": 1.8174943923950195,
      "learning_rate": 4.243699127194273e-05,
      "logits/chosen": 4.19357967376709,
      "logits/rejected": 4.213208198547363,
      "logps/chosen": -361.6526794433594,
      "logps/rejected": -350.98565673828125,
      "loss": 0.4065,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9938881993293762,
      "rewards/margins": 2.440113067626953,
      "rewards/rejected": -3.4340012073516846,
      "step": 7720
    },
    {
      "epoch": 0.4554146685887441,
      "grad_norm": 0.33900222182273865,
      "learning_rate": 4.2417377660096105e-05,
      "logits/chosen": 3.9294097423553467,
      "logits/rejected": 4.011731147766113,
      "logps/chosen": -395.63018798828125,
      "logps/rejected": -346.10791015625,
      "loss": 0.7138,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.046598196029663,
      "rewards/margins": 1.9271844625473022,
      "rewards/rejected": -2.973782777786255,
      "step": 7740
    },
    {
      "epoch": 0.4565914506781207,
      "grad_norm": 1.5182048082351685,
      "learning_rate": 4.239776404824949e-05,
      "logits/chosen": 3.8551387786865234,
      "logits/rejected": 3.8327736854553223,
      "logps/chosen": -356.8921813964844,
      "logps/rejected": -257.42327880859375,
      "loss": 0.5318,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8893327713012695,
      "rewards/margins": 2.137990951538086,
      "rewards/rejected": -3.0273234844207764,
      "step": 7760
    },
    {
      "epoch": 0.4577682327674973,
      "grad_norm": 1.4518609046936035,
      "learning_rate": 4.2378150436402864e-05,
      "logits/chosen": 4.374180793762207,
      "logits/rejected": 4.265384197235107,
      "logps/chosen": -383.6425476074219,
      "logps/rejected": -313.28765869140625,
      "loss": 0.5574,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.38362786173820496,
      "rewards/margins": 2.478309392929077,
      "rewards/rejected": -2.8619372844696045,
      "step": 7780
    },
    {
      "epoch": 0.4589450148568739,
      "grad_norm": 4.711517333984375,
      "learning_rate": 4.2358536824556247e-05,
      "logits/chosen": 3.9365837574005127,
      "logits/rejected": 3.8665878772735596,
      "logps/chosen": -375.333740234375,
      "logps/rejected": -287.59442138671875,
      "loss": 0.4782,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.30707675218582153,
      "rewards/margins": 2.7922489643096924,
      "rewards/rejected": -3.099325656890869,
      "step": 7800
    },
    {
      "epoch": 0.4601217969462505,
      "grad_norm": 2.663620710372925,
      "learning_rate": 4.233892321270962e-05,
      "logits/chosen": 3.9708359241485596,
      "logits/rejected": 3.7168922424316406,
      "logps/chosen": -383.8407287597656,
      "logps/rejected": -285.12176513671875,
      "loss": 0.4468,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5844009518623352,
      "rewards/margins": 2.105928421020508,
      "rewards/rejected": -2.690329074859619,
      "step": 7820
    },
    {
      "epoch": 0.4612985790356271,
      "grad_norm": 2.4929001331329346,
      "learning_rate": 4.2319309600863e-05,
      "logits/chosen": 3.691641330718994,
      "logits/rejected": 3.728869915008545,
      "logps/chosen": -354.492919921875,
      "logps/rejected": -304.4196472167969,
      "loss": 0.5301,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.3224627375602722,
      "rewards/margins": 2.2660696506500244,
      "rewards/rejected": -2.5885326862335205,
      "step": 7840
    },
    {
      "epoch": 0.4624753611250037,
      "grad_norm": 3.485222101211548,
      "learning_rate": 4.229969598901638e-05,
      "logits/chosen": 3.923252582550049,
      "logits/rejected": 3.8794238567352295,
      "logps/chosen": -385.5509338378906,
      "logps/rejected": -296.76348876953125,
      "loss": 0.4652,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.3588019013404846,
      "rewards/margins": 2.238842010498047,
      "rewards/rejected": -2.597644329071045,
      "step": 7860
    },
    {
      "epoch": 0.46365214321438025,
      "grad_norm": 1.9664734601974487,
      "learning_rate": 4.228008237716976e-05,
      "logits/chosen": 4.005255699157715,
      "logits/rejected": 3.860811710357666,
      "logps/chosen": -401.740966796875,
      "logps/rejected": -290.59088134765625,
      "loss": 0.5648,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.30559656023979187,
      "rewards/margins": 2.1183664798736572,
      "rewards/rejected": -2.4239630699157715,
      "step": 7880
    },
    {
      "epoch": 0.46482892530375686,
      "grad_norm": 3.1820120811462402,
      "learning_rate": 4.2260468765323134e-05,
      "logits/chosen": 3.7086422443389893,
      "logits/rejected": 3.8280036449432373,
      "logps/chosen": -366.8000183105469,
      "logps/rejected": -287.68206787109375,
      "loss": 0.4553,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8770186305046082,
      "rewards/margins": 2.1925759315490723,
      "rewards/rejected": -3.069594621658325,
      "step": 7900
    },
    {
      "epoch": 0.46600570739313346,
      "grad_norm": 1.2854104042053223,
      "learning_rate": 4.2240855153476516e-05,
      "logits/chosen": 4.096399307250977,
      "logits/rejected": 4.171299934387207,
      "logps/chosen": -386.64788818359375,
      "logps/rejected": -349.8212585449219,
      "loss": 0.5517,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9814525842666626,
      "rewards/margins": 2.3169407844543457,
      "rewards/rejected": -3.298393726348877,
      "step": 7920
    },
    {
      "epoch": 0.46718248948251007,
      "grad_norm": 1.1195597648620605,
      "learning_rate": 4.222124154162989e-05,
      "logits/chosen": 3.8570919036865234,
      "logits/rejected": 3.7674431800842285,
      "logps/chosen": -367.2353515625,
      "logps/rejected": -316.2283020019531,
      "loss": 0.5884,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.023942232131958,
      "rewards/margins": 2.0853798389434814,
      "rewards/rejected": -3.1093220710754395,
      "step": 7940
    },
    {
      "epoch": 0.46835927157188667,
      "grad_norm": 1.0523440837860107,
      "learning_rate": 4.220162792978327e-05,
      "logits/chosen": 3.9706332683563232,
      "logits/rejected": 4.018284797668457,
      "logps/chosen": -363.3163146972656,
      "logps/rejected": -332.6586608886719,
      "loss": 0.4254,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9503612518310547,
      "rewards/margins": 1.996180534362793,
      "rewards/rejected": -2.9465417861938477,
      "step": 7960
    },
    {
      "epoch": 0.4695360536612633,
      "grad_norm": 1.373422622680664,
      "learning_rate": 4.218201431793665e-05,
      "logits/chosen": 3.681670665740967,
      "logits/rejected": 3.7436070442199707,
      "logps/chosen": -369.3570556640625,
      "logps/rejected": -312.35443115234375,
      "loss": 0.49,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.919183075428009,
      "rewards/margins": 1.8258848190307617,
      "rewards/rejected": -2.745068073272705,
      "step": 7980
    },
    {
      "epoch": 0.4707128357506399,
      "grad_norm": 1.8080564737319946,
      "learning_rate": 4.216240070609003e-05,
      "logits/chosen": 3.871752977371216,
      "logits/rejected": 3.8620567321777344,
      "logps/chosen": -363.3699035644531,
      "logps/rejected": -301.84368896484375,
      "loss": 0.4852,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5763363838195801,
      "rewards/margins": 2.17169451713562,
      "rewards/rejected": -2.7480309009552,
      "step": 8000
    },
    {
      "epoch": 0.4718896178400165,
      "grad_norm": 0.6978434324264526,
      "learning_rate": 4.214278709424341e-05,
      "logits/chosen": 3.899829387664795,
      "logits/rejected": 3.847984790802002,
      "logps/chosen": -387.2344970703125,
      "logps/rejected": -274.0985412597656,
      "loss": 0.4687,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.21850626170635223,
      "rewards/margins": 2.084069013595581,
      "rewards/rejected": -2.3025753498077393,
      "step": 8020
    },
    {
      "epoch": 0.4730663999293931,
      "grad_norm": 1.6493037939071655,
      "learning_rate": 4.2123173482396786e-05,
      "logits/chosen": 3.662518262863159,
      "logits/rejected": 3.6568877696990967,
      "logps/chosen": -337.742919921875,
      "logps/rejected": -309.78289794921875,
      "loss": 0.4848,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.014202510938048363,
      "rewards/margins": 2.100559949874878,
      "rewards/rejected": -2.086357355117798,
      "step": 8040
    },
    {
      "epoch": 0.4742431820187697,
      "grad_norm": 3.195319652557373,
      "learning_rate": 4.210355987055016e-05,
      "logits/chosen": 3.9583277702331543,
      "logits/rejected": 3.936547040939331,
      "logps/chosen": -357.9012145996094,
      "logps/rejected": -281.2828674316406,
      "loss": 0.6628,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.840267539024353,
      "rewards/margins": 1.7311458587646484,
      "rewards/rejected": -2.571413278579712,
      "step": 8060
    },
    {
      "epoch": 0.4754199641081463,
      "grad_norm": 4.231186389923096,
      "learning_rate": 4.2083946258703545e-05,
      "logits/chosen": 4.024865627288818,
      "logits/rejected": 4.083451271057129,
      "logps/chosen": -420.5166015625,
      "logps/rejected": -349.208984375,
      "loss": 0.5841,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.06776972860097885,
      "rewards/margins": 2.239938259124756,
      "rewards/rejected": -2.307708263397217,
      "step": 8080
    },
    {
      "epoch": 0.47659674619752285,
      "grad_norm": 1.6195350885391235,
      "learning_rate": 4.206433264685692e-05,
      "logits/chosen": 4.1092119216918945,
      "logits/rejected": 3.8527417182922363,
      "logps/chosen": -394.7002868652344,
      "logps/rejected": -292.02191162109375,
      "loss": 0.4062,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.8594539761543274,
      "rewards/margins": 1.932983636856079,
      "rewards/rejected": -2.7924373149871826,
      "step": 8100
    },
    {
      "epoch": 0.47777352828689945,
      "grad_norm": 2.4221396446228027,
      "learning_rate": 4.20447190350103e-05,
      "logits/chosen": 3.8399975299835205,
      "logits/rejected": 3.8237743377685547,
      "logps/chosen": -366.7839660644531,
      "logps/rejected": -337.0528259277344,
      "loss": 0.6498,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.27159109711647034,
      "rewards/margins": 2.4194958209991455,
      "rewards/rejected": -2.691087007522583,
      "step": 8120
    },
    {
      "epoch": 0.47895031037627606,
      "grad_norm": 4.303933620452881,
      "learning_rate": 4.202510542316368e-05,
      "logits/chosen": 3.8256096839904785,
      "logits/rejected": 3.8151888847351074,
      "logps/chosen": -325.6100769042969,
      "logps/rejected": -255.60775756835938,
      "loss": 0.4852,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9293118715286255,
      "rewards/margins": 1.7144768238067627,
      "rewards/rejected": -2.6437885761260986,
      "step": 8140
    },
    {
      "epoch": 0.48012709246565266,
      "grad_norm": 0.9343037605285645,
      "learning_rate": 4.2005491811317056e-05,
      "logits/chosen": 3.7800018787384033,
      "logits/rejected": 3.720820665359497,
      "logps/chosen": -377.6228942871094,
      "logps/rejected": -292.91021728515625,
      "loss": 0.4413,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.912833034992218,
      "rewards/margins": 2.1732375621795654,
      "rewards/rejected": -3.086071014404297,
      "step": 8160
    },
    {
      "epoch": 0.48130387455502927,
      "grad_norm": 2.129169464111328,
      "learning_rate": 4.198587819947043e-05,
      "logits/chosen": 3.6065590381622314,
      "logits/rejected": 3.6774749755859375,
      "logps/chosen": -342.90484619140625,
      "logps/rejected": -327.9698181152344,
      "loss": 0.5314,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8245066404342651,
      "rewards/margins": 1.9522701501846313,
      "rewards/rejected": -2.7767767906188965,
      "step": 8180
    },
    {
      "epoch": 0.48248065664440587,
      "grad_norm": 2.6949851512908936,
      "learning_rate": 4.196626458762381e-05,
      "logits/chosen": 4.096658706665039,
      "logits/rejected": 4.035541534423828,
      "logps/chosen": -399.675048828125,
      "logps/rejected": -314.34527587890625,
      "loss": 0.5952,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.5895378589630127,
      "rewards/margins": 1.8507988452911377,
      "rewards/rejected": -3.4403367042541504,
      "step": 8200
    },
    {
      "epoch": 0.4836574387337825,
      "grad_norm": 0.07319170236587524,
      "learning_rate": 4.194665097577719e-05,
      "logits/chosen": 4.036267280578613,
      "logits/rejected": 4.004702568054199,
      "logps/chosen": -383.2283935546875,
      "logps/rejected": -302.34442138671875,
      "loss": 0.4033,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.857634425163269,
      "rewards/margins": 2.364264488220215,
      "rewards/rejected": -3.2218985557556152,
      "step": 8220
    },
    {
      "epoch": 0.4848342208231591,
      "grad_norm": 2.069066047668457,
      "learning_rate": 4.1927037363930574e-05,
      "logits/chosen": 3.9612483978271484,
      "logits/rejected": 3.9506492614746094,
      "logps/chosen": -415.1316833496094,
      "logps/rejected": -345.9836730957031,
      "loss": 0.4703,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.5766836404800415,
      "rewards/margins": 2.749072790145874,
      "rewards/rejected": -3.325756788253784,
      "step": 8240
    },
    {
      "epoch": 0.4860110029125357,
      "grad_norm": 2.4630463123321533,
      "learning_rate": 4.190742375208395e-05,
      "logits/chosen": 3.856576442718506,
      "logits/rejected": 3.9912192821502686,
      "logps/chosen": -371.40045166015625,
      "logps/rejected": -288.6993713378906,
      "loss": 0.4873,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5209074020385742,
      "rewards/margins": 2.1837525367736816,
      "rewards/rejected": -2.704659938812256,
      "step": 8260
    },
    {
      "epoch": 0.4871877850019123,
      "grad_norm": 1.7694255113601685,
      "learning_rate": 4.1887810140237326e-05,
      "logits/chosen": 3.701805830001831,
      "logits/rejected": 3.670929431915283,
      "logps/chosen": -341.60748291015625,
      "logps/rejected": -284.92120361328125,
      "loss": 0.7321,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.9463248252868652,
      "rewards/margins": 1.3656961917877197,
      "rewards/rejected": -2.312021255493164,
      "step": 8280
    },
    {
      "epoch": 0.4883645670912889,
      "grad_norm": 1.987612009048462,
      "learning_rate": 4.186819652839071e-05,
      "logits/chosen": 3.914191484451294,
      "logits/rejected": 3.923428773880005,
      "logps/chosen": -393.3204650878906,
      "logps/rejected": -287.63604736328125,
      "loss": 0.4403,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.13892003893852234,
      "rewards/margins": 2.267256259918213,
      "rewards/rejected": -2.4061760902404785,
      "step": 8300
    },
    {
      "epoch": 0.4895413491806655,
      "grad_norm": 2.536222219467163,
      "learning_rate": 4.1848582916544085e-05,
      "logits/chosen": 4.321911811828613,
      "logits/rejected": 4.148028373718262,
      "logps/chosen": -381.7750244140625,
      "logps/rejected": -322.2106018066406,
      "loss": 0.5066,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6698645353317261,
      "rewards/margins": 2.0922093391418457,
      "rewards/rejected": -2.7620739936828613,
      "step": 8320
    },
    {
      "epoch": 0.49071813127004205,
      "grad_norm": 25.532939910888672,
      "learning_rate": 4.182896930469746e-05,
      "logits/chosen": 4.010178565979004,
      "logits/rejected": 3.9649548530578613,
      "logps/chosen": -338.90704345703125,
      "logps/rejected": -315.32293701171875,
      "loss": 0.4619,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9521231651306152,
      "rewards/margins": 1.6280643939971924,
      "rewards/rejected": -2.5801875591278076,
      "step": 8340
    },
    {
      "epoch": 0.49189491335941865,
      "grad_norm": 13.886188507080078,
      "learning_rate": 4.180935569285084e-05,
      "logits/chosen": 3.8496692180633545,
      "logits/rejected": 3.8761749267578125,
      "logps/chosen": -383.7393493652344,
      "logps/rejected": -323.45574951171875,
      "loss": 0.6677,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0425775051116943,
      "rewards/margins": 2.1324450969696045,
      "rewards/rejected": -3.175022602081299,
      "step": 8360
    },
    {
      "epoch": 0.49307169544879526,
      "grad_norm": 2.8540525436401367,
      "learning_rate": 4.178974208100422e-05,
      "logits/chosen": 4.258664131164551,
      "logits/rejected": 4.233174800872803,
      "logps/chosen": -431.1923828125,
      "logps/rejected": -394.56341552734375,
      "loss": 0.4784,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9848170280456543,
      "rewards/margins": 2.4442694187164307,
      "rewards/rejected": -3.429086208343506,
      "step": 8380
    },
    {
      "epoch": 0.49424847753817186,
      "grad_norm": 5.065573215484619,
      "learning_rate": 4.17701284691576e-05,
      "logits/chosen": 4.201162815093994,
      "logits/rejected": 4.1543073654174805,
      "logps/chosen": -421.2752380371094,
      "logps/rejected": -346.82647705078125,
      "loss": 0.5369,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3080376386642456,
      "rewards/margins": 1.9164981842041016,
      "rewards/rejected": -3.224536180496216,
      "step": 8400
    },
    {
      "epoch": 0.49542525962754846,
      "grad_norm": 1.5581134557724,
      "learning_rate": 4.175051485731097e-05,
      "logits/chosen": 3.7932543754577637,
      "logits/rejected": 3.8517746925354004,
      "logps/chosen": -361.93511962890625,
      "logps/rejected": -353.6836242675781,
      "loss": 0.349,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1061068773269653,
      "rewards/margins": 2.682408094406128,
      "rewards/rejected": -3.7885146141052246,
      "step": 8420
    },
    {
      "epoch": 0.49660204171692507,
      "grad_norm": 3.03398060798645,
      "learning_rate": 4.1730901245464354e-05,
      "logits/chosen": 4.009873867034912,
      "logits/rejected": 3.9868056774139404,
      "logps/chosen": -347.5869140625,
      "logps/rejected": -322.2013854980469,
      "loss": 0.5057,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1925861835479736,
      "rewards/margins": 1.9191417694091797,
      "rewards/rejected": -3.111727476119995,
      "step": 8440
    },
    {
      "epoch": 0.4977788238063017,
      "grad_norm": 0.8837922215461731,
      "learning_rate": 4.171128763361774e-05,
      "logits/chosen": 3.7714552879333496,
      "logits/rejected": 3.7111382484436035,
      "logps/chosen": -373.7506408691406,
      "logps/rejected": -321.5179138183594,
      "loss": 0.6918,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4645572900772095,
      "rewards/margins": 1.7087841033935547,
      "rewards/rejected": -3.1733412742614746,
      "step": 8460
    },
    {
      "epoch": 0.4989556058956783,
      "grad_norm": 1.3954885005950928,
      "learning_rate": 4.169167402177111e-05,
      "logits/chosen": 3.921351194381714,
      "logits/rejected": 3.9050183296203613,
      "logps/chosen": -385.00286865234375,
      "logps/rejected": -315.60845947265625,
      "loss": 0.6417,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8472944498062134,
      "rewards/margins": 1.9481847286224365,
      "rewards/rejected": -3.7954792976379395,
      "step": 8480
    },
    {
      "epoch": 0.5001323879850549,
      "grad_norm": 3.571667194366455,
      "learning_rate": 4.167206040992449e-05,
      "logits/chosen": 3.952274799346924,
      "logits/rejected": 3.8621983528137207,
      "logps/chosen": -349.3116149902344,
      "logps/rejected": -290.1308288574219,
      "loss": 0.5153,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7066075801849365,
      "rewards/margins": 2.1413774490356445,
      "rewards/rejected": -2.847984790802002,
      "step": 8500
    },
    {
      "epoch": 0.5013091700744314,
      "grad_norm": 1.3516532182693481,
      "learning_rate": 4.1652446798077865e-05,
      "logits/chosen": 3.875621795654297,
      "logits/rejected": 3.848527193069458,
      "logps/chosen": -355.07745361328125,
      "logps/rejected": -263.49639892578125,
      "loss": 0.4734,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.6603177189826965,
      "rewards/margins": 2.135847806930542,
      "rewards/rejected": -2.7961654663085938,
      "step": 8520
    },
    {
      "epoch": 0.5024859521638081,
      "grad_norm": 3.797292470932007,
      "learning_rate": 4.163283318623125e-05,
      "logits/chosen": 3.8409359455108643,
      "logits/rejected": 3.944908618927002,
      "logps/chosen": -323.4106750488281,
      "logps/rejected": -324.55450439453125,
      "loss": 0.5178,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.38532179594039917,
      "rewards/margins": 2.073833703994751,
      "rewards/rejected": -2.459155559539795,
      "step": 8540
    },
    {
      "epoch": 0.5036627342531846,
      "grad_norm": 1.3233723640441895,
      "learning_rate": 4.1613219574384624e-05,
      "logits/chosen": 3.7747817039489746,
      "logits/rejected": 3.7973179817199707,
      "logps/chosen": -343.6529235839844,
      "logps/rejected": -278.28375244140625,
      "loss": 0.4801,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.739808201789856,
      "rewards/margins": 1.8735069036483765,
      "rewards/rejected": -2.6133153438568115,
      "step": 8560
    },
    {
      "epoch": 0.5048395163425613,
      "grad_norm": 1.1408519744873047,
      "learning_rate": 4.1593605962538e-05,
      "logits/chosen": 4.051868915557861,
      "logits/rejected": 4.132749080657959,
      "logps/chosen": -392.98577880859375,
      "logps/rejected": -336.9127197265625,
      "loss": 0.5667,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.49800461530685425,
      "rewards/margins": 2.0100924968719482,
      "rewards/rejected": -2.5080971717834473,
      "step": 8580
    },
    {
      "epoch": 0.5060162984319378,
      "grad_norm": 3.292041540145874,
      "learning_rate": 4.157399235069138e-05,
      "logits/chosen": 4.16721248626709,
      "logits/rejected": 4.1671037673950195,
      "logps/chosen": -408.87371826171875,
      "logps/rejected": -334.8275146484375,
      "loss": 0.4418,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.3339916169643402,
      "rewards/margins": 2.7256906032562256,
      "rewards/rejected": -2.3916990756988525,
      "step": 8600
    },
    {
      "epoch": 0.5071930805213145,
      "grad_norm": 3.6045002937316895,
      "learning_rate": 4.1554378738844766e-05,
      "logits/chosen": 3.8227343559265137,
      "logits/rejected": 3.8861477375030518,
      "logps/chosen": -363.40020751953125,
      "logps/rejected": -315.19964599609375,
      "loss": 0.6301,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.17665284872055054,
      "rewards/margins": 2.0032949447631836,
      "rewards/rejected": -2.1799476146698,
      "step": 8620
    },
    {
      "epoch": 0.5083698626106911,
      "grad_norm": 45.13915252685547,
      "learning_rate": 4.1534765126998135e-05,
      "logits/chosen": 4.149011611938477,
      "logits/rejected": 4.181840896606445,
      "logps/chosen": -379.2998046875,
      "logps/rejected": -321.8194885253906,
      "loss": 0.4961,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7835195660591125,
      "rewards/margins": 1.5815751552581787,
      "rewards/rejected": -2.3650946617126465,
      "step": 8640
    },
    {
      "epoch": 0.5095466447000677,
      "grad_norm": 0.6418129205703735,
      "learning_rate": 4.151515151515152e-05,
      "logits/chosen": 4.057207107543945,
      "logits/rejected": 4.083351135253906,
      "logps/chosen": -376.5202941894531,
      "logps/rejected": -299.31634521484375,
      "loss": 0.6019,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.41060739755630493,
      "rewards/margins": 2.146049976348877,
      "rewards/rejected": -2.556657314300537,
      "step": 8660
    },
    {
      "epoch": 0.5107234267894443,
      "grad_norm": 2.389704465866089,
      "learning_rate": 4.1495537903304894e-05,
      "logits/chosen": 3.8255455493927,
      "logits/rejected": 3.6964385509490967,
      "logps/chosen": -382.6808166503906,
      "logps/rejected": -321.439697265625,
      "loss": 0.5101,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.06899751722812653,
      "rewards/margins": 2.691258192062378,
      "rewards/rejected": -2.760255813598633,
      "step": 8680
    },
    {
      "epoch": 0.5119002088788208,
      "grad_norm": 2.0710437297821045,
      "learning_rate": 4.147592429145828e-05,
      "logits/chosen": 3.8932552337646484,
      "logits/rejected": 3.8229079246520996,
      "logps/chosen": -351.28240966796875,
      "logps/rejected": -322.0460510253906,
      "loss": 0.6115,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.39906877279281616,
      "rewards/margins": 1.9547885656356812,
      "rewards/rejected": -2.3538572788238525,
      "step": 8700
    },
    {
      "epoch": 0.5130769909681975,
      "grad_norm": 3.251128673553467,
      "learning_rate": 4.145631067961165e-05,
      "logits/chosen": 3.9520187377929688,
      "logits/rejected": 3.9366657733917236,
      "logps/chosen": -387.50677490234375,
      "logps/rejected": -300.44305419921875,
      "loss": 0.3463,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.3189209997653961,
      "rewards/margins": 2.505807638168335,
      "rewards/rejected": -2.824728488922119,
      "step": 8720
    },
    {
      "epoch": 0.514253773057574,
      "grad_norm": 2.885063409805298,
      "learning_rate": 4.143669706776503e-05,
      "logits/chosen": 4.266302108764648,
      "logits/rejected": 4.272526741027832,
      "logps/chosen": -371.0411682128906,
      "logps/rejected": -326.5513610839844,
      "loss": 0.4521,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.3044282793998718,
      "rewards/margins": 2.0797066688537598,
      "rewards/rejected": -2.3841347694396973,
      "step": 8740
    },
    {
      "epoch": 0.5154305551469507,
      "grad_norm": 0.6652846932411194,
      "learning_rate": 4.141708345591841e-05,
      "logits/chosen": 3.8978943824768066,
      "logits/rejected": 3.798597812652588,
      "logps/chosen": -358.72808837890625,
      "logps/rejected": -307.6227722167969,
      "loss": 0.4456,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.36466121673583984,
      "rewards/margins": 2.1318986415863037,
      "rewards/rejected": -2.4965600967407227,
      "step": 8760
    },
    {
      "epoch": 0.5166073372363272,
      "grad_norm": 1.6703500747680664,
      "learning_rate": 4.139746984407179e-05,
      "logits/chosen": 4.1434526443481445,
      "logits/rejected": 4.1601715087890625,
      "logps/chosen": -412.3346252441406,
      "logps/rejected": -286.4906005859375,
      "loss": 0.4819,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.693828284740448,
      "rewards/margins": 1.9692728519439697,
      "rewards/rejected": -2.6631009578704834,
      "step": 8780
    },
    {
      "epoch": 0.5177841193257039,
      "grad_norm": 1.3065696954727173,
      "learning_rate": 4.1377856232225164e-05,
      "logits/chosen": 4.040477275848389,
      "logits/rejected": 3.9171440601348877,
      "logps/chosen": -427.0621032714844,
      "logps/rejected": -360.0049743652344,
      "loss": 0.4712,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.23369260132312775,
      "rewards/margins": 2.300747871398926,
      "rewards/rejected": -2.534440517425537,
      "step": 8800
    },
    {
      "epoch": 0.5189609014150804,
      "grad_norm": 2.1881914138793945,
      "learning_rate": 4.1358242620378547e-05,
      "logits/chosen": 3.9789395332336426,
      "logits/rejected": 4.100894927978516,
      "logps/chosen": -332.07025146484375,
      "logps/rejected": -275.01763916015625,
      "loss": 0.4418,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8524202108383179,
      "rewards/margins": 1.9478085041046143,
      "rewards/rejected": -2.8002285957336426,
      "step": 8820
    },
    {
      "epoch": 0.5201376835044571,
      "grad_norm": 0.23156113922595978,
      "learning_rate": 4.133862900853192e-05,
      "logits/chosen": 4.203561305999756,
      "logits/rejected": 4.081877708435059,
      "logps/chosen": -427.65570068359375,
      "logps/rejected": -315.0052490234375,
      "loss": 0.4606,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.1972072422504425,
      "rewards/margins": 2.6508641242980957,
      "rewards/rejected": -2.848071575164795,
      "step": 8840
    },
    {
      "epoch": 0.5213144655938337,
      "grad_norm": 3.0205252170562744,
      "learning_rate": 4.13190153966853e-05,
      "logits/chosen": 3.827192783355713,
      "logits/rejected": 3.7181267738342285,
      "logps/chosen": -356.14971923828125,
      "logps/rejected": -265.1465759277344,
      "loss": 0.5141,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.4924340844154358,
      "rewards/margins": 1.8416271209716797,
      "rewards/rejected": -2.3340609073638916,
      "step": 8860
    },
    {
      "epoch": 0.5224912476832103,
      "grad_norm": 2.0793066024780273,
      "learning_rate": 4.129940178483868e-05,
      "logits/chosen": 4.056554317474365,
      "logits/rejected": 4.071950435638428,
      "logps/chosen": -376.5943603515625,
      "logps/rejected": -316.2996520996094,
      "loss": 0.3986,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.2597336173057556,
      "rewards/margins": 2.908310651779175,
      "rewards/rejected": -3.168044328689575,
      "step": 8880
    },
    {
      "epoch": 0.5236680297725869,
      "grad_norm": 8.216734886169434,
      "learning_rate": 4.127978817299206e-05,
      "logits/chosen": 3.8698649406433105,
      "logits/rejected": 3.8628528118133545,
      "logps/chosen": -384.8714294433594,
      "logps/rejected": -297.8735656738281,
      "loss": 0.6421,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.191992849111557,
      "rewards/margins": 1.9372456073760986,
      "rewards/rejected": -2.1292383670806885,
      "step": 8900
    },
    {
      "epoch": 0.5248448118619634,
      "grad_norm": 0.4937068521976471,
      "learning_rate": 4.126017456114544e-05,
      "logits/chosen": 4.098360538482666,
      "logits/rejected": 4.132082939147949,
      "logps/chosen": -435.8765563964844,
      "logps/rejected": -359.4690856933594,
      "loss": 0.4108,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.36894556879997253,
      "rewards/margins": 2.932295322418213,
      "rewards/rejected": -3.301240921020508,
      "step": 8920
    },
    {
      "epoch": 0.5260215939513401,
      "grad_norm": 1.1702100038528442,
      "learning_rate": 4.1240560949298816e-05,
      "logits/chosen": 4.248570919036865,
      "logits/rejected": 4.187942981719971,
      "logps/chosen": -373.4725646972656,
      "logps/rejected": -304.25714111328125,
      "loss": 0.587,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.42954111099243164,
      "rewards/margins": 2.0544486045837402,
      "rewards/rejected": -2.483989953994751,
      "step": 8940
    },
    {
      "epoch": 0.5271983760407166,
      "grad_norm": 2.5027894973754883,
      "learning_rate": 4.122094733745219e-05,
      "logits/chosen": 4.180222511291504,
      "logits/rejected": 4.0530171394348145,
      "logps/chosen": -361.6924743652344,
      "logps/rejected": -290.818115234375,
      "loss": 0.4739,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.3720068037509918,
      "rewards/margins": 2.3118748664855957,
      "rewards/rejected": -2.6838817596435547,
      "step": 8960
    },
    {
      "epoch": 0.5283751581300933,
      "grad_norm": 1.1596018075942993,
      "learning_rate": 4.1201333725605575e-05,
      "logits/chosen": 4.038039207458496,
      "logits/rejected": 4.1522393226623535,
      "logps/chosen": -383.5704040527344,
      "logps/rejected": -372.5906677246094,
      "loss": 0.4695,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.2710267901420593,
      "rewards/margins": 1.954845666885376,
      "rewards/rejected": -2.22587251663208,
      "step": 8980
    },
    {
      "epoch": 0.5295519402194698,
      "grad_norm": 4.264265537261963,
      "learning_rate": 4.118172011375895e-05,
      "logits/chosen": 3.987030506134033,
      "logits/rejected": 3.8493075370788574,
      "logps/chosen": -380.6448059082031,
      "logps/rejected": -320.7440185546875,
      "loss": 0.3576,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.3939787447452545,
      "rewards/margins": 2.76001238822937,
      "rewards/rejected": -3.153991222381592,
      "step": 9000
    },
    {
      "epoch": 0.5307287223088465,
      "grad_norm": 1.1821106672286987,
      "learning_rate": 4.116210650191233e-05,
      "logits/chosen": 4.075528144836426,
      "logits/rejected": 4.010042190551758,
      "logps/chosen": -371.6396484375,
      "logps/rejected": -319.62139892578125,
      "loss": 0.3629,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.4661681056022644,
      "rewards/margins": 2.786242961883545,
      "rewards/rejected": -3.252410888671875,
      "step": 9020
    },
    {
      "epoch": 0.531905504398223,
      "grad_norm": 2.5832643508911133,
      "learning_rate": 4.114249289006571e-05,
      "logits/chosen": 3.7801506519317627,
      "logits/rejected": 3.690720796585083,
      "logps/chosen": -371.7933654785156,
      "logps/rejected": -289.5904846191406,
      "loss": 0.4863,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4083988666534424,
      "rewards/margins": 2.198798179626465,
      "rewards/rejected": -3.6071972846984863,
      "step": 9040
    },
    {
      "epoch": 0.5330822864875997,
      "grad_norm": 2.2165427207946777,
      "learning_rate": 4.1122879278219086e-05,
      "logits/chosen": 4.175130367279053,
      "logits/rejected": 4.124006748199463,
      "logps/chosen": -405.51031494140625,
      "logps/rejected": -326.8526611328125,
      "loss": 0.458,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.168851613998413,
      "rewards/margins": 2.2501895427703857,
      "rewards/rejected": -3.419041156768799,
      "step": 9060
    },
    {
      "epoch": 0.5342590685769762,
      "grad_norm": 1.917863130569458,
      "learning_rate": 4.110326566637246e-05,
      "logits/chosen": 4.319436073303223,
      "logits/rejected": 4.178859710693359,
      "logps/chosen": -400.9605407714844,
      "logps/rejected": -303.9196472167969,
      "loss": 0.6419,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1088082790374756,
      "rewards/margins": 2.260634183883667,
      "rewards/rejected": -3.3694427013397217,
      "step": 9080
    },
    {
      "epoch": 0.5354358506663529,
      "grad_norm": 4.049769878387451,
      "learning_rate": 4.1083652054525845e-05,
      "logits/chosen": 4.101263999938965,
      "logits/rejected": 4.0482072830200195,
      "logps/chosen": -400.16204833984375,
      "logps/rejected": -324.6019287109375,
      "loss": 0.7192,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.6807304620742798,
      "rewards/margins": 1.7710329294204712,
      "rewards/rejected": -2.451763391494751,
      "step": 9100
    },
    {
      "epoch": 0.5366126327557295,
      "grad_norm": 4.071346282958984,
      "learning_rate": 4.106403844267922e-05,
      "logits/chosen": 3.8632500171661377,
      "logits/rejected": 3.8667588233947754,
      "logps/chosen": -367.1726379394531,
      "logps/rejected": -321.7315673828125,
      "loss": 0.5221,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.9100366830825806,
      "rewards/margins": 1.9799280166625977,
      "rewards/rejected": -2.889965057373047,
      "step": 9120
    },
    {
      "epoch": 0.537789414845106,
      "grad_norm": 1.0641980171203613,
      "learning_rate": 4.1044424830832604e-05,
      "logits/chosen": 4.104249954223633,
      "logits/rejected": 4.06528377532959,
      "logps/chosen": -399.5307312011719,
      "logps/rejected": -325.53472900390625,
      "loss": 0.4773,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.21392707526683807,
      "rewards/margins": 2.2118821144104004,
      "rewards/rejected": -2.425809144973755,
      "step": 9140
    },
    {
      "epoch": 0.5389661969344827,
      "grad_norm": 1.0154649019241333,
      "learning_rate": 4.102481121898597e-05,
      "logits/chosen": 3.841104507446289,
      "logits/rejected": 3.9423019886016846,
      "logps/chosen": -366.8551025390625,
      "logps/rejected": -332.1626892089844,
      "loss": 0.523,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9604787826538086,
      "rewards/margins": 2.3913533687591553,
      "rewards/rejected": -3.351832628250122,
      "step": 9160
    },
    {
      "epoch": 0.5401429790238592,
      "grad_norm": 2.8001315593719482,
      "learning_rate": 4.1005197607139356e-05,
      "logits/chosen": 3.643911838531494,
      "logits/rejected": 3.6465632915496826,
      "logps/chosen": -311.6212158203125,
      "logps/rejected": -274.88275146484375,
      "loss": 0.5574,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.2616573572158813,
      "rewards/margins": 1.337522029876709,
      "rewards/rejected": -2.59917950630188,
      "step": 9180
    },
    {
      "epoch": 0.5413197611132359,
      "grad_norm": 4.057774066925049,
      "learning_rate": 4.098558399529274e-05,
      "logits/chosen": 3.8821425437927246,
      "logits/rejected": 3.9054627418518066,
      "logps/chosen": -345.6036682128906,
      "logps/rejected": -307.8609924316406,
      "loss": 0.4517,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0624477863311768,
      "rewards/margins": 2.217982053756714,
      "rewards/rejected": -3.2804298400878906,
      "step": 9200
    },
    {
      "epoch": 0.5424965432026124,
      "grad_norm": 3.3471829891204834,
      "learning_rate": 4.0965970383446115e-05,
      "logits/chosen": 3.5606303215026855,
      "logits/rejected": 3.7786056995391846,
      "logps/chosen": -371.6751403808594,
      "logps/rejected": -327.0656433105469,
      "loss": 0.564,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.290693998336792,
      "rewards/margins": 1.7635549306869507,
      "rewards/rejected": -3.0542490482330322,
      "step": 9220
    },
    {
      "epoch": 0.5436733252919891,
      "grad_norm": 3.9743521213531494,
      "learning_rate": 4.094635677159949e-05,
      "logits/chosen": 3.7720115184783936,
      "logits/rejected": 4.0083112716674805,
      "logps/chosen": -431.37908935546875,
      "logps/rejected": -336.39801025390625,
      "loss": 0.5594,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4535306692123413,
      "rewards/margins": 2.2552125453948975,
      "rewards/rejected": -3.7087433338165283,
      "step": 9240
    },
    {
      "epoch": 0.5448501073813656,
      "grad_norm": 1.0087403059005737,
      "learning_rate": 4.0926743159752874e-05,
      "logits/chosen": 3.6462669372558594,
      "logits/rejected": 3.7804348468780518,
      "logps/chosen": -384.34759521484375,
      "logps/rejected": -290.8355712890625,
      "loss": 0.5752,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9032529592514038,
      "rewards/margins": 1.8209747076034546,
      "rewards/rejected": -2.7242276668548584,
      "step": 9260
    },
    {
      "epoch": 0.5460268894707423,
      "grad_norm": 1.2556853294372559,
      "learning_rate": 4.090712954790625e-05,
      "logits/chosen": 3.905412197113037,
      "logits/rejected": 3.969909191131592,
      "logps/chosen": -381.4994812011719,
      "logps/rejected": -306.22918701171875,
      "loss": 0.4759,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8019425272941589,
      "rewards/margins": 2.0082132816314697,
      "rewards/rejected": -2.8101556301116943,
      "step": 9280
    },
    {
      "epoch": 0.5472036715601188,
      "grad_norm": 0.5316019654273987,
      "learning_rate": 4.0887515936059626e-05,
      "logits/chosen": 4.0314202308654785,
      "logits/rejected": 3.9843361377716064,
      "logps/chosen": -362.0589904785156,
      "logps/rejected": -271.87835693359375,
      "loss": 0.359,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7379109859466553,
      "rewards/margins": 2.275505542755127,
      "rewards/rejected": -3.0134165287017822,
      "step": 9300
    },
    {
      "epoch": 0.5483804536494955,
      "grad_norm": 3.5608084201812744,
      "learning_rate": 4.0867902324213e-05,
      "logits/chosen": 4.0424299240112305,
      "logits/rejected": 4.078055381774902,
      "logps/chosen": -401.7777099609375,
      "logps/rejected": -306.19830322265625,
      "loss": 0.5763,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.077959656715393,
      "rewards/margins": 1.9417632818222046,
      "rewards/rejected": -3.0197231769561768,
      "step": 9320
    },
    {
      "epoch": 0.549557235738872,
      "grad_norm": 3.3257527351379395,
      "learning_rate": 4.0848288712366385e-05,
      "logits/chosen": 4.235838413238525,
      "logits/rejected": 4.085787296295166,
      "logps/chosen": -396.8063049316406,
      "logps/rejected": -318.49395751953125,
      "loss": 0.4057,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9478087425231934,
      "rewards/margins": 2.331260919570923,
      "rewards/rejected": -3.279069423675537,
      "step": 9340
    },
    {
      "epoch": 0.5507340178282486,
      "grad_norm": 3.279527425765991,
      "learning_rate": 4.082867510051977e-05,
      "logits/chosen": 3.8414299488067627,
      "logits/rejected": 3.9057869911193848,
      "logps/chosen": -332.99249267578125,
      "logps/rejected": -337.98944091796875,
      "loss": 0.6703,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.4852755069732666,
      "rewards/margins": 1.417483925819397,
      "rewards/rejected": -2.902759075164795,
      "step": 9360
    },
    {
      "epoch": 0.5519107999176253,
      "grad_norm": 2.529491901397705,
      "learning_rate": 4.080906148867314e-05,
      "logits/chosen": 3.9330761432647705,
      "logits/rejected": 3.9470152854919434,
      "logps/chosen": -429.68194580078125,
      "logps/rejected": -301.43585205078125,
      "loss": 0.3562,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8866052627563477,
      "rewards/margins": 2.839290142059326,
      "rewards/rejected": -3.725895404815674,
      "step": 9380
    },
    {
      "epoch": 0.5530875820070018,
      "grad_norm": 2.640664577484131,
      "learning_rate": 4.078944787682652e-05,
      "logits/chosen": 3.955526351928711,
      "logits/rejected": 3.78637433052063,
      "logps/chosen": -366.8486022949219,
      "logps/rejected": -300.4593200683594,
      "loss": 0.603,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3028123378753662,
      "rewards/margins": 1.6281547546386719,
      "rewards/rejected": -2.930967330932617,
      "step": 9400
    },
    {
      "epoch": 0.5542643640963785,
      "grad_norm": 1.1765344142913818,
      "learning_rate": 4.07698342649799e-05,
      "logits/chosen": 3.9653701782226562,
      "logits/rejected": 4.060903072357178,
      "logps/chosen": -364.4879455566406,
      "logps/rejected": -329.43402099609375,
      "loss": 0.418,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2007811069488525,
      "rewards/margins": 2.291879177093506,
      "rewards/rejected": -3.4926600456237793,
      "step": 9420
    },
    {
      "epoch": 0.555441146185755,
      "grad_norm": 3.2286741733551025,
      "learning_rate": 4.075022065313328e-05,
      "logits/chosen": 3.754627227783203,
      "logits/rejected": 3.7998600006103516,
      "logps/chosen": -358.7015075683594,
      "logps/rejected": -329.8731689453125,
      "loss": 0.458,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8196842074394226,
      "rewards/margins": 1.9093475341796875,
      "rewards/rejected": -2.729031562805176,
      "step": 9440
    },
    {
      "epoch": 0.5566179282751317,
      "grad_norm": 1.0683917999267578,
      "learning_rate": 4.0730607041286654e-05,
      "logits/chosen": 3.8507418632507324,
      "logits/rejected": 3.9636054039001465,
      "logps/chosen": -318.41864013671875,
      "logps/rejected": -322.0925598144531,
      "loss": 0.692,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.9127315282821655,
      "rewards/margins": 1.9119350910186768,
      "rewards/rejected": -2.824666738510132,
      "step": 9460
    },
    {
      "epoch": 0.5577947103645082,
      "grad_norm": 1.4659488201141357,
      "learning_rate": 4.071099342944003e-05,
      "logits/chosen": 3.939157009124756,
      "logits/rejected": 3.924421787261963,
      "logps/chosen": -372.79962158203125,
      "logps/rejected": -277.80450439453125,
      "loss": 0.6423,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8234289288520813,
      "rewards/margins": 1.7678216695785522,
      "rewards/rejected": -2.5912508964538574,
      "step": 9480
    },
    {
      "epoch": 0.5589714924538849,
      "grad_norm": 1.6684461832046509,
      "learning_rate": 4.069137981759341e-05,
      "logits/chosen": 3.9050071239471436,
      "logits/rejected": 3.7934250831604004,
      "logps/chosen": -339.5930480957031,
      "logps/rejected": -338.9531555175781,
      "loss": 0.6421,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.49376219511032104,
      "rewards/margins": 1.3188400268554688,
      "rewards/rejected": -1.8126022815704346,
      "step": 9500
    },
    {
      "epoch": 0.5601482745432614,
      "grad_norm": 1.3000080585479736,
      "learning_rate": 4.067176620574679e-05,
      "logits/chosen": 3.858738422393799,
      "logits/rejected": 3.8708393573760986,
      "logps/chosen": -408.2245178222656,
      "logps/rejected": -311.51171875,
      "loss": 0.3945,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.40163668990135193,
      "rewards/margins": 3.1950843334198,
      "rewards/rejected": -2.793447971343994,
      "step": 9520
    },
    {
      "epoch": 0.5613250566326381,
      "grad_norm": 1.7910102605819702,
      "learning_rate": 4.0652152593900165e-05,
      "logits/chosen": 3.8539280891418457,
      "logits/rejected": 3.8405871391296387,
      "logps/chosen": -339.76165771484375,
      "logps/rejected": -305.19696044921875,
      "loss": 0.4959,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.683810830116272,
      "rewards/margins": 1.9233825206756592,
      "rewards/rejected": -2.6071934700012207,
      "step": 9540
    },
    {
      "epoch": 0.5625018387220146,
      "grad_norm": 1.3619017601013184,
      "learning_rate": 4.063253898205355e-05,
      "logits/chosen": 4.068989276885986,
      "logits/rejected": 4.081272125244141,
      "logps/chosen": -377.8694763183594,
      "logps/rejected": -298.431396484375,
      "loss": 0.4764,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.5499661564826965,
      "rewards/margins": 1.9264400005340576,
      "rewards/rejected": -2.4764060974121094,
      "step": 9560
    },
    {
      "epoch": 0.5636786208113912,
      "grad_norm": 0.6537924408912659,
      "learning_rate": 4.061292537020693e-05,
      "logits/chosen": 4.083941459655762,
      "logits/rejected": 3.919848918914795,
      "logps/chosen": -376.0679016113281,
      "logps/rejected": -265.93157958984375,
      "loss": 0.4093,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.07641369104385376,
      "rewards/margins": 2.15293550491333,
      "rewards/rejected": -2.076521873474121,
      "step": 9580
    },
    {
      "epoch": 0.5648554029007679,
      "grad_norm": 1.6866810321807861,
      "learning_rate": 4.05933117583603e-05,
      "logits/chosen": 4.066014766693115,
      "logits/rejected": 4.03463077545166,
      "logps/chosen": -354.6896667480469,
      "logps/rejected": -300.60626220703125,
      "loss": 0.3931,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.3786877691745758,
      "rewards/margins": 2.165335178375244,
      "rewards/rejected": -2.544022798538208,
      "step": 9600
    },
    {
      "epoch": 0.5660321849901444,
      "grad_norm": 2.4969375133514404,
      "learning_rate": 4.057369814651368e-05,
      "logits/chosen": 4.007899761199951,
      "logits/rejected": 4.001226425170898,
      "logps/chosen": -323.6263122558594,
      "logps/rejected": -318.5283203125,
      "loss": 0.513,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.41702041029930115,
      "rewards/margins": 2.3331925868988037,
      "rewards/rejected": -2.750213146209717,
      "step": 9620
    },
    {
      "epoch": 0.5672089670795211,
      "grad_norm": 1.574933409690857,
      "learning_rate": 4.055408453466706e-05,
      "logits/chosen": 4.221745491027832,
      "logits/rejected": 4.130456447601318,
      "logps/chosen": -368.0975036621094,
      "logps/rejected": -303.1382751464844,
      "loss": 0.4019,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5207486748695374,
      "rewards/margins": 2.0124449729919434,
      "rewards/rejected": -2.533193588256836,
      "step": 9640
    },
    {
      "epoch": 0.5683857491688976,
      "grad_norm": 1.9264590740203857,
      "learning_rate": 4.053447092282044e-05,
      "logits/chosen": 4.000901222229004,
      "logits/rejected": 3.908698320388794,
      "logps/chosen": -378.9791259765625,
      "logps/rejected": -310.66949462890625,
      "loss": 0.4321,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.30289047956466675,
      "rewards/margins": 2.777317523956299,
      "rewards/rejected": -3.080207586288452,
      "step": 9660
    },
    {
      "epoch": 0.5695625312582743,
      "grad_norm": 1.3342589139938354,
      "learning_rate": 4.051485731097382e-05,
      "logits/chosen": 3.636601209640503,
      "logits/rejected": 3.6386044025421143,
      "logps/chosen": -337.05609130859375,
      "logps/rejected": -296.14739990234375,
      "loss": 0.4111,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5424941778182983,
      "rewards/margins": 2.272270917892456,
      "rewards/rejected": -2.814765453338623,
      "step": 9680
    },
    {
      "epoch": 0.5707393133476508,
      "grad_norm": 0.7211665511131287,
      "learning_rate": 4.0495243699127194e-05,
      "logits/chosen": 3.734248638153076,
      "logits/rejected": 3.6800975799560547,
      "logps/chosen": -340.10186767578125,
      "logps/rejected": -295.52874755859375,
      "loss": 0.541,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.0324748754501343,
      "rewards/margins": 1.665355920791626,
      "rewards/rejected": -2.69783091545105,
      "step": 9700
    },
    {
      "epoch": 0.5719160954370275,
      "grad_norm": 2.6743016242980957,
      "learning_rate": 4.047563008728058e-05,
      "logits/chosen": 3.6997451782226562,
      "logits/rejected": 3.712462902069092,
      "logps/chosen": -396.7400817871094,
      "logps/rejected": -320.3553161621094,
      "loss": 0.4823,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.4624611437320709,
      "rewards/margins": 2.5196549892425537,
      "rewards/rejected": -2.9821159839630127,
      "step": 9720
    },
    {
      "epoch": 0.573092877526404,
      "grad_norm": 8.906986236572266,
      "learning_rate": 4.045601647543395e-05,
      "logits/chosen": 4.090499401092529,
      "logits/rejected": 3.8458876609802246,
      "logps/chosen": -408.23687744140625,
      "logps/rejected": -322.93560791015625,
      "loss": 0.3054,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.5474132895469666,
      "rewards/margins": 2.695967197418213,
      "rewards/rejected": -3.2433807849884033,
      "step": 9740
    },
    {
      "epoch": 0.5742696596157807,
      "grad_norm": 2.1809959411621094,
      "learning_rate": 4.043640286358733e-05,
      "logits/chosen": 3.80549955368042,
      "logits/rejected": 3.754596710205078,
      "logps/chosen": -403.34033203125,
      "logps/rejected": -293.82379150390625,
      "loss": 0.4038,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.2802496552467346,
      "rewards/margins": 2.9212489128112793,
      "rewards/rejected": -2.6409990787506104,
      "step": 9760
    },
    {
      "epoch": 0.5754464417051572,
      "grad_norm": 3.6576855182647705,
      "learning_rate": 4.041678925174071e-05,
      "logits/chosen": 3.8637804985046387,
      "logits/rejected": 3.797818422317505,
      "logps/chosen": -394.11065673828125,
      "logps/rejected": -341.54522705078125,
      "loss": 0.6076,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6596012711524963,
      "rewards/margins": 2.4897003173828125,
      "rewards/rejected": -3.149301290512085,
      "step": 9780
    },
    {
      "epoch": 0.5766232237945339,
      "grad_norm": 1.4724246263504028,
      "learning_rate": 4.039717563989409e-05,
      "logits/chosen": 4.164950847625732,
      "logits/rejected": 4.051079273223877,
      "logps/chosen": -402.1771545410156,
      "logps/rejected": -343.15234375,
      "loss": 0.3575,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.18527671694755554,
      "rewards/margins": 3.1959681510925293,
      "rewards/rejected": -3.381244659423828,
      "step": 9800
    },
    {
      "epoch": 0.5778000058839105,
      "grad_norm": 2.721715211868286,
      "learning_rate": 4.0377562028047464e-05,
      "logits/chosen": 3.6844229698181152,
      "logits/rejected": 3.7379631996154785,
      "logps/chosen": -394.70404052734375,
      "logps/rejected": -348.39764404296875,
      "loss": 0.6306,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.0307670831680298,
      "rewards/margins": 1.8402286767959595,
      "rewards/rejected": -2.8709957599639893,
      "step": 9820
    },
    {
      "epoch": 0.578976787973287,
      "grad_norm": 0.4311069846153259,
      "learning_rate": 4.0357948416200847e-05,
      "logits/chosen": 3.660362720489502,
      "logits/rejected": 3.5237858295440674,
      "logps/chosen": -347.35986328125,
      "logps/rejected": -322.1944885253906,
      "loss": 0.4702,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.8946663737297058,
      "rewards/margins": 2.362663745880127,
      "rewards/rejected": -3.2573306560516357,
      "step": 9840
    },
    {
      "epoch": 0.5801535700626637,
      "grad_norm": 5.147718906402588,
      "learning_rate": 4.033833480435422e-05,
      "logits/chosen": 3.590273380279541,
      "logits/rejected": 3.467329502105713,
      "logps/chosen": -394.2672119140625,
      "logps/rejected": -312.36248779296875,
      "loss": 0.5386,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8140245676040649,
      "rewards/margins": 2.3061046600341797,
      "rewards/rejected": -3.120129346847534,
      "step": 9860
    },
    {
      "epoch": 0.5813303521520402,
      "grad_norm": 1.3451626300811768,
      "learning_rate": 4.0318721192507605e-05,
      "logits/chosen": 3.4030747413635254,
      "logits/rejected": 3.3588829040527344,
      "logps/chosen": -341.6468200683594,
      "logps/rejected": -258.85247802734375,
      "loss": 0.4748,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9591442942619324,
      "rewards/margins": 1.9044166803359985,
      "rewards/rejected": -2.8635611534118652,
      "step": 9880
    },
    {
      "epoch": 0.5825071342414169,
      "grad_norm": 1.5580095052719116,
      "learning_rate": 4.029910758066098e-05,
      "logits/chosen": 4.079236030578613,
      "logits/rejected": 3.930065631866455,
      "logps/chosen": -409.22406005859375,
      "logps/rejected": -331.6287536621094,
      "loss": 0.4336,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.9758862257003784,
      "rewards/margins": 2.504105567932129,
      "rewards/rejected": -3.479991912841797,
      "step": 9900
    },
    {
      "epoch": 0.5836839163307934,
      "grad_norm": 3.621591091156006,
      "learning_rate": 4.027949396881436e-05,
      "logits/chosen": 3.80975079536438,
      "logits/rejected": 3.7377028465270996,
      "logps/chosen": -389.9065246582031,
      "logps/rejected": -298.3333740234375,
      "loss": 0.4736,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.6125337481498718,
      "rewards/margins": 2.4707372188568115,
      "rewards/rejected": -3.083270788192749,
      "step": 9920
    },
    {
      "epoch": 0.5848606984201701,
      "grad_norm": 5.415091514587402,
      "learning_rate": 4.025988035696774e-05,
      "logits/chosen": 4.039492607116699,
      "logits/rejected": 3.8316969871520996,
      "logps/chosen": -445.9603576660156,
      "logps/rejected": -390.98175048828125,
      "loss": 0.5654,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.06472913920879364,
      "rewards/margins": 2.6988325119018555,
      "rewards/rejected": -2.763561964035034,
      "step": 9940
    },
    {
      "epoch": 0.5860374805095466,
      "grad_norm": 0.4535987377166748,
      "learning_rate": 4.0240266745121116e-05,
      "logits/chosen": 3.5722262859344482,
      "logits/rejected": 3.462937116622925,
      "logps/chosen": -360.6103515625,
      "logps/rejected": -273.14385986328125,
      "loss": 0.5637,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8466460108757019,
      "rewards/margins": 2.0153136253356934,
      "rewards/rejected": -2.86195969581604,
      "step": 9960
    },
    {
      "epoch": 0.5872142625989233,
      "grad_norm": 2.1194493770599365,
      "learning_rate": 4.022065313327449e-05,
      "logits/chosen": 3.7137019634246826,
      "logits/rejected": 3.589108943939209,
      "logps/chosen": -382.95843505859375,
      "logps/rejected": -284.6325378417969,
      "loss": 0.5059,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.2023468017578125,
      "rewards/margins": 2.4627091884613037,
      "rewards/rejected": -2.260362148284912,
      "step": 9980
    },
    {
      "epoch": 0.5883910446882998,
      "grad_norm": 0.6046461462974548,
      "learning_rate": 4.0201039521427875e-05,
      "logits/chosen": 3.7228026390075684,
      "logits/rejected": 3.9236340522766113,
      "logps/chosen": -323.0836486816406,
      "logps/rejected": -274.47735595703125,
      "loss": 0.4791,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.5261772871017456,
      "rewards/margins": 1.6607173681259155,
      "rewards/rejected": -2.186894416809082,
      "step": 10000
    },
    {
      "epoch": 0.5883910446882998,
      "eval_logits/chosen": 3.3727099895477295,
      "eval_logits/rejected": 3.363412618637085,
      "eval_logps/chosen": -363.3717346191406,
      "eval_logps/rejected": -324.9244689941406,
      "eval_loss": 0.5116240978240967,
      "eval_rewards/accuracies": 0.7680744528770447,
      "eval_rewards/chosen": -0.8791074156761169,
      "eval_rewards/margins": 1.9900206327438354,
      "eval_rewards/rejected": -2.8691277503967285,
      "eval_runtime": 3548.3569,
      "eval_samples_per_second": 3.15,
      "eval_steps_per_second": 3.15,
      "step": 10000
    },
    {
      "epoch": 0.5895678267776765,
      "grad_norm": 1.7778477668762207,
      "learning_rate": 4.018142590958125e-05,
      "logits/chosen": 3.7175612449645996,
      "logits/rejected": 3.7315430641174316,
      "logps/chosen": -383.5013732910156,
      "logps/rejected": -296.17340087890625,
      "loss": 0.3447,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.06779907643795013,
      "rewards/margins": 2.6284432411193848,
      "rewards/rejected": -2.5606439113616943,
      "step": 10020
    },
    {
      "epoch": 0.590744608867053,
      "grad_norm": 1.8653854131698608,
      "learning_rate": 4.016181229773463e-05,
      "logits/chosen": 3.8673179149627686,
      "logits/rejected": 3.668152332305908,
      "logps/chosen": -424.997802734375,
      "logps/rejected": -331.80596923828125,
      "loss": 0.5872,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9052297472953796,
      "rewards/margins": 2.03600811958313,
      "rewards/rejected": -2.9412379264831543,
      "step": 10040
    },
    {
      "epoch": 0.5919213909564296,
      "grad_norm": 0.7458221316337585,
      "learning_rate": 4.014219868588801e-05,
      "logits/chosen": 3.3654980659484863,
      "logits/rejected": 3.4078452587127686,
      "logps/chosen": -333.0875549316406,
      "logps/rejected": -297.2740478515625,
      "loss": 0.4142,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.7783096432685852,
      "rewards/margins": 2.6770334243774414,
      "rewards/rejected": -3.4553427696228027,
      "step": 10060
    },
    {
      "epoch": 0.5930981730458063,
      "grad_norm": 2.530024766921997,
      "learning_rate": 4.0122585074041386e-05,
      "logits/chosen": 3.214947462081909,
      "logits/rejected": 3.283207416534424,
      "logps/chosen": -333.6805114746094,
      "logps/rejected": -303.27392578125,
      "loss": 0.436,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.0320342779159546,
      "rewards/margins": 2.205993413925171,
      "rewards/rejected": -3.238028049468994,
      "step": 10080
    },
    {
      "epoch": 0.5942749551351828,
      "grad_norm": 1.6045458316802979,
      "learning_rate": 4.010297146219477e-05,
      "logits/chosen": 3.803173780441284,
      "logits/rejected": 3.755913257598877,
      "logps/chosen": -412.13372802734375,
      "logps/rejected": -344.7801208496094,
      "loss": 0.6573,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4195250272750854,
      "rewards/margins": 2.442075490951538,
      "rewards/rejected": -3.861600399017334,
      "step": 10100
    },
    {
      "epoch": 0.5954517372245595,
      "grad_norm": 4.010372161865234,
      "learning_rate": 4.008335785034814e-05,
      "logits/chosen": 3.6959316730499268,
      "logits/rejected": 3.768732786178589,
      "logps/chosen": -351.5884704589844,
      "logps/rejected": -328.69781494140625,
      "loss": 0.5883,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0379048585891724,
      "rewards/margins": 1.8276363611221313,
      "rewards/rejected": -2.8655409812927246,
      "step": 10120
    },
    {
      "epoch": 0.596628519313936,
      "grad_norm": 2.4597268104553223,
      "learning_rate": 4.006374423850152e-05,
      "logits/chosen": 3.712146043777466,
      "logits/rejected": 3.5706825256347656,
      "logps/chosen": -410.846435546875,
      "logps/rejected": -317.61004638671875,
      "loss": 0.3785,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.8576275110244751,
      "rewards/margins": 2.703763484954834,
      "rewards/rejected": -3.5613911151885986,
      "step": 10140
    },
    {
      "epoch": 0.5978053014033127,
      "grad_norm": 10.469403266906738,
      "learning_rate": 4.0045111307247226e-05,
      "logits/chosen": 3.7100281715393066,
      "logits/rejected": 3.701526165008545,
      "logps/chosen": -371.5936279296875,
      "logps/rejected": -299.91839599609375,
      "loss": 0.5407,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.35248667001724243,
      "rewards/margins": 2.475731134414673,
      "rewards/rejected": -2.8282177448272705,
      "step": 10160
    },
    {
      "epoch": 0.5989820834926892,
      "grad_norm": 3.744102716445923,
      "learning_rate": 4.002549769540061e-05,
      "logits/chosen": 3.7758400440216064,
      "logits/rejected": 3.825547695159912,
      "logps/chosen": -358.7080078125,
      "logps/rejected": -302.80816650390625,
      "loss": 0.4803,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.4031241536140442,
      "rewards/margins": 2.0833280086517334,
      "rewards/rejected": -2.486452102661133,
      "step": 10180
    },
    {
      "epoch": 0.6001588655820659,
      "grad_norm": 6.293105602264404,
      "learning_rate": 4.000588408355399e-05,
      "logits/chosen": 3.700230836868286,
      "logits/rejected": 3.6826653480529785,
      "logps/chosen": -392.03057861328125,
      "logps/rejected": -308.2869567871094,
      "loss": 0.5318,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.3367268741130829,
      "rewards/margins": 2.6241369247436523,
      "rewards/rejected": -2.9608638286590576,
      "step": 10200
    },
    {
      "epoch": 0.6013356476714424,
      "grad_norm": 1.1415055990219116,
      "learning_rate": 3.998627047170737e-05,
      "logits/chosen": 3.8962905406951904,
      "logits/rejected": 3.8477110862731934,
      "logps/chosen": -408.13409423828125,
      "logps/rejected": -332.0195617675781,
      "loss": 0.4956,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.2462082803249359,
      "rewards/margins": 2.3246800899505615,
      "rewards/rejected": -2.5708882808685303,
      "step": 10220
    },
    {
      "epoch": 0.6025124297608191,
      "grad_norm": 4.019266605377197,
      "learning_rate": 3.9966656859860744e-05,
      "logits/chosen": 4.281620502471924,
      "logits/rejected": 4.1698784828186035,
      "logps/chosen": -389.727783203125,
      "logps/rejected": -332.2115173339844,
      "loss": 0.683,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.3979181051254272,
      "rewards/margins": 1.7465887069702148,
      "rewards/rejected": -3.1445069313049316,
      "step": 10240
    },
    {
      "epoch": 0.6036892118501956,
      "grad_norm": 1.5333610773086548,
      "learning_rate": 3.994704324801412e-05,
      "logits/chosen": 3.781425952911377,
      "logits/rejected": 3.76295804977417,
      "logps/chosen": -347.7422790527344,
      "logps/rejected": -268.28857421875,
      "loss": 0.3491,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6057337522506714,
      "rewards/margins": 2.2166829109191895,
      "rewards/rejected": -2.8224165439605713,
      "step": 10260
    },
    {
      "epoch": 0.6048659939395722,
      "grad_norm": 2.29229474067688,
      "learning_rate": 3.99274296361675e-05,
      "logits/chosen": 3.8716073036193848,
      "logits/rejected": 3.8684165477752686,
      "logps/chosen": -342.47564697265625,
      "logps/rejected": -322.8580017089844,
      "loss": 0.432,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.4168795049190521,
      "rewards/margins": 2.175574541091919,
      "rewards/rejected": -2.592453956604004,
      "step": 10280
    },
    {
      "epoch": 0.6060427760289488,
      "grad_norm": 0.6295045614242554,
      "learning_rate": 3.990781602432088e-05,
      "logits/chosen": 3.8203532695770264,
      "logits/rejected": 3.8152618408203125,
      "logps/chosen": -351.2848205566406,
      "logps/rejected": -318.57373046875,
      "loss": 0.5481,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8109952807426453,
      "rewards/margins": 1.8770519495010376,
      "rewards/rejected": -2.688047170639038,
      "step": 10300
    },
    {
      "epoch": 0.6072195581183254,
      "grad_norm": 1.6289548873901367,
      "learning_rate": 3.9888202412474255e-05,
      "logits/chosen": 3.9323437213897705,
      "logits/rejected": 3.755842924118042,
      "logps/chosen": -379.06915283203125,
      "logps/rejected": -327.1470031738281,
      "loss": 0.3367,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.41850751638412476,
      "rewards/margins": 2.886793613433838,
      "rewards/rejected": -3.3053011894226074,
      "step": 10320
    },
    {
      "epoch": 0.6083963402077021,
      "grad_norm": 2.7853963375091553,
      "learning_rate": 3.986858880062764e-05,
      "logits/chosen": 3.8825860023498535,
      "logits/rejected": 3.947300434112549,
      "logps/chosen": -415.7191467285156,
      "logps/rejected": -300.0572204589844,
      "loss": 0.439,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9666716456413269,
      "rewards/margins": 2.2655410766601562,
      "rewards/rejected": -3.232212781906128,
      "step": 10340
    },
    {
      "epoch": 0.6095731222970786,
      "grad_norm": 7.26652717590332,
      "learning_rate": 3.984897518878102e-05,
      "logits/chosen": 3.5730698108673096,
      "logits/rejected": 3.4470934867858887,
      "logps/chosen": -349.4699401855469,
      "logps/rejected": -270.6104431152344,
      "loss": 0.3847,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.49590712785720825,
      "rewards/margins": 2.5671496391296387,
      "rewards/rejected": -3.063056707382202,
      "step": 10360
    },
    {
      "epoch": 0.6107499043864553,
      "grad_norm": 1.2005707025527954,
      "learning_rate": 3.982936157693439e-05,
      "logits/chosen": 3.7221291065216064,
      "logits/rejected": 3.708043336868286,
      "logps/chosen": -340.41015625,
      "logps/rejected": -264.90997314453125,
      "loss": 0.3505,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.6508492231369019,
      "rewards/margins": 2.1646969318389893,
      "rewards/rejected": -2.8155460357666016,
      "step": 10380
    },
    {
      "epoch": 0.6119266864758318,
      "grad_norm": 2.3904221057891846,
      "learning_rate": 3.980974796508777e-05,
      "logits/chosen": 3.5426182746887207,
      "logits/rejected": 3.537550687789917,
      "logps/chosen": -413.6368103027344,
      "logps/rejected": -326.1271057128906,
      "loss": 0.4592,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2456398010253906,
      "rewards/margins": 2.4870667457580566,
      "rewards/rejected": -3.7327067852020264,
      "step": 10400
    },
    {
      "epoch": 0.6131034685652085,
      "grad_norm": 4.3281683921813965,
      "learning_rate": 3.979013435324115e-05,
      "logits/chosen": 3.831458568572998,
      "logits/rejected": 3.6961045265197754,
      "logps/chosen": -380.2304382324219,
      "logps/rejected": -329.0843811035156,
      "loss": 0.4728,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7963274121284485,
      "rewards/margins": 2.7863807678222656,
      "rewards/rejected": -3.5827083587646484,
      "step": 10420
    },
    {
      "epoch": 0.614280250654585,
      "grad_norm": 1.6930829286575317,
      "learning_rate": 3.977052074139453e-05,
      "logits/chosen": 3.7384769916534424,
      "logits/rejected": 3.729480743408203,
      "logps/chosen": -388.9001159667969,
      "logps/rejected": -290.043701171875,
      "loss": 0.5569,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6283546090126038,
      "rewards/margins": 2.218670606613159,
      "rewards/rejected": -2.8470253944396973,
      "step": 10440
    },
    {
      "epoch": 0.6154570327439617,
      "grad_norm": 0.08745571970939636,
      "learning_rate": 3.975090712954791e-05,
      "logits/chosen": 3.9061119556427,
      "logits/rejected": 3.890475034713745,
      "logps/chosen": -394.5457763671875,
      "logps/rejected": -342.4004821777344,
      "loss": 0.3093,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.12756243348121643,
      "rewards/margins": 3.181292772293091,
      "rewards/rejected": -3.3088550567626953,
      "step": 10460
    },
    {
      "epoch": 0.6166338148333382,
      "grad_norm": 5.839005470275879,
      "learning_rate": 3.9731293517701283e-05,
      "logits/chosen": 3.946230411529541,
      "logits/rejected": 3.85614013671875,
      "logps/chosen": -410.0123596191406,
      "logps/rejected": -321.21173095703125,
      "loss": 0.619,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.623237669467926,
      "rewards/margins": 2.656721830368042,
      "rewards/rejected": -3.2799594402313232,
      "step": 10480
    },
    {
      "epoch": 0.6178105969227148,
      "grad_norm": 2.372175931930542,
      "learning_rate": 3.9711679905854666e-05,
      "logits/chosen": 3.9233450889587402,
      "logits/rejected": 3.979177951812744,
      "logps/chosen": -377.11383056640625,
      "logps/rejected": -321.3184509277344,
      "loss": 0.4093,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.45222869515419006,
      "rewards/margins": 2.6794843673706055,
      "rewards/rejected": -3.1317131519317627,
      "step": 10500
    },
    {
      "epoch": 0.6189873790120914,
      "grad_norm": 1.5822261571884155,
      "learning_rate": 3.969206629400804e-05,
      "logits/chosen": 3.645540952682495,
      "logits/rejected": 3.5609169006347656,
      "logps/chosen": -338.44451904296875,
      "logps/rejected": -279.9380187988281,
      "loss": 0.4677,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.04414087533950806,
      "rewards/margins": 2.514383316040039,
      "rewards/rejected": -2.5585238933563232,
      "step": 10520
    },
    {
      "epoch": 0.620164161101468,
      "grad_norm": 2.250962734222412,
      "learning_rate": 3.967245268216142e-05,
      "logits/chosen": 3.497591733932495,
      "logits/rejected": 3.5667216777801514,
      "logps/chosen": -336.3157958984375,
      "logps/rejected": -305.623779296875,
      "loss": 0.4281,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.47722309827804565,
      "rewards/margins": 2.1885385513305664,
      "rewards/rejected": -2.665761709213257,
      "step": 10540
    },
    {
      "epoch": 0.6213409431908447,
      "grad_norm": 2.776067018508911,
      "learning_rate": 3.96528390703148e-05,
      "logits/chosen": 3.807373523712158,
      "logits/rejected": 3.6469502449035645,
      "logps/chosen": -374.248046875,
      "logps/rejected": -297.08209228515625,
      "loss": 0.3826,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.42633256316185,
      "rewards/margins": 2.682258129119873,
      "rewards/rejected": -3.108590602874756,
      "step": 10560
    },
    {
      "epoch": 0.6225177252802212,
      "grad_norm": 3.975280284881592,
      "learning_rate": 3.963322545846818e-05,
      "logits/chosen": 3.7136313915252686,
      "logits/rejected": 3.66094970703125,
      "logps/chosen": -379.3625183105469,
      "logps/rejected": -312.40216064453125,
      "loss": 0.6085,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.37953415513038635,
      "rewards/margins": 2.5189340114593506,
      "rewards/rejected": -2.898468494415283,
      "step": 10580
    },
    {
      "epoch": 0.6236945073695979,
      "grad_norm": 8.064027786254883,
      "learning_rate": 3.961361184662156e-05,
      "logits/chosen": 3.9029250144958496,
      "logits/rejected": 3.8066654205322266,
      "logps/chosen": -338.9595031738281,
      "logps/rejected": -310.5757751464844,
      "loss": 0.5187,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.4613110423088074,
      "rewards/margins": 2.0933470726013184,
      "rewards/rejected": -2.5546579360961914,
      "step": 10600
    },
    {
      "epoch": 0.6248712894589744,
      "grad_norm": 4.2861409187316895,
      "learning_rate": 3.9593998234774936e-05,
      "logits/chosen": 3.8456807136535645,
      "logits/rejected": 3.701950788497925,
      "logps/chosen": -343.1411437988281,
      "logps/rejected": -308.65399169921875,
      "loss": 0.5232,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.31649452447891235,
      "rewards/margins": 3.09778094291687,
      "rewards/rejected": -3.414275646209717,
      "step": 10620
    },
    {
      "epoch": 0.6260480715483511,
      "grad_norm": 5.019137382507324,
      "learning_rate": 3.957438462292831e-05,
      "logits/chosen": 3.7923176288604736,
      "logits/rejected": 3.655773878097534,
      "logps/chosen": -328.4822692871094,
      "logps/rejected": -260.03009033203125,
      "loss": 0.4983,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.6177726984024048,
      "rewards/margins": 1.8550300598144531,
      "rewards/rejected": -2.4728026390075684,
      "step": 10640
    },
    {
      "epoch": 0.6272248536377276,
      "grad_norm": 0.14285396039485931,
      "learning_rate": 3.9554771011081695e-05,
      "logits/chosen": 3.927009105682373,
      "logits/rejected": 3.8686892986297607,
      "logps/chosen": -389.0267333984375,
      "logps/rejected": -332.15496826171875,
      "loss": 0.7226,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.21432533860206604,
      "rewards/margins": 1.7551212310791016,
      "rewards/rejected": -1.9694464206695557,
      "step": 10660
    },
    {
      "epoch": 0.6284016357271043,
      "grad_norm": 2.4403462409973145,
      "learning_rate": 3.953515739923507e-05,
      "logits/chosen": 3.814821243286133,
      "logits/rejected": 3.728163957595825,
      "logps/chosen": -359.9546813964844,
      "logps/rejected": -330.0853576660156,
      "loss": 0.4992,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7066159248352051,
      "rewards/margins": 2.254488229751587,
      "rewards/rejected": -2.961104154586792,
      "step": 10680
    },
    {
      "epoch": 0.6295784178164808,
      "grad_norm": 0.3322394788265228,
      "learning_rate": 3.951554378738845e-05,
      "logits/chosen": 3.9515891075134277,
      "logits/rejected": 3.8862502574920654,
      "logps/chosen": -399.7325744628906,
      "logps/rejected": -324.2010498046875,
      "loss": 0.4458,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.41052722930908203,
      "rewards/margins": 2.243195056915283,
      "rewards/rejected": -2.6537222862243652,
      "step": 10700
    },
    {
      "epoch": 0.6307551999058574,
      "grad_norm": 3.5887699127197266,
      "learning_rate": 3.949593017554183e-05,
      "logits/chosen": 3.7839081287384033,
      "logits/rejected": 3.7298922538757324,
      "logps/chosen": -389.9097595214844,
      "logps/rejected": -351.1708068847656,
      "loss": 0.5294,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.3843684792518616,
      "rewards/margins": 1.8156713247299194,
      "rewards/rejected": -2.200040102005005,
      "step": 10720
    },
    {
      "epoch": 0.631931981995234,
      "grad_norm": 0.8588842749595642,
      "learning_rate": 3.9476316563695206e-05,
      "logits/chosen": 3.8159492015838623,
      "logits/rejected": 3.7124252319335938,
      "logps/chosen": -396.94525146484375,
      "logps/rejected": -309.86444091796875,
      "loss": 0.5268,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1416690349578857,
      "rewards/margins": 2.4514312744140625,
      "rewards/rejected": -3.5931003093719482,
      "step": 10740
    },
    {
      "epoch": 0.6331087640846106,
      "grad_norm": 2.0367307662963867,
      "learning_rate": 3.945670295184858e-05,
      "logits/chosen": 3.806032657623291,
      "logits/rejected": 3.6318650245666504,
      "logps/chosen": -352.0440979003906,
      "logps/rejected": -268.0883483886719,
      "loss": 0.5397,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.0970970392227173,
      "rewards/margins": 2.0685698986053467,
      "rewards/rejected": -3.1656670570373535,
      "step": 10760
    },
    {
      "epoch": 0.6342855461739872,
      "grad_norm": 1.589085340499878,
      "learning_rate": 3.9437089340001965e-05,
      "logits/chosen": 3.488129138946533,
      "logits/rejected": 3.4671897888183594,
      "logps/chosen": -404.2030944824219,
      "logps/rejected": -318.4529113769531,
      "loss": 0.399,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8996671438217163,
      "rewards/margins": 3.1429286003112793,
      "rewards/rejected": -4.042595863342285,
      "step": 10780
    },
    {
      "epoch": 0.6354623282633638,
      "grad_norm": 3.818632125854492,
      "learning_rate": 3.941747572815534e-05,
      "logits/chosen": 3.5405335426330566,
      "logits/rejected": 3.2963154315948486,
      "logps/chosen": -368.08856201171875,
      "logps/rejected": -277.1580810546875,
      "loss": 0.5796,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.1782642602920532,
      "rewards/margins": 2.320197582244873,
      "rewards/rejected": -3.498461961746216,
      "step": 10800
    },
    {
      "epoch": 0.6366391103527405,
      "grad_norm": 0.88710618019104,
      "learning_rate": 3.9397862116308724e-05,
      "logits/chosen": 3.7463436126708984,
      "logits/rejected": 3.6486785411834717,
      "logps/chosen": -359.23809814453125,
      "logps/rejected": -328.37310791015625,
      "loss": 0.4687,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.8106966018676758,
      "rewards/margins": 2.059298038482666,
      "rewards/rejected": -2.869994640350342,
      "step": 10820
    },
    {
      "epoch": 0.637815892442117,
      "grad_norm": 0.8774216175079346,
      "learning_rate": 3.93782485044621e-05,
      "logits/chosen": 3.930572032928467,
      "logits/rejected": 3.8122544288635254,
      "logps/chosen": -383.33917236328125,
      "logps/rejected": -324.2052307128906,
      "loss": 0.4749,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.720755398273468,
      "rewards/margins": 2.364938735961914,
      "rewards/rejected": -3.0856940746307373,
      "step": 10840
    },
    {
      "epoch": 0.6389926745314937,
      "grad_norm": 0.8366966247558594,
      "learning_rate": 3.9358634892615476e-05,
      "logits/chosen": 3.7699081897735596,
      "logits/rejected": 3.8374366760253906,
      "logps/chosen": -380.703369140625,
      "logps/rejected": -331.3521423339844,
      "loss": 0.3276,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.23531489074230194,
      "rewards/margins": 2.758171558380127,
      "rewards/rejected": -2.9934864044189453,
      "step": 10860
    },
    {
      "epoch": 0.6401694566208702,
      "grad_norm": 1.9233510494232178,
      "learning_rate": 3.933902128076886e-05,
      "logits/chosen": 3.9035961627960205,
      "logits/rejected": 3.8966376781463623,
      "logps/chosen": -365.3447265625,
      "logps/rejected": -314.83453369140625,
      "loss": 0.5137,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.5771496891975403,
      "rewards/margins": 2.4526588916778564,
      "rewards/rejected": -3.029808521270752,
      "step": 10880
    },
    {
      "epoch": 0.6413462387102469,
      "grad_norm": 1.6213933229446411,
      "learning_rate": 3.9319407668922235e-05,
      "logits/chosen": 3.954158306121826,
      "logits/rejected": 3.8986029624938965,
      "logps/chosen": -420.7898864746094,
      "logps/rejected": -285.4742126464844,
      "loss": 0.3399,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.32425224781036377,
      "rewards/margins": 3.1232314109802246,
      "rewards/rejected": -3.447483777999878,
      "step": 10900
    },
    {
      "epoch": 0.6425230207996234,
      "grad_norm": 1.1383702754974365,
      "learning_rate": 3.929979405707561e-05,
      "logits/chosen": 3.8951504230499268,
      "logits/rejected": 3.847372055053711,
      "logps/chosen": -356.94964599609375,
      "logps/rejected": -309.5968322753906,
      "loss": 0.4061,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.8875120878219604,
      "rewards/margins": 2.321408271789551,
      "rewards/rejected": -3.2089202404022217,
      "step": 10920
    },
    {
      "epoch": 0.6436998028890001,
      "grad_norm": 0.708567202091217,
      "learning_rate": 3.928018044522899e-05,
      "logits/chosen": 3.947561264038086,
      "logits/rejected": 4.0071916580200195,
      "logps/chosen": -349.5021057128906,
      "logps/rejected": -284.8238525390625,
      "loss": 0.5169,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.43976449966430664,
      "rewards/margins": 2.571652889251709,
      "rewards/rejected": -3.0114171504974365,
      "step": 10940
    },
    {
      "epoch": 0.6448765849783766,
      "grad_norm": 1.7152172327041626,
      "learning_rate": 3.926056683338237e-05,
      "logits/chosen": 3.7345688343048096,
      "logits/rejected": 3.8526535034179688,
      "logps/chosen": -360.49627685546875,
      "logps/rejected": -336.50048828125,
      "loss": 0.3939,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.6555740833282471,
      "rewards/margins": 2.8428359031677246,
      "rewards/rejected": -3.4984099864959717,
      "step": 10960
    },
    {
      "epoch": 0.6460533670677532,
      "grad_norm": 3.9465696811676025,
      "learning_rate": 3.9240953221535745e-05,
      "logits/chosen": 3.8584113121032715,
      "logits/rejected": 3.8927245140075684,
      "logps/chosen": -429.708984375,
      "logps/rejected": -297.2660827636719,
      "loss": 0.3131,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -0.6479066014289856,
      "rewards/margins": 3.0898995399475098,
      "rewards/rejected": -3.7378058433532715,
      "step": 10980
    },
    {
      "epoch": 0.6472301491571298,
      "grad_norm": 0.21443027257919312,
      "learning_rate": 3.922133960968913e-05,
      "logits/chosen": 3.829437255859375,
      "logits/rejected": 3.9062416553497314,
      "logps/chosen": -371.8536682128906,
      "logps/rejected": -315.870849609375,
      "loss": 0.3513,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9627474546432495,
      "rewards/margins": 2.7390263080596924,
      "rewards/rejected": -3.7017738819122314,
      "step": 11000
    },
    {
      "epoch": 0.6484069312465064,
      "grad_norm": 4.127413272857666,
      "learning_rate": 3.9201725997842504e-05,
      "logits/chosen": 3.8493926525115967,
      "logits/rejected": 3.8785316944122314,
      "logps/chosen": -403.3135070800781,
      "logps/rejected": -338.81011962890625,
      "loss": 0.6021,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.877062201499939,
      "rewards/margins": 2.3528451919555664,
      "rewards/rejected": -3.229907274246216,
      "step": 11020
    },
    {
      "epoch": 0.649583713335883,
      "grad_norm": 1.9848891496658325,
      "learning_rate": 3.918211238599589e-05,
      "logits/chosen": 3.690217971801758,
      "logits/rejected": 3.607325792312622,
      "logps/chosen": -369.59771728515625,
      "logps/rejected": -289.2842102050781,
      "loss": 0.6352,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7100718021392822,
      "rewards/margins": 2.381958484649658,
      "rewards/rejected": -3.0920300483703613,
      "step": 11040
    },
    {
      "epoch": 0.6507604954252596,
      "grad_norm": 10.680717468261719,
      "learning_rate": 3.9162498774149256e-05,
      "logits/chosen": 3.6812281608581543,
      "logits/rejected": 3.674666166305542,
      "logps/chosen": -382.0979919433594,
      "logps/rejected": -300.69061279296875,
      "loss": 0.6338,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.5582936406135559,
      "rewards/margins": 2.0941762924194336,
      "rewards/rejected": -2.6524696350097656,
      "step": 11060
    },
    {
      "epoch": 0.6519372775146363,
      "grad_norm": 3.743762969970703,
      "learning_rate": 3.914288516230264e-05,
      "logits/chosen": 4.086502552032471,
      "logits/rejected": 3.8381245136260986,
      "logps/chosen": -391.9860534667969,
      "logps/rejected": -357.7206115722656,
      "loss": 0.6282,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9183775186538696,
      "rewards/margins": 2.2691256999969482,
      "rewards/rejected": -3.1875033378601074,
      "step": 11080
    },
    {
      "epoch": 0.6531140596040128,
      "grad_norm": 2.9790456295013428,
      "learning_rate": 3.912327155045602e-05,
      "logits/chosen": 3.868523359298706,
      "logits/rejected": 3.8383917808532715,
      "logps/chosen": -367.3097229003906,
      "logps/rejected": -343.83807373046875,
      "loss": 0.4677,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8482290506362915,
      "rewards/margins": 2.8730392456054688,
      "rewards/rejected": -3.72126841545105,
      "step": 11100
    },
    {
      "epoch": 0.6542908416933895,
      "grad_norm": 2.3988449573516846,
      "learning_rate": 3.91036579386094e-05,
      "logits/chosen": 3.6817562580108643,
      "logits/rejected": 3.644554615020752,
      "logps/chosen": -372.55352783203125,
      "logps/rejected": -290.31268310546875,
      "loss": 0.6337,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2909873723983765,
      "rewards/margins": 1.920636773109436,
      "rewards/rejected": -3.2116241455078125,
      "step": 11120
    },
    {
      "epoch": 0.655467623782766,
      "grad_norm": 3.6462481021881104,
      "learning_rate": 3.9084044326762774e-05,
      "logits/chosen": 3.8789761066436768,
      "logits/rejected": 3.8267338275909424,
      "logps/chosen": -347.7914733886719,
      "logps/rejected": -286.50469970703125,
      "loss": 0.5243,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5015170574188232,
      "rewards/margins": 2.0777788162231445,
      "rewards/rejected": -3.5792956352233887,
      "step": 11140
    },
    {
      "epoch": 0.6566444058721427,
      "grad_norm": 3.0349860191345215,
      "learning_rate": 3.906443071491616e-05,
      "logits/chosen": 3.9214470386505127,
      "logits/rejected": 3.820181369781494,
      "logps/chosen": -408.9368896484375,
      "logps/rejected": -307.22528076171875,
      "loss": 0.4332,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.10718919336795807,
      "rewards/margins": 2.7205233573913574,
      "rewards/rejected": -2.827712297439575,
      "step": 11160
    },
    {
      "epoch": 0.6578211879615192,
      "grad_norm": 0.8320520520210266,
      "learning_rate": 3.904481710306953e-05,
      "logits/chosen": 4.021834373474121,
      "logits/rejected": 4.03705358505249,
      "logps/chosen": -378.64678955078125,
      "logps/rejected": -316.4109802246094,
      "loss": 0.4709,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.19141675531864166,
      "rewards/margins": 2.0380308628082275,
      "rewards/rejected": -2.229447603225708,
      "step": 11180
    },
    {
      "epoch": 0.6589979700508958,
      "grad_norm": 1.970538854598999,
      "learning_rate": 3.902520349122291e-05,
      "logits/chosen": 4.025671482086182,
      "logits/rejected": 3.9214210510253906,
      "logps/chosen": -364.921630859375,
      "logps/rejected": -295.7309875488281,
      "loss": 0.632,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.4372468888759613,
      "rewards/margins": 2.240978240966797,
      "rewards/rejected": -2.678225040435791,
      "step": 11200
    },
    {
      "epoch": 0.6601747521402724,
      "grad_norm": 1.7295143604278564,
      "learning_rate": 3.9005589879376285e-05,
      "logits/chosen": 3.8902103900909424,
      "logits/rejected": 3.8997740745544434,
      "logps/chosen": -380.0694580078125,
      "logps/rejected": -291.707763671875,
      "loss": 0.4706,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.2136422097682953,
      "rewards/margins": 2.274021863937378,
      "rewards/rejected": -2.487664222717285,
      "step": 11220
    },
    {
      "epoch": 0.661351534229649,
      "grad_norm": 1.2106316089630127,
      "learning_rate": 3.898597626752967e-05,
      "logits/chosen": 3.96557354927063,
      "logits/rejected": 3.9330124855041504,
      "logps/chosen": -311.298583984375,
      "logps/rejected": -321.25506591796875,
      "loss": 0.4612,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.3484829068183899,
      "rewards/margins": 2.0852479934692383,
      "rewards/rejected": -2.4337310791015625,
      "step": 11240
    },
    {
      "epoch": 0.6625283163190256,
      "grad_norm": 2.345405340194702,
      "learning_rate": 3.896636265568305e-05,
      "logits/chosen": 4.046196937561035,
      "logits/rejected": 3.873466968536377,
      "logps/chosen": -362.2208251953125,
      "logps/rejected": -263.9423522949219,
      "loss": 0.4392,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.1465870887041092,
      "rewards/margins": 2.3199448585510254,
      "rewards/rejected": -2.466531991958618,
      "step": 11260
    },
    {
      "epoch": 0.6637050984084022,
      "grad_norm": 2.7596805095672607,
      "learning_rate": 3.894674904383642e-05,
      "logits/chosen": 4.103714466094971,
      "logits/rejected": 3.941183090209961,
      "logps/chosen": -411.5272521972656,
      "logps/rejected": -317.4466857910156,
      "loss": 0.4317,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.15006260573863983,
      "rewards/margins": 2.4205753803253174,
      "rewards/rejected": -2.5706379413604736,
      "step": 11280
    },
    {
      "epoch": 0.6648818804977789,
      "grad_norm": 1.2457619905471802,
      "learning_rate": 3.89271354319898e-05,
      "logits/chosen": 4.170008659362793,
      "logits/rejected": 3.9265589714050293,
      "logps/chosen": -388.1482849121094,
      "logps/rejected": -316.13140869140625,
      "loss": 0.4536,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.8783243894577026,
      "rewards/margins": 2.088392734527588,
      "rewards/rejected": -2.966717481613159,
      "step": 11300
    },
    {
      "epoch": 0.6660586625871554,
      "grad_norm": 3.1607072353363037,
      "learning_rate": 3.8907521820143186e-05,
      "logits/chosen": 3.94193959236145,
      "logits/rejected": 3.9579970836639404,
      "logps/chosen": -415.1266174316406,
      "logps/rejected": -345.5721130371094,
      "loss": 0.6034,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7020542025566101,
      "rewards/margins": 2.0717196464538574,
      "rewards/rejected": -2.7737743854522705,
      "step": 11320
    },
    {
      "epoch": 0.6672354446765321,
      "grad_norm": 2.1778666973114014,
      "learning_rate": 3.888790820829656e-05,
      "logits/chosen": 3.8781790733337402,
      "logits/rejected": 3.8117668628692627,
      "logps/chosen": -366.17742919921875,
      "logps/rejected": -310.76702880859375,
      "loss": 0.5972,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.12036869674921036,
      "rewards/margins": 2.2058491706848145,
      "rewards/rejected": -2.3262181282043457,
      "step": 11340
    },
    {
      "epoch": 0.6684122267659086,
      "grad_norm": 1.2737903594970703,
      "learning_rate": 3.886829459644994e-05,
      "logits/chosen": 3.863034725189209,
      "logits/rejected": 3.9607722759246826,
      "logps/chosen": -405.376708984375,
      "logps/rejected": -332.0345153808594,
      "loss": 0.4939,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.18343469500541687,
      "rewards/margins": 2.427293300628662,
      "rewards/rejected": -2.6107280254364014,
      "step": 11360
    },
    {
      "epoch": 0.6695890088552853,
      "grad_norm": 2.0906453132629395,
      "learning_rate": 3.8848680984603314e-05,
      "logits/chosen": 3.730457305908203,
      "logits/rejected": 3.7114243507385254,
      "logps/chosen": -354.231201171875,
      "logps/rejected": -265.9486999511719,
      "loss": 0.4998,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.009365275502204895,
      "rewards/margins": 2.1052565574645996,
      "rewards/rejected": -2.0958914756774902,
      "step": 11380
    },
    {
      "epoch": 0.6707657909446618,
      "grad_norm": 0.642417311668396,
      "learning_rate": 3.8829067372756696e-05,
      "logits/chosen": 3.9253456592559814,
      "logits/rejected": 3.7596030235290527,
      "logps/chosen": -370.12042236328125,
      "logps/rejected": -293.91131591796875,
      "loss": 0.4032,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.0503334179520607,
      "rewards/margins": 2.8270957469940186,
      "rewards/rejected": -2.7767622470855713,
      "step": 11400
    },
    {
      "epoch": 0.6719425730340384,
      "grad_norm": 0.22618074715137482,
      "learning_rate": 3.880945376091007e-05,
      "logits/chosen": 4.103545188903809,
      "logits/rejected": 4.013925075531006,
      "logps/chosen": -379.4058532714844,
      "logps/rejected": -297.466796875,
      "loss": 0.457,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.014878633432090282,
      "rewards/margins": 2.229170083999634,
      "rewards/rejected": -2.244048595428467,
      "step": 11420
    },
    {
      "epoch": 0.673119355123415,
      "grad_norm": 1.600756049156189,
      "learning_rate": 3.878984014906345e-05,
      "logits/chosen": 3.6988894939422607,
      "logits/rejected": 3.6285252571105957,
      "logps/chosen": -367.34075927734375,
      "logps/rejected": -309.12841796875,
      "loss": 0.4898,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": 0.11320449411869049,
      "rewards/margins": 2.1107029914855957,
      "rewards/rejected": -1.9974982738494873,
      "step": 11440
    },
    {
      "epoch": 0.6742961372127916,
      "grad_norm": 11.340181350708008,
      "learning_rate": 3.877022653721683e-05,
      "logits/chosen": 3.7392101287841797,
      "logits/rejected": 3.8517558574676514,
      "logps/chosen": -370.2089538574219,
      "logps/rejected": -320.1678161621094,
      "loss": 0.5696,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.2278086245059967,
      "rewards/margins": 2.1779625415802,
      "rewards/rejected": -1.9501537084579468,
      "step": 11460
    },
    {
      "epoch": 0.6754729193021682,
      "grad_norm": 0.3403036296367645,
      "learning_rate": 3.8750612925370214e-05,
      "logits/chosen": 3.874586820602417,
      "logits/rejected": 3.978517532348633,
      "logps/chosen": -418.45263671875,
      "logps/rejected": -312.27947998046875,
      "loss": 0.4928,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.2009810507297516,
      "rewards/margins": 1.992194414138794,
      "rewards/rejected": -2.1931755542755127,
      "step": 11480
    },
    {
      "epoch": 0.6766497013915448,
      "grad_norm": 4.6714959144592285,
      "learning_rate": 3.8730999313523583e-05,
      "logits/chosen": 3.936187267303467,
      "logits/rejected": 3.833300828933716,
      "logps/chosen": -355.01104736328125,
      "logps/rejected": -324.154296875,
      "loss": 0.6138,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.1876925677061081,
      "rewards/margins": 2.179755449295044,
      "rewards/rejected": -2.367448091506958,
      "step": 11500
    },
    {
      "epoch": 0.6778264834809214,
      "grad_norm": 0.688289999961853,
      "learning_rate": 3.8711385701676966e-05,
      "logits/chosen": 3.9333672523498535,
      "logits/rejected": 3.7630512714385986,
      "logps/chosen": -425.7554626464844,
      "logps/rejected": -336.40264892578125,
      "loss": 0.39,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": 0.1828763335943222,
      "rewards/margins": 3.0146894454956055,
      "rewards/rejected": -2.831813335418701,
      "step": 11520
    },
    {
      "epoch": 0.679003265570298,
      "grad_norm": 0.8318092823028564,
      "learning_rate": 3.869177208983034e-05,
      "logits/chosen": 3.9135944843292236,
      "logits/rejected": 3.9099984169006348,
      "logps/chosen": -361.8121337890625,
      "logps/rejected": -328.88433837890625,
      "loss": 0.4789,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.049564674496650696,
      "rewards/margins": 2.1561214923858643,
      "rewards/rejected": -2.1065571308135986,
      "step": 11540
    },
    {
      "epoch": 0.6801800476596747,
      "grad_norm": 2.323601722717285,
      "learning_rate": 3.8672158477983725e-05,
      "logits/chosen": 3.8548836708068848,
      "logits/rejected": 3.9013214111328125,
      "logps/chosen": -351.3851013183594,
      "logps/rejected": -275.85302734375,
      "loss": 0.5727,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.3890320658683777,
      "rewards/margins": 1.6840260028839111,
      "rewards/rejected": -2.0730581283569336,
      "step": 11560
    },
    {
      "epoch": 0.6813568297490512,
      "grad_norm": 2.2209136486053467,
      "learning_rate": 3.86525448661371e-05,
      "logits/chosen": 3.9906158447265625,
      "logits/rejected": 3.96260142326355,
      "logps/chosen": -387.7002258300781,
      "logps/rejected": -300.61187744140625,
      "loss": 0.4013,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.07162748277187347,
      "rewards/margins": 2.3378474712371826,
      "rewards/rejected": -2.2662200927734375,
      "step": 11580
    },
    {
      "epoch": 0.6825336118384279,
      "grad_norm": 2.0426180362701416,
      "learning_rate": 3.863293125429048e-05,
      "logits/chosen": 4.132498264312744,
      "logits/rejected": 4.179394721984863,
      "logps/chosen": -344.60693359375,
      "logps/rejected": -290.3832702636719,
      "loss": 0.4279,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.36956921219825745,
      "rewards/margins": 2.192107677459717,
      "rewards/rejected": -2.5616769790649414,
      "step": 11600
    },
    {
      "epoch": 0.6837103939278044,
      "grad_norm": 7.956020355224609,
      "learning_rate": 3.861331764244386e-05,
      "logits/chosen": 3.877255916595459,
      "logits/rejected": 3.7686798572540283,
      "logps/chosen": -380.34954833984375,
      "logps/rejected": -333.09100341796875,
      "loss": 0.5016,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.19746720790863037,
      "rewards/margins": 2.5209686756134033,
      "rewards/rejected": -2.718435764312744,
      "step": 11620
    },
    {
      "epoch": 0.684887176017181,
      "grad_norm": 1.4588714838027954,
      "learning_rate": 3.8593704030597236e-05,
      "logits/chosen": 4.047036647796631,
      "logits/rejected": 3.945298433303833,
      "logps/chosen": -385.9853515625,
      "logps/rejected": -328.3312683105469,
      "loss": 0.4025,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.2721042037010193,
      "rewards/margins": 2.649458646774292,
      "rewards/rejected": -2.921562910079956,
      "step": 11640
    },
    {
      "epoch": 0.6860639581065576,
      "grad_norm": 1.304909348487854,
      "learning_rate": 3.857409041875061e-05,
      "logits/chosen": 3.6703593730926514,
      "logits/rejected": 3.6756324768066406,
      "logps/chosen": -416.01171875,
      "logps/rejected": -323.350341796875,
      "loss": 0.4178,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3278372287750244,
      "rewards/margins": 2.1155943870544434,
      "rewards/rejected": -3.443431854248047,
      "step": 11660
    },
    {
      "epoch": 0.6872407401959342,
      "grad_norm": 1.4466462135314941,
      "learning_rate": 3.8554476806903995e-05,
      "logits/chosen": 4.011279582977295,
      "logits/rejected": 3.8938660621643066,
      "logps/chosen": -392.8756408691406,
      "logps/rejected": -346.481689453125,
      "loss": 0.461,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.2953556776046753,
      "rewards/margins": 2.8493573665618896,
      "rewards/rejected": -4.144712924957275,
      "step": 11680
    },
    {
      "epoch": 0.6884175222853108,
      "grad_norm": 1.9318833351135254,
      "learning_rate": 3.853486319505737e-05,
      "logits/chosen": 3.9577605724334717,
      "logits/rejected": 3.8217978477478027,
      "logps/chosen": -408.62408447265625,
      "logps/rejected": -318.1331481933594,
      "loss": 0.6506,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8171923756599426,
      "rewards/margins": 2.393833875656128,
      "rewards/rejected": -3.2110259532928467,
      "step": 11700
    },
    {
      "epoch": 0.6895943043746874,
      "grad_norm": 2.2602956295013428,
      "learning_rate": 3.851524958321075e-05,
      "logits/chosen": 3.6175003051757812,
      "logits/rejected": 3.557724714279175,
      "logps/chosen": -347.2764892578125,
      "logps/rejected": -310.8990783691406,
      "loss": 0.3604,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1077053546905518,
      "rewards/margins": 2.2149817943573,
      "rewards/rejected": -3.3226866722106934,
      "step": 11720
    },
    {
      "epoch": 0.690771086464064,
      "grad_norm": 1.7589575052261353,
      "learning_rate": 3.849563597136413e-05,
      "logits/chosen": 4.098244667053223,
      "logits/rejected": 4.080811977386475,
      "logps/chosen": -447.43115234375,
      "logps/rejected": -349.65283203125,
      "loss": 0.3854,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1282646656036377,
      "rewards/margins": 2.8313214778900146,
      "rewards/rejected": -3.9595863819122314,
      "step": 11740
    },
    {
      "epoch": 0.6919478685534406,
      "grad_norm": 1.802391529083252,
      "learning_rate": 3.8476022359517506e-05,
      "logits/chosen": 3.640625476837158,
      "logits/rejected": 3.499756336212158,
      "logps/chosen": -395.354248046875,
      "logps/rejected": -348.6343688964844,
      "loss": 0.5309,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.4984848499298096,
      "rewards/margins": 2.6607139110565186,
      "rewards/rejected": -4.159199237823486,
      "step": 11760
    },
    {
      "epoch": 0.6931246506428173,
      "grad_norm": 1.8080052137374878,
      "learning_rate": 3.845640874767089e-05,
      "logits/chosen": 3.637943744659424,
      "logits/rejected": 3.7217864990234375,
      "logps/chosen": -373.31793212890625,
      "logps/rejected": -338.18988037109375,
      "loss": 0.5668,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.736060380935669,
      "rewards/margins": 1.5454928874969482,
      "rewards/rejected": -3.281553268432617,
      "step": 11780
    },
    {
      "epoch": 0.6943014327321938,
      "grad_norm": 1.7786955833435059,
      "learning_rate": 3.8436795135824265e-05,
      "logits/chosen": 3.8577582836151123,
      "logits/rejected": 3.625627040863037,
      "logps/chosen": -429.936279296875,
      "logps/rejected": -340.3675842285156,
      "loss": 0.402,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4930089712142944,
      "rewards/margins": 2.843329429626465,
      "rewards/rejected": -4.336338996887207,
      "step": 11800
    },
    {
      "epoch": 0.6954782148215705,
      "grad_norm": 2.1414783000946045,
      "learning_rate": 3.841718152397764e-05,
      "logits/chosen": 3.5694117546081543,
      "logits/rejected": 3.650078535079956,
      "logps/chosen": -406.35107421875,
      "logps/rejected": -332.12017822265625,
      "loss": 0.5297,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3335399627685547,
      "rewards/margins": 2.396514654159546,
      "rewards/rejected": -3.7300548553466797,
      "step": 11820
    },
    {
      "epoch": 0.696654996910947,
      "grad_norm": 2.417738437652588,
      "learning_rate": 3.8397567912131024e-05,
      "logits/chosen": 3.983675003051758,
      "logits/rejected": 3.9408154487609863,
      "logps/chosen": -426.5985412597656,
      "logps/rejected": -336.82427978515625,
      "loss": 0.4367,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4819164276123047,
      "rewards/margins": 2.841264486312866,
      "rewards/rejected": -4.323180675506592,
      "step": 11840
    },
    {
      "epoch": 0.6978317790003236,
      "grad_norm": 1.1814918518066406,
      "learning_rate": 3.83779543002844e-05,
      "logits/chosen": 3.692051649093628,
      "logits/rejected": 3.682438611984253,
      "logps/chosen": -347.19439697265625,
      "logps/rejected": -263.77923583984375,
      "loss": 0.3929,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9982585906982422,
      "rewards/margins": 2.108018398284912,
      "rewards/rejected": -3.1062769889831543,
      "step": 11860
    },
    {
      "epoch": 0.6990085610897002,
      "grad_norm": 0.659858226776123,
      "learning_rate": 3.8358340688437776e-05,
      "logits/chosen": 3.6471176147460938,
      "logits/rejected": 3.62507700920105,
      "logps/chosen": -428.0696716308594,
      "logps/rejected": -332.91656494140625,
      "loss": 0.6476,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9597005844116211,
      "rewards/margins": 2.0924184322357178,
      "rewards/rejected": -3.052119016647339,
      "step": 11880
    },
    {
      "epoch": 0.7001853431790768,
      "grad_norm": 1.1385401487350464,
      "learning_rate": 3.833872707659116e-05,
      "logits/chosen": 3.9570059776306152,
      "logits/rejected": 3.8981127738952637,
      "logps/chosen": -381.13873291015625,
      "logps/rejected": -332.7221374511719,
      "loss": 0.4289,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.0627706050872803,
      "rewards/margins": 2.7088074684143066,
      "rewards/rejected": -3.771577835083008,
      "step": 11900
    },
    {
      "epoch": 0.7013621252684534,
      "grad_norm": 2.068930149078369,
      "learning_rate": 3.8319113464744534e-05,
      "logits/chosen": 3.8178112506866455,
      "logits/rejected": 3.7962212562561035,
      "logps/chosen": -403.1875,
      "logps/rejected": -292.40093994140625,
      "loss": 0.419,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.292883276939392,
      "rewards/margins": 2.5054874420166016,
      "rewards/rejected": -3.798370361328125,
      "step": 11920
    },
    {
      "epoch": 0.70253890735783,
      "grad_norm": 1.612763524055481,
      "learning_rate": 3.829949985289791e-05,
      "logits/chosen": 3.830160617828369,
      "logits/rejected": 3.687978744506836,
      "logps/chosen": -368.54095458984375,
      "logps/rejected": -365.9364013671875,
      "loss": 0.4947,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2722547054290771,
      "rewards/margins": 1.9827287197113037,
      "rewards/rejected": -3.254983425140381,
      "step": 11940
    },
    {
      "epoch": 0.7037156894472066,
      "grad_norm": 4.790899753570557,
      "learning_rate": 3.827988624105129e-05,
      "logits/chosen": 3.6841506958007812,
      "logits/rejected": 3.7797350883483887,
      "logps/chosen": -387.5303039550781,
      "logps/rejected": -329.5262451171875,
      "loss": 0.6393,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4035065174102783,
      "rewards/margins": 2.4201643466949463,
      "rewards/rejected": -3.8236708641052246,
      "step": 11960
    },
    {
      "epoch": 0.7048924715365832,
      "grad_norm": 2.678483724594116,
      "learning_rate": 3.826027262920467e-05,
      "logits/chosen": 3.878272533416748,
      "logits/rejected": 3.903427839279175,
      "logps/chosen": -378.01263427734375,
      "logps/rejected": -294.8495178222656,
      "loss": 0.4712,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5719974040985107,
      "rewards/margins": 2.6882808208465576,
      "rewards/rejected": -4.26027774810791,
      "step": 11980
    },
    {
      "epoch": 0.7060692536259598,
      "grad_norm": 1.7557591199874878,
      "learning_rate": 3.824065901735805e-05,
      "logits/chosen": 3.7776541709899902,
      "logits/rejected": 3.630087375640869,
      "logps/chosen": -398.6932067871094,
      "logps/rejected": -297.03961181640625,
      "loss": 0.5956,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.4807746410369873,
      "rewards/margins": 1.7653357982635498,
      "rewards/rejected": -3.246110200881958,
      "step": 12000
    },
    {
      "epoch": 0.7072460357153364,
      "grad_norm": 1.715224266052246,
      "learning_rate": 3.822104540551142e-05,
      "logits/chosen": 3.7299652099609375,
      "logits/rejected": 3.705270290374756,
      "logps/chosen": -402.57440185546875,
      "logps/rejected": -325.5278015136719,
      "loss": 0.5413,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7708484530448914,
      "rewards/margins": 2.464733362197876,
      "rewards/rejected": -3.235581874847412,
      "step": 12020
    },
    {
      "epoch": 0.7084228178047131,
      "grad_norm": 3.507463216781616,
      "learning_rate": 3.8201431793664804e-05,
      "logits/chosen": 3.9251933097839355,
      "logits/rejected": 4.054594039916992,
      "logps/chosen": -445.94940185546875,
      "logps/rejected": -336.7200622558594,
      "loss": 0.381,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.39437445998191833,
      "rewards/margins": 3.274750232696533,
      "rewards/rejected": -2.880375623703003,
      "step": 12040
    },
    {
      "epoch": 0.7095995998940896,
      "grad_norm": 4.515529632568359,
      "learning_rate": 3.818181818181819e-05,
      "logits/chosen": 3.9571175575256348,
      "logits/rejected": 3.800602436065674,
      "logps/chosen": -366.25115966796875,
      "logps/rejected": -320.5111083984375,
      "loss": 0.453,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.4258877635002136,
      "rewards/margins": 2.6768598556518555,
      "rewards/rejected": -3.1027474403381348,
      "step": 12060
    },
    {
      "epoch": 0.7107763819834663,
      "grad_norm": 2.7295429706573486,
      "learning_rate": 3.816220456997156e-05,
      "logits/chosen": 4.053861141204834,
      "logits/rejected": 4.067513465881348,
      "logps/chosen": -421.5127868652344,
      "logps/rejected": -331.89129638671875,
      "loss": 0.4143,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.3730427920818329,
      "rewards/margins": 2.4367804527282715,
      "rewards/rejected": -2.809823513031006,
      "step": 12080
    },
    {
      "epoch": 0.7119531640728428,
      "grad_norm": 4.386795520782471,
      "learning_rate": 3.814259095812494e-05,
      "logits/chosen": 3.8238959312438965,
      "logits/rejected": 3.7516086101531982,
      "logps/chosen": -345.7614440917969,
      "logps/rejected": -282.26776123046875,
      "loss": 0.7146,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.7740570306777954,
      "rewards/margins": 1.8542207479476929,
      "rewards/rejected": -2.6282780170440674,
      "step": 12100
    },
    {
      "epoch": 0.7131299461622194,
      "grad_norm": 5.571606159210205,
      "learning_rate": 3.812297734627832e-05,
      "logits/chosen": 3.873119831085205,
      "logits/rejected": 4.00173282623291,
      "logps/chosen": -370.38592529296875,
      "logps/rejected": -321.59075927734375,
      "loss": 0.4449,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9617918729782104,
      "rewards/margins": 2.048506498336792,
      "rewards/rejected": -3.010298490524292,
      "step": 12120
    },
    {
      "epoch": 0.714306728251596,
      "grad_norm": 0.5364222526550293,
      "learning_rate": 3.81033637344317e-05,
      "logits/chosen": 3.8888049125671387,
      "logits/rejected": 3.7949156761169434,
      "logps/chosen": -363.5220947265625,
      "logps/rejected": -287.7674560546875,
      "loss": 0.4657,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.6535083055496216,
      "rewards/margins": 2.4754140377044678,
      "rewards/rejected": -3.1289222240448,
      "step": 12140
    },
    {
      "epoch": 0.7154835103409726,
      "grad_norm": 5.400298118591309,
      "learning_rate": 3.8083750122585074e-05,
      "logits/chosen": 4.1959638595581055,
      "logits/rejected": 4.114689826965332,
      "logps/chosen": -452.26177978515625,
      "logps/rejected": -355.66180419921875,
      "loss": 0.4591,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6889615654945374,
      "rewards/margins": 2.5795178413391113,
      "rewards/rejected": -3.268479585647583,
      "step": 12160
    },
    {
      "epoch": 0.7166602924303492,
      "grad_norm": 2.818758010864258,
      "learning_rate": 3.806413651073845e-05,
      "logits/chosen": 3.6566176414489746,
      "logits/rejected": 3.4677634239196777,
      "logps/chosen": -414.321044921875,
      "logps/rejected": -356.3074035644531,
      "loss": 0.7976,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.253753900527954,
      "rewards/margins": 1.8878997564315796,
      "rewards/rejected": -3.141653537750244,
      "step": 12180
    },
    {
      "epoch": 0.7178370745197258,
      "grad_norm": 2.085658311843872,
      "learning_rate": 3.804452289889183e-05,
      "logits/chosen": 3.7431411743164062,
      "logits/rejected": 3.7674903869628906,
      "logps/chosen": -398.323974609375,
      "logps/rejected": -299.8079528808594,
      "loss": 0.4763,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9151671528816223,
      "rewards/margins": 2.3210604190826416,
      "rewards/rejected": -3.236227512359619,
      "step": 12200
    },
    {
      "epoch": 0.7190138566091024,
      "grad_norm": 1.878113865852356,
      "learning_rate": 3.8024909287045216e-05,
      "logits/chosen": 3.8271918296813965,
      "logits/rejected": 3.86207914352417,
      "logps/chosen": -386.58978271484375,
      "logps/rejected": -308.7217102050781,
      "loss": 0.6217,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.536507785320282,
      "rewards/margins": 1.6482696533203125,
      "rewards/rejected": -2.1847777366638184,
      "step": 12220
    },
    {
      "epoch": 0.720190638698479,
      "grad_norm": 0.9049375653266907,
      "learning_rate": 3.8005295675198585e-05,
      "logits/chosen": 3.963141679763794,
      "logits/rejected": 3.886000156402588,
      "logps/chosen": -358.22662353515625,
      "logps/rejected": -339.790283203125,
      "loss": 0.2832,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6719496846199036,
      "rewards/margins": 2.946201801300049,
      "rewards/rejected": -3.6181511878967285,
      "step": 12240
    },
    {
      "epoch": 0.7213674207878557,
      "grad_norm": 1.640046238899231,
      "learning_rate": 3.798568206335197e-05,
      "logits/chosen": 3.7473273277282715,
      "logits/rejected": 3.583251476287842,
      "logps/chosen": -399.01220703125,
      "logps/rejected": -307.20245361328125,
      "loss": 0.5807,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8892642855644226,
      "rewards/margins": 2.1753411293029785,
      "rewards/rejected": -3.064605236053467,
      "step": 12260
    },
    {
      "epoch": 0.7225442028772322,
      "grad_norm": 0.31026577949523926,
      "learning_rate": 3.796606845150535e-05,
      "logits/chosen": 4.074105739593506,
      "logits/rejected": 3.9660568237304688,
      "logps/chosen": -385.5948181152344,
      "logps/rejected": -294.23406982421875,
      "loss": 0.3844,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.9990703463554382,
      "rewards/margins": 2.6799418926239014,
      "rewards/rejected": -3.6790122985839844,
      "step": 12280
    },
    {
      "epoch": 0.7237209849666089,
      "grad_norm": 0.262113481760025,
      "learning_rate": 3.794645483965873e-05,
      "logits/chosen": 3.9841818809509277,
      "logits/rejected": 4.007718086242676,
      "logps/chosen": -398.1753234863281,
      "logps/rejected": -380.69012451171875,
      "loss": 0.3951,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9571248888969421,
      "rewards/margins": 2.840472936630249,
      "rewards/rejected": -3.797598361968994,
      "step": 12300
    },
    {
      "epoch": 0.7248977670559854,
      "grad_norm": 3.852320432662964,
      "learning_rate": 3.79268412278121e-05,
      "logits/chosen": 3.5955262184143066,
      "logits/rejected": 3.766500473022461,
      "logps/chosen": -315.35821533203125,
      "logps/rejected": -293.8775329589844,
      "loss": 0.4776,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9018807411193848,
      "rewards/margins": 1.9963819980621338,
      "rewards/rejected": -2.8982625007629395,
      "step": 12320
    },
    {
      "epoch": 0.726074549145362,
      "grad_norm": 0.4356643557548523,
      "learning_rate": 3.790722761596548e-05,
      "logits/chosen": 3.8740768432617188,
      "logits/rejected": 3.841702938079834,
      "logps/chosen": -351.7453918457031,
      "logps/rejected": -289.9952697753906,
      "loss": 0.468,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8791559338569641,
      "rewards/margins": 2.459514856338501,
      "rewards/rejected": -3.3386707305908203,
      "step": 12340
    },
    {
      "epoch": 0.7272513312347386,
      "grad_norm": 1.8779844045639038,
      "learning_rate": 3.788761400411886e-05,
      "logits/chosen": 3.8784992694854736,
      "logits/rejected": 3.973146915435791,
      "logps/chosen": -407.5242004394531,
      "logps/rejected": -315.06317138671875,
      "loss": 0.3753,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.15243451297283173,
      "rewards/margins": 2.963505744934082,
      "rewards/rejected": -3.115940570831299,
      "step": 12360
    },
    {
      "epoch": 0.7284281133241152,
      "grad_norm": 0.8025063872337341,
      "learning_rate": 3.786800039227224e-05,
      "logits/chosen": 3.9915099143981934,
      "logits/rejected": 3.9060912132263184,
      "logps/chosen": -422.0990295410156,
      "logps/rejected": -319.55010986328125,
      "loss": 0.4305,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8341696858406067,
      "rewards/margins": 2.61148738861084,
      "rewards/rejected": -3.445657253265381,
      "step": 12380
    },
    {
      "epoch": 0.7296048954134918,
      "grad_norm": 3.7313008308410645,
      "learning_rate": 3.7848386780425614e-05,
      "logits/chosen": 3.8940353393554688,
      "logits/rejected": 3.8423526287078857,
      "logps/chosen": -383.408447265625,
      "logps/rejected": -329.8629150390625,
      "loss": 0.3401,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.7133225202560425,
      "rewards/margins": 3.0036425590515137,
      "rewards/rejected": -3.7169651985168457,
      "step": 12400
    },
    {
      "epoch": 0.7307816775028684,
      "grad_norm": 0.33896404504776,
      "learning_rate": 3.7828773168578996e-05,
      "logits/chosen": 3.903754472732544,
      "logits/rejected": 3.9800262451171875,
      "logps/chosen": -358.6346130371094,
      "logps/rejected": -333.15899658203125,
      "loss": 0.5045,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.7256395816802979,
      "rewards/margins": 2.109410285949707,
      "rewards/rejected": -2.835050106048584,
      "step": 12420
    },
    {
      "epoch": 0.731958459592245,
      "grad_norm": 2.7172155380249023,
      "learning_rate": 3.780915955673238e-05,
      "logits/chosen": 3.8377552032470703,
      "logits/rejected": 3.768779754638672,
      "logps/chosen": -408.0701904296875,
      "logps/rejected": -316.9825439453125,
      "loss": 0.5028,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.5186105966567993,
      "rewards/margins": 2.3382105827331543,
      "rewards/rejected": -2.856821060180664,
      "step": 12440
    },
    {
      "epoch": 0.7331352416816216,
      "grad_norm": 2.1781442165374756,
      "learning_rate": 3.778954594488575e-05,
      "logits/chosen": 3.5959486961364746,
      "logits/rejected": 3.6927170753479004,
      "logps/chosen": -365.5129699707031,
      "logps/rejected": -294.98291015625,
      "loss": 0.3865,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.051687825471162796,
      "rewards/margins": 3.196404457092285,
      "rewards/rejected": -3.24809193611145,
      "step": 12460
    },
    {
      "epoch": 0.7343120237709982,
      "grad_norm": 2.205014705657959,
      "learning_rate": 3.776993233303913e-05,
      "logits/chosen": 3.7863929271698,
      "logits/rejected": 3.758665084838867,
      "logps/chosen": -384.86480712890625,
      "logps/rejected": -294.2458801269531,
      "loss": 0.5223,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.6047803163528442,
      "rewards/margins": 2.7030112743377686,
      "rewards/rejected": -3.3077914714813232,
      "step": 12480
    },
    {
      "epoch": 0.7354888058603748,
      "grad_norm": 2.2032878398895264,
      "learning_rate": 3.775031872119251e-05,
      "logits/chosen": 3.9152438640594482,
      "logits/rejected": 3.9454619884490967,
      "logps/chosen": -375.056396484375,
      "logps/rejected": -304.8622741699219,
      "loss": 0.5238,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.4095051884651184,
      "rewards/margins": 2.2864296436309814,
      "rewards/rejected": -2.695934772491455,
      "step": 12500
    },
    {
      "epoch": 0.7366655879497515,
      "grad_norm": 1.406083106994629,
      "learning_rate": 3.773070510934589e-05,
      "logits/chosen": 3.8922228813171387,
      "logits/rejected": 3.9832520484924316,
      "logps/chosen": -381.68499755859375,
      "logps/rejected": -355.3994140625,
      "loss": 0.4145,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.03804123401641846,
      "rewards/margins": 3.0242793560028076,
      "rewards/rejected": -3.0623209476470947,
      "step": 12520
    },
    {
      "epoch": 0.737842370039128,
      "grad_norm": 2.845033884048462,
      "learning_rate": 3.7711091497499266e-05,
      "logits/chosen": 4.118500709533691,
      "logits/rejected": 3.8304829597473145,
      "logps/chosen": -388.6708068847656,
      "logps/rejected": -301.0728759765625,
      "loss": 0.5413,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.0328012704849243,
      "rewards/margins": 2.212632656097412,
      "rewards/rejected": -3.245433807373047,
      "step": 12540
    },
    {
      "epoch": 0.7390191521285046,
      "grad_norm": 4.218930244445801,
      "learning_rate": 3.769147788565264e-05,
      "logits/chosen": 4.1475419998168945,
      "logits/rejected": 4.010366916656494,
      "logps/chosen": -407.00225830078125,
      "logps/rejected": -324.71258544921875,
      "loss": 0.6256,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.0378522872924805,
      "rewards/margins": 1.6305062770843506,
      "rewards/rejected": -2.668358325958252,
      "step": 12560
    },
    {
      "epoch": 0.7401959342178812,
      "grad_norm": 1.340334177017212,
      "learning_rate": 3.7671864273806025e-05,
      "logits/chosen": 3.8592047691345215,
      "logits/rejected": 3.930997133255005,
      "logps/chosen": -378.98760986328125,
      "logps/rejected": -321.54022216796875,
      "loss": 0.5137,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.32182401418685913,
      "rewards/margins": 2.533842086791992,
      "rewards/rejected": -2.855666399002075,
      "step": 12580
    },
    {
      "epoch": 0.7413727163072578,
      "grad_norm": 3.80747127532959,
      "learning_rate": 3.76522506619594e-05,
      "logits/chosen": 3.7095115184783936,
      "logits/rejected": 3.487889051437378,
      "logps/chosen": -362.10968017578125,
      "logps/rejected": -302.86297607421875,
      "loss": 0.3888,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.7894998788833618,
      "rewards/margins": 2.6277177333831787,
      "rewards/rejected": -3.41721773147583,
      "step": 12600
    },
    {
      "epoch": 0.7425494983966344,
      "grad_norm": 2.266489267349243,
      "learning_rate": 3.763263705011278e-05,
      "logits/chosen": 3.96940541267395,
      "logits/rejected": 3.97271466255188,
      "logps/chosen": -395.2729797363281,
      "logps/rejected": -365.99249267578125,
      "loss": 0.3431,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.9469445943832397,
      "rewards/margins": 2.4858086109161377,
      "rewards/rejected": -3.432753324508667,
      "step": 12620
    },
    {
      "epoch": 0.743726280486011,
      "grad_norm": 2.0246686935424805,
      "learning_rate": 3.761302343826616e-05,
      "logits/chosen": 3.5368289947509766,
      "logits/rejected": 3.5352635383605957,
      "logps/chosen": -335.3645324707031,
      "logps/rejected": -298.85760498046875,
      "loss": 0.3516,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.9599713087081909,
      "rewards/margins": 2.824599504470825,
      "rewards/rejected": -3.7845711708068848,
      "step": 12640
    },
    {
      "epoch": 0.7449030625753876,
      "grad_norm": 3.8438830375671387,
      "learning_rate": 3.7593409826419536e-05,
      "logits/chosen": 3.7717995643615723,
      "logits/rejected": 3.8258376121520996,
      "logps/chosen": -406.1817932128906,
      "logps/rejected": -333.91839599609375,
      "loss": 0.5317,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.0337293148040771,
      "rewards/margins": 1.8767805099487305,
      "rewards/rejected": -2.9105100631713867,
      "step": 12660
    },
    {
      "epoch": 0.7460798446647642,
      "grad_norm": 0.4275088906288147,
      "learning_rate": 3.757379621457291e-05,
      "logits/chosen": 3.8232245445251465,
      "logits/rejected": 3.8960022926330566,
      "logps/chosen": -373.5361328125,
      "logps/rejected": -331.6582946777344,
      "loss": 0.5174,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9209564328193665,
      "rewards/margins": 2.3550314903259277,
      "rewards/rejected": -3.2759883403778076,
      "step": 12680
    },
    {
      "epoch": 0.7472566267541408,
      "grad_norm": 1.7912989854812622,
      "learning_rate": 3.7554182602726295e-05,
      "logits/chosen": 3.6124234199523926,
      "logits/rejected": 3.520966053009033,
      "logps/chosen": -324.9551696777344,
      "logps/rejected": -282.21148681640625,
      "loss": 0.5864,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.207054853439331,
      "rewards/margins": 1.8179466724395752,
      "rewards/rejected": -3.025001287460327,
      "step": 12700
    },
    {
      "epoch": 0.7484334088435174,
      "grad_norm": 1.3775607347488403,
      "learning_rate": 3.753456899087967e-05,
      "logits/chosen": 3.761570692062378,
      "logits/rejected": 3.723931074142456,
      "logps/chosen": -367.99847412109375,
      "logps/rejected": -313.7394714355469,
      "loss": 0.5012,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.31686270236969,
      "rewards/margins": 2.0931105613708496,
      "rewards/rejected": -3.409973621368408,
      "step": 12720
    },
    {
      "epoch": 0.749610190932894,
      "grad_norm": 0.8354300260543823,
      "learning_rate": 3.7514955379033054e-05,
      "logits/chosen": 3.6203219890594482,
      "logits/rejected": 3.6091480255126953,
      "logps/chosen": -361.59356689453125,
      "logps/rejected": -287.32373046875,
      "loss": 0.555,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.8955330848693848,
      "rewards/margins": 2.71331787109375,
      "rewards/rejected": -3.6088509559631348,
      "step": 12740
    },
    {
      "epoch": 0.7507869730222706,
      "grad_norm": 10.644704818725586,
      "learning_rate": 3.749534176718643e-05,
      "logits/chosen": 3.991682767868042,
      "logits/rejected": 3.817354917526245,
      "logps/chosen": -409.668212890625,
      "logps/rejected": -306.501953125,
      "loss": 0.5844,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.963146984577179,
      "rewards/margins": 2.046536922454834,
      "rewards/rejected": -3.0096840858459473,
      "step": 12760
    },
    {
      "epoch": 0.7519637551116471,
      "grad_norm": 1.399054765701294,
      "learning_rate": 3.7475728155339806e-05,
      "logits/chosen": 3.739441394805908,
      "logits/rejected": 3.8148231506347656,
      "logps/chosen": -330.41168212890625,
      "logps/rejected": -280.9595947265625,
      "loss": 0.4847,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.901375412940979,
      "rewards/margins": 1.8864424228668213,
      "rewards/rejected": -2.78781795501709,
      "step": 12780
    },
    {
      "epoch": 0.7531405372010238,
      "grad_norm": 0.6847689151763916,
      "learning_rate": 3.745611454349319e-05,
      "logits/chosen": 3.689221143722534,
      "logits/rejected": 3.8559646606445312,
      "logps/chosen": -351.04376220703125,
      "logps/rejected": -292.21148681640625,
      "loss": 0.3636,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7076628804206848,
      "rewards/margins": 2.5169458389282227,
      "rewards/rejected": -3.224608898162842,
      "step": 12800
    },
    {
      "epoch": 0.7543173192904004,
      "grad_norm": 0.9697437882423401,
      "learning_rate": 3.7436500931646565e-05,
      "logits/chosen": 3.8116233348846436,
      "logits/rejected": 3.8056225776672363,
      "logps/chosen": -336.8663635253906,
      "logps/rejected": -314.25762939453125,
      "loss": 0.6049,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.7306922674179077,
      "rewards/margins": 1.9522682428359985,
      "rewards/rejected": -2.6829605102539062,
      "step": 12820
    },
    {
      "epoch": 0.755494101379777,
      "grad_norm": 0.9193733930587769,
      "learning_rate": 3.741688731979994e-05,
      "logits/chosen": 3.726706027984619,
      "logits/rejected": 3.6641387939453125,
      "logps/chosen": -330.9996643066406,
      "logps/rejected": -287.7159118652344,
      "loss": 0.3426,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.15683992207050323,
      "rewards/margins": 2.865082263946533,
      "rewards/rejected": -3.0219221115112305,
      "step": 12840
    },
    {
      "epoch": 0.7566708834691536,
      "grad_norm": 2.205618143081665,
      "learning_rate": 3.7397273707953324e-05,
      "logits/chosen": 4.000811576843262,
      "logits/rejected": 4.0395188331604,
      "logps/chosen": -353.48748779296875,
      "logps/rejected": -305.7775573730469,
      "loss": 0.447,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7065795063972473,
      "rewards/margins": 2.414947271347046,
      "rewards/rejected": -3.1215267181396484,
      "step": 12860
    },
    {
      "epoch": 0.7578476655585302,
      "grad_norm": 1.7157673835754395,
      "learning_rate": 3.73776600961067e-05,
      "logits/chosen": 3.6051723957061768,
      "logits/rejected": 3.566565990447998,
      "logps/chosen": -364.48394775390625,
      "logps/rejected": -309.8647766113281,
      "loss": 0.5265,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.02937396802008152,
      "rewards/margins": 2.7373902797698975,
      "rewards/rejected": -2.7080163955688477,
      "step": 12880
    },
    {
      "epoch": 0.7590244476479068,
      "grad_norm": 1.4145607948303223,
      "learning_rate": 3.7358046484260076e-05,
      "logits/chosen": 3.8728606700897217,
      "logits/rejected": 4.0499982833862305,
      "logps/chosen": -361.75286865234375,
      "logps/rejected": -311.63360595703125,
      "loss": 0.5713,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.763157308101654,
      "rewards/margins": 2.0569024085998535,
      "rewards/rejected": -2.8200600147247314,
      "step": 12900
    },
    {
      "epoch": 0.7602012297372834,
      "grad_norm": 2.4130728244781494,
      "learning_rate": 3.733843287241346e-05,
      "logits/chosen": 4.146183490753174,
      "logits/rejected": 4.087014198303223,
      "logps/chosen": -451.6837463378906,
      "logps/rejected": -286.24884033203125,
      "loss": 0.3534,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8937085270881653,
      "rewards/margins": 2.6492223739624023,
      "rewards/rejected": -3.5429306030273438,
      "step": 12920
    },
    {
      "epoch": 0.76137801182666,
      "grad_norm": 2.8462579250335693,
      "learning_rate": 3.7318819260566834e-05,
      "logits/chosen": 3.881160259246826,
      "logits/rejected": 3.8285622596740723,
      "logps/chosen": -336.78839111328125,
      "logps/rejected": -313.39837646484375,
      "loss": 0.5547,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.378023386001587,
      "rewards/margins": 1.789121389389038,
      "rewards/rejected": -3.167144775390625,
      "step": 12940
    },
    {
      "epoch": 0.7625547939160366,
      "grad_norm": 5.050897598266602,
      "learning_rate": 3.729920564872022e-05,
      "logits/chosen": 4.0034027099609375,
      "logits/rejected": 4.023706436157227,
      "logps/chosen": -383.6518859863281,
      "logps/rejected": -348.957275390625,
      "loss": 0.5851,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.0037922859191895,
      "rewards/margins": 2.2914748191833496,
      "rewards/rejected": -3.295267105102539,
      "step": 12960
    },
    {
      "epoch": 0.7637315760054132,
      "grad_norm": 0.5519399046897888,
      "learning_rate": 3.7279592036873587e-05,
      "logits/chosen": 4.030184268951416,
      "logits/rejected": 3.8942909240722656,
      "logps/chosen": -415.49951171875,
      "logps/rejected": -340.33831787109375,
      "loss": 0.5533,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1293437480926514,
      "rewards/margins": 2.4039306640625,
      "rewards/rejected": -3.5332748889923096,
      "step": 12980
    },
    {
      "epoch": 0.7649083580947897,
      "grad_norm": 2.124847650527954,
      "learning_rate": 3.725997842502697e-05,
      "logits/chosen": 3.765639066696167,
      "logits/rejected": 3.7270960807800293,
      "logps/chosen": -353.7018737792969,
      "logps/rejected": -322.6133117675781,
      "loss": 0.5153,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1661310195922852,
      "rewards/margins": 2.365516185760498,
      "rewards/rejected": -3.531646728515625,
      "step": 13000
    },
    {
      "epoch": 0.7660851401841664,
      "grad_norm": 0.7916717529296875,
      "learning_rate": 3.724036481318035e-05,
      "logits/chosen": 3.805771589279175,
      "logits/rejected": 3.8463008403778076,
      "logps/chosen": -389.22991943359375,
      "logps/rejected": -357.0899353027344,
      "loss": 0.6267,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.7119853496551514,
      "rewards/margins": 2.1190669536590576,
      "rewards/rejected": -3.831052303314209,
      "step": 13020
    },
    {
      "epoch": 0.767261922273543,
      "grad_norm": 1.5541046857833862,
      "learning_rate": 3.722075120133373e-05,
      "logits/chosen": 3.8691627979278564,
      "logits/rejected": 3.7879364490509033,
      "logps/chosen": -370.089111328125,
      "logps/rejected": -295.2281799316406,
      "loss": 0.3409,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1329845190048218,
      "rewards/margins": 2.8998067378997803,
      "rewards/rejected": -4.0327911376953125,
      "step": 13040
    },
    {
      "epoch": 0.7684387043629196,
      "grad_norm": 0.945755660533905,
      "learning_rate": 3.7201137589487104e-05,
      "logits/chosen": 4.183636665344238,
      "logits/rejected": 4.1275200843811035,
      "logps/chosen": -422.3619079589844,
      "logps/rejected": -311.99053955078125,
      "loss": 0.5536,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.8183403015136719,
      "rewards/margins": 2.210695743560791,
      "rewards/rejected": -4.029036045074463,
      "step": 13060
    },
    {
      "epoch": 0.7696154864522962,
      "grad_norm": 2.0237600803375244,
      "learning_rate": 3.718152397764049e-05,
      "logits/chosen": 4.141266345977783,
      "logits/rejected": 4.056354999542236,
      "logps/chosen": -431.2999572753906,
      "logps/rejected": -333.23052978515625,
      "loss": 0.4853,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2151179313659668,
      "rewards/margins": 2.680861711502075,
      "rewards/rejected": -3.895979404449463,
      "step": 13080
    },
    {
      "epoch": 0.7707922685416728,
      "grad_norm": 2.403104305267334,
      "learning_rate": 3.716191036579386e-05,
      "logits/chosen": 3.865541458129883,
      "logits/rejected": 3.7091598510742188,
      "logps/chosen": -354.5262145996094,
      "logps/rejected": -314.89959716796875,
      "loss": 0.6364,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.2300633192062378,
      "rewards/margins": 1.9010776281356812,
      "rewards/rejected": -3.131141185760498,
      "step": 13100
    },
    {
      "epoch": 0.7719690506310494,
      "grad_norm": 3.3014883995056152,
      "learning_rate": 3.714229675394724e-05,
      "logits/chosen": 3.9833731651306152,
      "logits/rejected": 3.797957181930542,
      "logps/chosen": -390.1669616699219,
      "logps/rejected": -297.13232421875,
      "loss": 0.4269,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1382067203521729,
      "rewards/margins": 2.4632582664489746,
      "rewards/rejected": -3.6014647483825684,
      "step": 13120
    },
    {
      "epoch": 0.773145832720426,
      "grad_norm": 2.156907081604004,
      "learning_rate": 3.7122683142100615e-05,
      "logits/chosen": 3.6690304279327393,
      "logits/rejected": 3.6542344093322754,
      "logps/chosen": -352.11871337890625,
      "logps/rejected": -333.1004943847656,
      "loss": 0.6463,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5659514665603638,
      "rewards/margins": 1.6814649105072021,
      "rewards/rejected": -3.2474167346954346,
      "step": 13140
    },
    {
      "epoch": 0.7743226148098026,
      "grad_norm": 3.2587637901306152,
      "learning_rate": 3.7103069530254e-05,
      "logits/chosen": 3.756514072418213,
      "logits/rejected": 3.790095567703247,
      "logps/chosen": -345.02783203125,
      "logps/rejected": -315.65960693359375,
      "loss": 0.4721,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.473997712135315,
      "rewards/margins": 2.2932591438293457,
      "rewards/rejected": -3.76725697517395,
      "step": 13160
    },
    {
      "epoch": 0.7754993968991792,
      "grad_norm": 0.11926790326833725,
      "learning_rate": 3.708345591840738e-05,
      "logits/chosen": 4.021649360656738,
      "logits/rejected": 3.934408187866211,
      "logps/chosen": -418.8163146972656,
      "logps/rejected": -328.74786376953125,
      "loss": 0.3666,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1506775617599487,
      "rewards/margins": 3.2323050498962402,
      "rewards/rejected": -4.382983207702637,
      "step": 13180
    },
    {
      "epoch": 0.7766761789885558,
      "grad_norm": 1.0388168096542358,
      "learning_rate": 3.706384230656075e-05,
      "logits/chosen": 3.6453323364257812,
      "logits/rejected": 3.66924786567688,
      "logps/chosen": -377.7240905761719,
      "logps/rejected": -341.6136474609375,
      "loss": 0.7934,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.3592212200164795,
      "rewards/margins": 1.5599403381347656,
      "rewards/rejected": -2.919161319732666,
      "step": 13200
    },
    {
      "epoch": 0.7778529610779324,
      "grad_norm": 2.2327497005462646,
      "learning_rate": 3.704422869471413e-05,
      "logits/chosen": 3.7382476329803467,
      "logits/rejected": 3.667506694793701,
      "logps/chosen": -353.31439208984375,
      "logps/rejected": -288.5743713378906,
      "loss": 0.4334,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9794942140579224,
      "rewards/margins": 2.3951809406280518,
      "rewards/rejected": -3.3746750354766846,
      "step": 13220
    },
    {
      "epoch": 0.779029743167309,
      "grad_norm": 0.3983752727508545,
      "learning_rate": 3.7024615082867516e-05,
      "logits/chosen": 4.017999172210693,
      "logits/rejected": 3.9076499938964844,
      "logps/chosen": -405.660400390625,
      "logps/rejected": -324.3932800292969,
      "loss": 0.6778,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8625019192695618,
      "rewards/margins": 2.4520883560180664,
      "rewards/rejected": -3.3145899772644043,
      "step": 13240
    },
    {
      "epoch": 0.7802065252566855,
      "grad_norm": 1.1895772218704224,
      "learning_rate": 3.700500147102089e-05,
      "logits/chosen": 3.8267054557800293,
      "logits/rejected": 3.8914475440979004,
      "logps/chosen": -360.2933654785156,
      "logps/rejected": -320.994384765625,
      "loss": 0.4557,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8836630582809448,
      "rewards/margins": 2.123196840286255,
      "rewards/rejected": -3.0068600177764893,
      "step": 13260
    },
    {
      "epoch": 0.7813833073460622,
      "grad_norm": 1.179103136062622,
      "learning_rate": 3.698538785917427e-05,
      "logits/chosen": 3.72229266166687,
      "logits/rejected": 3.612351894378662,
      "logps/chosen": -354.1809997558594,
      "logps/rejected": -265.9830017089844,
      "loss": 0.5101,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9823638796806335,
      "rewards/margins": 1.6892364025115967,
      "rewards/rejected": -2.671600580215454,
      "step": 13280
    },
    {
      "epoch": 0.7825600894354388,
      "grad_norm": 3.674816846847534,
      "learning_rate": 3.6965774247327644e-05,
      "logits/chosen": 3.7117347717285156,
      "logits/rejected": 3.710341215133667,
      "logps/chosen": -333.99700927734375,
      "logps/rejected": -273.739990234375,
      "loss": 0.5051,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3011170625686646,
      "rewards/margins": 1.9524192810058594,
      "rewards/rejected": -3.2535362243652344,
      "step": 13300
    },
    {
      "epoch": 0.7837368715248154,
      "grad_norm": 0.909531831741333,
      "learning_rate": 3.694616063548103e-05,
      "logits/chosen": 4.014784336090088,
      "logits/rejected": 3.968975067138672,
      "logps/chosen": -390.7972717285156,
      "logps/rejected": -331.27655029296875,
      "loss": 0.4825,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1296494007110596,
      "rewards/margins": 2.0957624912261963,
      "rewards/rejected": -3.2254116535186768,
      "step": 13320
    },
    {
      "epoch": 0.784913653614192,
      "grad_norm": 1.6492921113967896,
      "learning_rate": 3.69265470236344e-05,
      "logits/chosen": 3.9659430980682373,
      "logits/rejected": 3.8291714191436768,
      "logps/chosen": -412.14892578125,
      "logps/rejected": -324.3280334472656,
      "loss": 0.6104,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4926708936691284,
      "rewards/margins": 1.969944715499878,
      "rewards/rejected": -3.462615489959717,
      "step": 13340
    },
    {
      "epoch": 0.7860904357035686,
      "grad_norm": 3.564343214035034,
      "learning_rate": 3.690693341178778e-05,
      "logits/chosen": 4.2638959884643555,
      "logits/rejected": 4.194889545440674,
      "logps/chosen": -457.9781188964844,
      "logps/rejected": -374.31103515625,
      "loss": 0.4164,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5149835348129272,
      "rewards/margins": 3.3656630516052246,
      "rewards/rejected": -3.8806469440460205,
      "step": 13360
    },
    {
      "epoch": 0.7872672177929452,
      "grad_norm": 2.2923357486724854,
      "learning_rate": 3.688731979994116e-05,
      "logits/chosen": 4.064732074737549,
      "logits/rejected": 3.9406561851501465,
      "logps/chosen": -381.662841796875,
      "logps/rejected": -343.0131530761719,
      "loss": 0.4312,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.8885862231254578,
      "rewards/margins": 2.3111424446105957,
      "rewards/rejected": -3.1997287273406982,
      "step": 13380
    },
    {
      "epoch": 0.7884439998823218,
      "grad_norm": 2.7588412761688232,
      "learning_rate": 3.6867706188094544e-05,
      "logits/chosen": 3.876999616622925,
      "logits/rejected": 3.962294340133667,
      "logps/chosen": -408.79083251953125,
      "logps/rejected": -337.41241455078125,
      "loss": 0.3396,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.1069949865341187,
      "rewards/margins": 2.636960506439209,
      "rewards/rejected": -3.743955612182617,
      "step": 13400
    },
    {
      "epoch": 0.7896207819716984,
      "grad_norm": 0.5969140529632568,
      "learning_rate": 3.6848092576247914e-05,
      "logits/chosen": 3.9089202880859375,
      "logits/rejected": 3.761094331741333,
      "logps/chosen": -419.2732849121094,
      "logps/rejected": -307.3210754394531,
      "loss": 0.3301,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.0143572092056274,
      "rewards/margins": 2.8186721801757812,
      "rewards/rejected": -3.833029270172119,
      "step": 13420
    },
    {
      "epoch": 0.790797564061075,
      "grad_norm": 2.3896429538726807,
      "learning_rate": 3.6828478964401296e-05,
      "logits/chosen": 3.9247279167175293,
      "logits/rejected": 3.8180508613586426,
      "logps/chosen": -391.4608459472656,
      "logps/rejected": -295.1797790527344,
      "loss": 0.4756,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6160888671875,
      "rewards/margins": 2.3997254371643066,
      "rewards/rejected": -4.015814781188965,
      "step": 13440
    },
    {
      "epoch": 0.7919743461504516,
      "grad_norm": 0.46949201822280884,
      "learning_rate": 3.680886535255467e-05,
      "logits/chosen": 3.6562552452087402,
      "logits/rejected": 3.5952847003936768,
      "logps/chosen": -381.2722473144531,
      "logps/rejected": -263.0862121582031,
      "loss": 0.3684,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.9870675802230835,
      "rewards/margins": 2.5211265087127686,
      "rewards/rejected": -3.5081939697265625,
      "step": 13460
    },
    {
      "epoch": 0.7931511282398281,
      "grad_norm": 2.589961290359497,
      "learning_rate": 3.6789251740708055e-05,
      "logits/chosen": 3.731611728668213,
      "logits/rejected": 3.763427257537842,
      "logps/chosen": -356.72894287109375,
      "logps/rejected": -287.90362548828125,
      "loss": 0.3797,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9045807719230652,
      "rewards/margins": 2.705169200897217,
      "rewards/rejected": -3.6097495555877686,
      "step": 13480
    },
    {
      "epoch": 0.7943279103292048,
      "grad_norm": 1.2702757120132446,
      "learning_rate": 3.676963812886143e-05,
      "logits/chosen": 4.083821773529053,
      "logits/rejected": 3.889838457107544,
      "logps/chosen": -385.81658935546875,
      "logps/rejected": -304.72344970703125,
      "loss": 0.4299,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9050677418708801,
      "rewards/margins": 2.53114914894104,
      "rewards/rejected": -3.4362170696258545,
      "step": 13500
    },
    {
      "epoch": 0.7955046924185813,
      "grad_norm": 17.968753814697266,
      "learning_rate": 3.675002451701481e-05,
      "logits/chosen": 4.041988849639893,
      "logits/rejected": 4.013386249542236,
      "logps/chosen": -373.9524841308594,
      "logps/rejected": -380.76739501953125,
      "loss": 0.4265,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2779629230499268,
      "rewards/margins": 2.6519041061401367,
      "rewards/rejected": -3.9298672676086426,
      "step": 13520
    },
    {
      "epoch": 0.796681474507958,
      "grad_norm": 5.216410160064697,
      "learning_rate": 3.673041090516819e-05,
      "logits/chosen": 3.5611424446105957,
      "logits/rejected": 3.593140125274658,
      "logps/chosen": -377.347412109375,
      "logps/rejected": -333.4997253417969,
      "loss": 0.5241,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6309093236923218,
      "rewards/margins": 2.5734081268310547,
      "rewards/rejected": -4.204317092895508,
      "step": 13540
    },
    {
      "epoch": 0.7978582565973346,
      "grad_norm": 1.4544681310653687,
      "learning_rate": 3.6710797293321566e-05,
      "logits/chosen": 3.812377452850342,
      "logits/rejected": 3.710784435272217,
      "logps/chosen": -370.88958740234375,
      "logps/rejected": -346.65338134765625,
      "loss": 0.4697,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.554123878479004,
      "rewards/margins": 2.8027806282043457,
      "rewards/rejected": -4.35690450668335,
      "step": 13560
    },
    {
      "epoch": 0.7990350386867112,
      "grad_norm": 4.0293354988098145,
      "learning_rate": 3.669118368147494e-05,
      "logits/chosen": 4.031460762023926,
      "logits/rejected": 3.9561362266540527,
      "logps/chosen": -399.80389404296875,
      "logps/rejected": -286.05804443359375,
      "loss": 0.4811,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2597222328186035,
      "rewards/margins": 2.7564120292663574,
      "rewards/rejected": -4.016134262084961,
      "step": 13580
    },
    {
      "epoch": 0.8002118207760878,
      "grad_norm": 1.9660757780075073,
      "learning_rate": 3.6671570069628325e-05,
      "logits/chosen": 3.955495834350586,
      "logits/rejected": 3.8671562671661377,
      "logps/chosen": -361.0657958984375,
      "logps/rejected": -341.04937744140625,
      "loss": 0.84,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3998892307281494,
      "rewards/margins": 2.1506288051605225,
      "rewards/rejected": -3.55051851272583,
      "step": 13600
    },
    {
      "epoch": 0.8013886028654644,
      "grad_norm": 3.1898059844970703,
      "learning_rate": 3.66519564577817e-05,
      "logits/chosen": 3.9115538597106934,
      "logits/rejected": 3.97520112991333,
      "logps/chosen": -354.6539611816406,
      "logps/rejected": -335.38873291015625,
      "loss": 0.461,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.7135623693466187,
      "rewards/margins": 2.657346248626709,
      "rewards/rejected": -3.370908737182617,
      "step": 13620
    },
    {
      "epoch": 0.802565384954841,
      "grad_norm": 0.9349530339241028,
      "learning_rate": 3.663234284593508e-05,
      "logits/chosen": 3.989565372467041,
      "logits/rejected": 3.816037654876709,
      "logps/chosen": -415.42303466796875,
      "logps/rejected": -320.08953857421875,
      "loss": 0.4159,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.5849617123603821,
      "rewards/margins": 3.138820171356201,
      "rewards/rejected": -3.7237820625305176,
      "step": 13640
    },
    {
      "epoch": 0.8037421670442176,
      "grad_norm": 2.7583959102630615,
      "learning_rate": 3.661272923408846e-05,
      "logits/chosen": 3.8939433097839355,
      "logits/rejected": 3.8515419960021973,
      "logps/chosen": -399.30633544921875,
      "logps/rejected": -340.4485778808594,
      "loss": 0.6096,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1176445484161377,
      "rewards/margins": 2.3203961849212646,
      "rewards/rejected": -3.4380409717559814,
      "step": 13660
    },
    {
      "epoch": 0.8049189491335942,
      "grad_norm": 2.1973562240600586,
      "learning_rate": 3.6593115622241836e-05,
      "logits/chosen": 3.8165149688720703,
      "logits/rejected": 3.91300892829895,
      "logps/chosen": -340.7392272949219,
      "logps/rejected": -326.0001525878906,
      "loss": 0.4628,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.0740087032318115,
      "rewards/margins": 2.6262242794036865,
      "rewards/rejected": -3.7002334594726562,
      "step": 13680
    },
    {
      "epoch": 0.8060957312229707,
      "grad_norm": 1.9480966329574585,
      "learning_rate": 3.657350201039522e-05,
      "logits/chosen": 4.147671699523926,
      "logits/rejected": 3.99151873588562,
      "logps/chosen": -397.24200439453125,
      "logps/rejected": -344.7205505371094,
      "loss": 0.4281,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.288069486618042,
      "rewards/margins": 3.0106284618377686,
      "rewards/rejected": -4.298698425292969,
      "step": 13700
    },
    {
      "epoch": 0.8072725133123474,
      "grad_norm": 2.8809726238250732,
      "learning_rate": 3.6553888398548595e-05,
      "logits/chosen": 3.6140639781951904,
      "logits/rejected": 3.7024974822998047,
      "logps/chosen": -376.04046630859375,
      "logps/rejected": -328.75189208984375,
      "loss": 0.4008,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1006577014923096,
      "rewards/margins": 2.5943408012390137,
      "rewards/rejected": -3.6949989795684814,
      "step": 13720
    },
    {
      "epoch": 0.8084492954017239,
      "grad_norm": 16.297658920288086,
      "learning_rate": 3.653427478670197e-05,
      "logits/chosen": 3.7863128185272217,
      "logits/rejected": 3.778367280960083,
      "logps/chosen": -392.577392578125,
      "logps/rejected": -330.3354797363281,
      "loss": 0.532,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.990752100944519,
      "rewards/margins": 2.076205253601074,
      "rewards/rejected": -3.066957473754883,
      "step": 13740
    },
    {
      "epoch": 0.8096260774911006,
      "grad_norm": 0.42631635069847107,
      "learning_rate": 3.6514661174855354e-05,
      "logits/chosen": 4.061251640319824,
      "logits/rejected": 3.7989628314971924,
      "logps/chosen": -451.4754943847656,
      "logps/rejected": -295.2054443359375,
      "loss": 0.3199,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.8435592651367188,
      "rewards/margins": 2.6150078773498535,
      "rewards/rejected": -3.4585671424865723,
      "step": 13760
    },
    {
      "epoch": 0.8108028595804772,
      "grad_norm": 2.417757034301758,
      "learning_rate": 3.649504756300873e-05,
      "logits/chosen": 4.05233097076416,
      "logits/rejected": 4.029143333435059,
      "logps/chosen": -447.25848388671875,
      "logps/rejected": -331.322509765625,
      "loss": 0.4112,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.25545939803123474,
      "rewards/margins": 3.5257821083068848,
      "rewards/rejected": -3.781240940093994,
      "step": 13780
    },
    {
      "epoch": 0.8119796416698538,
      "grad_norm": 1.4005565643310547,
      "learning_rate": 3.6475433951162106e-05,
      "logits/chosen": 3.7887635231018066,
      "logits/rejected": 3.7682316303253174,
      "logps/chosen": -341.48699951171875,
      "logps/rejected": -295.76043701171875,
      "loss": 0.4772,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7870277166366577,
      "rewards/margins": 2.9111199378967285,
      "rewards/rejected": -3.6981475353240967,
      "step": 13800
    },
    {
      "epoch": 0.8131564237592304,
      "grad_norm": 0.5626721382141113,
      "learning_rate": 3.645582033931549e-05,
      "logits/chosen": 4.251959323883057,
      "logits/rejected": 4.015228271484375,
      "logps/chosen": -437.4134826660156,
      "logps/rejected": -321.3033752441406,
      "loss": 0.4573,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.8397065997123718,
      "rewards/margins": 2.434173345565796,
      "rewards/rejected": -3.2738800048828125,
      "step": 13820
    },
    {
      "epoch": 0.814333205848607,
      "grad_norm": 2.0433926582336426,
      "learning_rate": 3.6436206727468865e-05,
      "logits/chosen": 4.162197113037109,
      "logits/rejected": 3.937666654586792,
      "logps/chosen": -390.53839111328125,
      "logps/rejected": -314.5958251953125,
      "loss": 0.4426,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.0250091552734375,
      "rewards/margins": 2.564347743988037,
      "rewards/rejected": -3.5893568992614746,
      "step": 13840
    },
    {
      "epoch": 0.8155099879379836,
      "grad_norm": 1.7980962991714478,
      "learning_rate": 3.641659311562224e-05,
      "logits/chosen": 3.950230121612549,
      "logits/rejected": 3.772381544113159,
      "logps/chosen": -368.8052978515625,
      "logps/rejected": -285.86767578125,
      "loss": 0.4423,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.9695575833320618,
      "rewards/margins": 2.6576685905456543,
      "rewards/rejected": -3.6272263526916504,
      "step": 13860
    },
    {
      "epoch": 0.8166867700273602,
      "grad_norm": 1.3295233249664307,
      "learning_rate": 3.6396979503775624e-05,
      "logits/chosen": 3.879697322845459,
      "logits/rejected": 3.8175578117370605,
      "logps/chosen": -396.3735656738281,
      "logps/rejected": -336.4224548339844,
      "loss": 0.7212,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.2147411108016968,
      "rewards/margins": 2.1636481285095215,
      "rewards/rejected": -3.378389835357666,
      "step": 13880
    },
    {
      "epoch": 0.8178635521167368,
      "grad_norm": 0.9154900312423706,
      "learning_rate": 3.6377365891929e-05,
      "logits/chosen": 4.079825401306152,
      "logits/rejected": 4.048945426940918,
      "logps/chosen": -326.837890625,
      "logps/rejected": -298.8874206542969,
      "loss": 0.3981,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0937557220458984,
      "rewards/margins": 2.4656450748443604,
      "rewards/rejected": -3.5594005584716797,
      "step": 13900
    },
    {
      "epoch": 0.8190403342061133,
      "grad_norm": 1.9823930263519287,
      "learning_rate": 3.635775228008238e-05,
      "logits/chosen": 4.152219772338867,
      "logits/rejected": 4.03896427154541,
      "logps/chosen": -392.85797119140625,
      "logps/rejected": -312.80291748046875,
      "loss": 0.3398,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.78810715675354,
      "rewards/margins": 2.6848182678222656,
      "rewards/rejected": -3.4729251861572266,
      "step": 13920
    },
    {
      "epoch": 0.82021711629549,
      "grad_norm": 1.242921233177185,
      "learning_rate": 3.633813866823575e-05,
      "logits/chosen": 3.771296739578247,
      "logits/rejected": 3.744786024093628,
      "logps/chosen": -401.81988525390625,
      "logps/rejected": -318.74072265625,
      "loss": 0.5452,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8921481966972351,
      "rewards/margins": 2.267936944961548,
      "rewards/rejected": -3.1600849628448486,
      "step": 13940
    },
    {
      "epoch": 0.8213938983848665,
      "grad_norm": 2.0386464595794678,
      "learning_rate": 3.6318525056389134e-05,
      "logits/chosen": 4.009449481964111,
      "logits/rejected": 3.8044114112854004,
      "logps/chosen": -366.5013732910156,
      "logps/rejected": -287.59417724609375,
      "loss": 0.4026,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.4492550790309906,
      "rewards/margins": 2.833528518676758,
      "rewards/rejected": -3.2827835083007812,
      "step": 13960
    },
    {
      "epoch": 0.8225706804742432,
      "grad_norm": 4.910645484924316,
      "learning_rate": 3.629891144454252e-05,
      "logits/chosen": 4.019444465637207,
      "logits/rejected": 3.8455138206481934,
      "logps/chosen": -420.49542236328125,
      "logps/rejected": -285.12457275390625,
      "loss": 0.4844,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.377284288406372,
      "rewards/margins": 2.5323386192321777,
      "rewards/rejected": -3.9096226692199707,
      "step": 13980
    },
    {
      "epoch": 0.8237474625636197,
      "grad_norm": 0.5184699296951294,
      "learning_rate": 3.627929783269589e-05,
      "logits/chosen": 4.128853797912598,
      "logits/rejected": 3.948106288909912,
      "logps/chosen": -379.9201354980469,
      "logps/rejected": -314.6624450683594,
      "loss": 0.4129,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8517339825630188,
      "rewards/margins": 2.778454303741455,
      "rewards/rejected": -3.63018798828125,
      "step": 14000
    },
    {
      "epoch": 0.8249242446529964,
      "grad_norm": 1.1039382219314575,
      "learning_rate": 3.625968422084927e-05,
      "logits/chosen": 4.048531532287598,
      "logits/rejected": 3.7600104808807373,
      "logps/chosen": -386.209716796875,
      "logps/rejected": -326.0526428222656,
      "loss": 0.4887,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5718371868133545,
      "rewards/margins": 2.852248430252075,
      "rewards/rejected": -3.4240856170654297,
      "step": 14020
    },
    {
      "epoch": 0.826101026742373,
      "grad_norm": 0.5605725049972534,
      "learning_rate": 3.624007060900265e-05,
      "logits/chosen": 4.019754886627197,
      "logits/rejected": 4.009526252746582,
      "logps/chosen": -434.265869140625,
      "logps/rejected": -351.43902587890625,
      "loss": 0.5651,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.7495553493499756,
      "rewards/margins": 2.835113048553467,
      "rewards/rejected": -3.5846683979034424,
      "step": 14040
    },
    {
      "epoch": 0.8272778088317496,
      "grad_norm": 1.9043389558792114,
      "learning_rate": 3.622045699715603e-05,
      "logits/chosen": 3.7870476245880127,
      "logits/rejected": 3.7255167961120605,
      "logps/chosen": -343.12322998046875,
      "logps/rejected": -283.1442565917969,
      "loss": 0.4389,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8842808604240417,
      "rewards/margins": 2.074171543121338,
      "rewards/rejected": -2.958451986312866,
      "step": 14060
    },
    {
      "epoch": 0.8284545909211262,
      "grad_norm": 2.6864397525787354,
      "learning_rate": 3.6200843385309404e-05,
      "logits/chosen": 3.958203077316284,
      "logits/rejected": 3.758958101272583,
      "logps/chosen": -343.5794677734375,
      "logps/rejected": -296.7246398925781,
      "loss": 0.3935,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.4565610885620117,
      "rewards/margins": 2.4692611694335938,
      "rewards/rejected": -2.9258222579956055,
      "step": 14080
    },
    {
      "epoch": 0.8296313730105028,
      "grad_norm": 0.7142742872238159,
      "learning_rate": 3.618122977346278e-05,
      "logits/chosen": 4.092217445373535,
      "logits/rejected": 4.052080154418945,
      "logps/chosen": -412.85052490234375,
      "logps/rejected": -346.4334716796875,
      "loss": 0.3664,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.5627930760383606,
      "rewards/margins": 2.88470196723938,
      "rewards/rejected": -3.447495222091675,
      "step": 14100
    },
    {
      "epoch": 0.8308081550998794,
      "grad_norm": 1.3101803064346313,
      "learning_rate": 3.616161616161616e-05,
      "logits/chosen": 3.752138614654541,
      "logits/rejected": 3.792095899581909,
      "logps/chosen": -391.5184326171875,
      "logps/rejected": -332.8181457519531,
      "loss": 0.3799,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.7876908779144287,
      "rewards/margins": 2.814427614212036,
      "rewards/rejected": -3.602118730545044,
      "step": 14120
    },
    {
      "epoch": 0.8319849371892559,
      "grad_norm": 1.1529524326324463,
      "learning_rate": 3.6142002549769546e-05,
      "logits/chosen": 3.6371734142303467,
      "logits/rejected": 3.6084377765655518,
      "logps/chosen": -353.89306640625,
      "logps/rejected": -287.35150146484375,
      "loss": 0.6494,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.9018325805664062,
      "rewards/margins": 1.8570209741592407,
      "rewards/rejected": -2.7588534355163574,
      "step": 14140
    },
    {
      "epoch": 0.8331617192786326,
      "grad_norm": 0.7744545340538025,
      "learning_rate": 3.6122388937922915e-05,
      "logits/chosen": 3.978717088699341,
      "logits/rejected": 3.9731528759002686,
      "logps/chosen": -397.15228271484375,
      "logps/rejected": -314.7340087890625,
      "loss": 0.4452,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.2983670234680176,
      "rewards/margins": 3.294973373413086,
      "rewards/rejected": -3.5933403968811035,
      "step": 14160
    },
    {
      "epoch": 0.8343385013680091,
      "grad_norm": 0.32652440667152405,
      "learning_rate": 3.61027753260763e-05,
      "logits/chosen": 3.9070377349853516,
      "logits/rejected": 3.7929749488830566,
      "logps/chosen": -414.37109375,
      "logps/rejected": -335.6666259765625,
      "loss": 0.4224,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.561883270740509,
      "rewards/margins": 3.519075870513916,
      "rewards/rejected": -4.080959320068359,
      "step": 14180
    },
    {
      "epoch": 0.8355152834573858,
      "grad_norm": 1.6260465383529663,
      "learning_rate": 3.608316171422968e-05,
      "logits/chosen": 3.7942862510681152,
      "logits/rejected": 3.803750514984131,
      "logps/chosen": -335.8197326660156,
      "logps/rejected": -283.41748046875,
      "loss": 0.5182,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.56441330909729,
      "rewards/margins": 1.8402588367462158,
      "rewards/rejected": -3.4046719074249268,
      "step": 14200
    },
    {
      "epoch": 0.8366920655467623,
      "grad_norm": 5.71705961227417,
      "learning_rate": 3.606354810238306e-05,
      "logits/chosen": 4.113895893096924,
      "logits/rejected": 4.05049991607666,
      "logps/chosen": -378.52197265625,
      "logps/rejected": -345.67974853515625,
      "loss": 0.6053,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.1011039018630981,
      "rewards/margins": 2.168673515319824,
      "rewards/rejected": -3.269777774810791,
      "step": 14220
    },
    {
      "epoch": 0.837868847636139,
      "grad_norm": 0.08117089420557022,
      "learning_rate": 3.604393449053643e-05,
      "logits/chosen": 3.9493775367736816,
      "logits/rejected": 4.047263145446777,
      "logps/chosen": -419.43670654296875,
      "logps/rejected": -347.7676086425781,
      "loss": 0.4329,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8819783329963684,
      "rewards/margins": 2.6527180671691895,
      "rewards/rejected": -3.5346970558166504,
      "step": 14240
    },
    {
      "epoch": 0.8390456297255156,
      "grad_norm": 1.2895054817199707,
      "learning_rate": 3.602432087868981e-05,
      "logits/chosen": 3.8365883827209473,
      "logits/rejected": 3.8106319904327393,
      "logps/chosen": -376.44146728515625,
      "logps/rejected": -333.879638671875,
      "loss": 0.3651,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.980810821056366,
      "rewards/margins": 2.673928737640381,
      "rewards/rejected": -3.6547398567199707,
      "step": 14260
    },
    {
      "epoch": 0.8402224118148922,
      "grad_norm": 3.1604371070861816,
      "learning_rate": 3.600470726684319e-05,
      "logits/chosen": 4.143187522888184,
      "logits/rejected": 4.0422868728637695,
      "logps/chosen": -393.6264953613281,
      "logps/rejected": -358.761962890625,
      "loss": 0.5383,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.816383719444275,
      "rewards/margins": 2.42741060256958,
      "rewards/rejected": -4.2437944412231445,
      "step": 14280
    },
    {
      "epoch": 0.8413991939042688,
      "grad_norm": 2.3060905933380127,
      "learning_rate": 3.598509365499657e-05,
      "logits/chosen": 3.738806962966919,
      "logits/rejected": 3.6225597858428955,
      "logps/chosen": -334.9776306152344,
      "logps/rejected": -262.8052978515625,
      "loss": 0.4781,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9664473533630371,
      "rewards/margins": 2.158055543899536,
      "rewards/rejected": -3.1245028972625732,
      "step": 14300
    },
    {
      "epoch": 0.8425759759936454,
      "grad_norm": 3.3524041175842285,
      "learning_rate": 3.5965480043149944e-05,
      "logits/chosen": 4.013487815856934,
      "logits/rejected": 3.9204494953155518,
      "logps/chosen": -384.74053955078125,
      "logps/rejected": -287.0496520996094,
      "loss": 0.4316,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3619619607925415,
      "rewards/margins": 2.3060803413391113,
      "rewards/rejected": -3.6680426597595215,
      "step": 14320
    },
    {
      "epoch": 0.843752758083022,
      "grad_norm": 0.6295338869094849,
      "learning_rate": 3.594586643130333e-05,
      "logits/chosen": 4.061034202575684,
      "logits/rejected": 4.024655818939209,
      "logps/chosen": -451.98602294921875,
      "logps/rejected": -344.8045654296875,
      "loss": 0.3567,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.3227788209915161,
      "rewards/margins": 2.894829273223877,
      "rewards/rejected": -4.217608451843262,
      "step": 14340
    },
    {
      "epoch": 0.8449295401723986,
      "grad_norm": 12.079830169677734,
      "learning_rate": 3.592625281945671e-05,
      "logits/chosen": 3.7452750205993652,
      "logits/rejected": 3.6373729705810547,
      "logps/chosen": -368.3631896972656,
      "logps/rejected": -278.97869873046875,
      "loss": 0.4169,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1741989850997925,
      "rewards/margins": 2.8511478900909424,
      "rewards/rejected": -4.025346755981445,
      "step": 14360
    },
    {
      "epoch": 0.8461063222617752,
      "grad_norm": 1.710042119026184,
      "learning_rate": 3.5906639207610085e-05,
      "logits/chosen": 4.2575483322143555,
      "logits/rejected": 4.150637149810791,
      "logps/chosen": -398.1203308105469,
      "logps/rejected": -302.0102844238281,
      "loss": 0.559,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1574851274490356,
      "rewards/margins": 2.4181268215179443,
      "rewards/rejected": -3.5756118297576904,
      "step": 14380
    },
    {
      "epoch": 0.8472831043511517,
      "grad_norm": 1.957259178161621,
      "learning_rate": 3.588702559576346e-05,
      "logits/chosen": 3.9185843467712402,
      "logits/rejected": 3.8278751373291016,
      "logps/chosen": -346.3910827636719,
      "logps/rejected": -264.48486328125,
      "loss": 0.4022,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5587915778160095,
      "rewards/margins": 2.5852174758911133,
      "rewards/rejected": -3.1440088748931885,
      "step": 14400
    },
    {
      "epoch": 0.8484598864405284,
      "grad_norm": 1.8058785200119019,
      "learning_rate": 3.586741198391684e-05,
      "logits/chosen": 4.061997890472412,
      "logits/rejected": 4.0405168533325195,
      "logps/chosen": -404.46478271484375,
      "logps/rejected": -345.541015625,
      "loss": 0.5815,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.7201570272445679,
      "rewards/margins": 2.7786288261413574,
      "rewards/rejected": -3.498786211013794,
      "step": 14420
    },
    {
      "epoch": 0.8496366685299049,
      "grad_norm": 1.9139102697372437,
      "learning_rate": 3.584779837207022e-05,
      "logits/chosen": 3.9000015258789062,
      "logits/rejected": 3.8401942253112793,
      "logps/chosen": -372.27825927734375,
      "logps/rejected": -293.4215393066406,
      "loss": 0.3969,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8498584032058716,
      "rewards/margins": 2.4874002933502197,
      "rewards/rejected": -3.3372585773468018,
      "step": 14440
    },
    {
      "epoch": 0.8508134506192816,
      "grad_norm": 1.0262680053710938,
      "learning_rate": 3.5828184760223596e-05,
      "logits/chosen": 4.056861400604248,
      "logits/rejected": 3.854262113571167,
      "logps/chosen": -385.4920349121094,
      "logps/rejected": -288.4426574707031,
      "loss": 0.4501,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.244465708732605,
      "rewards/margins": 2.813028335571289,
      "rewards/rejected": -4.057494163513184,
      "step": 14460
    },
    {
      "epoch": 0.8519902327086581,
      "grad_norm": 4.681997299194336,
      "learning_rate": 3.580857114837697e-05,
      "logits/chosen": 3.903581142425537,
      "logits/rejected": 3.7404403686523438,
      "logps/chosen": -346.757080078125,
      "logps/rejected": -305.7064208984375,
      "loss": 0.584,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0490366220474243,
      "rewards/margins": 2.026641845703125,
      "rewards/rejected": -3.075678586959839,
      "step": 14480
    },
    {
      "epoch": 0.8531670147980348,
      "grad_norm": 2.315366744995117,
      "learning_rate": 3.5788957536530355e-05,
      "logits/chosen": 3.987351179122925,
      "logits/rejected": 4.016772270202637,
      "logps/chosen": -366.3283386230469,
      "logps/rejected": -311.49688720703125,
      "loss": 0.4717,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.18387262523174286,
      "rewards/margins": 2.6597354412078857,
      "rewards/rejected": -2.8436086177825928,
      "step": 14500
    },
    {
      "epoch": 0.8543437968874114,
      "grad_norm": 0.3776130974292755,
      "learning_rate": 3.576934392468374e-05,
      "logits/chosen": 4.324159145355225,
      "logits/rejected": 4.230815887451172,
      "logps/chosen": -372.85638427734375,
      "logps/rejected": -329.23193359375,
      "loss": 0.3629,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.6750985383987427,
      "rewards/margins": 2.981806755065918,
      "rewards/rejected": -3.656904935836792,
      "step": 14520
    },
    {
      "epoch": 0.855520578976788,
      "grad_norm": 0.6472315788269043,
      "learning_rate": 3.574973031283711e-05,
      "logits/chosen": 4.392849445343018,
      "logits/rejected": 4.303752422332764,
      "logps/chosen": -445.1990661621094,
      "logps/rejected": -347.3636169433594,
      "loss": 0.4705,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.09192828834056854,
      "rewards/margins": 3.253969192504883,
      "rewards/rejected": -3.1620407104492188,
      "step": 14540
    },
    {
      "epoch": 0.8566973610661646,
      "grad_norm": 0.15084746479988098,
      "learning_rate": 3.573011670099049e-05,
      "logits/chosen": 4.162626266479492,
      "logits/rejected": 3.9466071128845215,
      "logps/chosen": -350.12554931640625,
      "logps/rejected": -280.27001953125,
      "loss": 0.4335,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7185966968536377,
      "rewards/margins": 3.0294172763824463,
      "rewards/rejected": -3.748013973236084,
      "step": 14560
    },
    {
      "epoch": 0.8578741431555412,
      "grad_norm": 6.299740314483643,
      "learning_rate": 3.5710503089143866e-05,
      "logits/chosen": 3.891031265258789,
      "logits/rejected": 3.8160271644592285,
      "logps/chosen": -392.55804443359375,
      "logps/rejected": -320.1649169921875,
      "loss": 0.5835,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.0053699016571045,
      "rewards/margins": 1.797502875328064,
      "rewards/rejected": -2.802872896194458,
      "step": 14580
    },
    {
      "epoch": 0.8590509252449178,
      "grad_norm": 2.2323174476623535,
      "learning_rate": 3.569088947729725e-05,
      "logits/chosen": 4.007292747497559,
      "logits/rejected": 3.792346239089966,
      "logps/chosen": -348.22198486328125,
      "logps/rejected": -338.79949951171875,
      "loss": 0.5145,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.142210841178894,
      "rewards/margins": 2.2692408561706543,
      "rewards/rejected": -3.411451816558838,
      "step": 14600
    },
    {
      "epoch": 0.8602277073342943,
      "grad_norm": 3.558405876159668,
      "learning_rate": 3.5671275865450625e-05,
      "logits/chosen": 3.7235851287841797,
      "logits/rejected": 3.727160930633545,
      "logps/chosen": -383.74383544921875,
      "logps/rejected": -312.2526550292969,
      "loss": 0.4778,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.452032446861267,
      "rewards/margins": 2.275550365447998,
      "rewards/rejected": -3.7275829315185547,
      "step": 14620
    },
    {
      "epoch": 0.861404489423671,
      "grad_norm": 3.178196430206299,
      "learning_rate": 3.565264293419634e-05,
      "logits/chosen": 3.8643622398376465,
      "logits/rejected": 3.737396717071533,
      "logps/chosen": -339.7308654785156,
      "logps/rejected": -330.990966796875,
      "loss": 0.4868,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4838635921478271,
      "rewards/margins": 2.745755672454834,
      "rewards/rejected": -4.229619026184082,
      "step": 14640
    },
    {
      "epoch": 0.8625812715130475,
      "grad_norm": 2.536259651184082,
      "learning_rate": 3.563302932234971e-05,
      "logits/chosen": 4.034862041473389,
      "logits/rejected": 3.807724714279175,
      "logps/chosen": -421.2515563964844,
      "logps/rejected": -314.38104248046875,
      "loss": 0.4042,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.277187466621399,
      "rewards/margins": 2.6184375286102295,
      "rewards/rejected": -3.895625352859497,
      "step": 14660
    },
    {
      "epoch": 0.8637580536024242,
      "grad_norm": 6.773502826690674,
      "learning_rate": 3.561341571050309e-05,
      "logits/chosen": 3.792147159576416,
      "logits/rejected": 3.738114833831787,
      "logps/chosen": -383.2464904785156,
      "logps/rejected": -336.7169189453125,
      "loss": 0.7556,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2296229600906372,
      "rewards/margins": 2.2247116565704346,
      "rewards/rejected": -3.4543347358703613,
      "step": 14680
    },
    {
      "epoch": 0.8649348356918007,
      "grad_norm": 2.3510050773620605,
      "learning_rate": 3.559380209865647e-05,
      "logits/chosen": 4.04395055770874,
      "logits/rejected": 4.094679355621338,
      "logps/chosen": -434.5035095214844,
      "logps/rejected": -313.7450866699219,
      "loss": 0.4692,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.6503458023071289,
      "rewards/margins": 2.447783946990967,
      "rewards/rejected": -3.098129987716675,
      "step": 14700
    },
    {
      "epoch": 0.8661116177811774,
      "grad_norm": 1.1853833198547363,
      "learning_rate": 3.557418848680985e-05,
      "logits/chosen": 3.8794105052948,
      "logits/rejected": 4.048266410827637,
      "logps/chosen": -348.9603576660156,
      "logps/rejected": -291.24945068359375,
      "loss": 0.4524,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6096839904785156,
      "rewards/margins": 1.8132820129394531,
      "rewards/rejected": -2.422966241836548,
      "step": 14720
    },
    {
      "epoch": 0.867288399870554,
      "grad_norm": 5.727426528930664,
      "learning_rate": 3.5554574874963224e-05,
      "logits/chosen": 3.915066957473755,
      "logits/rejected": 3.8427581787109375,
      "logps/chosen": -379.69647216796875,
      "logps/rejected": -315.8939514160156,
      "loss": 0.4485,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.45488619804382324,
      "rewards/margins": 2.496157169342041,
      "rewards/rejected": -2.9510436058044434,
      "step": 14740
    },
    {
      "epoch": 0.8684651819599306,
      "grad_norm": 1.7905616760253906,
      "learning_rate": 3.553496126311661e-05,
      "logits/chosen": 3.7205474376678467,
      "logits/rejected": 3.6408684253692627,
      "logps/chosen": -356.2950134277344,
      "logps/rejected": -309.91229248046875,
      "loss": 0.586,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.16661718487739563,
      "rewards/margins": 2.6222357749938965,
      "rewards/rejected": -2.788853168487549,
      "step": 14760
    },
    {
      "epoch": 0.8696419640493072,
      "grad_norm": 2.6828553676605225,
      "learning_rate": 3.551534765126998e-05,
      "logits/chosen": 3.3501052856445312,
      "logits/rejected": 3.36466908454895,
      "logps/chosen": -331.2853698730469,
      "logps/rejected": -248.9219207763672,
      "loss": 0.773,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.44975003600120544,
      "rewards/margins": 2.000713348388672,
      "rewards/rejected": -2.45046329498291,
      "step": 14780
    },
    {
      "epoch": 0.8708187461386838,
      "grad_norm": 1.9375,
      "learning_rate": 3.549573403942336e-05,
      "logits/chosen": 3.8947224617004395,
      "logits/rejected": 3.7676632404327393,
      "logps/chosen": -370.4145202636719,
      "logps/rejected": -325.53228759765625,
      "loss": 0.7833,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.0911680459976196,
      "rewards/margins": 2.321525812149048,
      "rewards/rejected": -3.412693738937378,
      "step": 14800
    },
    {
      "epoch": 0.8719955282280604,
      "grad_norm": 1.7444361448287964,
      "learning_rate": 3.547612042757674e-05,
      "logits/chosen": 3.7796432971954346,
      "logits/rejected": 3.7248282432556152,
      "logps/chosen": -373.39141845703125,
      "logps/rejected": -289.74249267578125,
      "loss": 0.5965,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.009450292214751244,
      "rewards/margins": 2.7236828804016113,
      "rewards/rejected": -2.733132839202881,
      "step": 14820
    },
    {
      "epoch": 0.8731723103174369,
      "grad_norm": 0.4300536513328552,
      "learning_rate": 3.545650681573012e-05,
      "logits/chosen": 3.997898578643799,
      "logits/rejected": 3.9494354724884033,
      "logps/chosen": -399.87091064453125,
      "logps/rejected": -300.19921875,
      "loss": 0.3761,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": 0.2704789936542511,
      "rewards/margins": 3.1856532096862793,
      "rewards/rejected": -2.9151742458343506,
      "step": 14840
    },
    {
      "epoch": 0.8743490924068136,
      "grad_norm": 0.9486347436904907,
      "learning_rate": 3.54368932038835e-05,
      "logits/chosen": 4.123311519622803,
      "logits/rejected": 4.096284866333008,
      "logps/chosen": -421.715576171875,
      "logps/rejected": -373.3187255859375,
      "loss": 0.5786,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7027345895767212,
      "rewards/margins": 2.454193592071533,
      "rewards/rejected": -3.156928300857544,
      "step": 14860
    },
    {
      "epoch": 0.8755258744961901,
      "grad_norm": 1.0534472465515137,
      "learning_rate": 3.541727959203687e-05,
      "logits/chosen": 3.9659698009490967,
      "logits/rejected": 3.9379215240478516,
      "logps/chosen": -394.28289794921875,
      "logps/rejected": -344.18328857421875,
      "loss": 0.4948,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.6174525022506714,
      "rewards/margins": 2.585592031478882,
      "rewards/rejected": -3.2030444145202637,
      "step": 14880
    },
    {
      "epoch": 0.8767026565855668,
      "grad_norm": 0.8105626106262207,
      "learning_rate": 3.539766598019025e-05,
      "logits/chosen": 3.705512285232544,
      "logits/rejected": 3.7616615295410156,
      "logps/chosen": -357.37939453125,
      "logps/rejected": -318.5928955078125,
      "loss": 0.3641,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.3156258165836334,
      "rewards/margins": 3.1193926334381104,
      "rewards/rejected": -3.435018539428711,
      "step": 14900
    },
    {
      "epoch": 0.8778794386749433,
      "grad_norm": 1.3618100881576538,
      "learning_rate": 3.5378052368343635e-05,
      "logits/chosen": 4.024827003479004,
      "logits/rejected": 4.012803077697754,
      "logps/chosen": -389.3460693359375,
      "logps/rejected": -335.08026123046875,
      "loss": 0.5815,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.8150461912155151,
      "rewards/margins": 2.2935314178466797,
      "rewards/rejected": -3.1085777282714844,
      "step": 14920
    },
    {
      "epoch": 0.87905622076432,
      "grad_norm": 19.98406410217285,
      "learning_rate": 3.535843875649701e-05,
      "logits/chosen": 4.087640285491943,
      "logits/rejected": 4.088118553161621,
      "logps/chosen": -417.71142578125,
      "logps/rejected": -350.54193115234375,
      "loss": 0.7333,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.8732447624206543,
      "rewards/margins": 2.459988594055176,
      "rewards/rejected": -3.333233594894409,
      "step": 14940
    },
    {
      "epoch": 0.8802330028536965,
      "grad_norm": 3.846165180206299,
      "learning_rate": 3.533882514465039e-05,
      "logits/chosen": 3.8907153606414795,
      "logits/rejected": 3.7922370433807373,
      "logps/chosen": -389.7831115722656,
      "logps/rejected": -319.5617980957031,
      "loss": 0.473,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0164949893951416,
      "rewards/margins": 1.986396074295044,
      "rewards/rejected": -3.0028910636901855,
      "step": 14960
    },
    {
      "epoch": 0.8814097849430732,
      "grad_norm": 1.688188076019287,
      "learning_rate": 3.531921153280377e-05,
      "logits/chosen": 4.057548522949219,
      "logits/rejected": 3.9304046630859375,
      "logps/chosen": -355.2289123535156,
      "logps/rejected": -288.1685791015625,
      "loss": 0.5871,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.028537631034851,
      "rewards/margins": 1.6341512203216553,
      "rewards/rejected": -2.662689208984375,
      "step": 14980
    },
    {
      "epoch": 0.8825865670324498,
      "grad_norm": 1.20518958568573,
      "learning_rate": 3.5299597920957146e-05,
      "logits/chosen": 4.139245510101318,
      "logits/rejected": 4.116495132446289,
      "logps/chosen": -374.20013427734375,
      "logps/rejected": -355.78375244140625,
      "loss": 0.4557,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8032041788101196,
      "rewards/margins": 2.2889699935913086,
      "rewards/rejected": -3.0921740531921387,
      "step": 15000
    },
    {
      "epoch": 0.8825865670324498,
      "eval_logits/chosen": 3.6009573936462402,
      "eval_logits/rejected": 3.5932774543762207,
      "eval_logps/chosen": -363.0773620605469,
      "eval_logps/rejected": -324.80487060546875,
      "eval_loss": 0.5141610503196716,
      "eval_rewards/accuracies": 0.7681639194488525,
      "eval_rewards/chosen": -0.8496675491333008,
      "eval_rewards/margins": 2.007495880126953,
      "eval_rewards/rejected": -2.857163667678833,
      "eval_runtime": 3547.6589,
      "eval_samples_per_second": 3.15,
      "eval_steps_per_second": 3.15,
      "step": 15000
    },
    {
      "epoch": 0.8837633491218264,
      "grad_norm": 2.3010356426239014,
      "learning_rate": 3.527998430911052e-05,
      "logits/chosen": 3.9646315574645996,
      "logits/rejected": 3.832782030105591,
      "logps/chosen": -354.563232421875,
      "logps/rejected": -271.904296875,
      "loss": 0.5305,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.023704910650849342,
      "rewards/margins": 2.9924120903015137,
      "rewards/rejected": -3.0161170959472656,
      "step": 15020
    },
    {
      "epoch": 0.884940131211203,
      "grad_norm": 2.761131763458252,
      "learning_rate": 3.52603706972639e-05,
      "logits/chosen": 4.135679244995117,
      "logits/rejected": 4.059798240661621,
      "logps/chosen": -397.22296142578125,
      "logps/rejected": -319.0980529785156,
      "loss": 0.3015,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.9392341375350952,
      "rewards/margins": 2.552971124649048,
      "rewards/rejected": -3.4922053813934326,
      "step": 15040
    },
    {
      "epoch": 0.8861169133005795,
      "grad_norm": 0.6120240092277527,
      "learning_rate": 3.524075708541728e-05,
      "logits/chosen": 4.133128643035889,
      "logits/rejected": 4.065455436706543,
      "logps/chosen": -341.90692138671875,
      "logps/rejected": -321.3575744628906,
      "loss": 0.429,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.344535231590271,
      "rewards/margins": 2.235767126083374,
      "rewards/rejected": -3.5803024768829346,
      "step": 15060
    },
    {
      "epoch": 0.8872936953899562,
      "grad_norm": 1.194841980934143,
      "learning_rate": 3.5221143473570664e-05,
      "logits/chosen": 3.987229824066162,
      "logits/rejected": 3.9079864025115967,
      "logps/chosen": -383.59521484375,
      "logps/rejected": -348.557373046875,
      "loss": 0.4041,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.139474868774414,
      "rewards/margins": 2.609367847442627,
      "rewards/rejected": -3.74884295463562,
      "step": 15080
    },
    {
      "epoch": 0.8884704774793327,
      "grad_norm": 4.196463584899902,
      "learning_rate": 3.5201529861724033e-05,
      "logits/chosen": 4.03037166595459,
      "logits/rejected": 3.743851900100708,
      "logps/chosen": -402.7945556640625,
      "logps/rejected": -306.466796875,
      "loss": 0.4264,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8393591046333313,
      "rewards/margins": 3.1067028045654297,
      "rewards/rejected": -3.946061611175537,
      "step": 15100
    },
    {
      "epoch": 0.8896472595687094,
      "grad_norm": 0.5391677618026733,
      "learning_rate": 3.5181916249877416e-05,
      "logits/chosen": 4.005043029785156,
      "logits/rejected": 3.968940019607544,
      "logps/chosen": -382.63763427734375,
      "logps/rejected": -308.55096435546875,
      "loss": 0.4035,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.38084906339645386,
      "rewards/margins": 3.196685552597046,
      "rewards/rejected": -3.5775349140167236,
      "step": 15120
    },
    {
      "epoch": 0.8908240416580859,
      "grad_norm": 1.824614405632019,
      "learning_rate": 3.51623026380308e-05,
      "logits/chosen": 3.626422166824341,
      "logits/rejected": 3.558976650238037,
      "logps/chosen": -331.4780578613281,
      "logps/rejected": -290.50701904296875,
      "loss": 0.4908,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.617570161819458,
      "rewards/margins": 2.434199094772339,
      "rewards/rejected": -3.051769256591797,
      "step": 15140
    },
    {
      "epoch": 0.8920008237474626,
      "grad_norm": 1.7618690729141235,
      "learning_rate": 3.5142689026184175e-05,
      "logits/chosen": 4.021048545837402,
      "logits/rejected": 4.0548553466796875,
      "logps/chosen": -322.5707092285156,
      "logps/rejected": -289.18450927734375,
      "loss": 0.5002,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.023277759552002,
      "rewards/margins": 2.151632308959961,
      "rewards/rejected": -3.174910068511963,
      "step": 15160
    },
    {
      "epoch": 0.8931776058368391,
      "grad_norm": 1.4652323722839355,
      "learning_rate": 3.512307541433755e-05,
      "logits/chosen": 3.961024522781372,
      "logits/rejected": 3.9521725177764893,
      "logps/chosen": -360.8753356933594,
      "logps/rejected": -294.4744567871094,
      "loss": 0.3475,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8562928438186646,
      "rewards/margins": 2.710684299468994,
      "rewards/rejected": -3.5669772624969482,
      "step": 15180
    },
    {
      "epoch": 0.8943543879262158,
      "grad_norm": 0.8228702545166016,
      "learning_rate": 3.510346180249093e-05,
      "logits/chosen": 3.8871796131134033,
      "logits/rejected": 3.949235439300537,
      "logps/chosen": -369.04473876953125,
      "logps/rejected": -353.29046630859375,
      "loss": 0.4264,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.798875093460083,
      "rewards/margins": 3.056715488433838,
      "rewards/rejected": -3.855590343475342,
      "step": 15200
    },
    {
      "epoch": 0.8955311700155923,
      "grad_norm": 0.9949069619178772,
      "learning_rate": 3.508384819064431e-05,
      "logits/chosen": 3.92829966545105,
      "logits/rejected": 3.9347357749938965,
      "logps/chosen": -372.9388732910156,
      "logps/rejected": -322.00128173828125,
      "loss": 0.5908,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5188804864883423,
      "rewards/margins": 2.0620906352996826,
      "rewards/rejected": -3.5809712409973145,
      "step": 15220
    },
    {
      "epoch": 0.896707952104969,
      "grad_norm": 2.216310977935791,
      "learning_rate": 3.5064234578797686e-05,
      "logits/chosen": 4.066656589508057,
      "logits/rejected": 3.934739351272583,
      "logps/chosen": -374.2000427246094,
      "logps/rejected": -317.98577880859375,
      "loss": 0.3812,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.524259626865387,
      "rewards/margins": 3.099224805831909,
      "rewards/rejected": -3.6234841346740723,
      "step": 15240
    },
    {
      "epoch": 0.8978847341943456,
      "grad_norm": 4.737018585205078,
      "learning_rate": 3.504462096695106e-05,
      "logits/chosen": 4.201900005340576,
      "logits/rejected": 4.044484615325928,
      "logps/chosen": -383.7872314453125,
      "logps/rejected": -291.6937255859375,
      "loss": 0.3272,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.9382036924362183,
      "rewards/margins": 2.848386764526367,
      "rewards/rejected": -3.786591053009033,
      "step": 15260
    },
    {
      "epoch": 0.8990615162837221,
      "grad_norm": 0.20499330759048462,
      "learning_rate": 3.5025007355104445e-05,
      "logits/chosen": 4.330917835235596,
      "logits/rejected": 4.141354084014893,
      "logps/chosen": -419.44317626953125,
      "logps/rejected": -320.66876220703125,
      "loss": 0.3448,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.6050862073898315,
      "rewards/margins": 3.0812978744506836,
      "rewards/rejected": -3.6863842010498047,
      "step": 15280
    },
    {
      "epoch": 0.9002382983730988,
      "grad_norm": 1.262852668762207,
      "learning_rate": 3.500539374325783e-05,
      "logits/chosen": 4.00022554397583,
      "logits/rejected": 3.9581217765808105,
      "logps/chosen": -361.135009765625,
      "logps/rejected": -314.7633972167969,
      "loss": 0.3889,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.3117462396621704,
      "rewards/margins": 3.0385916233062744,
      "rewards/rejected": -3.3503379821777344,
      "step": 15300
    },
    {
      "epoch": 0.9014150804624753,
      "grad_norm": 3.297288179397583,
      "learning_rate": 3.49857801314112e-05,
      "logits/chosen": 3.870051622390747,
      "logits/rejected": 3.8206558227539062,
      "logps/chosen": -430.79327392578125,
      "logps/rejected": -371.82452392578125,
      "loss": 0.5644,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": 0.12288644164800644,
      "rewards/margins": 3.5011086463928223,
      "rewards/rejected": -3.3782222270965576,
      "step": 15320
    },
    {
      "epoch": 0.902591862551852,
      "grad_norm": 0.847792387008667,
      "learning_rate": 3.496616651956458e-05,
      "logits/chosen": 4.115324974060059,
      "logits/rejected": 4.071435928344727,
      "logps/chosen": -397.49920654296875,
      "logps/rejected": -343.56878662109375,
      "loss": 0.4069,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.6273670792579651,
      "rewards/margins": 3.343327760696411,
      "rewards/rejected": -3.9706947803497314,
      "step": 15340
    },
    {
      "epoch": 0.9037686446412285,
      "grad_norm": 0.8904139995574951,
      "learning_rate": 3.4946552907717956e-05,
      "logits/chosen": 4.109581470489502,
      "logits/rejected": 3.975956678390503,
      "logps/chosen": -437.20880126953125,
      "logps/rejected": -326.2853088378906,
      "loss": 0.3978,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5913744568824768,
      "rewards/margins": 3.026298999786377,
      "rewards/rejected": -3.617673873901367,
      "step": 15360
    },
    {
      "epoch": 0.9049454267306052,
      "grad_norm": 3.0702385902404785,
      "learning_rate": 3.492693929587134e-05,
      "logits/chosen": 3.9320571422576904,
      "logits/rejected": 3.9750072956085205,
      "logps/chosen": -345.4940185546875,
      "logps/rejected": -311.8659973144531,
      "loss": 0.415,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2856082916259766,
      "rewards/margins": 2.872471570968628,
      "rewards/rejected": -4.158080101013184,
      "step": 15380
    },
    {
      "epoch": 0.9061222088199817,
      "grad_norm": 4.726980209350586,
      "learning_rate": 3.4907325684024715e-05,
      "logits/chosen": 3.7995522022247314,
      "logits/rejected": 3.843944549560547,
      "logps/chosen": -382.9656677246094,
      "logps/rejected": -327.6526794433594,
      "loss": 0.419,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.5140037536621094,
      "rewards/margins": 3.114598035812378,
      "rewards/rejected": -3.628601551055908,
      "step": 15400
    },
    {
      "epoch": 0.9072989909093584,
      "grad_norm": 5.289061069488525,
      "learning_rate": 3.488771207217809e-05,
      "logits/chosen": 3.9674575328826904,
      "logits/rejected": 3.96000599861145,
      "logps/chosen": -387.7608947753906,
      "logps/rejected": -356.320556640625,
      "loss": 0.4428,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.6671415567398071,
      "rewards/margins": 3.1272101402282715,
      "rewards/rejected": -3.7943520545959473,
      "step": 15420
    },
    {
      "epoch": 0.9084757729987349,
      "grad_norm": 1.2546322345733643,
      "learning_rate": 3.4868098460331473e-05,
      "logits/chosen": 3.9732956886291504,
      "logits/rejected": 3.894075393676758,
      "logps/chosen": -431.30877685546875,
      "logps/rejected": -342.1146545410156,
      "loss": 0.4387,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.9611144065856934,
      "rewards/margins": 3.196624517440796,
      "rewards/rejected": -4.15773868560791,
      "step": 15440
    },
    {
      "epoch": 0.9096525550881116,
      "grad_norm": 5.196598052978516,
      "learning_rate": 3.484848484848485e-05,
      "logits/chosen": 4.052244663238525,
      "logits/rejected": 3.9724388122558594,
      "logps/chosen": -442.45587158203125,
      "logps/rejected": -311.125732421875,
      "loss": 0.532,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.5897088646888733,
      "rewards/margins": 2.782845973968506,
      "rewards/rejected": -3.3725547790527344,
      "step": 15460
    },
    {
      "epoch": 0.9108293371774882,
      "grad_norm": 1.4103238582611084,
      "learning_rate": 3.4828871236638226e-05,
      "logits/chosen": 3.9293789863586426,
      "logits/rejected": 3.8328514099121094,
      "logps/chosen": -390.7580261230469,
      "logps/rejected": -320.8384094238281,
      "loss": 0.5061,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.7183529138565063,
      "rewards/margins": 2.3495187759399414,
      "rewards/rejected": -3.067871570587158,
      "step": 15480
    },
    {
      "epoch": 0.9120061192668648,
      "grad_norm": 0.9521251916885376,
      "learning_rate": 3.480925762479161e-05,
      "logits/chosen": 3.8466999530792236,
      "logits/rejected": 3.8759701251983643,
      "logps/chosen": -386.381591796875,
      "logps/rejected": -332.62030029296875,
      "loss": 0.42,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.8510036468505859,
      "rewards/margins": 3.0005829334259033,
      "rewards/rejected": -3.851586103439331,
      "step": 15500
    },
    {
      "epoch": 0.9131829013562414,
      "grad_norm": 5.652709007263184,
      "learning_rate": 3.4789644012944984e-05,
      "logits/chosen": 3.95973539352417,
      "logits/rejected": 3.8991599082946777,
      "logps/chosen": -351.6891174316406,
      "logps/rejected": -309.9817810058594,
      "loss": 0.5179,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.116113305091858,
      "rewards/margins": 2.6525747776031494,
      "rewards/rejected": -3.768688201904297,
      "step": 15520
    },
    {
      "epoch": 0.9143596834456179,
      "grad_norm": 1.8990765810012817,
      "learning_rate": 3.477003040109836e-05,
      "logits/chosen": 3.7711455821990967,
      "logits/rejected": 3.8061435222625732,
      "logps/chosen": -385.1772155761719,
      "logps/rejected": -326.6446533203125,
      "loss": 0.5094,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.8408511877059937,
      "rewards/margins": 2.6282458305358887,
      "rewards/rejected": -3.469097137451172,
      "step": 15540
    },
    {
      "epoch": 0.9155364655349946,
      "grad_norm": 1.6207281351089478,
      "learning_rate": 3.475041678925174e-05,
      "logits/chosen": 3.606449842453003,
      "logits/rejected": 3.664088726043701,
      "logps/chosen": -347.86151123046875,
      "logps/rejected": -327.74481201171875,
      "loss": 0.6529,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.3944833278656006,
      "rewards/margins": 1.8376966714859009,
      "rewards/rejected": -3.232180118560791,
      "step": 15560
    },
    {
      "epoch": 0.9167132476243711,
      "grad_norm": 2.239649772644043,
      "learning_rate": 3.473080317740512e-05,
      "logits/chosen": 3.9845480918884277,
      "logits/rejected": 3.911226272583008,
      "logps/chosen": -371.8819885253906,
      "logps/rejected": -338.28765869140625,
      "loss": 0.3018,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.1882299184799194,
      "rewards/margins": 3.299330234527588,
      "rewards/rejected": -4.487560272216797,
      "step": 15580
    },
    {
      "epoch": 0.9178900297137478,
      "grad_norm": 1.3882094621658325,
      "learning_rate": 3.47111895655585e-05,
      "logits/chosen": 3.6285014152526855,
      "logits/rejected": 3.5726158618927,
      "logps/chosen": -409.3416442871094,
      "logps/rejected": -359.26031494140625,
      "loss": 0.3658,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7822000980377197,
      "rewards/margins": 3.492053270339966,
      "rewards/rejected": -5.274252891540527,
      "step": 15600
    },
    {
      "epoch": 0.9190668118031243,
      "grad_norm": 1.6380131244659424,
      "learning_rate": 3.469157595371188e-05,
      "logits/chosen": 4.035763740539551,
      "logits/rejected": 3.9394729137420654,
      "logps/chosen": -431.4788513183594,
      "logps/rejected": -332.2919006347656,
      "loss": 0.5251,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.30169677734375,
      "rewards/margins": 3.1460964679718018,
      "rewards/rejected": -5.447793483734131,
      "step": 15620
    },
    {
      "epoch": 0.920243593892501,
      "grad_norm": 0.7551402449607849,
      "learning_rate": 3.4671962341865254e-05,
      "logits/chosen": 4.2596025466918945,
      "logits/rejected": 3.973235607147217,
      "logps/chosen": -451.78729248046875,
      "logps/rejected": -325.17803955078125,
      "loss": 0.4048,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6657378673553467,
      "rewards/margins": 3.103851318359375,
      "rewards/rejected": -4.769589424133301,
      "step": 15640
    },
    {
      "epoch": 0.9214203759818775,
      "grad_norm": 1.1198532581329346,
      "learning_rate": 3.465234873001864e-05,
      "logits/chosen": 3.8675785064697266,
      "logits/rejected": 3.7128663063049316,
      "logps/chosen": -385.99957275390625,
      "logps/rejected": -287.8075866699219,
      "loss": 0.3898,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4261033535003662,
      "rewards/margins": 2.701873302459717,
      "rewards/rejected": -4.127976417541504,
      "step": 15660
    },
    {
      "epoch": 0.9225971580712542,
      "grad_norm": 1.5409740209579468,
      "learning_rate": 3.463273511817201e-05,
      "logits/chosen": 3.902616024017334,
      "logits/rejected": 3.902905225753784,
      "logps/chosen": -377.40350341796875,
      "logps/rejected": -318.79461669921875,
      "loss": 0.3068,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.2842330932617188,
      "rewards/margins": 3.2937302589416504,
      "rewards/rejected": -4.577963352203369,
      "step": 15680
    },
    {
      "epoch": 0.9237739401606307,
      "grad_norm": 2.7340457439422607,
      "learning_rate": 3.461312150632539e-05,
      "logits/chosen": 3.5394794940948486,
      "logits/rejected": 3.5783774852752686,
      "logps/chosen": -393.145751953125,
      "logps/rejected": -279.63116455078125,
      "loss": 0.4369,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.0287058353424072,
      "rewards/margins": 2.980525016784668,
      "rewards/rejected": -4.009230613708496,
      "step": 15700
    },
    {
      "epoch": 0.9249507222500074,
      "grad_norm": 1.714910864830017,
      "learning_rate": 3.459350789447877e-05,
      "logits/chosen": 3.9004573822021484,
      "logits/rejected": 3.792466640472412,
      "logps/chosen": -414.55609130859375,
      "logps/rejected": -314.9476623535156,
      "loss": 0.4975,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6936123967170715,
      "rewards/margins": 3.1604113578796387,
      "rewards/rejected": -3.8540236949920654,
      "step": 15720
    },
    {
      "epoch": 0.926127504339384,
      "grad_norm": 3.579822540283203,
      "learning_rate": 3.457389428263215e-05,
      "logits/chosen": 3.7332091331481934,
      "logits/rejected": 3.6054673194885254,
      "logps/chosen": -366.22967529296875,
      "logps/rejected": -329.5192565917969,
      "loss": 0.4795,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.883134663105011,
      "rewards/margins": 2.9528918266296387,
      "rewards/rejected": -3.836026668548584,
      "step": 15740
    },
    {
      "epoch": 0.9273042864287605,
      "grad_norm": 0.7494171261787415,
      "learning_rate": 3.4554280670785524e-05,
      "logits/chosen": 3.983611583709717,
      "logits/rejected": 3.9176011085510254,
      "logps/chosen": -411.6890563964844,
      "logps/rejected": -334.6026306152344,
      "loss": 0.4335,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.7695527076721191,
      "rewards/margins": 2.9214494228363037,
      "rewards/rejected": -3.691002368927002,
      "step": 15760
    },
    {
      "epoch": 0.9284810685181372,
      "grad_norm": 3.1820895671844482,
      "learning_rate": 3.453466705893891e-05,
      "logits/chosen": 3.6652679443359375,
      "logits/rejected": 3.7677223682403564,
      "logps/chosen": -341.2052917480469,
      "logps/rejected": -351.7047424316406,
      "loss": 0.5555,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": 0.08880039304494858,
      "rewards/margins": 2.8534891605377197,
      "rewards/rejected": -2.7646889686584473,
      "step": 15780
    },
    {
      "epoch": 0.9296578506075137,
      "grad_norm": 0.6251823902130127,
      "learning_rate": 3.451505344709228e-05,
      "logits/chosen": 4.146622657775879,
      "logits/rejected": 4.065159797668457,
      "logps/chosen": -388.6861572265625,
      "logps/rejected": -330.1944274902344,
      "loss": 0.4357,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.8668611645698547,
      "rewards/margins": 2.751847505569458,
      "rewards/rejected": -3.618708848953247,
      "step": 15800
    },
    {
      "epoch": 0.9308346326968904,
      "grad_norm": 2.694965362548828,
      "learning_rate": 3.4495439835245666e-05,
      "logits/chosen": 3.9581685066223145,
      "logits/rejected": 4.00588846206665,
      "logps/chosen": -367.5289306640625,
      "logps/rejected": -308.3334045410156,
      "loss": 0.6959,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.615810751914978,
      "rewards/margins": 2.001300096511841,
      "rewards/rejected": -2.6171107292175293,
      "step": 15820
    },
    {
      "epoch": 0.9320114147862669,
      "grad_norm": 1.3204056024551392,
      "learning_rate": 3.4475826223399035e-05,
      "logits/chosen": 4.107813835144043,
      "logits/rejected": 4.071738243103027,
      "logps/chosen": -401.44781494140625,
      "logps/rejected": -301.02667236328125,
      "loss": 0.4918,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.7162960171699524,
      "rewards/margins": 2.516770124435425,
      "rewards/rejected": -3.2330665588378906,
      "step": 15840
    },
    {
      "epoch": 0.9331881968756436,
      "grad_norm": 2.73370099067688,
      "learning_rate": 3.4457193292144754e-05,
      "logits/chosen": 3.9647459983825684,
      "logits/rejected": 3.8817505836486816,
      "logps/chosen": -362.748779296875,
      "logps/rejected": -315.1699523925781,
      "loss": 0.6805,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.6060396432876587,
      "rewards/margins": 1.8693301677703857,
      "rewards/rejected": -2.475369930267334,
      "step": 15860
    },
    {
      "epoch": 0.9343649789650201,
      "grad_norm": 2.3801522254943848,
      "learning_rate": 3.443757968029813e-05,
      "logits/chosen": 3.778067111968994,
      "logits/rejected": 3.7571098804473877,
      "logps/chosen": -307.5457763671875,
      "logps/rejected": -275.8663024902344,
      "loss": 0.4547,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.476173460483551,
      "rewards/margins": 2.4591565132141113,
      "rewards/rejected": -2.9353299140930176,
      "step": 15880
    },
    {
      "epoch": 0.9355417610543968,
      "grad_norm": 1.164107322692871,
      "learning_rate": 3.4417966068451506e-05,
      "logits/chosen": 4.188312530517578,
      "logits/rejected": 4.138314247131348,
      "logps/chosen": -386.56689453125,
      "logps/rejected": -338.8053894042969,
      "loss": 0.4536,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.2963692545890808,
      "rewards/margins": 2.658053159713745,
      "rewards/rejected": -2.95442271232605,
      "step": 15900
    },
    {
      "epoch": 0.9367185431437733,
      "grad_norm": 0.411479115486145,
      "learning_rate": 3.439835245660489e-05,
      "logits/chosen": 4.337279319763184,
      "logits/rejected": 4.166481971740723,
      "logps/chosen": -422.8896484375,
      "logps/rejected": -329.47802734375,
      "loss": 0.4076,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": 0.16417978703975677,
      "rewards/margins": 3.64447021484375,
      "rewards/rejected": -3.480290651321411,
      "step": 15920
    },
    {
      "epoch": 0.93789532523315,
      "grad_norm": 2.9558563232421875,
      "learning_rate": 3.4378738844758265e-05,
      "logits/chosen": 4.149467945098877,
      "logits/rejected": 4.1263909339904785,
      "logps/chosen": -358.4181823730469,
      "logps/rejected": -312.36834716796875,
      "loss": 0.3867,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": 0.006143218372017145,
      "rewards/margins": 2.3812692165374756,
      "rewards/rejected": -2.375126361846924,
      "step": 15940
    },
    {
      "epoch": 0.9390721073225266,
      "grad_norm": 2.5530269145965576,
      "learning_rate": 3.435912523291164e-05,
      "logits/chosen": 3.6681861877441406,
      "logits/rejected": 3.678835391998291,
      "logps/chosen": -317.76141357421875,
      "logps/rejected": -279.6222229003906,
      "loss": 0.4748,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.46737757325172424,
      "rewards/margins": 2.6842730045318604,
      "rewards/rejected": -3.1516501903533936,
      "step": 15960
    },
    {
      "epoch": 0.9402488894119031,
      "grad_norm": 2.5190987586975098,
      "learning_rate": 3.433951162106502e-05,
      "logits/chosen": 3.704051971435547,
      "logits/rejected": 3.7990200519561768,
      "logps/chosen": -346.2625732421875,
      "logps/rejected": -291.1796875,
      "loss": 0.4516,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7506015300750732,
      "rewards/margins": 2.6773552894592285,
      "rewards/rejected": -3.4279568195343018,
      "step": 15980
    },
    {
      "epoch": 0.9414256715012798,
      "grad_norm": 1.4404600858688354,
      "learning_rate": 3.43198980092184e-05,
      "logits/chosen": 3.831641674041748,
      "logits/rejected": 3.820847272872925,
      "logps/chosen": -389.4490661621094,
      "logps/rejected": -314.11444091796875,
      "loss": 0.4017,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.08815839141607285,
      "rewards/margins": 3.185413122177124,
      "rewards/rejected": -3.273571491241455,
      "step": 16000
    },
    {
      "epoch": 0.9426024535906563,
      "grad_norm": 5.31058931350708,
      "learning_rate": 3.430028439737178e-05,
      "logits/chosen": 3.8706302642822266,
      "logits/rejected": 3.817331314086914,
      "logps/chosen": -428.01239013671875,
      "logps/rejected": -304.299560546875,
      "loss": 0.3674,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.898629367351532,
      "rewards/margins": 3.235813856124878,
      "rewards/rejected": -4.134442329406738,
      "step": 16020
    },
    {
      "epoch": 0.943779235680033,
      "grad_norm": 2.726299285888672,
      "learning_rate": 3.428067078552515e-05,
      "logits/chosen": 3.638709306716919,
      "logits/rejected": 3.7513580322265625,
      "logps/chosen": -360.09649658203125,
      "logps/rejected": -304.6625061035156,
      "loss": 0.4815,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.43069028854370117,
      "rewards/margins": 2.45062255859375,
      "rewards/rejected": -2.8813130855560303,
      "step": 16040
    },
    {
      "epoch": 0.9449560177694095,
      "grad_norm": 3.422417640686035,
      "learning_rate": 3.4261057173678534e-05,
      "logits/chosen": 4.343904972076416,
      "logits/rejected": 4.264734745025635,
      "logps/chosen": -394.50079345703125,
      "logps/rejected": -338.6923828125,
      "loss": 0.4612,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0129344463348389,
      "rewards/margins": 2.8589694499969482,
      "rewards/rejected": -3.871903657913208,
      "step": 16060
    },
    {
      "epoch": 0.9461327998587862,
      "grad_norm": 0.26630011200904846,
      "learning_rate": 3.424144356183192e-05,
      "logits/chosen": 3.841454029083252,
      "logits/rejected": 3.843453884124756,
      "logps/chosen": -411.6123046875,
      "logps/rejected": -357.20892333984375,
      "loss": 0.5099,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8972080945968628,
      "rewards/margins": 2.9999563694000244,
      "rewards/rejected": -3.8971645832061768,
      "step": 16080
    },
    {
      "epoch": 0.9473095819481627,
      "grad_norm": 2.6155295372009277,
      "learning_rate": 3.422182994998529e-05,
      "logits/chosen": 4.13179349899292,
      "logits/rejected": 4.2451066970825195,
      "logps/chosen": -426.36920166015625,
      "logps/rejected": -390.5482482910156,
      "loss": 0.5387,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7006099224090576,
      "rewards/margins": 2.0637001991271973,
      "rewards/rejected": -3.764310359954834,
      "step": 16100
    },
    {
      "epoch": 0.9484863640375394,
      "grad_norm": 3.0386111736297607,
      "learning_rate": 3.420221633813867e-05,
      "logits/chosen": 4.167108535766602,
      "logits/rejected": 4.153807163238525,
      "logps/chosen": -393.6578063964844,
      "logps/rejected": -323.3572998046875,
      "loss": 0.5793,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3038009405136108,
      "rewards/margins": 2.59194278717041,
      "rewards/rejected": -3.8957438468933105,
      "step": 16120
    },
    {
      "epoch": 0.9496631461269159,
      "grad_norm": 1.7163439989089966,
      "learning_rate": 3.4182602726292045e-05,
      "logits/chosen": 4.136788368225098,
      "logits/rejected": 4.068988800048828,
      "logps/chosen": -328.8583984375,
      "logps/rejected": -321.1248779296875,
      "loss": 0.4276,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.050292730331421,
      "rewards/margins": 2.650611400604248,
      "rewards/rejected": -3.700904130935669,
      "step": 16140
    },
    {
      "epoch": 0.9508399282162926,
      "grad_norm": 3.4731814861297607,
      "learning_rate": 3.416298911444543e-05,
      "logits/chosen": 4.045064926147461,
      "logits/rejected": 4.032822608947754,
      "logps/chosen": -367.29901123046875,
      "logps/rejected": -315.61309814453125,
      "loss": 0.5234,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.8421424627304077,
      "rewards/margins": 2.325610637664795,
      "rewards/rejected": -3.1677534580230713,
      "step": 16160
    },
    {
      "epoch": 0.9520167103056691,
      "grad_norm": 2.2872204780578613,
      "learning_rate": 3.4143375502598804e-05,
      "logits/chosen": 4.002471446990967,
      "logits/rejected": 3.90929913520813,
      "logps/chosen": -408.3155822753906,
      "logps/rejected": -300.7630920410156,
      "loss": 0.4391,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.4711487889289856,
      "rewards/margins": 2.769559621810913,
      "rewards/rejected": -3.240708589553833,
      "step": 16180
    },
    {
      "epoch": 0.9531934923950457,
      "grad_norm": 3.703246593475342,
      "learning_rate": 3.412376189075218e-05,
      "logits/chosen": 4.1471147537231445,
      "logits/rejected": 4.234055519104004,
      "logps/chosen": -346.0904846191406,
      "logps/rejected": -325.2579650878906,
      "loss": 0.4162,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.47674208879470825,
      "rewards/margins": 2.4020962715148926,
      "rewards/rejected": -2.878838539123535,
      "step": 16200
    },
    {
      "epoch": 0.9543702744844224,
      "grad_norm": 4.106728553771973,
      "learning_rate": 3.410414827890556e-05,
      "logits/chosen": 3.9832680225372314,
      "logits/rejected": 4.118422508239746,
      "logps/chosen": -389.09271240234375,
      "logps/rejected": -389.2074890136719,
      "loss": 0.4043,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": 0.20224738121032715,
      "rewards/margins": 3.0118401050567627,
      "rewards/rejected": -2.8095927238464355,
      "step": 16220
    },
    {
      "epoch": 0.9555470565737989,
      "grad_norm": 0.025721531361341476,
      "learning_rate": 3.4084534667058946e-05,
      "logits/chosen": 3.8888556957244873,
      "logits/rejected": 3.8358559608459473,
      "logps/chosen": -382.66253662109375,
      "logps/rejected": -324.5045471191406,
      "loss": 0.4924,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.3437547981739044,
      "rewards/margins": 2.5464768409729004,
      "rewards/rejected": -2.8902316093444824,
      "step": 16240
    },
    {
      "epoch": 0.9567238386631756,
      "grad_norm": 3.602992534637451,
      "learning_rate": 3.4064921055212315e-05,
      "logits/chosen": 3.7967886924743652,
      "logits/rejected": 3.693437099456787,
      "logps/chosen": -355.3118591308594,
      "logps/rejected": -332.9861145019531,
      "loss": 0.4621,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.3939428925514221,
      "rewards/margins": 2.900695323944092,
      "rewards/rejected": -3.294638156890869,
      "step": 16260
    },
    {
      "epoch": 0.9579006207525521,
      "grad_norm": 1.3918049335479736,
      "learning_rate": 3.40453074433657e-05,
      "logits/chosen": 3.595233201980591,
      "logits/rejected": 3.5277457237243652,
      "logps/chosen": -347.7545166015625,
      "logps/rejected": -261.6937255859375,
      "loss": 0.5656,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.3158160150051117,
      "rewards/margins": 2.232185125350952,
      "rewards/rejected": -2.5480008125305176,
      "step": 16280
    },
    {
      "epoch": 0.9590774028419288,
      "grad_norm": 0.7138044238090515,
      "learning_rate": 3.4025693831519074e-05,
      "logits/chosen": 3.9546959400177,
      "logits/rejected": 3.9173152446746826,
      "logps/chosen": -374.98040771484375,
      "logps/rejected": -286.7104187011719,
      "loss": 0.6411,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.9287451505661011,
      "rewards/margins": 2.09077787399292,
      "rewards/rejected": -3.0195231437683105,
      "step": 16300
    },
    {
      "epoch": 0.9602541849313053,
      "grad_norm": 3.0992560386657715,
      "learning_rate": 3.400608021967246e-05,
      "logits/chosen": 3.9337921142578125,
      "logits/rejected": 3.935274600982666,
      "logps/chosen": -377.5467224121094,
      "logps/rejected": -278.6227722167969,
      "loss": 0.3862,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.7856708765029907,
      "rewards/margins": 2.7879157066345215,
      "rewards/rejected": -3.5735867023468018,
      "step": 16320
    },
    {
      "epoch": 0.961430967020682,
      "grad_norm": 2.741753101348877,
      "learning_rate": 3.398646660782583e-05,
      "logits/chosen": 4.050366401672363,
      "logits/rejected": 4.0401611328125,
      "logps/chosen": -366.07958984375,
      "logps/rejected": -298.1005859375,
      "loss": 0.4917,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1263402700424194,
      "rewards/margins": 2.160755157470703,
      "rewards/rejected": -3.287095308303833,
      "step": 16340
    },
    {
      "epoch": 0.9626077491100585,
      "grad_norm": 1.7325266599655151,
      "learning_rate": 3.396685299597921e-05,
      "logits/chosen": 3.9773013591766357,
      "logits/rejected": 3.9376304149627686,
      "logps/chosen": -380.56787109375,
      "logps/rejected": -279.06610107421875,
      "loss": 0.402,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.5843476057052612,
      "rewards/margins": 2.344092845916748,
      "rewards/rejected": -2.928440570831299,
      "step": 16360
    },
    {
      "epoch": 0.9637845311994352,
      "grad_norm": 8.70556926727295,
      "learning_rate": 3.394723938413259e-05,
      "logits/chosen": 3.63716197013855,
      "logits/rejected": 3.6271941661834717,
      "logps/chosen": -352.27056884765625,
      "logps/rejected": -282.80389404296875,
      "loss": 0.5652,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.18294422328472137,
      "rewards/margins": 1.8880987167358398,
      "rewards/rejected": -2.071043014526367,
      "step": 16380
    },
    {
      "epoch": 0.9649613132888117,
      "grad_norm": 0.7904548645019531,
      "learning_rate": 3.392762577228597e-05,
      "logits/chosen": 4.138106346130371,
      "logits/rejected": 4.2437639236450195,
      "logps/chosen": -404.28515625,
      "logps/rejected": -378.0616760253906,
      "loss": 0.3428,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.5397211313247681,
      "rewards/margins": 3.409254789352417,
      "rewards/rejected": -3.9489760398864746,
      "step": 16400
    },
    {
      "epoch": 0.9661380953781883,
      "grad_norm": 2.454468011856079,
      "learning_rate": 3.3908012160439344e-05,
      "logits/chosen": 4.141293525695801,
      "logits/rejected": 4.319467067718506,
      "logps/chosen": -366.64300537109375,
      "logps/rejected": -321.6838684082031,
      "loss": 0.3939,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.25054502487182617,
      "rewards/margins": 2.906153440475464,
      "rewards/rejected": -3.156698703765869,
      "step": 16420
    },
    {
      "epoch": 0.967314877467565,
      "grad_norm": 0.025137843564152718,
      "learning_rate": 3.3888398548592727e-05,
      "logits/chosen": 4.368962287902832,
      "logits/rejected": 4.316486358642578,
      "logps/chosen": -402.0962829589844,
      "logps/rejected": -374.4852600097656,
      "loss": 0.5724,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5555239915847778,
      "rewards/margins": 2.5100979804992676,
      "rewards/rejected": -3.065622091293335,
      "step": 16440
    },
    {
      "epoch": 0.9684916595569415,
      "grad_norm": 0.7649776935577393,
      "learning_rate": 3.38687849367461e-05,
      "logits/chosen": 4.243714809417725,
      "logits/rejected": 4.1083550453186035,
      "logps/chosen": -403.20587158203125,
      "logps/rejected": -305.04034423828125,
      "loss": 0.5089,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.5976302027702332,
      "rewards/margins": 1.9893563985824585,
      "rewards/rejected": -2.5869863033294678,
      "step": 16460
    },
    {
      "epoch": 0.9696684416463182,
      "grad_norm": 0.7129126191139221,
      "learning_rate": 3.384917132489948e-05,
      "logits/chosen": 3.9765536785125732,
      "logits/rejected": 3.922565460205078,
      "logps/chosen": -388.66265869140625,
      "logps/rejected": -332.40496826171875,
      "loss": 0.4258,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.2636733949184418,
      "rewards/margins": 2.379777193069458,
      "rewards/rejected": -2.6434507369995117,
      "step": 16480
    },
    {
      "epoch": 0.9708452237356947,
      "grad_norm": 2.8234622478485107,
      "learning_rate": 3.382955771305286e-05,
      "logits/chosen": 3.7962653636932373,
      "logits/rejected": 3.8168575763702393,
      "logps/chosen": -336.3111877441406,
      "logps/rejected": -323.7355651855469,
      "loss": 0.5589,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.539889931678772,
      "rewards/margins": 2.083359479904175,
      "rewards/rejected": -2.6232492923736572,
      "step": 16500
    },
    {
      "epoch": 0.9720220058250714,
      "grad_norm": 5.554967880249023,
      "learning_rate": 3.380994410120624e-05,
      "logits/chosen": 4.151905536651611,
      "logits/rejected": 4.197296142578125,
      "logps/chosen": -361.9378662109375,
      "logps/rejected": -304.6239318847656,
      "loss": 0.5122,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.577135443687439,
      "rewards/margins": 2.1302952766418457,
      "rewards/rejected": -2.707430839538574,
      "step": 16520
    },
    {
      "epoch": 0.9731987879144479,
      "grad_norm": 0.12696275115013123,
      "learning_rate": 3.379033048935962e-05,
      "logits/chosen": 4.183884620666504,
      "logits/rejected": 4.101974010467529,
      "logps/chosen": -366.52325439453125,
      "logps/rejected": -293.39404296875,
      "loss": 0.4759,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.5677599310874939,
      "rewards/margins": 2.6889073848724365,
      "rewards/rejected": -3.256667375564575,
      "step": 16540
    },
    {
      "epoch": 0.9743755700038246,
      "grad_norm": 1.2432397603988647,
      "learning_rate": 3.3770716877512996e-05,
      "logits/chosen": 3.988187074661255,
      "logits/rejected": 4.167281150817871,
      "logps/chosen": -384.6819152832031,
      "logps/rejected": -306.36273193359375,
      "loss": 0.4322,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.47095146775245667,
      "rewards/margins": 2.6150128841400146,
      "rewards/rejected": -3.0859639644622803,
      "step": 16560
    },
    {
      "epoch": 0.9755523520932011,
      "grad_norm": 3.084404706954956,
      "learning_rate": 3.375110326566637e-05,
      "logits/chosen": 4.329082012176514,
      "logits/rejected": 4.186560153961182,
      "logps/chosen": -410.75738525390625,
      "logps/rejected": -308.7079162597656,
      "loss": 0.4654,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.6809945106506348,
      "rewards/margins": 2.6576027870178223,
      "rewards/rejected": -3.338596820831299,
      "step": 16580
    },
    {
      "epoch": 0.9767291341825778,
      "grad_norm": 1.0097945928573608,
      "learning_rate": 3.3731489653819755e-05,
      "logits/chosen": 4.255897521972656,
      "logits/rejected": 4.083622932434082,
      "logps/chosen": -413.21063232421875,
      "logps/rejected": -326.1199951171875,
      "loss": 0.4804,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.9466284513473511,
      "rewards/margins": 2.800187587738037,
      "rewards/rejected": -3.7468159198760986,
      "step": 16600
    },
    {
      "epoch": 0.9779059162719543,
      "grad_norm": 2.0233166217803955,
      "learning_rate": 3.371187604197313e-05,
      "logits/chosen": 3.8320088386535645,
      "logits/rejected": 3.8189029693603516,
      "logps/chosen": -333.67449951171875,
      "logps/rejected": -293.3554382324219,
      "loss": 0.6959,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.8877338171005249,
      "rewards/margins": 1.899915099143982,
      "rewards/rejected": -2.787648916244507,
      "step": 16620
    },
    {
      "epoch": 0.979082698361331,
      "grad_norm": 0.09304676204919815,
      "learning_rate": 3.369226243012651e-05,
      "logits/chosen": 4.072929382324219,
      "logits/rejected": 3.9898521900177,
      "logps/chosen": -401.9169006347656,
      "logps/rejected": -277.8560485839844,
      "loss": 0.4844,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.4309595227241516,
      "rewards/margins": 2.572680711746216,
      "rewards/rejected": -3.0036401748657227,
      "step": 16640
    },
    {
      "epoch": 0.9802594804507075,
      "grad_norm": 1.4043593406677246,
      "learning_rate": 3.367264881827989e-05,
      "logits/chosen": 4.2536725997924805,
      "logits/rejected": 4.103086948394775,
      "logps/chosen": -426.3804626464844,
      "logps/rejected": -376.2825012207031,
      "loss": 0.4609,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.6375246047973633,
      "rewards/margins": 3.328728437423706,
      "rewards/rejected": -3.9662528038024902,
      "step": 16660
    },
    {
      "epoch": 0.9814362625400841,
      "grad_norm": 1.1628459692001343,
      "learning_rate": 3.3653035206433266e-05,
      "logits/chosen": 4.191304683685303,
      "logits/rejected": 3.924914836883545,
      "logps/chosen": -443.6983337402344,
      "logps/rejected": -357.2552795410156,
      "loss": 0.3961,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5782318711280823,
      "rewards/margins": 3.115161418914795,
      "rewards/rejected": -3.6933932304382324,
      "step": 16680
    },
    {
      "epoch": 0.9826130446294608,
      "grad_norm": 1.0504859685897827,
      "learning_rate": 3.363342159458664e-05,
      "logits/chosen": 4.043608665466309,
      "logits/rejected": 3.9626412391662598,
      "logps/chosen": -378.31805419921875,
      "logps/rejected": -311.6976623535156,
      "loss": 0.7044,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2074848413467407,
      "rewards/margins": 1.944276213645935,
      "rewards/rejected": -3.1517608165740967,
      "step": 16700
    },
    {
      "epoch": 0.9837898267188373,
      "grad_norm": 6.060964584350586,
      "learning_rate": 3.3613807982740025e-05,
      "logits/chosen": 3.988941192626953,
      "logits/rejected": 3.9681713581085205,
      "logps/chosen": -453.40740966796875,
      "logps/rejected": -354.55950927734375,
      "loss": 0.5073,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2410107851028442,
      "rewards/margins": 3.2148232460021973,
      "rewards/rejected": -4.45583438873291,
      "step": 16720
    },
    {
      "epoch": 0.984966608808214,
      "grad_norm": 0.4965086877346039,
      "learning_rate": 3.35941943708934e-05,
      "logits/chosen": 4.0421271324157715,
      "logits/rejected": 4.079598903656006,
      "logps/chosen": -407.63330078125,
      "logps/rejected": -301.415283203125,
      "loss": 0.3367,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2984578609466553,
      "rewards/margins": 2.606902599334717,
      "rewards/rejected": -3.905360460281372,
      "step": 16740
    },
    {
      "epoch": 0.9861433908975905,
      "grad_norm": 0.25225821137428284,
      "learning_rate": 3.3574580759046784e-05,
      "logits/chosen": 3.9761245250701904,
      "logits/rejected": 4.082194805145264,
      "logps/chosen": -367.3409423828125,
      "logps/rejected": -288.44769287109375,
      "loss": 0.3317,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -0.6944534182548523,
      "rewards/margins": 2.7775285243988037,
      "rewards/rejected": -3.47198224067688,
      "step": 16760
    },
    {
      "epoch": 0.9873201729869672,
      "grad_norm": 4.149029731750488,
      "learning_rate": 3.355496714720015e-05,
      "logits/chosen": 4.123724937438965,
      "logits/rejected": 4.076930046081543,
      "logps/chosen": -391.3065490722656,
      "logps/rejected": -330.43798828125,
      "loss": 0.6708,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.036027193069458,
      "rewards/margins": 2.317173480987549,
      "rewards/rejected": -3.3532004356384277,
      "step": 16780
    },
    {
      "epoch": 0.9884969550763437,
      "grad_norm": 0.5316811203956604,
      "learning_rate": 3.3535353535353536e-05,
      "logits/chosen": 4.4016923904418945,
      "logits/rejected": 4.333987236022949,
      "logps/chosen": -358.6256103515625,
      "logps/rejected": -297.81451416015625,
      "loss": 0.4983,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.8332492709159851,
      "rewards/margins": 2.481693744659424,
      "rewards/rejected": -3.3149428367614746,
      "step": 16800
    },
    {
      "epoch": 0.9896737371657204,
      "grad_norm": 0.5859460830688477,
      "learning_rate": 3.351573992350692e-05,
      "logits/chosen": 4.363387107849121,
      "logits/rejected": 4.323611259460449,
      "logps/chosen": -380.1919860839844,
      "logps/rejected": -349.9786682128906,
      "loss": 0.5033,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.0885010957717896,
      "rewards/margins": 2.570666790008545,
      "rewards/rejected": -3.659167766571045,
      "step": 16820
    },
    {
      "epoch": 0.9908505192550969,
      "grad_norm": 0.7043747901916504,
      "learning_rate": 3.3496126311660295e-05,
      "logits/chosen": 4.04904842376709,
      "logits/rejected": 4.065041542053223,
      "logps/chosen": -360.8848876953125,
      "logps/rejected": -338.67559814453125,
      "loss": 0.4729,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.7002297639846802,
      "rewards/margins": 3.0224006175994873,
      "rewards/rejected": -3.722630262374878,
      "step": 16840
    },
    {
      "epoch": 0.9920273013444736,
      "grad_norm": 2.8055579662323,
      "learning_rate": 3.347651269981367e-05,
      "logits/chosen": 3.7845757007598877,
      "logits/rejected": 3.813282012939453,
      "logps/chosen": -397.58306884765625,
      "logps/rejected": -323.3167419433594,
      "loss": 0.5255,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.1765788793563843,
      "rewards/margins": 2.564079761505127,
      "rewards/rejected": -3.7406585216522217,
      "step": 16860
    },
    {
      "epoch": 0.9932040834338501,
      "grad_norm": 4.449687480926514,
      "learning_rate": 3.3456899087967054e-05,
      "logits/chosen": 4.192238807678223,
      "logits/rejected": 4.070062160491943,
      "logps/chosen": -399.5902099609375,
      "logps/rejected": -283.41510009765625,
      "loss": 0.4172,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.5698999166488647,
      "rewards/margins": 2.8637776374816895,
      "rewards/rejected": -3.433678150177002,
      "step": 16880
    },
    {
      "epoch": 0.9943808655232267,
      "grad_norm": 0.5102842450141907,
      "learning_rate": 3.343728547612043e-05,
      "logits/chosen": 3.961756944656372,
      "logits/rejected": 3.969144344329834,
      "logps/chosen": -331.4961853027344,
      "logps/rejected": -295.4610595703125,
      "loss": 0.4437,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0714374780654907,
      "rewards/margins": 1.966046690940857,
      "rewards/rejected": -3.0374844074249268,
      "step": 16900
    },
    {
      "epoch": 0.9955576476126033,
      "grad_norm": 1.7862930297851562,
      "learning_rate": 3.3417671864273806e-05,
      "logits/chosen": 3.845156192779541,
      "logits/rejected": 3.9203109741210938,
      "logps/chosen": -369.0885925292969,
      "logps/rejected": -310.33404541015625,
      "loss": 0.3587,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.5262033343315125,
      "rewards/margins": 2.995664119720459,
      "rewards/rejected": -3.521867275238037,
      "step": 16920
    },
    {
      "epoch": 0.9967344297019799,
      "grad_norm": 1.793610692024231,
      "learning_rate": 3.339805825242718e-05,
      "logits/chosen": 4.08249568939209,
      "logits/rejected": 4.140552043914795,
      "logps/chosen": -337.17755126953125,
      "logps/rejected": -298.5152893066406,
      "loss": 0.5845,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2474417686462402,
      "rewards/margins": 2.4570746421813965,
      "rewards/rejected": -3.704516649246216,
      "step": 16940
    },
    {
      "epoch": 0.9979112117913566,
      "grad_norm": 2.445828914642334,
      "learning_rate": 3.3378444640580565e-05,
      "logits/chosen": 4.124268531799316,
      "logits/rejected": 4.12817907333374,
      "logps/chosen": -377.2428283691406,
      "logps/rejected": -321.8909912109375,
      "loss": 0.4952,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.0347219705581665,
      "rewards/margins": 2.3736281394958496,
      "rewards/rejected": -3.4083499908447266,
      "step": 16960
    },
    {
      "epoch": 0.9990879938807331,
      "grad_norm": 1.629715085029602,
      "learning_rate": 3.335883102873395e-05,
      "logits/chosen": 3.871241331100464,
      "logits/rejected": 3.9028916358947754,
      "logps/chosen": -430.89599609375,
      "logps/rejected": -326.555419921875,
      "loss": 0.4335,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.1081862449645996,
      "rewards/margins": 2.937394857406616,
      "rewards/rejected": -4.045580863952637,
      "step": 16980
    },
    {
      "epoch": 1.0002647759701098,
      "grad_norm": 0.5928720831871033,
      "learning_rate": 3.333921741688732e-05,
      "logits/chosen": 3.6654064655303955,
      "logits/rejected": 3.7219650745391846,
      "logps/chosen": -355.2230529785156,
      "logps/rejected": -262.5572814941406,
      "loss": 0.5608,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.7959178686141968,
      "rewards/margins": 2.0560994148254395,
      "rewards/rejected": -2.8520171642303467,
      "step": 17000
    },
    {
      "epoch": 1.0014415580594864,
      "grad_norm": 2.084665298461914,
      "learning_rate": 3.33196038050407e-05,
      "logits/chosen": 4.381033420562744,
      "logits/rejected": 4.28603458404541,
      "logps/chosen": -383.15771484375,
      "logps/rejected": -362.5395202636719,
      "loss": 0.4986,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9642454981803894,
      "rewards/margins": 2.3328447341918945,
      "rewards/rejected": -3.297090530395508,
      "step": 17020
    },
    {
      "epoch": 1.0026183401488629,
      "grad_norm": 2.042520523071289,
      "learning_rate": 3.329999019319408e-05,
      "logits/chosen": 4.26531457901001,
      "logits/rejected": 4.044647693634033,
      "logps/chosen": -395.7669372558594,
      "logps/rejected": -298.85052490234375,
      "loss": 0.3172,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.06155264377594,
      "rewards/margins": 2.6141037940979004,
      "rewards/rejected": -3.67565655708313,
      "step": 17040
    },
    {
      "epoch": 1.0037951222382395,
      "grad_norm": 1.5446891784667969,
      "learning_rate": 3.328037658134746e-05,
      "logits/chosen": 3.8839783668518066,
      "logits/rejected": 3.8385989665985107,
      "logps/chosen": -340.59661865234375,
      "logps/rejected": -301.50457763671875,
      "loss": 0.3625,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.3281170129776,
      "rewards/margins": 2.607475757598877,
      "rewards/rejected": -3.9355931282043457,
      "step": 17060
    },
    {
      "epoch": 1.0049719043276162,
      "grad_norm": 0.42183417081832886,
      "learning_rate": 3.3260762969500834e-05,
      "logits/chosen": 4.134434700012207,
      "logits/rejected": 4.105029106140137,
      "logps/chosen": -447.711669921875,
      "logps/rejected": -331.95269775390625,
      "loss": 0.2721,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -0.7592650651931763,
      "rewards/margins": 3.4980156421661377,
      "rewards/rejected": -4.257281303405762,
      "step": 17080
    },
    {
      "epoch": 1.0061486864169928,
      "grad_norm": 0.25697317719459534,
      "learning_rate": 3.324114935765421e-05,
      "logits/chosen": 3.7658920288085938,
      "logits/rejected": 3.8786025047302246,
      "logps/chosen": -375.9942321777344,
      "logps/rejected": -342.8753967285156,
      "loss": 0.3155,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.8227485418319702,
      "rewards/margins": 2.9528872966766357,
      "rewards/rejected": -3.7756361961364746,
      "step": 17100
    },
    {
      "epoch": 1.0073254685063693,
      "grad_norm": 2.822136402130127,
      "learning_rate": 3.322153574580759e-05,
      "logits/chosen": 3.944664478302002,
      "logits/rejected": 3.9405593872070312,
      "logps/chosen": -355.24102783203125,
      "logps/rejected": -261.23626708984375,
      "loss": 0.3073,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.82658451795578,
      "rewards/margins": 2.6503548622131348,
      "rewards/rejected": -3.4769389629364014,
      "step": 17120
    },
    {
      "epoch": 1.008502250595746,
      "grad_norm": 38.46241760253906,
      "learning_rate": 3.320192213396097e-05,
      "logits/chosen": 4.100222110748291,
      "logits/rejected": 4.05753231048584,
      "logps/chosen": -399.05047607421875,
      "logps/rejected": -307.4037170410156,
      "loss": 0.314,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.082048773765564,
      "rewards/margins": 3.280768632888794,
      "rewards/rejected": -4.362817764282227,
      "step": 17140
    },
    {
      "epoch": 1.0096790326851226,
      "grad_norm": 0.9222779870033264,
      "learning_rate": 3.3182308522114345e-05,
      "logits/chosen": 4.03354024887085,
      "logits/rejected": 4.086527347564697,
      "logps/chosen": -400.1012878417969,
      "logps/rejected": -338.57244873046875,
      "loss": 0.2179,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.4353002309799194,
      "rewards/margins": 3.2778897285461426,
      "rewards/rejected": -4.71319055557251,
      "step": 17160
    },
    {
      "epoch": 1.010855814774499,
      "grad_norm": 1.0200737714767456,
      "learning_rate": 3.316269491026773e-05,
      "logits/chosen": 3.782590389251709,
      "logits/rejected": 3.9455482959747314,
      "logps/chosen": -379.5533447265625,
      "logps/rejected": -343.7727355957031,
      "loss": 0.2441,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.3596055507659912,
      "rewards/margins": 3.345529556274414,
      "rewards/rejected": -4.705135822296143,
      "step": 17180
    },
    {
      "epoch": 1.0120325968638757,
      "grad_norm": 0.794661283493042,
      "learning_rate": 3.314308129842111e-05,
      "logits/chosen": 3.9603633880615234,
      "logits/rejected": 3.914224624633789,
      "logps/chosen": -426.342529296875,
      "logps/rejected": -383.0708312988281,
      "loss": 0.3019,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.082030773162842,
      "rewards/margins": 3.4936954975128174,
      "rewards/rejected": -5.575725555419922,
      "step": 17200
    },
    {
      "epoch": 1.0132093789532524,
      "grad_norm": 1.1130057573318481,
      "learning_rate": 3.312346768657448e-05,
      "logits/chosen": 3.906367540359497,
      "logits/rejected": 3.6557774543762207,
      "logps/chosen": -380.6932067871094,
      "logps/rejected": -294.1393127441406,
      "loss": 0.3694,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1641108989715576,
      "rewards/margins": 3.304039716720581,
      "rewards/rejected": -5.468150615692139,
      "step": 17220
    },
    {
      "epoch": 1.014386161042629,
      "grad_norm": 2.548305034637451,
      "learning_rate": 3.310385407472786e-05,
      "logits/chosen": 3.8097541332244873,
      "logits/rejected": 3.8880176544189453,
      "logps/chosen": -443.8421936035156,
      "logps/rejected": -311.81549072265625,
      "loss": 0.3063,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1328459978103638,
      "rewards/margins": 4.262066841125488,
      "rewards/rejected": -5.394912242889404,
      "step": 17240
    },
    {
      "epoch": 1.0155629431320055,
      "grad_norm": 1.555185079574585,
      "learning_rate": 3.308424046288124e-05,
      "logits/chosen": 3.8017284870147705,
      "logits/rejected": 3.7865920066833496,
      "logps/chosen": -418.73748779296875,
      "logps/rejected": -325.9312744140625,
      "loss": 0.3065,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.9867333173751831,
      "rewards/margins": 3.576449155807495,
      "rewards/rejected": -4.563182830810547,
      "step": 17260
    },
    {
      "epoch": 1.0167397252213821,
      "grad_norm": 2.3721604347229004,
      "learning_rate": 3.306462685103462e-05,
      "logits/chosen": 4.250980377197266,
      "logits/rejected": 4.203869819641113,
      "logps/chosen": -458.8186950683594,
      "logps/rejected": -370.5769958496094,
      "loss": 0.1531,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -1.0330482721328735,
      "rewards/margins": 4.075358867645264,
      "rewards/rejected": -5.108407497406006,
      "step": 17280
    },
    {
      "epoch": 1.0179165073107588,
      "grad_norm": 2.571070432662964,
      "learning_rate": 3.3045013239188e-05,
      "logits/chosen": 4.182852745056152,
      "logits/rejected": 4.092621326446533,
      "logps/chosen": -378.17547607421875,
      "logps/rejected": -323.2992248535156,
      "loss": 0.3915,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6682608127593994,
      "rewards/margins": 3.387993335723877,
      "rewards/rejected": -5.056253910064697,
      "step": 17300
    },
    {
      "epoch": 1.0190932894001354,
      "grad_norm": 2.8215084075927734,
      "learning_rate": 3.3025399627341374e-05,
      "logits/chosen": 3.846039295196533,
      "logits/rejected": 3.7352428436279297,
      "logps/chosen": -406.6158142089844,
      "logps/rejected": -335.7540283203125,
      "loss": 0.3644,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.1081756353378296,
      "rewards/margins": 3.235170364379883,
      "rewards/rejected": -4.343346118927002,
      "step": 17320
    },
    {
      "epoch": 1.0202700714895119,
      "grad_norm": 1.0756930112838745,
      "learning_rate": 3.300578601549476e-05,
      "logits/chosen": 3.8874125480651855,
      "logits/rejected": 3.8634610176086426,
      "logps/chosen": -359.0607604980469,
      "logps/rejected": -364.0735778808594,
      "loss": 0.3867,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.279793620109558,
      "rewards/margins": 3.1708712577819824,
      "rewards/rejected": -4.450665473937988,
      "step": 17340
    },
    {
      "epoch": 1.0214468535788885,
      "grad_norm": 1.5972161293029785,
      "learning_rate": 3.298617240364813e-05,
      "logits/chosen": 4.285258769989014,
      "logits/rejected": 4.27675724029541,
      "logps/chosen": -380.1784973144531,
      "logps/rejected": -343.5516662597656,
      "loss": 0.4144,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6062462329864502,
      "rewards/margins": 2.892609119415283,
      "rewards/rejected": -4.498855113983154,
      "step": 17360
    },
    {
      "epoch": 1.0226236356682652,
      "grad_norm": 1.6482843160629272,
      "learning_rate": 3.296655879180151e-05,
      "logits/chosen": 3.7655367851257324,
      "logits/rejected": 3.8726069927215576,
      "logps/chosen": -380.14361572265625,
      "logps/rejected": -302.7040710449219,
      "loss": 0.2876,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.0873035192489624,
      "rewards/margins": 3.262680768966675,
      "rewards/rejected": -4.349984169006348,
      "step": 17380
    },
    {
      "epoch": 1.0238004177576416,
      "grad_norm": 2.386380910873413,
      "learning_rate": 3.294694517995489e-05,
      "logits/chosen": 3.945620059967041,
      "logits/rejected": 3.727668046951294,
      "logps/chosen": -379.7679138183594,
      "logps/rejected": -297.71466064453125,
      "loss": 0.3977,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6035124063491821,
      "rewards/margins": 2.678338050842285,
      "rewards/rejected": -4.281850814819336,
      "step": 17400
    },
    {
      "epoch": 1.0249771998470183,
      "grad_norm": 1.0861762762069702,
      "learning_rate": 3.292733156810827e-05,
      "logits/chosen": 3.4245517253875732,
      "logits/rejected": 3.494783401489258,
      "logps/chosen": -329.44366455078125,
      "logps/rejected": -296.2154541015625,
      "loss": 0.2843,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.3475825786590576,
      "rewards/margins": 3.1565864086151123,
      "rewards/rejected": -4.504168510437012,
      "step": 17420
    },
    {
      "epoch": 1.026153981936395,
      "grad_norm": 2.351386785507202,
      "learning_rate": 3.2907717956261644e-05,
      "logits/chosen": 4.076879501342773,
      "logits/rejected": 3.8944461345672607,
      "logps/chosen": -385.3706359863281,
      "logps/rejected": -333.63909912109375,
      "loss": 0.3613,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.9402837753295898,
      "rewards/margins": 3.3479628562927246,
      "rewards/rejected": -4.2882466316223145,
      "step": 17440
    },
    {
      "epoch": 1.0273307640257716,
      "grad_norm": 2.1135783195495605,
      "learning_rate": 3.2888104344415027e-05,
      "logits/chosen": 3.9177868366241455,
      "logits/rejected": 3.8693153858184814,
      "logps/chosen": -388.803466796875,
      "logps/rejected": -291.16802978515625,
      "loss": 0.2739,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.6707542538642883,
      "rewards/margins": 3.1720974445343018,
      "rewards/rejected": -3.8428516387939453,
      "step": 17460
    },
    {
      "epoch": 1.028507546115148,
      "grad_norm": 0.6563950181007385,
      "learning_rate": 3.28684907325684e-05,
      "logits/chosen": 3.9317641258239746,
      "logits/rejected": 3.9855315685272217,
      "logps/chosen": -379.5455627441406,
      "logps/rejected": -290.35931396484375,
      "loss": 0.3636,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.0441306829452515,
      "rewards/margins": 3.5192527770996094,
      "rewards/rejected": -4.56338357925415,
      "step": 17480
    },
    {
      "epoch": 1.0296843282045247,
      "grad_norm": 2.8396759033203125,
      "learning_rate": 3.2848877120721785e-05,
      "logits/chosen": 3.92303729057312,
      "logits/rejected": 3.935159206390381,
      "logps/chosen": -404.5058898925781,
      "logps/rejected": -371.9971923828125,
      "loss": 0.243,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.8657073974609375,
      "rewards/margins": 3.7749485969543457,
      "rewards/rejected": -4.640656471252441,
      "step": 17500
    },
    {
      "epoch": 1.0308611102939014,
      "grad_norm": 0.4008030891418457,
      "learning_rate": 3.282926350887516e-05,
      "logits/chosen": 4.135577201843262,
      "logits/rejected": 3.8814663887023926,
      "logps/chosen": -413.7940368652344,
      "logps/rejected": -329.9093933105469,
      "loss": 0.3721,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.36603111028671265,
      "rewards/margins": 3.688309907913208,
      "rewards/rejected": -4.054340362548828,
      "step": 17520
    },
    {
      "epoch": 1.032037892383278,
      "grad_norm": 0.3070426285266876,
      "learning_rate": 3.280964989702854e-05,
      "logits/chosen": 3.9929962158203125,
      "logits/rejected": 3.933026075363159,
      "logps/chosen": -377.4805603027344,
      "logps/rejected": -373.71026611328125,
      "loss": 0.2376,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.3969171941280365,
      "rewards/margins": 3.2428886890411377,
      "rewards/rejected": -3.639805555343628,
      "step": 17540
    },
    {
      "epoch": 1.0332146744726545,
      "grad_norm": 0.9174468517303467,
      "learning_rate": 3.279003628518192e-05,
      "logits/chosen": 3.897587537765503,
      "logits/rejected": 3.727199077606201,
      "logps/chosen": -408.1175231933594,
      "logps/rejected": -339.164306640625,
      "loss": 0.2635,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -0.9693681001663208,
      "rewards/margins": 4.236563682556152,
      "rewards/rejected": -5.205931663513184,
      "step": 17560
    },
    {
      "epoch": 1.0343914565620311,
      "grad_norm": 0.28611302375793457,
      "learning_rate": 3.2770422673335296e-05,
      "logits/chosen": 3.7310543060302734,
      "logits/rejected": 3.667440414428711,
      "logps/chosen": -401.6289367675781,
      "logps/rejected": -347.59857177734375,
      "loss": 0.3206,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3914684057235718,
      "rewards/margins": 3.237178087234497,
      "rewards/rejected": -4.6286468505859375,
      "step": 17580
    },
    {
      "epoch": 1.0355682386514078,
      "grad_norm": 2.410611391067505,
      "learning_rate": 3.275080906148867e-05,
      "logits/chosen": 3.796675205230713,
      "logits/rejected": 3.7626450061798096,
      "logps/chosen": -379.7973327636719,
      "logps/rejected": -331.25640869140625,
      "loss": 0.3706,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3329966068267822,
      "rewards/margins": 3.0149598121643066,
      "rewards/rejected": -4.347956657409668,
      "step": 17600
    },
    {
      "epoch": 1.0367450207407842,
      "grad_norm": 1.0703144073486328,
      "learning_rate": 3.2731195449642055e-05,
      "logits/chosen": 3.6399810314178467,
      "logits/rejected": 3.7679800987243652,
      "logps/chosen": -409.7337951660156,
      "logps/rejected": -351.99420166015625,
      "loss": 0.2337,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.1897218227386475,
      "rewards/margins": 3.506014347076416,
      "rewards/rejected": -4.695736408233643,
      "step": 17620
    },
    {
      "epoch": 1.0379218028301609,
      "grad_norm": 0.35036706924438477,
      "learning_rate": 3.271158183779543e-05,
      "logits/chosen": 3.8190929889678955,
      "logits/rejected": 3.8276920318603516,
      "logps/chosen": -376.59063720703125,
      "logps/rejected": -314.072509765625,
      "loss": 0.3552,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.5382440090179443,
      "rewards/margins": 3.164339303970337,
      "rewards/rejected": -4.702582836151123,
      "step": 17640
    },
    {
      "epoch": 1.0390985849195375,
      "grad_norm": 0.38525068759918213,
      "learning_rate": 3.269196822594881e-05,
      "logits/chosen": 3.9782347679138184,
      "logits/rejected": 3.827014923095703,
      "logps/chosen": -379.0287780761719,
      "logps/rejected": -326.0056457519531,
      "loss": 0.2991,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4722055196762085,
      "rewards/margins": 3.1637651920318604,
      "rewards/rejected": -4.635970592498779,
      "step": 17660
    },
    {
      "epoch": 1.0402753670089142,
      "grad_norm": 3.5204668045043945,
      "learning_rate": 3.267235461410219e-05,
      "logits/chosen": 3.4541778564453125,
      "logits/rejected": 3.5164597034454346,
      "logps/chosen": -349.06243896484375,
      "logps/rejected": -287.86822509765625,
      "loss": 0.3366,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.204041838645935,
      "rewards/margins": 3.0377542972564697,
      "rewards/rejected": -4.241796493530273,
      "step": 17680
    },
    {
      "epoch": 1.0414521490982906,
      "grad_norm": 0.22754237055778503,
      "learning_rate": 3.2652741002255566e-05,
      "logits/chosen": 4.176142692565918,
      "logits/rejected": 4.193498611450195,
      "logps/chosen": -426.7433166503906,
      "logps/rejected": -377.24468994140625,
      "loss": 0.2015,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.3194401264190674,
      "rewards/margins": 4.350902557373047,
      "rewards/rejected": -5.670342445373535,
      "step": 17700
    },
    {
      "epoch": 1.0426289311876673,
      "grad_norm": 1.0406924486160278,
      "learning_rate": 3.263312739040895e-05,
      "logits/chosen": 3.9591002464294434,
      "logits/rejected": 3.889730930328369,
      "logps/chosen": -376.7291564941406,
      "logps/rejected": -322.5582580566406,
      "loss": 0.2687,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.6509628295898438,
      "rewards/margins": 2.9865548610687256,
      "rewards/rejected": -4.63751745223999,
      "step": 17720
    },
    {
      "epoch": 1.043805713277044,
      "grad_norm": 0.23713983595371246,
      "learning_rate": 3.261351377856232e-05,
      "logits/chosen": 3.8031108379364014,
      "logits/rejected": 3.871363878250122,
      "logps/chosen": -386.9989318847656,
      "logps/rejected": -314.9725036621094,
      "loss": 0.3285,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.826756238937378,
      "rewards/margins": 3.547855854034424,
      "rewards/rejected": -5.374612331390381,
      "step": 17740
    },
    {
      "epoch": 1.0449824953664206,
      "grad_norm": 2.8445494174957275,
      "learning_rate": 3.25939001667157e-05,
      "logits/chosen": 3.7751545906066895,
      "logits/rejected": 3.7391953468322754,
      "logps/chosen": -407.4307861328125,
      "logps/rejected": -361.5469970703125,
      "loss": 0.2061,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -1.2907378673553467,
      "rewards/margins": 4.653172492980957,
      "rewards/rejected": -5.943910121917725,
      "step": 17760
    },
    {
      "epoch": 1.046159277455797,
      "grad_norm": 4.6530961990356445,
      "learning_rate": 3.2574286554869084e-05,
      "logits/chosen": 3.89768648147583,
      "logits/rejected": 3.912968158721924,
      "logps/chosen": -419.9955139160156,
      "logps/rejected": -324.5664978027344,
      "loss": 0.3404,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2457374334335327,
      "rewards/margins": 3.5629889965057373,
      "rewards/rejected": -4.808727264404297,
      "step": 17780
    },
    {
      "epoch": 1.0473360595451737,
      "grad_norm": 2.2939441204071045,
      "learning_rate": 3.255467294302246e-05,
      "logits/chosen": 3.568743944168091,
      "logits/rejected": 3.4473445415496826,
      "logps/chosen": -357.9122009277344,
      "logps/rejected": -299.4007873535156,
      "loss": 0.2763,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.3429538011550903,
      "rewards/margins": 3.1856682300567627,
      "rewards/rejected": -4.528621673583984,
      "step": 17800
    },
    {
      "epoch": 1.0485128416345504,
      "grad_norm": 0.2451508492231369,
      "learning_rate": 3.2535059331175836e-05,
      "logits/chosen": 3.7141900062561035,
      "logits/rejected": 3.625087261199951,
      "logps/chosen": -373.63592529296875,
      "logps/rejected": -356.1300354003906,
      "loss": 0.3858,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.3341763019561768,
      "rewards/margins": 3.3646068572998047,
      "rewards/rejected": -4.698782920837402,
      "step": 17820
    },
    {
      "epoch": 1.0496896237239268,
      "grad_norm": 4.489145278930664,
      "learning_rate": 3.251544571932922e-05,
      "logits/chosen": 4.017255783081055,
      "logits/rejected": 4.042375564575195,
      "logps/chosen": -429.16497802734375,
      "logps/rejected": -314.3858642578125,
      "loss": 0.3506,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1227856874465942,
      "rewards/margins": 3.712014675140381,
      "rewards/rejected": -4.834800720214844,
      "step": 17840
    },
    {
      "epoch": 1.0508664058133035,
      "grad_norm": 1.8873581886291504,
      "learning_rate": 3.2495832107482595e-05,
      "logits/chosen": 3.487004518508911,
      "logits/rejected": 3.5180504322052,
      "logps/chosen": -337.6397705078125,
      "logps/rejected": -325.97222900390625,
      "loss": 0.3516,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6005747318267822,
      "rewards/margins": 3.625869035720825,
      "rewards/rejected": -5.226443290710449,
      "step": 17860
    },
    {
      "epoch": 1.0520431879026801,
      "grad_norm": 1.112207055091858,
      "learning_rate": 3.247621849563597e-05,
      "logits/chosen": 3.560621738433838,
      "logits/rejected": 3.5281002521514893,
      "logps/chosen": -371.02166748046875,
      "logps/rejected": -337.35137939453125,
      "loss": 0.251,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.9960924983024597,
      "rewards/margins": 3.2995738983154297,
      "rewards/rejected": -4.295666694641113,
      "step": 17880
    },
    {
      "epoch": 1.0532199699920568,
      "grad_norm": 1.5042973756790161,
      "learning_rate": 3.245660488378935e-05,
      "logits/chosen": 3.1462035179138184,
      "logits/rejected": 3.5368714332580566,
      "logps/chosen": -343.1671447753906,
      "logps/rejected": -354.5303649902344,
      "loss": 0.2795,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.1822210550308228,
      "rewards/margins": 2.6559181213378906,
      "rewards/rejected": -3.838139295578003,
      "step": 17900
    },
    {
      "epoch": 1.0543967520814332,
      "grad_norm": 2.079160690307617,
      "learning_rate": 3.243699127194273e-05,
      "logits/chosen": 3.902678966522217,
      "logits/rejected": 3.77760648727417,
      "logps/chosen": -365.32440185546875,
      "logps/rejected": -303.0372314453125,
      "loss": 0.4127,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5392756462097168,
      "rewards/margins": 3.334730863571167,
      "rewards/rejected": -4.874007225036621,
      "step": 17920
    },
    {
      "epoch": 1.05557353417081,
      "grad_norm": 1.9267241954803467,
      "learning_rate": 3.241737766009611e-05,
      "logits/chosen": 3.9384396076202393,
      "logits/rejected": 3.9654383659362793,
      "logps/chosen": -367.4612121582031,
      "logps/rejected": -322.7091369628906,
      "loss": 0.3656,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.910635232925415,
      "rewards/margins": 2.707514524459839,
      "rewards/rejected": -4.618149757385254,
      "step": 17940
    },
    {
      "epoch": 1.0567503162601866,
      "grad_norm": 1.8207536935806274,
      "learning_rate": 3.239776404824948e-05,
      "logits/chosen": 3.8621678352355957,
      "logits/rejected": 3.837794780731201,
      "logps/chosen": -425.7842712402344,
      "logps/rejected": -388.4494323730469,
      "loss": 0.2381,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3583340644836426,
      "rewards/margins": 4.337311267852783,
      "rewards/rejected": -5.695645332336426,
      "step": 17960
    },
    {
      "epoch": 1.0579270983495632,
      "grad_norm": 2.1288082599639893,
      "learning_rate": 3.2378150436402865e-05,
      "logits/chosen": 4.1288981437683105,
      "logits/rejected": 3.9528746604919434,
      "logps/chosen": -407.0252990722656,
      "logps/rejected": -337.1508483886719,
      "loss": 0.3947,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0324571132659912,
      "rewards/margins": 3.597132921218872,
      "rewards/rejected": -4.629590034484863,
      "step": 17980
    },
    {
      "epoch": 1.0591038804389397,
      "grad_norm": 1.056943416595459,
      "learning_rate": 3.235853682455625e-05,
      "logits/chosen": 3.4565281867980957,
      "logits/rejected": 3.5231711864471436,
      "logps/chosen": -325.6867980957031,
      "logps/rejected": -302.99578857421875,
      "loss": 0.3604,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.4960324764251709,
      "rewards/margins": 2.9541661739349365,
      "rewards/rejected": -3.4501986503601074,
      "step": 18000
    },
    {
      "epoch": 1.0602806625283163,
      "grad_norm": 1.6551454067230225,
      "learning_rate": 3.2338923212709623e-05,
      "logits/chosen": 3.941331148147583,
      "logits/rejected": 3.947613477706909,
      "logps/chosen": -433.09307861328125,
      "logps/rejected": -337.57183837890625,
      "loss": 0.319,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1464159488677979,
      "rewards/margins": 3.4061198234558105,
      "rewards/rejected": -4.5525360107421875,
      "step": 18020
    },
    {
      "epoch": 1.061457444617693,
      "grad_norm": 4.142780303955078,
      "learning_rate": 3.2319309600863e-05,
      "logits/chosen": 3.85929799079895,
      "logits/rejected": 3.9754397869110107,
      "logps/chosen": -398.03668212890625,
      "logps/rejected": -317.9193420410156,
      "loss": 0.2494,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.1204986572265625,
      "rewards/margins": 3.030944347381592,
      "rewards/rejected": -4.151442527770996,
      "step": 18040
    },
    {
      "epoch": 1.0626342267070694,
      "grad_norm": 0.2672252953052521,
      "learning_rate": 3.2299695989016376e-05,
      "logits/chosen": 3.898946762084961,
      "logits/rejected": 3.784538984298706,
      "logps/chosen": -337.4010314941406,
      "logps/rejected": -340.5614013671875,
      "loss": 0.3543,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.1346826553344727,
      "rewards/margins": 3.2560322284698486,
      "rewards/rejected": -4.3907151222229,
      "step": 18060
    },
    {
      "epoch": 1.063811008796446,
      "grad_norm": 3.8338537216186523,
      "learning_rate": 3.228008237716976e-05,
      "logits/chosen": 3.946258068084717,
      "logits/rejected": 3.9319369792938232,
      "logps/chosen": -382.5373229980469,
      "logps/rejected": -343.9660949707031,
      "loss": 0.3892,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.251837968826294,
      "rewards/margins": 2.8370203971862793,
      "rewards/rejected": -4.088858127593994,
      "step": 18080
    },
    {
      "epoch": 1.0649877908858227,
      "grad_norm": 1.3207652568817139,
      "learning_rate": 3.2260468765323134e-05,
      "logits/chosen": 3.500767230987549,
      "logits/rejected": 3.5700244903564453,
      "logps/chosen": -359.76708984375,
      "logps/rejected": -320.78839111328125,
      "loss": 0.2471,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.4989556074142456,
      "rewards/margins": 3.088400363922119,
      "rewards/rejected": -4.587355613708496,
      "step": 18100
    },
    {
      "epoch": 1.0661645729751994,
      "grad_norm": 6.266862869262695,
      "learning_rate": 3.224085515347651e-05,
      "logits/chosen": 3.5749351978302,
      "logits/rejected": 3.549407958984375,
      "logps/chosen": -370.7090148925781,
      "logps/rejected": -320.4541931152344,
      "loss": 0.4008,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2590440511703491,
      "rewards/margins": 3.3017029762268066,
      "rewards/rejected": -4.5607476234436035,
      "step": 18120
    },
    {
      "epoch": 1.0673413550645758,
      "grad_norm": 1.1671466827392578,
      "learning_rate": 3.222124154162989e-05,
      "logits/chosen": 3.8781802654266357,
      "logits/rejected": 3.8815948963165283,
      "logps/chosen": -358.48321533203125,
      "logps/rejected": -348.99859619140625,
      "loss": 0.2693,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.2755086421966553,
      "rewards/margins": 3.8671505451202393,
      "rewards/rejected": -5.1426591873168945,
      "step": 18140
    },
    {
      "epoch": 1.0685181371539525,
      "grad_norm": 0.2554689943790436,
      "learning_rate": 3.2201627929783276e-05,
      "logits/chosen": 3.8903231620788574,
      "logits/rejected": 3.8224594593048096,
      "logps/chosen": -360.1185302734375,
      "logps/rejected": -329.818115234375,
      "loss": 0.3584,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9259237051010132,
      "rewards/margins": 2.7876431941986084,
      "rewards/rejected": -4.713566780090332,
      "step": 18160
    },
    {
      "epoch": 1.0696949192433292,
      "grad_norm": 1.0328106880187988,
      "learning_rate": 3.2182014317936645e-05,
      "logits/chosen": 3.805846691131592,
      "logits/rejected": 3.993542432785034,
      "logps/chosen": -366.98486328125,
      "logps/rejected": -353.5766906738281,
      "loss": 0.3105,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.367919921875,
      "rewards/margins": 3.46467661857605,
      "rewards/rejected": -4.832596778869629,
      "step": 18180
    },
    {
      "epoch": 1.0708717013327058,
      "grad_norm": 0.8259992003440857,
      "learning_rate": 3.216240070609003e-05,
      "logits/chosen": 3.7302074432373047,
      "logits/rejected": 3.7872650623321533,
      "logps/chosen": -354.4034118652344,
      "logps/rejected": -296.32269287109375,
      "loss": 0.2363,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.0871243476867676,
      "rewards/margins": 3.2255992889404297,
      "rewards/rejected": -4.3127241134643555,
      "step": 18200
    },
    {
      "epoch": 1.0720484834220823,
      "grad_norm": 4.081981182098389,
      "learning_rate": 3.2142787094243404e-05,
      "logits/chosen": 3.7680106163024902,
      "logits/rejected": 3.965127944946289,
      "logps/chosen": -372.2577819824219,
      "logps/rejected": -335.38299560546875,
      "loss": 0.2891,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.433622121810913,
      "rewards/margins": 3.55951189994812,
      "rewards/rejected": -4.993134021759033,
      "step": 18220
    },
    {
      "epoch": 1.073225265511459,
      "grad_norm": 1.4742690324783325,
      "learning_rate": 3.212317348239679e-05,
      "logits/chosen": 3.539867401123047,
      "logits/rejected": 3.5163276195526123,
      "logps/chosen": -394.12457275390625,
      "logps/rejected": -340.8766174316406,
      "loss": 0.3986,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8293259143829346,
      "rewards/margins": 3.2737879753112793,
      "rewards/rejected": -5.103113651275635,
      "step": 18240
    },
    {
      "epoch": 1.0744020476008356,
      "grad_norm": 1.3382465839385986,
      "learning_rate": 3.210355987055016e-05,
      "logits/chosen": 3.9005286693573,
      "logits/rejected": 3.9291324615478516,
      "logps/chosen": -432.5301208496094,
      "logps/rejected": -345.07440185546875,
      "loss": 0.2329,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.2695256471633911,
      "rewards/margins": 3.8687057495117188,
      "rewards/rejected": -5.1382317543029785,
      "step": 18260
    },
    {
      "epoch": 1.075578829690212,
      "grad_norm": 0.4340701401233673,
      "learning_rate": 3.208394625870354e-05,
      "logits/chosen": 3.9302477836608887,
      "logits/rejected": 4.291919708251953,
      "logps/chosen": -404.58416748046875,
      "logps/rejected": -358.6559753417969,
      "loss": 0.2541,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.2711975574493408,
      "rewards/margins": 3.913752317428589,
      "rewards/rejected": -5.1849493980407715,
      "step": 18280
    },
    {
      "epoch": 1.0767556117795887,
      "grad_norm": 1.5320261716842651,
      "learning_rate": 3.206433264685692e-05,
      "logits/chosen": 3.723789691925049,
      "logits/rejected": 3.8988757133483887,
      "logps/chosen": -372.5718078613281,
      "logps/rejected": -362.51348876953125,
      "loss": 0.3361,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.4502075910568237,
      "rewards/margins": 2.75529146194458,
      "rewards/rejected": -4.205499172210693,
      "step": 18300
    },
    {
      "epoch": 1.0779323938689653,
      "grad_norm": 1.679794192314148,
      "learning_rate": 3.20447190350103e-05,
      "logits/chosen": 3.811408281326294,
      "logits/rejected": 3.720003128051758,
      "logps/chosen": -352.57208251953125,
      "logps/rejected": -306.79168701171875,
      "loss": 0.4945,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7995847463607788,
      "rewards/margins": 3.0705432891845703,
      "rewards/rejected": -4.8701276779174805,
      "step": 18320
    },
    {
      "epoch": 1.079109175958342,
      "grad_norm": 0.4539659917354584,
      "learning_rate": 3.2025105423163674e-05,
      "logits/chosen": 3.6466026306152344,
      "logits/rejected": 3.720174789428711,
      "logps/chosen": -355.96600341796875,
      "logps/rejected": -311.2597961425781,
      "loss": 0.2709,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.2703306674957275,
      "rewards/margins": 3.303300142288208,
      "rewards/rejected": -4.573631286621094,
      "step": 18340
    },
    {
      "epoch": 1.0802859580477184,
      "grad_norm": 1.5342676639556885,
      "learning_rate": 3.200549181131706e-05,
      "logits/chosen": 4.135939121246338,
      "logits/rejected": 4.103932857513428,
      "logps/chosen": -410.6451721191406,
      "logps/rejected": -350.47979736328125,
      "loss": 0.3721,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.8320169448852539,
      "rewards/margins": 3.5263543128967285,
      "rewards/rejected": -4.358370780944824,
      "step": 18360
    },
    {
      "epoch": 1.081462740137095,
      "grad_norm": 3.8350296020507812,
      "learning_rate": 3.198587819947043e-05,
      "logits/chosen": 3.724445343017578,
      "logits/rejected": 3.803420305252075,
      "logps/chosen": -373.2215270996094,
      "logps/rejected": -368.05718994140625,
      "loss": 0.2252,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -0.8649271726608276,
      "rewards/margins": 4.016348361968994,
      "rewards/rejected": -4.881275177001953,
      "step": 18380
    },
    {
      "epoch": 1.0826395222264718,
      "grad_norm": 1.0238314867019653,
      "learning_rate": 3.196626458762381e-05,
      "logits/chosen": 3.927039384841919,
      "logits/rejected": 3.9247848987579346,
      "logps/chosen": -401.1158142089844,
      "logps/rejected": -325.05352783203125,
      "loss": 0.2397,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.5859538316726685,
      "rewards/margins": 4.05387020111084,
      "rewards/rejected": -4.639823913574219,
      "step": 18400
    },
    {
      "epoch": 1.0838163043158484,
      "grad_norm": 0.538879930973053,
      "learning_rate": 3.194665097577719e-05,
      "logits/chosen": 3.927478075027466,
      "logits/rejected": 3.932516098022461,
      "logps/chosen": -422.635009765625,
      "logps/rejected": -343.2282409667969,
      "loss": 0.2785,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.5612791776657104,
      "rewards/margins": 3.421149492263794,
      "rewards/rejected": -4.982428550720215,
      "step": 18420
    },
    {
      "epoch": 1.0849930864052248,
      "grad_norm": 6.384016513824463,
      "learning_rate": 3.192703736393057e-05,
      "logits/chosen": 3.2400074005126953,
      "logits/rejected": 3.359104871749878,
      "logps/chosen": -366.09735107421875,
      "logps/rejected": -315.6435241699219,
      "loss": 0.3983,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.973030686378479,
      "rewards/margins": 2.5162618160247803,
      "rewards/rejected": -4.489292621612549,
      "step": 18440
    },
    {
      "epoch": 1.0861698684946015,
      "grad_norm": 2.6763830184936523,
      "learning_rate": 3.190742375208395e-05,
      "logits/chosen": 3.9909234046936035,
      "logits/rejected": 3.9788384437561035,
      "logps/chosen": -385.6459045410156,
      "logps/rejected": -289.67425537109375,
      "loss": 0.3662,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3294947147369385,
      "rewards/margins": 3.1889326572418213,
      "rewards/rejected": -5.51842737197876,
      "step": 18460
    },
    {
      "epoch": 1.0873466505839782,
      "grad_norm": 4.298635959625244,
      "learning_rate": 3.1887810140237327e-05,
      "logits/chosen": 3.8317317962646484,
      "logits/rejected": 3.9137160778045654,
      "logps/chosen": -382.40875244140625,
      "logps/rejected": -347.2012939453125,
      "loss": 0.3879,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8345590829849243,
      "rewards/margins": 3.358402967453003,
      "rewards/rejected": -5.192961692810059,
      "step": 18480
    },
    {
      "epoch": 1.0885234326733548,
      "grad_norm": 1.1717805862426758,
      "learning_rate": 3.18681965283907e-05,
      "logits/chosen": 3.411534547805786,
      "logits/rejected": 3.4973883628845215,
      "logps/chosen": -387.8650817871094,
      "logps/rejected": -301.0267333984375,
      "loss": 0.2411,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.7382291555404663,
      "rewards/margins": 3.7498984336853027,
      "rewards/rejected": -5.488128185272217,
      "step": 18500
    },
    {
      "epoch": 1.0897002147627313,
      "grad_norm": 0.8720170259475708,
      "learning_rate": 3.1848582916544085e-05,
      "logits/chosen": 3.925708055496216,
      "logits/rejected": 3.8987979888916016,
      "logps/chosen": -390.7511291503906,
      "logps/rejected": -362.7197570800781,
      "loss": 0.32,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.1620144844055176,
      "rewards/margins": 3.383939027786255,
      "rewards/rejected": -5.545952796936035,
      "step": 18520
    },
    {
      "epoch": 1.090876996852108,
      "grad_norm": 0.013521685265004635,
      "learning_rate": 3.182896930469746e-05,
      "logits/chosen": 3.95184326171875,
      "logits/rejected": 4.00173282623291,
      "logps/chosen": -399.75604248046875,
      "logps/rejected": -356.35174560546875,
      "loss": 0.3202,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.7535310983657837,
      "rewards/margins": 3.4764084815979004,
      "rewards/rejected": -5.2299394607543945,
      "step": 18540
    },
    {
      "epoch": 1.0920537789414846,
      "grad_norm": 5.111541271209717,
      "learning_rate": 3.180935569285084e-05,
      "logits/chosen": 3.83941650390625,
      "logits/rejected": 3.79951548576355,
      "logps/chosen": -365.91815185546875,
      "logps/rejected": -329.0556640625,
      "loss": 0.3933,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.569688320159912,
      "rewards/margins": 3.2982497215270996,
      "rewards/rejected": -4.867938041687012,
      "step": 18560
    },
    {
      "epoch": 1.093230561030861,
      "grad_norm": 0.33196157217025757,
      "learning_rate": 3.178974208100422e-05,
      "logits/chosen": 4.032616138458252,
      "logits/rejected": 3.9810702800750732,
      "logps/chosen": -427.145751953125,
      "logps/rejected": -360.8910217285156,
      "loss": 0.3668,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9048395156860352,
      "rewards/margins": 4.300192832946777,
      "rewards/rejected": -6.205031394958496,
      "step": 18580
    },
    {
      "epoch": 1.0944073431202377,
      "grad_norm": 1.320623755455017,
      "learning_rate": 3.1770128469157596e-05,
      "logits/chosen": 3.782966136932373,
      "logits/rejected": 3.739386796951294,
      "logps/chosen": -427.63409423828125,
      "logps/rejected": -427.8661193847656,
      "loss": 0.2631,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.0846861600875854,
      "rewards/margins": 3.7700648307800293,
      "rewards/rejected": -4.854752063751221,
      "step": 18600
    },
    {
      "epoch": 1.0955841252096143,
      "grad_norm": 3.3976268768310547,
      "learning_rate": 3.175051485731097e-05,
      "logits/chosen": 3.6854209899902344,
      "logits/rejected": 3.719017505645752,
      "logps/chosen": -362.7727966308594,
      "logps/rejected": -334.65130615234375,
      "loss": 0.3406,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.6830689311027527,
      "rewards/margins": 2.927053689956665,
      "rewards/rejected": -3.6101222038269043,
      "step": 18620
    },
    {
      "epoch": 1.096760907298991,
      "grad_norm": 0.42264896631240845,
      "learning_rate": 3.1730901245464355e-05,
      "logits/chosen": 3.9602599143981934,
      "logits/rejected": 4.0027055740356445,
      "logps/chosen": -400.98065185546875,
      "logps/rejected": -332.19622802734375,
      "loss": 0.4661,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6124969720840454,
      "rewards/margins": 2.885730743408203,
      "rewards/rejected": -4.498227596282959,
      "step": 18640
    },
    {
      "epoch": 1.0979376893883674,
      "grad_norm": 1.3409799337387085,
      "learning_rate": 3.171128763361773e-05,
      "logits/chosen": 3.8090717792510986,
      "logits/rejected": 3.9220211505889893,
      "logps/chosen": -391.87158203125,
      "logps/rejected": -310.58734130859375,
      "loss": 0.3007,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.4385815858840942,
      "rewards/margins": 3.341294527053833,
      "rewards/rejected": -4.779875755310059,
      "step": 18660
    },
    {
      "epoch": 1.099114471477744,
      "grad_norm": 1.3283900022506714,
      "learning_rate": 3.1691674021771114e-05,
      "logits/chosen": 4.0665202140808105,
      "logits/rejected": 4.067912578582764,
      "logps/chosen": -430.7477111816406,
      "logps/rejected": -356.2518615722656,
      "loss": 0.3674,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7037327289581299,
      "rewards/margins": 2.991647481918335,
      "rewards/rejected": -4.695380210876465,
      "step": 18680
    },
    {
      "epoch": 1.1002912535671208,
      "grad_norm": 0.8027963042259216,
      "learning_rate": 3.167206040992448e-05,
      "logits/chosen": 3.6547656059265137,
      "logits/rejected": 3.7345681190490723,
      "logps/chosen": -417.8020935058594,
      "logps/rejected": -334.69281005859375,
      "loss": 0.4506,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.9654648900032043,
      "rewards/margins": 3.6411221027374268,
      "rewards/rejected": -4.6065874099731445,
      "step": 18700
    },
    {
      "epoch": 1.1014680356564974,
      "grad_norm": 1.0512700080871582,
      "learning_rate": 3.1652446798077866e-05,
      "logits/chosen": 3.7949650287628174,
      "logits/rejected": 3.7754645347595215,
      "logps/chosen": -352.3185119628906,
      "logps/rejected": -324.54620361328125,
      "loss": 0.2826,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.2935335636138916,
      "rewards/margins": 3.510331392288208,
      "rewards/rejected": -4.803864479064941,
      "step": 18720
    },
    {
      "epoch": 1.1026448177458739,
      "grad_norm": 1.9268587827682495,
      "learning_rate": 3.163283318623125e-05,
      "logits/chosen": 4.260537624359131,
      "logits/rejected": 4.207333564758301,
      "logps/chosen": -421.4773864746094,
      "logps/rejected": -359.03851318359375,
      "loss": 0.1946,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -0.748664379119873,
      "rewards/margins": 3.4752635955810547,
      "rewards/rejected": -4.223927974700928,
      "step": 18740
    },
    {
      "epoch": 1.1038215998352505,
      "grad_norm": 2.8695085048675537,
      "learning_rate": 3.1613219574384625e-05,
      "logits/chosen": 3.8715481758117676,
      "logits/rejected": 3.8935585021972656,
      "logps/chosen": -394.9891662597656,
      "logps/rejected": -346.01715087890625,
      "loss": 0.3478,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.2115341424942017,
      "rewards/margins": 2.8401095867156982,
      "rewards/rejected": -4.051643371582031,
      "step": 18760
    },
    {
      "epoch": 1.1049983819246272,
      "grad_norm": 1.8346138000488281,
      "learning_rate": 3.1593605962538e-05,
      "logits/chosen": 4.112210273742676,
      "logits/rejected": 4.301770210266113,
      "logps/chosen": -410.45281982421875,
      "logps/rejected": -327.28643798828125,
      "loss": 0.4428,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3530677556991577,
      "rewards/margins": 2.3748810291290283,
      "rewards/rejected": -3.7279491424560547,
      "step": 18780
    },
    {
      "epoch": 1.1061751640140036,
      "grad_norm": 1.1129320859909058,
      "learning_rate": 3.1573992350691384e-05,
      "logits/chosen": 4.0269293785095215,
      "logits/rejected": 3.9680075645446777,
      "logps/chosen": -400.67218017578125,
      "logps/rejected": -323.31512451171875,
      "loss": 0.3276,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.309935450553894,
      "rewards/margins": 3.312533140182495,
      "rewards/rejected": -4.6224684715271,
      "step": 18800
    },
    {
      "epoch": 1.1073519461033803,
      "grad_norm": 4.230312347412109,
      "learning_rate": 3.155437873884476e-05,
      "logits/chosen": 3.7315382957458496,
      "logits/rejected": 3.8238399028778076,
      "logps/chosen": -375.65496826171875,
      "logps/rejected": -359.9463806152344,
      "loss": 0.382,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.9248411059379578,
      "rewards/margins": 3.6046345233917236,
      "rewards/rejected": -4.529475212097168,
      "step": 18820
    },
    {
      "epoch": 1.108528728192757,
      "grad_norm": 0.07810404896736145,
      "learning_rate": 3.1534765126998136e-05,
      "logits/chosen": 3.9530282020568848,
      "logits/rejected": 3.9728915691375732,
      "logps/chosen": -330.91241455078125,
      "logps/rejected": -290.1174621582031,
      "loss": 0.2952,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.240954875946045,
      "rewards/margins": 2.8026766777038574,
      "rewards/rejected": -4.043631553649902,
      "step": 18840
    },
    {
      "epoch": 1.1097055102821336,
      "grad_norm": 0.04895486682653427,
      "learning_rate": 3.151515151515151e-05,
      "logits/chosen": 3.6520469188690186,
      "logits/rejected": 3.677630662918091,
      "logps/chosen": -381.8958740234375,
      "logps/rejected": -279.35882568359375,
      "loss": 0.2303,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.134738802909851,
      "rewards/margins": 3.134183645248413,
      "rewards/rejected": -4.268922328948975,
      "step": 18860
    },
    {
      "epoch": 1.11088229237151,
      "grad_norm": 6.361453056335449,
      "learning_rate": 3.1495537903304895e-05,
      "logits/chosen": 3.7680656909942627,
      "logits/rejected": 3.6442463397979736,
      "logps/chosen": -380.59661865234375,
      "logps/rejected": -338.12139892578125,
      "loss": 0.4533,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5228402614593506,
      "rewards/margins": 2.5637216567993164,
      "rewards/rejected": -4.086562156677246,
      "step": 18880
    },
    {
      "epoch": 1.1120590744608867,
      "grad_norm": 1.5248507261276245,
      "learning_rate": 3.147592429145828e-05,
      "logits/chosen": 3.82853627204895,
      "logits/rejected": 3.830242872238159,
      "logps/chosen": -383.0445861816406,
      "logps/rejected": -333.62176513671875,
      "loss": 0.2902,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.990441620349884,
      "rewards/margins": 3.0781989097595215,
      "rewards/rejected": -4.068640232086182,
      "step": 18900
    },
    {
      "epoch": 1.1132358565502634,
      "grad_norm": 0.5109351277351379,
      "learning_rate": 3.145631067961165e-05,
      "logits/chosen": 3.6753993034362793,
      "logits/rejected": 3.834088087081909,
      "logps/chosen": -362.23675537109375,
      "logps/rejected": -295.51336669921875,
      "loss": 0.2498,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.1163413524627686,
      "rewards/margins": 2.624660015106201,
      "rewards/rejected": -3.741001605987549,
      "step": 18920
    },
    {
      "epoch": 1.11441263863964,
      "grad_norm": 2.657053232192993,
      "learning_rate": 3.143669706776503e-05,
      "logits/chosen": 3.9175643920898438,
      "logits/rejected": 3.844769239425659,
      "logps/chosen": -365.05120849609375,
      "logps/rejected": -352.2139892578125,
      "loss": 0.4076,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9187257289886475,
      "rewards/margins": 2.8912405967712402,
      "rewards/rejected": -4.809966087341309,
      "step": 18940
    },
    {
      "epoch": 1.1155894207290165,
      "grad_norm": 3.1593291759490967,
      "learning_rate": 3.141708345591841e-05,
      "logits/chosen": 3.9400951862335205,
      "logits/rejected": 3.941960573196411,
      "logps/chosen": -414.65069580078125,
      "logps/rejected": -354.29864501953125,
      "loss": 0.2797,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.6083036661148071,
      "rewards/margins": 3.753960371017456,
      "rewards/rejected": -5.362264633178711,
      "step": 18960
    },
    {
      "epoch": 1.1167662028183931,
      "grad_norm": 2.3002750873565674,
      "learning_rate": 3.139746984407179e-05,
      "logits/chosen": 3.554278612136841,
      "logits/rejected": 3.56681752204895,
      "logps/chosen": -384.4775695800781,
      "logps/rejected": -304.48321533203125,
      "loss": 0.3963,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.3645951747894287,
      "rewards/margins": 3.5989716053009033,
      "rewards/rejected": -4.963566780090332,
      "step": 18980
    },
    {
      "epoch": 1.1179429849077698,
      "grad_norm": 0.9157756567001343,
      "learning_rate": 3.1377856232225165e-05,
      "logits/chosen": 3.820748805999756,
      "logits/rejected": 3.9458625316619873,
      "logps/chosen": -364.27703857421875,
      "logps/rejected": -323.73150634765625,
      "loss": 0.3424,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6015312671661377,
      "rewards/margins": 2.978699207305908,
      "rewards/rejected": -4.580231189727783,
      "step": 19000
    },
    {
      "epoch": 1.1191197669971462,
      "grad_norm": 2.3081235885620117,
      "learning_rate": 3.135824262037854e-05,
      "logits/chosen": 4.020781517028809,
      "logits/rejected": 4.098788261413574,
      "logps/chosen": -391.6491394042969,
      "logps/rejected": -325.71954345703125,
      "loss": 0.3679,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.9616934657096863,
      "rewards/margins": 2.8037521839141846,
      "rewards/rejected": -3.7654452323913574,
      "step": 19020
    },
    {
      "epoch": 1.1202965490865229,
      "grad_norm": 0.9027310013771057,
      "learning_rate": 3.1338629008531923e-05,
      "logits/chosen": 3.8354690074920654,
      "logits/rejected": 3.8360447883605957,
      "logps/chosen": -397.53955078125,
      "logps/rejected": -318.55206298828125,
      "loss": 0.3048,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.09978367388248444,
      "rewards/margins": 3.125272274017334,
      "rewards/rejected": -3.2250561714172363,
      "step": 19040
    },
    {
      "epoch": 1.1214733311758995,
      "grad_norm": 0.955978512763977,
      "learning_rate": 3.13190153966853e-05,
      "logits/chosen": 3.924617290496826,
      "logits/rejected": 3.997163772583008,
      "logps/chosen": -371.7330322265625,
      "logps/rejected": -298.49383544921875,
      "loss": 0.2527,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.1246081590652466,
      "rewards/margins": 2.975313901901245,
      "rewards/rejected": -4.099921703338623,
      "step": 19060
    },
    {
      "epoch": 1.1226501132652762,
      "grad_norm": 0.04401956498622894,
      "learning_rate": 3.1299401784838676e-05,
      "logits/chosen": 3.900211811065674,
      "logits/rejected": 3.8469173908233643,
      "logps/chosen": -390.82757568359375,
      "logps/rejected": -291.13641357421875,
      "loss": 0.3222,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8108619451522827,
      "rewards/margins": 3.145317554473877,
      "rewards/rejected": -4.956179618835449,
      "step": 19080
    },
    {
      "epoch": 1.1238268953546526,
      "grad_norm": 0.6005380749702454,
      "learning_rate": 3.127978817299206e-05,
      "logits/chosen": 4.042879104614258,
      "logits/rejected": 3.9657349586486816,
      "logps/chosen": -355.77703857421875,
      "logps/rejected": -352.74957275390625,
      "loss": 0.2568,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8764985799789429,
      "rewards/margins": 2.948744535446167,
      "rewards/rejected": -4.82524299621582,
      "step": 19100
    },
    {
      "epoch": 1.1250036774440293,
      "grad_norm": 0.501372754573822,
      "learning_rate": 3.126017456114544e-05,
      "logits/chosen": 3.822237014770508,
      "logits/rejected": 3.7278449535369873,
      "logps/chosen": -429.30401611328125,
      "logps/rejected": -345.9486389160156,
      "loss": 0.2229,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8383054733276367,
      "rewards/margins": 4.091281890869141,
      "rewards/rejected": -5.929587364196777,
      "step": 19120
    },
    {
      "epoch": 1.126180459533406,
      "grad_norm": 5.269712448120117,
      "learning_rate": 3.124056094929882e-05,
      "logits/chosen": 3.946962356567383,
      "logits/rejected": 3.943746566772461,
      "logps/chosen": -420.7005920410156,
      "logps/rejected": -361.83062744140625,
      "loss": 0.3958,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8631913661956787,
      "rewards/margins": 3.1873106956481934,
      "rewards/rejected": -5.050502777099609,
      "step": 19140
    },
    {
      "epoch": 1.1273572416227826,
      "grad_norm": 0.015233219601213932,
      "learning_rate": 3.122094733745219e-05,
      "logits/chosen": 4.017904281616211,
      "logits/rejected": 3.8817734718322754,
      "logps/chosen": -454.5943298339844,
      "logps/rejected": -361.13128662109375,
      "loss": 0.4159,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5461496114730835,
      "rewards/margins": 3.2984066009521484,
      "rewards/rejected": -4.8445563316345215,
      "step": 19160
    },
    {
      "epoch": 1.128534023712159,
      "grad_norm": 0.9203895330429077,
      "learning_rate": 3.120133372560557e-05,
      "logits/chosen": 4.306652545928955,
      "logits/rejected": 4.020725250244141,
      "logps/chosen": -445.4720764160156,
      "logps/rejected": -377.2502136230469,
      "loss": 0.2129,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.1732966899871826,
      "rewards/margins": 3.8556067943573,
      "rewards/rejected": -5.028903484344482,
      "step": 19180
    },
    {
      "epoch": 1.1297108058015357,
      "grad_norm": 1.6606404781341553,
      "learning_rate": 3.118172011375895e-05,
      "logits/chosen": 3.6382083892822266,
      "logits/rejected": 3.7681002616882324,
      "logps/chosen": -383.7023010253906,
      "logps/rejected": -351.8806457519531,
      "loss": 0.4057,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.9473444223403931,
      "rewards/margins": 3.3438384532928467,
      "rewards/rejected": -4.291182518005371,
      "step": 19200
    },
    {
      "epoch": 1.1308875878909124,
      "grad_norm": 3.590627431869507,
      "learning_rate": 3.116210650191233e-05,
      "logits/chosen": 3.575568675994873,
      "logits/rejected": 3.4874653816223145,
      "logps/chosen": -388.95697021484375,
      "logps/rejected": -330.98394775390625,
      "loss": 0.3152,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9576823115348816,
      "rewards/margins": 3.895031690597534,
      "rewards/rejected": -4.852713584899902,
      "step": 19220
    },
    {
      "epoch": 1.1320643699802888,
      "grad_norm": 1.7201741933822632,
      "learning_rate": 3.1142492890065704e-05,
      "logits/chosen": 3.884438991546631,
      "logits/rejected": 3.806365966796875,
      "logps/chosen": -369.3460388183594,
      "logps/rejected": -340.370361328125,
      "loss": 0.2968,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.7133735418319702,
      "rewards/margins": 3.295884609222412,
      "rewards/rejected": -5.009258270263672,
      "step": 19240
    },
    {
      "epoch": 1.1332411520696655,
      "grad_norm": 4.844620227813721,
      "learning_rate": 3.112287927821909e-05,
      "logits/chosen": 3.2393546104431152,
      "logits/rejected": 3.4826431274414062,
      "logps/chosen": -354.6818542480469,
      "logps/rejected": -310.7868347167969,
      "loss": 0.3261,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.468063235282898,
      "rewards/margins": 3.101532459259033,
      "rewards/rejected": -4.569596290588379,
      "step": 19260
    },
    {
      "epoch": 1.1344179341590421,
      "grad_norm": 4.443316459655762,
      "learning_rate": 3.110326566637247e-05,
      "logits/chosen": 3.5041096210479736,
      "logits/rejected": 3.5513548851013184,
      "logps/chosen": -399.0403747558594,
      "logps/rejected": -363.5935974121094,
      "loss": 0.2807,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.736201286315918,
      "rewards/margins": 3.7886080741882324,
      "rewards/rejected": -5.52480936050415,
      "step": 19280
    },
    {
      "epoch": 1.1355947162484188,
      "grad_norm": 2.468402147293091,
      "learning_rate": 3.108365205452584e-05,
      "logits/chosen": 3.820880889892578,
      "logits/rejected": 3.7498297691345215,
      "logps/chosen": -430.0240173339844,
      "logps/rejected": -394.7916564941406,
      "loss": 0.2122,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9643762111663818,
      "rewards/margins": 4.657010078430176,
      "rewards/rejected": -6.6213860511779785,
      "step": 19300
    },
    {
      "epoch": 1.1367714983377952,
      "grad_norm": 4.343264102935791,
      "learning_rate": 3.106403844267922e-05,
      "logits/chosen": 3.4312520027160645,
      "logits/rejected": 3.5926296710968018,
      "logps/chosen": -392.4075622558594,
      "logps/rejected": -299.9140319824219,
      "loss": 0.347,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.944331407546997,
      "rewards/margins": 3.2224907875061035,
      "rewards/rejected": -5.1668219566345215,
      "step": 19320
    },
    {
      "epoch": 1.1379482804271719,
      "grad_norm": 3.5963406562805176,
      "learning_rate": 3.10444248308326e-05,
      "logits/chosen": 3.413538694381714,
      "logits/rejected": 3.560080051422119,
      "logps/chosen": -374.10357666015625,
      "logps/rejected": -319.1427307128906,
      "loss": 0.3669,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9887501001358032,
      "rewards/margins": 3.2869789600372314,
      "rewards/rejected": -5.275729179382324,
      "step": 19340
    },
    {
      "epoch": 1.1391250625165485,
      "grad_norm": 1.9052584171295166,
      "learning_rate": 3.102481121898598e-05,
      "logits/chosen": 3.6641159057617188,
      "logits/rejected": 3.5595614910125732,
      "logps/chosen": -407.27685546875,
      "logps/rejected": -358.5625915527344,
      "loss": 0.4149,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.344575881958008,
      "rewards/margins": 3.3687338829040527,
      "rewards/rejected": -5.7133097648620605,
      "step": 19360
    },
    {
      "epoch": 1.1403018446059252,
      "grad_norm": 1.4839369058609009,
      "learning_rate": 3.100519760713936e-05,
      "logits/chosen": 3.9026520252227783,
      "logits/rejected": 3.8463845252990723,
      "logps/chosen": -400.4975280761719,
      "logps/rejected": -343.97442626953125,
      "loss": 0.2299,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.7593955993652344,
      "rewards/margins": 3.7132067680358887,
      "rewards/rejected": -5.472601890563965,
      "step": 19380
    },
    {
      "epoch": 1.1414786266953016,
      "grad_norm": 2.172182321548462,
      "learning_rate": 3.098558399529273e-05,
      "logits/chosen": 3.4126744270324707,
      "logits/rejected": 3.5351452827453613,
      "logps/chosen": -321.6227111816406,
      "logps/rejected": -325.22491455078125,
      "loss": 0.3145,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7564576864242554,
      "rewards/margins": 3.331465482711792,
      "rewards/rejected": -5.0879225730896,
      "step": 19400
    },
    {
      "epoch": 1.1426554087846783,
      "grad_norm": 2.8309760093688965,
      "learning_rate": 3.0965970383446116e-05,
      "logits/chosen": 3.622347354888916,
      "logits/rejected": 3.54888916015625,
      "logps/chosen": -440.103759765625,
      "logps/rejected": -327.7729797363281,
      "loss": 0.3959,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3069350719451904,
      "rewards/margins": 3.8745312690734863,
      "rewards/rejected": -5.181466579437256,
      "step": 19420
    },
    {
      "epoch": 1.143832190874055,
      "grad_norm": 5.26546049118042,
      "learning_rate": 3.094635677159949e-05,
      "logits/chosen": 3.356732130050659,
      "logits/rejected": 3.3834214210510254,
      "logps/chosen": -385.77081298828125,
      "logps/rejected": -319.9908752441406,
      "loss": 0.2429,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.7873191833496094,
      "rewards/margins": 3.4864165782928467,
      "rewards/rejected": -5.273736000061035,
      "step": 19440
    },
    {
      "epoch": 1.1450089729634314,
      "grad_norm": 0.5812022686004639,
      "learning_rate": 3.092674315975287e-05,
      "logits/chosen": 4.060198783874512,
      "logits/rejected": 4.031454563140869,
      "logps/chosen": -441.265380859375,
      "logps/rejected": -373.6613464355469,
      "loss": 0.2144,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.411780595779419,
      "rewards/margins": 4.033207893371582,
      "rewards/rejected": -5.444988250732422,
      "step": 19460
    },
    {
      "epoch": 1.146185755052808,
      "grad_norm": 2.536655902862549,
      "learning_rate": 3.090712954790625e-05,
      "logits/chosen": 3.9338297843933105,
      "logits/rejected": 3.891608476638794,
      "logps/chosen": -425.951416015625,
      "logps/rejected": -339.7120361328125,
      "loss": 0.2894,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.405214548110962,
      "rewards/margins": 3.404256820678711,
      "rewards/rejected": -4.809471607208252,
      "step": 19480
    },
    {
      "epoch": 1.1473625371421847,
      "grad_norm": 3.9103293418884277,
      "learning_rate": 3.0887515936059627e-05,
      "logits/chosen": 3.766784191131592,
      "logits/rejected": 3.830577850341797,
      "logps/chosen": -434.55926513671875,
      "logps/rejected": -370.80682373046875,
      "loss": 0.2869,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.3333505392074585,
      "rewards/margins": 4.0933308601379395,
      "rewards/rejected": -5.426680564880371,
      "step": 19500
    },
    {
      "epoch": 1.1485393192315614,
      "grad_norm": 4.819515705108643,
      "learning_rate": 3.0867902324213e-05,
      "logits/chosen": 3.9287707805633545,
      "logits/rejected": 3.8431556224823,
      "logps/chosen": -414.0370178222656,
      "logps/rejected": -379.37908935546875,
      "loss": 0.3923,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7922157049179077,
      "rewards/margins": 3.1398544311523438,
      "rewards/rejected": -4.932069778442383,
      "step": 19520
    },
    {
      "epoch": 1.1497161013209378,
      "grad_norm": 0.5798949599266052,
      "learning_rate": 3.0848288712366385e-05,
      "logits/chosen": 4.087193489074707,
      "logits/rejected": 3.9563050270080566,
      "logps/chosen": -467.92645263671875,
      "logps/rejected": -376.629638671875,
      "loss": 0.2548,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.6645148992538452,
      "rewards/margins": 4.320558547973633,
      "rewards/rejected": -5.985073089599609,
      "step": 19540
    },
    {
      "epoch": 1.1508928834103145,
      "grad_norm": 0.7768028974533081,
      "learning_rate": 3.082867510051976e-05,
      "logits/chosen": 3.8121345043182373,
      "logits/rejected": 3.8671908378601074,
      "logps/chosen": -400.57562255859375,
      "logps/rejected": -329.40106201171875,
      "loss": 0.436,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0308330059051514,
      "rewards/margins": 2.9989373683929443,
      "rewards/rejected": -5.029770374298096,
      "step": 19560
    },
    {
      "epoch": 1.1520696654996911,
      "grad_norm": 1.4036117792129517,
      "learning_rate": 3.0809061488673144e-05,
      "logits/chosen": 3.9081528186798096,
      "logits/rejected": 3.8523247241973877,
      "logps/chosen": -429.23822021484375,
      "logps/rejected": -387.79315185546875,
      "loss": 0.2687,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.2568941116333008,
      "rewards/margins": 3.6112561225891113,
      "rewards/rejected": -4.868150234222412,
      "step": 19580
    },
    {
      "epoch": 1.1532464475890678,
      "grad_norm": 0.6576834917068481,
      "learning_rate": 3.078944787682652e-05,
      "logits/chosen": 3.7105553150177,
      "logits/rejected": 3.8143539428710938,
      "logps/chosen": -368.7886047363281,
      "logps/rejected": -312.27874755859375,
      "loss": 0.2359,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -0.9877058267593384,
      "rewards/margins": 3.3516621589660645,
      "rewards/rejected": -4.339367866516113,
      "step": 19600
    },
    {
      "epoch": 1.1544232296784442,
      "grad_norm": 3.4529385566711426,
      "learning_rate": 3.0769834264979896e-05,
      "logits/chosen": 3.7140209674835205,
      "logits/rejected": 3.6817665100097656,
      "logps/chosen": -342.102294921875,
      "logps/rejected": -347.90618896484375,
      "loss": 0.3472,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6513407230377197,
      "rewards/margins": 2.8112378120422363,
      "rewards/rejected": -4.462578296661377,
      "step": 19620
    },
    {
      "epoch": 1.155600011767821,
      "grad_norm": 2.3447952270507812,
      "learning_rate": 3.075022065313328e-05,
      "logits/chosen": 3.919459581375122,
      "logits/rejected": 4.057248592376709,
      "logps/chosen": -409.89874267578125,
      "logps/rejected": -377.9105224609375,
      "loss": 0.3099,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.7842090129852295,
      "rewards/margins": 3.1572184562683105,
      "rewards/rejected": -4.941428184509277,
      "step": 19640
    },
    {
      "epoch": 1.1567767938571976,
      "grad_norm": 2.756497383117676,
      "learning_rate": 3.0730607041286655e-05,
      "logits/chosen": 4.0231146812438965,
      "logits/rejected": 3.8708081245422363,
      "logps/chosen": -397.474853515625,
      "logps/rejected": -353.2739562988281,
      "loss": 0.3229,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6027683019638062,
      "rewards/margins": 3.2293248176574707,
      "rewards/rejected": -4.832093238830566,
      "step": 19660
    },
    {
      "epoch": 1.157953575946574,
      "grad_norm": 1.546270489692688,
      "learning_rate": 3.071099342944003e-05,
      "logits/chosen": 4.1480255126953125,
      "logits/rejected": 3.9278671741485596,
      "logps/chosen": -440.3125,
      "logps/rejected": -366.47344970703125,
      "loss": 0.3616,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.2351939678192139,
      "rewards/margins": 3.6677584648132324,
      "rewards/rejected": -4.902952194213867,
      "step": 19680
    },
    {
      "epoch": 1.1591303580359507,
      "grad_norm": 4.3449602127075195,
      "learning_rate": 3.0691379817593414e-05,
      "logits/chosen": 3.9793357849121094,
      "logits/rejected": 3.9520981311798096,
      "logps/chosen": -384.89678955078125,
      "logps/rejected": -328.5992431640625,
      "loss": 0.4734,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.230703592300415,
      "rewards/margins": 2.216510057449341,
      "rewards/rejected": -4.447213649749756,
      "step": 19700
    },
    {
      "epoch": 1.1603071401253273,
      "grad_norm": 1.4189246892929077,
      "learning_rate": 3.067176620574679e-05,
      "logits/chosen": 3.688920497894287,
      "logits/rejected": 3.6997790336608887,
      "logps/chosen": -348.31427001953125,
      "logps/rejected": -310.4861755371094,
      "loss": 0.2798,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.6069597005844116,
      "rewards/margins": 3.401189088821411,
      "rewards/rejected": -5.008149147033691,
      "step": 19720
    },
    {
      "epoch": 1.161483922214704,
      "grad_norm": 1.9062212705612183,
      "learning_rate": 3.0652152593900166e-05,
      "logits/chosen": 3.4622890949249268,
      "logits/rejected": 3.436626434326172,
      "logps/chosen": -384.24053955078125,
      "logps/rejected": -345.6543884277344,
      "loss": 0.323,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.818195104598999,
      "rewards/margins": 3.12650465965271,
      "rewards/rejected": -4.944700241088867,
      "step": 19740
    },
    {
      "epoch": 1.1626607043040804,
      "grad_norm": 0.7183383107185364,
      "learning_rate": 3.063253898205355e-05,
      "logits/chosen": 3.6559600830078125,
      "logits/rejected": 3.605928421020508,
      "logps/chosen": -430.4560546875,
      "logps/rejected": -345.21160888671875,
      "loss": 0.2522,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.995486855506897,
      "rewards/margins": 3.2775185108184814,
      "rewards/rejected": -5.273005485534668,
      "step": 19760
    },
    {
      "epoch": 1.163837486393457,
      "grad_norm": 1.5760983228683472,
      "learning_rate": 3.0612925370206925e-05,
      "logits/chosen": 3.7061665058135986,
      "logits/rejected": 3.7083449363708496,
      "logps/chosen": -376.3265075683594,
      "logps/rejected": -334.0897216796875,
      "loss": 0.2888,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0552659034729004,
      "rewards/margins": 3.701009750366211,
      "rewards/rejected": -5.7562761306762695,
      "step": 19780
    },
    {
      "epoch": 1.1650142684828337,
      "grad_norm": 0.3318181037902832,
      "learning_rate": 3.059331175836031e-05,
      "logits/chosen": 3.893976926803589,
      "logits/rejected": 3.860816240310669,
      "logps/chosen": -415.795654296875,
      "logps/rejected": -395.33770751953125,
      "loss": 0.3831,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6761192083358765,
      "rewards/margins": 3.661266803741455,
      "rewards/rejected": -5.337385654449463,
      "step": 19800
    },
    {
      "epoch": 1.1661910505722104,
      "grad_norm": 3.141777515411377,
      "learning_rate": 3.057369814651368e-05,
      "logits/chosen": 3.595388412475586,
      "logits/rejected": 3.5874786376953125,
      "logps/chosen": -392.20477294921875,
      "logps/rejected": -314.71612548828125,
      "loss": 0.3836,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.169496536254883,
      "rewards/margins": 3.4289650917053223,
      "rewards/rejected": -5.598461627960205,
      "step": 19820
    },
    {
      "epoch": 1.1673678326615868,
      "grad_norm": 0.7454925179481506,
      "learning_rate": 3.055408453466706e-05,
      "logits/chosen": 3.607642412185669,
      "logits/rejected": 3.550373077392578,
      "logps/chosen": -418.9327697753906,
      "logps/rejected": -340.1410827636719,
      "loss": 0.3226,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4243193864822388,
      "rewards/margins": 3.3037612438201904,
      "rewards/rejected": -4.7280802726745605,
      "step": 19840
    },
    {
      "epoch": 1.1685446147509635,
      "grad_norm": 2.7531557083129883,
      "learning_rate": 3.053447092282044e-05,
      "logits/chosen": 3.892169237136841,
      "logits/rejected": 3.7597222328186035,
      "logps/chosen": -390.81329345703125,
      "logps/rejected": -361.2134704589844,
      "loss": 0.4283,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8496229648590088,
      "rewards/margins": 3.063148021697998,
      "rewards/rejected": -4.9127702713012695,
      "step": 19860
    },
    {
      "epoch": 1.1697213968403402,
      "grad_norm": 2.364489793777466,
      "learning_rate": 3.0514857310973815e-05,
      "logits/chosen": 3.4417285919189453,
      "logits/rejected": 3.4016547203063965,
      "logps/chosen": -331.2823181152344,
      "logps/rejected": -309.58074951171875,
      "loss": 0.3154,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8480865955352783,
      "rewards/margins": 2.8906161785125732,
      "rewards/rejected": -4.73870325088501,
      "step": 19880
    },
    {
      "epoch": 1.1708981789297166,
      "grad_norm": 1.1015558242797852,
      "learning_rate": 3.0495243699127195e-05,
      "logits/chosen": 3.3726577758789062,
      "logits/rejected": 3.4954047203063965,
      "logps/chosen": -348.7687683105469,
      "logps/rejected": -350.01983642578125,
      "loss": 0.2916,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.6041332483291626,
      "rewards/margins": 2.725355386734009,
      "rewards/rejected": -4.329488754272461,
      "step": 19900
    },
    {
      "epoch": 1.1720749610190933,
      "grad_norm": 2.392465114593506,
      "learning_rate": 3.0475630087280578e-05,
      "logits/chosen": 3.2363555431365967,
      "logits/rejected": 3.320178985595703,
      "logps/chosen": -333.00286865234375,
      "logps/rejected": -296.0901184082031,
      "loss": 0.3662,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3019059896469116,
      "rewards/margins": 2.746738910675049,
      "rewards/rejected": -4.048644542694092,
      "step": 19920
    },
    {
      "epoch": 1.17325174310847,
      "grad_norm": 0.45935872197151184,
      "learning_rate": 3.0456997156026286e-05,
      "logits/chosen": 3.671259641647339,
      "logits/rejected": 3.621918201446533,
      "logps/chosen": -403.7933044433594,
      "logps/rejected": -345.0375061035156,
      "loss": 0.3491,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.1556575298309326,
      "rewards/margins": 2.9143753051757812,
      "rewards/rejected": -4.070033073425293,
      "step": 19940
    },
    {
      "epoch": 1.1744285251978466,
      "grad_norm": 0.936790943145752,
      "learning_rate": 3.043738354417966e-05,
      "logits/chosen": 3.897960662841797,
      "logits/rejected": 3.8171310424804688,
      "logps/chosen": -368.5680236816406,
      "logps/rejected": -352.2357482910156,
      "loss": 0.2574,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.4197943210601807,
      "rewards/margins": 3.5162739753723145,
      "rewards/rejected": -4.936068534851074,
      "step": 19960
    },
    {
      "epoch": 1.175605307287223,
      "grad_norm": 0.8780409097671509,
      "learning_rate": 3.041776993233304e-05,
      "logits/chosen": 3.4737613201141357,
      "logits/rejected": 3.546832323074341,
      "logps/chosen": -337.0143737792969,
      "logps/rejected": -278.53753662109375,
      "loss": 0.2892,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.591611385345459,
      "rewards/margins": 2.796588897705078,
      "rewards/rejected": -4.388200283050537,
      "step": 19980
    },
    {
      "epoch": 1.1767820893765997,
      "grad_norm": 0.65188068151474,
      "learning_rate": 3.039815632048642e-05,
      "logits/chosen": 3.754229784011841,
      "logits/rejected": 3.8205771446228027,
      "logps/chosen": -378.11761474609375,
      "logps/rejected": -361.7730407714844,
      "loss": 0.327,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8305728435516357,
      "rewards/margins": 3.601724147796631,
      "rewards/rejected": -5.432297229766846,
      "step": 20000
    },
    {
      "epoch": 1.1767820893765997,
      "eval_logits/chosen": 3.247943878173828,
      "eval_logits/rejected": 3.2693159580230713,
      "eval_logps/chosen": -380.86480712890625,
      "eval_logps/rejected": -348.23638916015625,
      "eval_loss": 0.5170069932937622,
      "eval_rewards/accuracies": 0.7876700162887573,
      "eval_rewards/chosen": -2.6284148693084717,
      "eval_rewards/margins": 2.571901798248291,
      "eval_rewards/rejected": -5.200316429138184,
      "eval_runtime": 3546.7155,
      "eval_samples_per_second": 3.151,
      "eval_steps_per_second": 3.151,
      "step": 20000
    },
    {
      "epoch": 1.1779588714659763,
      "grad_norm": 1.6566689014434814,
      "learning_rate": 3.0378542708639797e-05,
      "logits/chosen": 3.8879711627960205,
      "logits/rejected": 3.9251694679260254,
      "logps/chosen": -416.060791015625,
      "logps/rejected": -363.3588562011719,
      "loss": 0.3699,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.306926965713501,
      "rewards/margins": 3.7255795001983643,
      "rewards/rejected": -6.032506465911865,
      "step": 20020
    },
    {
      "epoch": 1.179135653555353,
      "grad_norm": 1.7661292552947998,
      "learning_rate": 3.0358929096793177e-05,
      "logits/chosen": 3.910618543624878,
      "logits/rejected": 3.8973782062530518,
      "logps/chosen": -390.279296875,
      "logps/rejected": -301.59649658203125,
      "loss": 0.2399,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.4686912298202515,
      "rewards/margins": 3.6876087188720703,
      "rewards/rejected": -5.156300067901611,
      "step": 20040
    },
    {
      "epoch": 1.1803124356447294,
      "grad_norm": 1.048896074295044,
      "learning_rate": 3.0339315484946556e-05,
      "logits/chosen": 3.7856125831604004,
      "logits/rejected": 3.802483320236206,
      "logps/chosen": -389.3013000488281,
      "logps/rejected": -328.0937194824219,
      "loss": 0.3753,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.971261978149414,
      "rewards/margins": 3.3267509937286377,
      "rewards/rejected": -5.298012733459473,
      "step": 20060
    },
    {
      "epoch": 1.181489217734106,
      "grad_norm": 5.9270758628845215,
      "learning_rate": 3.0319701873099932e-05,
      "logits/chosen": 3.7608649730682373,
      "logits/rejected": 3.8157615661621094,
      "logps/chosen": -346.4476013183594,
      "logps/rejected": -384.80670166015625,
      "loss": 0.3873,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.076145887374878,
      "rewards/margins": 2.695164203643799,
      "rewards/rejected": -4.771310329437256,
      "step": 20080
    },
    {
      "epoch": 1.1826659998234827,
      "grad_norm": 6.06948709487915,
      "learning_rate": 3.030008826125331e-05,
      "logits/chosen": 3.6475186347961426,
      "logits/rejected": 3.6921024322509766,
      "logps/chosen": -334.49505615234375,
      "logps/rejected": -310.02203369140625,
      "loss": 0.4834,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.1152422428131104,
      "rewards/margins": 2.2600104808807373,
      "rewards/rejected": -4.375253677368164,
      "step": 20100
    },
    {
      "epoch": 1.1838427819128592,
      "grad_norm": 0.9711772799491882,
      "learning_rate": 3.0280474649406687e-05,
      "logits/chosen": 3.633023500442505,
      "logits/rejected": 3.636538028717041,
      "logps/chosen": -380.3455810546875,
      "logps/rejected": -327.286376953125,
      "loss": 0.3743,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.7403936386108398,
      "rewards/margins": 3.314865827560425,
      "rewards/rejected": -5.0552592277526855,
      "step": 20120
    },
    {
      "epoch": 1.1850195640022358,
      "grad_norm": 4.917215347290039,
      "learning_rate": 3.0260861037560067e-05,
      "logits/chosen": 3.6508820056915283,
      "logits/rejected": 3.6735634803771973,
      "logps/chosen": -402.3821105957031,
      "logps/rejected": -314.5163879394531,
      "loss": 0.2146,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -0.9003020524978638,
      "rewards/margins": 3.5425057411193848,
      "rewards/rejected": -4.442807674407959,
      "step": 20140
    },
    {
      "epoch": 1.1861963460916125,
      "grad_norm": 0.29696860909461975,
      "learning_rate": 3.024124742571345e-05,
      "logits/chosen": 3.7258262634277344,
      "logits/rejected": 3.671111583709717,
      "logps/chosen": -387.1600036621094,
      "logps/rejected": -288.7640075683594,
      "loss": 0.3206,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.5855659246444702,
      "rewards/margins": 3.6005561351776123,
      "rewards/rejected": -5.186121940612793,
      "step": 20160
    },
    {
      "epoch": 1.1873731281809892,
      "grad_norm": 4.338932037353516,
      "learning_rate": 3.0221633813866822e-05,
      "logits/chosen": 4.052037239074707,
      "logits/rejected": 4.00543212890625,
      "logps/chosen": -367.5909423828125,
      "logps/rejected": -320.3769836425781,
      "loss": 0.4114,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.7945924997329712,
      "rewards/margins": 3.3660659790039062,
      "rewards/rejected": -5.160658359527588,
      "step": 20180
    },
    {
      "epoch": 1.1885499102703656,
      "grad_norm": 0.18798640370368958,
      "learning_rate": 3.0202020202020205e-05,
      "logits/chosen": 3.852909803390503,
      "logits/rejected": 3.7981128692626953,
      "logps/chosen": -386.14837646484375,
      "logps/rejected": -322.8409118652344,
      "loss": 0.307,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.661556601524353,
      "rewards/margins": 3.4944567680358887,
      "rewards/rejected": -5.1560139656066895,
      "step": 20200
    },
    {
      "epoch": 1.1897266923597423,
      "grad_norm": 3.8022968769073486,
      "learning_rate": 3.0182406590173585e-05,
      "logits/chosen": 3.758401393890381,
      "logits/rejected": 3.777207136154175,
      "logps/chosen": -362.2701110839844,
      "logps/rejected": -341.5487365722656,
      "loss": 0.3642,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.4217642545700073,
      "rewards/margins": 2.9704155921936035,
      "rewards/rejected": -4.392180442810059,
      "step": 20220
    },
    {
      "epoch": 1.190903474449119,
      "grad_norm": 0.06438817083835602,
      "learning_rate": 3.0163773658919293e-05,
      "logits/chosen": 3.934297561645508,
      "logits/rejected": 3.9749977588653564,
      "logps/chosen": -383.25494384765625,
      "logps/rejected": -323.42425537109375,
      "loss": 0.1871,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.1807403564453125,
      "rewards/margins": 3.9007840156555176,
      "rewards/rejected": -5.081523895263672,
      "step": 20240
    },
    {
      "epoch": 1.1920802565384956,
      "grad_norm": 5.310135364532471,
      "learning_rate": 3.0144160047072673e-05,
      "logits/chosen": 3.3290469646453857,
      "logits/rejected": 3.531092405319214,
      "logps/chosen": -322.99151611328125,
      "logps/rejected": -280.2710266113281,
      "loss": 0.3917,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.2204244136810303,
      "rewards/margins": 2.884294033050537,
      "rewards/rejected": -5.104718208312988,
      "step": 20260
    },
    {
      "epoch": 1.193257038627872,
      "grad_norm": 2.848400354385376,
      "learning_rate": 3.012454643522605e-05,
      "logits/chosen": 3.902434825897217,
      "logits/rejected": 3.6943092346191406,
      "logps/chosen": -415.2261657714844,
      "logps/rejected": -312.93524169921875,
      "loss": 0.3288,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0391128063201904,
      "rewards/margins": 3.4108614921569824,
      "rewards/rejected": -5.449974536895752,
      "step": 20280
    },
    {
      "epoch": 1.1944338207172487,
      "grad_norm": 1.0447646379470825,
      "learning_rate": 3.0104932823379428e-05,
      "logits/chosen": 3.733365535736084,
      "logits/rejected": 3.5786633491516113,
      "logps/chosen": -384.9873962402344,
      "logps/rejected": -291.60162353515625,
      "loss": 0.306,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.975752592086792,
      "rewards/margins": 3.5732460021972656,
      "rewards/rejected": -5.548998832702637,
      "step": 20300
    },
    {
      "epoch": 1.1956106028066253,
      "grad_norm": 5.603774547576904,
      "learning_rate": 3.0085319211532804e-05,
      "logits/chosen": 3.7017312049865723,
      "logits/rejected": 3.7849297523498535,
      "logps/chosen": -349.25848388671875,
      "logps/rejected": -294.82330322265625,
      "loss": 0.4161,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3383586406707764,
      "rewards/margins": 2.888000726699829,
      "rewards/rejected": -5.2263593673706055,
      "step": 20320
    },
    {
      "epoch": 1.1967873848960018,
      "grad_norm": 1.6048951148986816,
      "learning_rate": 3.0065705599686184e-05,
      "logits/chosen": 4.142379283905029,
      "logits/rejected": 4.070784091949463,
      "logps/chosen": -445.02117919921875,
      "logps/rejected": -380.6284484863281,
      "loss": 0.404,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.5520498752593994,
      "rewards/margins": 3.4962310791015625,
      "rewards/rejected": -5.048281192779541,
      "step": 20340
    },
    {
      "epoch": 1.1979641669853784,
      "grad_norm": 0.6128422617912292,
      "learning_rate": 3.0046091987839563e-05,
      "logits/chosen": 3.7393276691436768,
      "logits/rejected": 3.8449625968933105,
      "logps/chosen": -373.208740234375,
      "logps/rejected": -346.1596374511719,
      "loss": 0.2816,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.483686089515686,
      "rewards/margins": 3.758391857147217,
      "rewards/rejected": -5.242077827453613,
      "step": 20360
    },
    {
      "epoch": 1.199140949074755,
      "grad_norm": 4.942039489746094,
      "learning_rate": 3.002647837599294e-05,
      "logits/chosen": 3.8433079719543457,
      "logits/rejected": 3.745587110519409,
      "logps/chosen": -395.08880615234375,
      "logps/rejected": -340.13189697265625,
      "loss": 0.3672,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0313544273376465,
      "rewards/margins": 3.439487934112549,
      "rewards/rejected": -5.470841884613037,
      "step": 20380
    },
    {
      "epoch": 1.2003177311641318,
      "grad_norm": 1.1402391195297241,
      "learning_rate": 3.000686476414632e-05,
      "logits/chosen": 4.079075336456299,
      "logits/rejected": 4.0446271896362305,
      "logps/chosen": -454.69677734375,
      "logps/rejected": -369.7340087890625,
      "loss": 0.2416,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.3615574836730957,
      "rewards/margins": 3.5247721672058105,
      "rewards/rejected": -4.8863301277160645,
      "step": 20400
    },
    {
      "epoch": 1.2014945132535082,
      "grad_norm": 2.6319825649261475,
      "learning_rate": 2.99872511522997e-05,
      "logits/chosen": 3.8706817626953125,
      "logits/rejected": 3.70405650138855,
      "logps/chosen": -440.3221130371094,
      "logps/rejected": -358.43597412109375,
      "loss": 0.3943,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0713601112365723,
      "rewards/margins": 4.151089668273926,
      "rewards/rejected": -6.22244930267334,
      "step": 20420
    },
    {
      "epoch": 1.2026712953428849,
      "grad_norm": 6.816105842590332,
      "learning_rate": 2.9967637540453074e-05,
      "logits/chosen": 3.751164674758911,
      "logits/rejected": 3.890076160430908,
      "logps/chosen": -409.94183349609375,
      "logps/rejected": -360.628173828125,
      "loss": 0.2467,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6268692016601562,
      "rewards/margins": 3.9008030891418457,
      "rewards/rejected": -5.527672290802002,
      "step": 20440
    },
    {
      "epoch": 1.2038480774322615,
      "grad_norm": 2.4966890811920166,
      "learning_rate": 2.9948023928606457e-05,
      "logits/chosen": 3.735621690750122,
      "logits/rejected": 3.5443649291992188,
      "logps/chosen": -348.5321960449219,
      "logps/rejected": -277.62615966796875,
      "loss": 0.2965,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.4127506017684937,
      "rewards/margins": 3.774231433868408,
      "rewards/rejected": -5.186982154846191,
      "step": 20460
    },
    {
      "epoch": 1.2050248595216382,
      "grad_norm": 1.9692713022232056,
      "learning_rate": 2.992841031675983e-05,
      "logits/chosen": 3.9204888343811035,
      "logits/rejected": 3.9466280937194824,
      "logps/chosen": -433.1026916503906,
      "logps/rejected": -343.0332336425781,
      "loss": 0.2435,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1981310844421387,
      "rewards/margins": 3.9776763916015625,
      "rewards/rejected": -6.175806999206543,
      "step": 20480
    },
    {
      "epoch": 1.2062016416110146,
      "grad_norm": 1.6248719692230225,
      "learning_rate": 2.9908796704913212e-05,
      "logits/chosen": 3.8017406463623047,
      "logits/rejected": 3.856003522872925,
      "logps/chosen": -400.92559814453125,
      "logps/rejected": -339.1986083984375,
      "loss": 0.2041,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -0.9373732805252075,
      "rewards/margins": 4.010406970977783,
      "rewards/rejected": -4.947780609130859,
      "step": 20500
    },
    {
      "epoch": 1.2073784237003913,
      "grad_norm": 2.5005300045013428,
      "learning_rate": 2.988918309306659e-05,
      "logits/chosen": 3.7787985801696777,
      "logits/rejected": 3.755964994430542,
      "logps/chosen": -390.4307861328125,
      "logps/rejected": -316.3125305175781,
      "loss": 0.3379,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9451040029525757,
      "rewards/margins": 3.208768367767334,
      "rewards/rejected": -5.153872489929199,
      "step": 20520
    },
    {
      "epoch": 1.208555205789768,
      "grad_norm": 2.852658987045288,
      "learning_rate": 2.9869569481219968e-05,
      "logits/chosen": 3.716754198074341,
      "logits/rejected": 3.6925289630889893,
      "logps/chosen": -416.57537841796875,
      "logps/rejected": -338.98162841796875,
      "loss": 0.2839,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.5168737173080444,
      "rewards/margins": 3.861121654510498,
      "rewards/rejected": -5.377995491027832,
      "step": 20540
    },
    {
      "epoch": 1.2097319878791444,
      "grad_norm": 1.5534284114837646,
      "learning_rate": 2.9849955869373347e-05,
      "logits/chosen": 3.9119644165039062,
      "logits/rejected": 4.053175449371338,
      "logps/chosen": -362.0307312011719,
      "logps/rejected": -347.328857421875,
      "loss": 0.4219,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6714494228363037,
      "rewards/margins": 2.568512439727783,
      "rewards/rejected": -4.239962100982666,
      "step": 20560
    },
    {
      "epoch": 1.210908769968521,
      "grad_norm": 3.0439252853393555,
      "learning_rate": 2.9830342257526727e-05,
      "logits/chosen": 3.751782178878784,
      "logits/rejected": 3.647622585296631,
      "logps/chosen": -356.2617492675781,
      "logps/rejected": -311.2279357910156,
      "loss": 0.4256,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3673408031463623,
      "rewards/margins": 3.2157340049743652,
      "rewards/rejected": -4.583075046539307,
      "step": 20580
    },
    {
      "epoch": 1.2120855520578977,
      "grad_norm": 3.0021815299987793,
      "learning_rate": 2.9810728645680103e-05,
      "logits/chosen": 3.8583335876464844,
      "logits/rejected": 3.9624900817871094,
      "logps/chosen": -358.9930419921875,
      "logps/rejected": -372.47906494140625,
      "loss": 0.4433,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.8007548451423645,
      "rewards/margins": 2.8448688983917236,
      "rewards/rejected": -3.6456241607666016,
      "step": 20600
    },
    {
      "epoch": 1.2132623341472744,
      "grad_norm": 4.26491641998291,
      "learning_rate": 2.9791115033833482e-05,
      "logits/chosen": 4.0173020362854,
      "logits/rejected": 3.9840774536132812,
      "logps/chosen": -426.802734375,
      "logps/rejected": -344.28131103515625,
      "loss": 0.3247,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.9689353108406067,
      "rewards/margins": 3.171577215194702,
      "rewards/rejected": -4.140512466430664,
      "step": 20620
    },
    {
      "epoch": 1.2144391162366508,
      "grad_norm": 0.04861648753285408,
      "learning_rate": 2.9771501421986858e-05,
      "logits/chosen": 3.6464600563049316,
      "logits/rejected": 3.6030869483947754,
      "logps/chosen": -375.75177001953125,
      "logps/rejected": -311.44073486328125,
      "loss": 0.3367,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.6761307716369629,
      "rewards/margins": 3.916071653366089,
      "rewards/rejected": -4.592202186584473,
      "step": 20640
    },
    {
      "epoch": 1.2156158983260275,
      "grad_norm": 5.823369026184082,
      "learning_rate": 2.9751887810140237e-05,
      "logits/chosen": 4.11704158782959,
      "logits/rejected": 4.00940465927124,
      "logps/chosen": -386.24908447265625,
      "logps/rejected": -298.6900939941406,
      "loss": 0.3715,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6103289127349854,
      "rewards/margins": 3.177386999130249,
      "rewards/rejected": -4.787716388702393,
      "step": 20660
    },
    {
      "epoch": 1.2167926804154041,
      "grad_norm": 2.1791932582855225,
      "learning_rate": 2.973227419829362e-05,
      "logits/chosen": 3.8915696144104004,
      "logits/rejected": 3.9316318035125732,
      "logps/chosen": -361.98321533203125,
      "logps/rejected": -316.79254150390625,
      "loss": 0.3773,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9047253131866455,
      "rewards/margins": 2.721262216567993,
      "rewards/rejected": -4.6259870529174805,
      "step": 20680
    },
    {
      "epoch": 1.2179694625047808,
      "grad_norm": 2.3108620643615723,
      "learning_rate": 2.9712660586446993e-05,
      "logits/chosen": 3.8196778297424316,
      "logits/rejected": 4.0022196769714355,
      "logps/chosen": -411.1907653808594,
      "logps/rejected": -316.4430847167969,
      "loss": 0.3046,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.151440382003784,
      "rewards/margins": 3.5342392921447754,
      "rewards/rejected": -5.685680389404297,
      "step": 20700
    },
    {
      "epoch": 1.2191462445941572,
      "grad_norm": 2.799445629119873,
      "learning_rate": 2.9693046974600376e-05,
      "logits/chosen": 3.617280960083008,
      "logits/rejected": 3.6856067180633545,
      "logps/chosen": -342.28277587890625,
      "logps/rejected": -271.05718994140625,
      "loss": 0.3687,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8038127422332764,
      "rewards/margins": 2.6450448036193848,
      "rewards/rejected": -4.448858261108398,
      "step": 20720
    },
    {
      "epoch": 1.2203230266835339,
      "grad_norm": 3.0824429988861084,
      "learning_rate": 2.9673433362753755e-05,
      "logits/chosen": 3.8626999855041504,
      "logits/rejected": 3.818089246749878,
      "logps/chosen": -387.668701171875,
      "logps/rejected": -316.17254638671875,
      "loss": 0.3204,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.0411806106567383,
      "rewards/margins": 3.3486900329589844,
      "rewards/rejected": -5.389870643615723,
      "step": 20740
    },
    {
      "epoch": 1.2214998087729105,
      "grad_norm": 5.078453063964844,
      "learning_rate": 2.965381975090713e-05,
      "logits/chosen": 3.7945570945739746,
      "logits/rejected": 3.927863597869873,
      "logps/chosen": -370.17816162109375,
      "logps/rejected": -311.4305725097656,
      "loss": 0.2438,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.0014221668243408,
      "rewards/margins": 3.6276822090148926,
      "rewards/rejected": -4.629104137420654,
      "step": 20760
    },
    {
      "epoch": 1.222676590862287,
      "grad_norm": 3.2385847568511963,
      "learning_rate": 2.963420613906051e-05,
      "logits/chosen": 3.875781297683716,
      "logits/rejected": 3.8689911365509033,
      "logps/chosen": -393.16583251953125,
      "logps/rejected": -324.7236328125,
      "loss": 0.2957,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.373813509941101,
      "rewards/margins": 3.1752915382385254,
      "rewards/rejected": -4.549104690551758,
      "step": 20780
    },
    {
      "epoch": 1.2238533729516636,
      "grad_norm": 3.124833583831787,
      "learning_rate": 2.9614592527213887e-05,
      "logits/chosen": 3.8734734058380127,
      "logits/rejected": 3.7824835777282715,
      "logps/chosen": -391.10418701171875,
      "logps/rejected": -335.0263671875,
      "loss": 0.3999,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5706241130828857,
      "rewards/margins": 2.9471192359924316,
      "rewards/rejected": -4.5177435874938965,
      "step": 20800
    },
    {
      "epoch": 1.2250301550410403,
      "grad_norm": 1.0441412925720215,
      "learning_rate": 2.9594978915367266e-05,
      "logits/chosen": 4.0334577560424805,
      "logits/rejected": 4.036075592041016,
      "logps/chosen": -395.8645935058594,
      "logps/rejected": -366.8715515136719,
      "loss": 0.466,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7545239925384521,
      "rewards/margins": 3.0949320793151855,
      "rewards/rejected": -4.849455833435059,
      "step": 20820
    },
    {
      "epoch": 1.226206937130417,
      "grad_norm": 1.0932559967041016,
      "learning_rate": 2.9575365303520646e-05,
      "logits/chosen": 3.850592851638794,
      "logits/rejected": 3.8600013256073,
      "logps/chosen": -346.1029968261719,
      "logps/rejected": -300.21380615234375,
      "loss": 0.4803,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.80315101146698,
      "rewards/margins": 2.9719462394714355,
      "rewards/rejected": -3.775097370147705,
      "step": 20840
    },
    {
      "epoch": 1.2273837192197934,
      "grad_norm": 1.236106276512146,
      "learning_rate": 2.955575169167402e-05,
      "logits/chosen": 3.7225825786590576,
      "logits/rejected": 3.7154440879821777,
      "logps/chosen": -376.117431640625,
      "logps/rejected": -309.90478515625,
      "loss": 0.225,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -0.5122634172439575,
      "rewards/margins": 4.173835754394531,
      "rewards/rejected": -4.686099052429199,
      "step": 20860
    },
    {
      "epoch": 1.22856050130917,
      "grad_norm": 2.8161845207214355,
      "learning_rate": 2.95361380798274e-05,
      "logits/chosen": 3.8765406608581543,
      "logits/rejected": 4.011727333068848,
      "logps/chosen": -385.60870361328125,
      "logps/rejected": -306.1034851074219,
      "loss": 0.3357,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.4709794521331787,
      "rewards/margins": 2.6673312187194824,
      "rewards/rejected": -4.138310432434082,
      "step": 20880
    },
    {
      "epoch": 1.2297372833985467,
      "grad_norm": 1.313561201095581,
      "learning_rate": 2.9516524467980777e-05,
      "logits/chosen": 3.886986255645752,
      "logits/rejected": 3.8622100353240967,
      "logps/chosen": -378.7001037597656,
      "logps/rejected": -290.9561462402344,
      "loss": 0.267,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.3508541584014893,
      "rewards/margins": 2.7299811840057373,
      "rewards/rejected": -4.080834865570068,
      "step": 20900
    },
    {
      "epoch": 1.2309140654879234,
      "grad_norm": 2.633782386779785,
      "learning_rate": 2.9496910856134156e-05,
      "logits/chosen": 3.869168758392334,
      "logits/rejected": 3.761392116546631,
      "logps/chosen": -364.21771240234375,
      "logps/rejected": -310.62469482421875,
      "loss": 0.4277,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6073076725006104,
      "rewards/margins": 2.7339792251586914,
      "rewards/rejected": -4.341286659240723,
      "step": 20920
    },
    {
      "epoch": 1.2320908475772998,
      "grad_norm": 3.3695173263549805,
      "learning_rate": 2.947729724428754e-05,
      "logits/chosen": 3.7639732360839844,
      "logits/rejected": 3.766813278198242,
      "logps/chosen": -407.7537536621094,
      "logps/rejected": -345.96942138671875,
      "loss": 0.3871,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.748438835144043,
      "rewards/margins": 2.707312822341919,
      "rewards/rejected": -4.455751895904541,
      "step": 20940
    },
    {
      "epoch": 1.2332676296666765,
      "grad_norm": 2.676356077194214,
      "learning_rate": 2.9457683632440912e-05,
      "logits/chosen": 3.584808349609375,
      "logits/rejected": 3.5883262157440186,
      "logps/chosen": -378.37237548828125,
      "logps/rejected": -326.7184143066406,
      "loss": 0.2045,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.4695510864257812,
      "rewards/margins": 4.429668426513672,
      "rewards/rejected": -5.899219512939453,
      "step": 20960
    },
    {
      "epoch": 1.2344444117560531,
      "grad_norm": 2.0450267791748047,
      "learning_rate": 2.9438070020594295e-05,
      "logits/chosen": 3.9247710704803467,
      "logits/rejected": 3.943930149078369,
      "logps/chosen": -390.3916931152344,
      "logps/rejected": -341.27349853515625,
      "loss": 0.3065,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.059199333190918,
      "rewards/margins": 3.154512643814087,
      "rewards/rejected": -5.213711738586426,
      "step": 20980
    },
    {
      "epoch": 1.2356211938454296,
      "grad_norm": 3.690880537033081,
      "learning_rate": 2.9418456408747674e-05,
      "logits/chosen": 3.858445405960083,
      "logits/rejected": 4.016097068786621,
      "logps/chosen": -412.13592529296875,
      "logps/rejected": -360.2039489746094,
      "loss": 0.3404,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.840888261795044,
      "rewards/margins": 3.1745290756225586,
      "rewards/rejected": -5.015417098999023,
      "step": 21000
    },
    {
      "epoch": 1.2367979759348062,
      "grad_norm": 0.20241566002368927,
      "learning_rate": 2.939884279690105e-05,
      "logits/chosen": 3.982374668121338,
      "logits/rejected": 3.9254698753356934,
      "logps/chosen": -425.2076721191406,
      "logps/rejected": -339.239990234375,
      "loss": 0.2644,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.2654887437820435,
      "rewards/margins": 3.6972579956054688,
      "rewards/rejected": -4.962746620178223,
      "step": 21020
    },
    {
      "epoch": 1.2379747580241829,
      "grad_norm": 1.2188800573349,
      "learning_rate": 2.937922918505443e-05,
      "logits/chosen": 3.6552841663360596,
      "logits/rejected": 3.647063732147217,
      "logps/chosen": -367.45654296875,
      "logps/rejected": -294.46820068359375,
      "loss": 0.2407,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.6499639749526978,
      "rewards/margins": 3.447401762008667,
      "rewards/rejected": -5.097365856170654,
      "step": 21040
    },
    {
      "epoch": 1.2391515401135595,
      "grad_norm": 3.1231613159179688,
      "learning_rate": 2.9359615573207806e-05,
      "logits/chosen": 3.966723680496216,
      "logits/rejected": 3.8437752723693848,
      "logps/chosen": -378.243408203125,
      "logps/rejected": -325.6004638671875,
      "loss": 0.2227,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.865006446838379,
      "rewards/margins": 3.974961757659912,
      "rewards/rejected": -5.839967727661133,
      "step": 21060
    },
    {
      "epoch": 1.240328322202936,
      "grad_norm": 3.4765264987945557,
      "learning_rate": 2.9340001961361185e-05,
      "logits/chosen": 3.765552043914795,
      "logits/rejected": 3.75203013420105,
      "logps/chosen": -389.4284973144531,
      "logps/rejected": -283.4869079589844,
      "loss": 0.3225,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0658106803894043,
      "rewards/margins": 3.0367658138275146,
      "rewards/rejected": -5.10257625579834,
      "step": 21080
    },
    {
      "epoch": 1.2415051042923126,
      "grad_norm": 3.0072853565216064,
      "learning_rate": 2.9320388349514565e-05,
      "logits/chosen": 3.697922945022583,
      "logits/rejected": 3.7258617877960205,
      "logps/chosen": -376.9519958496094,
      "logps/rejected": -295.48211669921875,
      "loss": 0.3121,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6539465188980103,
      "rewards/margins": 3.029123067855835,
      "rewards/rejected": -4.683069705963135,
      "step": 21100
    },
    {
      "epoch": 1.2426818863816893,
      "grad_norm": 1.4572697877883911,
      "learning_rate": 2.930077473766794e-05,
      "logits/chosen": 3.775486707687378,
      "logits/rejected": 3.699836254119873,
      "logps/chosen": -387.42156982421875,
      "logps/rejected": -309.81463623046875,
      "loss": 0.2388,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4112210273742676,
      "rewards/margins": 3.2019729614257812,
      "rewards/rejected": -5.613194465637207,
      "step": 21120
    },
    {
      "epoch": 1.243858668471066,
      "grad_norm": 1.931501865386963,
      "learning_rate": 2.928116112582132e-05,
      "logits/chosen": 4.090472221374512,
      "logits/rejected": 3.9297726154327393,
      "logps/chosen": -437.44952392578125,
      "logps/rejected": -372.8003234863281,
      "loss": 0.2487,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.0243890285491943,
      "rewards/margins": 3.618767499923706,
      "rewards/rejected": -5.643157005310059,
      "step": 21140
    },
    {
      "epoch": 1.2450354505604424,
      "grad_norm": 0.719344437122345,
      "learning_rate": 2.9261547513974703e-05,
      "logits/chosen": 4.058457374572754,
      "logits/rejected": 4.0808210372924805,
      "logps/chosen": -442.369140625,
      "logps/rejected": -364.32598876953125,
      "loss": 0.295,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.644270896911621,
      "rewards/margins": 3.419766664505005,
      "rewards/rejected": -5.064036846160889,
      "step": 21160
    },
    {
      "epoch": 1.246212232649819,
      "grad_norm": 0.04850206524133682,
      "learning_rate": 2.9241933902128075e-05,
      "logits/chosen": 3.752077579498291,
      "logits/rejected": 3.7702414989471436,
      "logps/chosen": -454.21160888671875,
      "logps/rejected": -325.98394775390625,
      "loss": 0.2065,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5055294036865234,
      "rewards/margins": 4.162497043609619,
      "rewards/rejected": -5.668026924133301,
      "step": 21180
    },
    {
      "epoch": 1.2473890147391957,
      "grad_norm": 2.8355188369750977,
      "learning_rate": 2.9222320290281458e-05,
      "logits/chosen": 3.44520902633667,
      "logits/rejected": 3.5696969032287598,
      "logps/chosen": -376.9529724121094,
      "logps/rejected": -322.26385498046875,
      "loss": 0.3921,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.368393898010254,
      "rewards/margins": 3.228099822998047,
      "rewards/rejected": -5.596493721008301,
      "step": 21200
    },
    {
      "epoch": 1.2485657968285722,
      "grad_norm": 1.096585750579834,
      "learning_rate": 2.920270667843483e-05,
      "logits/chosen": 4.08247184753418,
      "logits/rejected": 4.073263168334961,
      "logps/chosen": -388.31964111328125,
      "logps/rejected": -339.9948425292969,
      "loss": 0.3517,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9031997919082642,
      "rewards/margins": 3.4799628257751465,
      "rewards/rejected": -5.383162498474121,
      "step": 21220
    },
    {
      "epoch": 1.2497425789179488,
      "grad_norm": 2.3978683948516846,
      "learning_rate": 2.9183093066588214e-05,
      "logits/chosen": 3.730839252471924,
      "logits/rejected": 3.8309521675109863,
      "logps/chosen": -388.87603759765625,
      "logps/rejected": -335.1762390136719,
      "loss": 0.3536,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2849836349487305,
      "rewards/margins": 3.106708288192749,
      "rewards/rejected": -5.391692161560059,
      "step": 21240
    },
    {
      "epoch": 1.2509193610073255,
      "grad_norm": 2.18807053565979,
      "learning_rate": 2.9163479454741593e-05,
      "logits/chosen": 3.697326183319092,
      "logits/rejected": 3.638782024383545,
      "logps/chosen": -394.98004150390625,
      "logps/rejected": -354.3069763183594,
      "loss": 0.2752,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.2045091390609741,
      "rewards/margins": 4.195074558258057,
      "rewards/rejected": -5.399583339691162,
      "step": 21260
    },
    {
      "epoch": 1.2520961430967021,
      "grad_norm": 4.198554515838623,
      "learning_rate": 2.914386584289497e-05,
      "logits/chosen": 3.6362907886505127,
      "logits/rejected": 3.655869960784912,
      "logps/chosen": -336.864013671875,
      "logps/rejected": -315.4228210449219,
      "loss": 0.3335,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5834081172943115,
      "rewards/margins": 3.04793119430542,
      "rewards/rejected": -4.631340026855469,
      "step": 21280
    },
    {
      "epoch": 1.2532729251860788,
      "grad_norm": 5.306090354919434,
      "learning_rate": 2.912425223104835e-05,
      "logits/chosen": 3.7471401691436768,
      "logits/rejected": 3.730149745941162,
      "logps/chosen": -388.90496826171875,
      "logps/rejected": -369.24957275390625,
      "loss": 0.4406,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9314647912979126,
      "rewards/margins": 3.1226558685302734,
      "rewards/rejected": -5.054121017456055,
      "step": 21300
    },
    {
      "epoch": 1.2544497072754552,
      "grad_norm": 0.800889253616333,
      "learning_rate": 2.9104638619201728e-05,
      "logits/chosen": 3.8476767539978027,
      "logits/rejected": 3.7128849029541016,
      "logps/chosen": -392.3988037109375,
      "logps/rejected": -342.2555236816406,
      "loss": 0.22,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.6403658390045166,
      "rewards/margins": 4.175099849700928,
      "rewards/rejected": -5.815466403961182,
      "step": 21320
    },
    {
      "epoch": 1.255626489364832,
      "grad_norm": 2.217663049697876,
      "learning_rate": 2.9085025007355104e-05,
      "logits/chosen": 3.735607147216797,
      "logits/rejected": 3.702904224395752,
      "logps/chosen": -382.0140075683594,
      "logps/rejected": -285.8785095214844,
      "loss": 0.3444,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.8533468246459961,
      "rewards/margins": 4.3523125648498535,
      "rewards/rejected": -5.205658912658691,
      "step": 21340
    },
    {
      "epoch": 1.2568032714542086,
      "grad_norm": 2.9259018898010254,
      "learning_rate": 2.9065411395508484e-05,
      "logits/chosen": 3.6618735790252686,
      "logits/rejected": 3.7786757946014404,
      "logps/chosen": -355.1084899902344,
      "logps/rejected": -348.67144775390625,
      "loss": 0.3028,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1715426445007324,
      "rewards/margins": 3.718475341796875,
      "rewards/rejected": -5.890017986297607,
      "step": 21360
    },
    {
      "epoch": 1.257980053543585,
      "grad_norm": 5.576501369476318,
      "learning_rate": 2.904579778366186e-05,
      "logits/chosen": 3.6479873657226562,
      "logits/rejected": 3.7162022590637207,
      "logps/chosen": -326.7409362792969,
      "logps/rejected": -331.31207275390625,
      "loss": 0.3222,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9650905132293701,
      "rewards/margins": 3.6414623260498047,
      "rewards/rejected": -5.606552600860596,
      "step": 21380
    },
    {
      "epoch": 1.2591568356329617,
      "grad_norm": 1.9310591220855713,
      "learning_rate": 2.902618417181524e-05,
      "logits/chosen": 4.0134687423706055,
      "logits/rejected": 4.06466817855835,
      "logps/chosen": -403.027099609375,
      "logps/rejected": -366.106201171875,
      "loss": 0.2958,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.496425986289978,
      "rewards/margins": 4.3265204429626465,
      "rewards/rejected": -5.822946548461914,
      "step": 21400
    },
    {
      "epoch": 1.2603336177223383,
      "grad_norm": 0.026794834062457085,
      "learning_rate": 2.9006570559968622e-05,
      "logits/chosen": 3.7099640369415283,
      "logits/rejected": 3.6576428413391113,
      "logps/chosen": -365.4809875488281,
      "logps/rejected": -341.17510986328125,
      "loss": 0.3142,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.0163182020187378,
      "rewards/margins": 3.7388217449188232,
      "rewards/rejected": -4.755139350891113,
      "step": 21420
    },
    {
      "epoch": 1.2615103998117148,
      "grad_norm": 6.082691192626953,
      "learning_rate": 2.8986956948121994e-05,
      "logits/chosen": 3.957993984222412,
      "logits/rejected": 4.021737098693848,
      "logps/chosen": -404.430908203125,
      "logps/rejected": -374.18817138671875,
      "loss": 0.3371,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.1428495645523071,
      "rewards/margins": 3.3253722190856934,
      "rewards/rejected": -4.468221664428711,
      "step": 21440
    },
    {
      "epoch": 1.2626871819010914,
      "grad_norm": 1.5348049402236938,
      "learning_rate": 2.8967343336275377e-05,
      "logits/chosen": 3.6633193492889404,
      "logits/rejected": 3.696669101715088,
      "logps/chosen": -384.23455810546875,
      "logps/rejected": -300.0528869628906,
      "loss": 0.2326,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.46627938747406,
      "rewards/margins": 3.493298292160034,
      "rewards/rejected": -4.959578037261963,
      "step": 21460
    },
    {
      "epoch": 1.263863963990468,
      "grad_norm": 3.2106363773345947,
      "learning_rate": 2.8947729724428757e-05,
      "logits/chosen": 4.050808906555176,
      "logits/rejected": 4.0999298095703125,
      "logps/chosen": -375.7320251464844,
      "logps/rejected": -324.18560791015625,
      "loss": 0.218,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.9382842779159546,
      "rewards/margins": 4.246399879455566,
      "rewards/rejected": -6.184683799743652,
      "step": 21480
    },
    {
      "epoch": 1.2650407460798447,
      "grad_norm": 0.9982648491859436,
      "learning_rate": 2.8928116112582133e-05,
      "logits/chosen": 3.6903228759765625,
      "logits/rejected": 3.7110888957977295,
      "logps/chosen": -448.3807067871094,
      "logps/rejected": -386.3449401855469,
      "loss": 0.3163,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9501781463623047,
      "rewards/margins": 4.155238151550293,
      "rewards/rejected": -6.105416297912598,
      "step": 21500
    },
    {
      "epoch": 1.2662175281692214,
      "grad_norm": 0.4138239026069641,
      "learning_rate": 2.8908502500735512e-05,
      "logits/chosen": 3.861255168914795,
      "logits/rejected": 3.8089041709899902,
      "logps/chosen": -416.88494873046875,
      "logps/rejected": -339.45733642578125,
      "loss": 0.41,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4675018787384033,
      "rewards/margins": 3.2374210357666016,
      "rewards/rejected": -4.704922676086426,
      "step": 21520
    },
    {
      "epoch": 1.2673943102585978,
      "grad_norm": 1.1711167097091675,
      "learning_rate": 2.8888888888888888e-05,
      "logits/chosen": 3.6244235038757324,
      "logits/rejected": 3.7279205322265625,
      "logps/chosen": -351.54608154296875,
      "logps/rejected": -326.576416015625,
      "loss": 0.3202,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6652418375015259,
      "rewards/margins": 3.2781753540039062,
      "rewards/rejected": -4.943417549133301,
      "step": 21540
    },
    {
      "epoch": 1.2685710923479745,
      "grad_norm": 0.07043353468179703,
      "learning_rate": 2.8869275277042268e-05,
      "logits/chosen": 3.7636895179748535,
      "logits/rejected": 3.751502275466919,
      "logps/chosen": -403.79339599609375,
      "logps/rejected": -331.3492736816406,
      "loss": 0.2053,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.5508443117141724,
      "rewards/margins": 3.940436840057373,
      "rewards/rejected": -5.491281032562256,
      "step": 21560
    },
    {
      "epoch": 1.2697478744373512,
      "grad_norm": 0.6645081043243408,
      "learning_rate": 2.8849661665195647e-05,
      "logits/chosen": 3.6800332069396973,
      "logits/rejected": 3.6625843048095703,
      "logps/chosen": -353.56378173828125,
      "logps/rejected": -347.22955322265625,
      "loss": 0.4198,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.1063473224639893,
      "rewards/margins": 3.488487720489502,
      "rewards/rejected": -5.59483528137207,
      "step": 21580
    },
    {
      "epoch": 1.2709246565267276,
      "grad_norm": 4.535781383514404,
      "learning_rate": 2.8830048053349023e-05,
      "logits/chosen": 3.8212196826934814,
      "logits/rejected": 3.8838226795196533,
      "logps/chosen": -392.7899169921875,
      "logps/rejected": -341.1343688964844,
      "loss": 0.301,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.824501395225525,
      "rewards/margins": 3.91172456741333,
      "rewards/rejected": -5.7362260818481445,
      "step": 21600
    },
    {
      "epoch": 1.2721014386161043,
      "grad_norm": 2.0503220558166504,
      "learning_rate": 2.8810434441502403e-05,
      "logits/chosen": 3.8929240703582764,
      "logits/rejected": 3.8612656593322754,
      "logps/chosen": -426.11700439453125,
      "logps/rejected": -325.7626647949219,
      "loss": 0.277,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.28574538230896,
      "rewards/margins": 3.7868762016296387,
      "rewards/rejected": -5.0726213455200195,
      "step": 21620
    },
    {
      "epoch": 1.273278220705481,
      "grad_norm": 1.4299819469451904,
      "learning_rate": 2.8790820829655785e-05,
      "logits/chosen": 4.011420249938965,
      "logits/rejected": 3.9156079292297363,
      "logps/chosen": -419.0157775878906,
      "logps/rejected": -373.12591552734375,
      "loss": 0.2864,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.942300796508789,
      "rewards/margins": 3.149794578552246,
      "rewards/rejected": -5.092095375061035,
      "step": 21640
    },
    {
      "epoch": 1.2744550027948574,
      "grad_norm": 1.183948278427124,
      "learning_rate": 2.8771207217809158e-05,
      "logits/chosen": 3.6425864696502686,
      "logits/rejected": 3.6178672313690186,
      "logps/chosen": -396.0401611328125,
      "logps/rejected": -292.60211181640625,
      "loss": 0.304,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7308002710342407,
      "rewards/margins": 3.241140842437744,
      "rewards/rejected": -4.971940994262695,
      "step": 21660
    },
    {
      "epoch": 1.275631784884234,
      "grad_norm": 4.221201419830322,
      "learning_rate": 2.875159360596254e-05,
      "logits/chosen": 3.71185302734375,
      "logits/rejected": 3.5925726890563965,
      "logps/chosen": -411.65509033203125,
      "logps/rejected": -336.435546875,
      "loss": 0.434,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.8854005336761475,
      "rewards/margins": 3.486794948577881,
      "rewards/rejected": -5.372195720672607,
      "step": 21680
    },
    {
      "epoch": 1.2768085669736107,
      "grad_norm": 3.8278276920318604,
      "learning_rate": 2.8731979994115913e-05,
      "logits/chosen": 3.652545213699341,
      "logits/rejected": 3.3604540824890137,
      "logps/chosen": -407.6927490234375,
      "logps/rejected": -382.70220947265625,
      "loss": 0.2353,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8646652698516846,
      "rewards/margins": 3.712833881378174,
      "rewards/rejected": -5.577498912811279,
      "step": 21700
    },
    {
      "epoch": 1.2779853490629873,
      "grad_norm": 0.36763036251068115,
      "learning_rate": 2.8712366382269296e-05,
      "logits/chosen": 3.3570220470428467,
      "logits/rejected": 3.4226012229919434,
      "logps/chosen": -437.46923828125,
      "logps/rejected": -382.23590087890625,
      "loss": 0.2768,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.322042942047119,
      "rewards/margins": 4.29453706741333,
      "rewards/rejected": -6.616579532623291,
      "step": 21720
    },
    {
      "epoch": 1.279162131152364,
      "grad_norm": 3.684626340866089,
      "learning_rate": 2.8692752770422676e-05,
      "logits/chosen": 3.5081794261932373,
      "logits/rejected": 3.335486650466919,
      "logps/chosen": -385.290283203125,
      "logps/rejected": -335.81439208984375,
      "loss": 0.456,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.5811915397644043,
      "rewards/margins": 2.997938871383667,
      "rewards/rejected": -5.57913064956665,
      "step": 21740
    },
    {
      "epoch": 1.2803389132417404,
      "grad_norm": 3.3809077739715576,
      "learning_rate": 2.8673139158576052e-05,
      "logits/chosen": 4.020575523376465,
      "logits/rejected": 3.8475289344787598,
      "logps/chosen": -406.6468811035156,
      "logps/rejected": -334.0384216308594,
      "loss": 0.2264,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.5963759422302246,
      "rewards/margins": 3.7033019065856934,
      "rewards/rejected": -6.299677848815918,
      "step": 21760
    },
    {
      "epoch": 1.281515695331117,
      "grad_norm": 1.1046079397201538,
      "learning_rate": 2.865352554672943e-05,
      "logits/chosen": 3.268958568572998,
      "logits/rejected": 3.2920989990234375,
      "logps/chosen": -401.251953125,
      "logps/rejected": -334.2366943359375,
      "loss": 0.3876,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.814981460571289,
      "rewards/margins": 4.405760288238525,
      "rewards/rejected": -7.22074031829834,
      "step": 21780
    },
    {
      "epoch": 1.2826924774204937,
      "grad_norm": 3.584563970565796,
      "learning_rate": 2.863391193488281e-05,
      "logits/chosen": 3.4821746349334717,
      "logits/rejected": 3.5300698280334473,
      "logps/chosen": -395.0378723144531,
      "logps/rejected": -365.0002746582031,
      "loss": 0.3599,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.5902514457702637,
      "rewards/margins": 3.2618682384490967,
      "rewards/rejected": -5.852120399475098,
      "step": 21800
    },
    {
      "epoch": 1.2838692595098702,
      "grad_norm": 0.6832207441329956,
      "learning_rate": 2.8614298323036187e-05,
      "logits/chosen": 3.417280673980713,
      "logits/rejected": 3.352113723754883,
      "logps/chosen": -368.36474609375,
      "logps/rejected": -298.44793701171875,
      "loss": 0.2082,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.4674744606018066,
      "rewards/margins": 3.2494475841522217,
      "rewards/rejected": -5.716921806335449,
      "step": 21820
    },
    {
      "epoch": 1.2850460415992468,
      "grad_norm": 0.8690662980079651,
      "learning_rate": 2.8594684711189566e-05,
      "logits/chosen": 3.3392529487609863,
      "logits/rejected": 3.2167563438415527,
      "logps/chosen": -405.1305847167969,
      "logps/rejected": -340.2429504394531,
      "loss": 0.2846,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -3.00380277633667,
      "rewards/margins": 3.984804153442383,
      "rewards/rejected": -6.988607883453369,
      "step": 21840
    },
    {
      "epoch": 1.2862228236886235,
      "grad_norm": 9.037052154541016,
      "learning_rate": 2.8575071099342942e-05,
      "logits/chosen": 3.3997013568878174,
      "logits/rejected": 3.4133827686309814,
      "logps/chosen": -406.3501892089844,
      "logps/rejected": -336.2084045410156,
      "loss": 0.261,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.7366607189178467,
      "rewards/margins": 3.5739383697509766,
      "rewards/rejected": -5.310599327087402,
      "step": 21860
    },
    {
      "epoch": 1.287399605778,
      "grad_norm": 3.8829843997955322,
      "learning_rate": 2.855545748749632e-05,
      "logits/chosen": 3.2832343578338623,
      "logits/rejected": 3.4330646991729736,
      "logps/chosen": -378.1278076171875,
      "logps/rejected": -355.3215637207031,
      "loss": 0.3172,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.5213851928710938,
      "rewards/margins": 3.8357250690460205,
      "rewards/rejected": -6.357110500335693,
      "step": 21880
    },
    {
      "epoch": 1.2885763878673766,
      "grad_norm": 2.7983522415161133,
      "learning_rate": 2.8535843875649704e-05,
      "logits/chosen": 3.873833417892456,
      "logits/rejected": 3.7669596672058105,
      "logps/chosen": -366.1053161621094,
      "logps/rejected": -326.7012939453125,
      "loss": 0.2827,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.2589664459228516,
      "rewards/margins": 3.654646396636963,
      "rewards/rejected": -5.913612365722656,
      "step": 21900
    },
    {
      "epoch": 1.2897531699567533,
      "grad_norm": 0.7766930460929871,
      "learning_rate": 2.8516230263803077e-05,
      "logits/chosen": 3.3422341346740723,
      "logits/rejected": 3.3760921955108643,
      "logps/chosen": -389.0615539550781,
      "logps/rejected": -343.325439453125,
      "loss": 0.2934,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0427863597869873,
      "rewards/margins": 4.05021333694458,
      "rewards/rejected": -6.092999458312988,
      "step": 21920
    },
    {
      "epoch": 1.29092995204613,
      "grad_norm": 1.7618465423583984,
      "learning_rate": 2.849661665195646e-05,
      "logits/chosen": 3.992341995239258,
      "logits/rejected": 3.777353286743164,
      "logps/chosen": -447.8998107910156,
      "logps/rejected": -372.9640197753906,
      "loss": 0.2357,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.524780750274658,
      "rewards/margins": 3.498633623123169,
      "rewards/rejected": -6.02341365814209,
      "step": 21940
    },
    {
      "epoch": 1.2921067341355066,
      "grad_norm": 1.9077657461166382,
      "learning_rate": 2.847700304010984e-05,
      "logits/chosen": 3.048051118850708,
      "logits/rejected": 3.1937642097473145,
      "logps/chosen": -309.4759521484375,
      "logps/rejected": -314.06475830078125,
      "loss": 0.4168,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.763453483581543,
      "rewards/margins": 3.2369213104248047,
      "rewards/rejected": -6.000375270843506,
      "step": 21960
    },
    {
      "epoch": 1.293283516224883,
      "grad_norm": 3.843337059020996,
      "learning_rate": 2.8457389428263215e-05,
      "logits/chosen": 3.6775145530700684,
      "logits/rejected": 3.6746063232421875,
      "logps/chosen": -351.0731506347656,
      "logps/rejected": -326.3158264160156,
      "loss": 0.2742,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1846768856048584,
      "rewards/margins": 3.702857494354248,
      "rewards/rejected": -5.887534141540527,
      "step": 21980
    },
    {
      "epoch": 1.2944602983142597,
      "grad_norm": 0.5747985243797302,
      "learning_rate": 2.8437775816416595e-05,
      "logits/chosen": 3.612635850906372,
      "logits/rejected": 3.5732319355010986,
      "logps/chosen": -440.8837890625,
      "logps/rejected": -378.32513427734375,
      "loss": 0.2618,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.077155590057373,
      "rewards/margins": 4.78659725189209,
      "rewards/rejected": -6.863752841949463,
      "step": 22000
    },
    {
      "epoch": 1.2956370804036363,
      "grad_norm": 1.4873883724212646,
      "learning_rate": 2.841816220456997e-05,
      "logits/chosen": 3.490807056427002,
      "logits/rejected": 3.5211682319641113,
      "logps/chosen": -409.6170349121094,
      "logps/rejected": -324.2212829589844,
      "loss": 0.4186,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.702423095703125,
      "rewards/margins": 3.1760220527648926,
      "rewards/rejected": -5.878444671630859,
      "step": 22020
    },
    {
      "epoch": 1.2968138624930128,
      "grad_norm": 1.3726756572723389,
      "learning_rate": 2.839854859272335e-05,
      "logits/chosen": 3.5818533897399902,
      "logits/rejected": 3.564044952392578,
      "logps/chosen": -392.014892578125,
      "logps/rejected": -289.9269104003906,
      "loss": 0.345,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.099550485610962,
      "rewards/margins": 3.7309508323669434,
      "rewards/rejected": -5.830501079559326,
      "step": 22040
    },
    {
      "epoch": 1.2979906445823894,
      "grad_norm": 0.641658365726471,
      "learning_rate": 2.837893498087673e-05,
      "logits/chosen": 3.8864974975585938,
      "logits/rejected": 3.9046988487243652,
      "logps/chosen": -383.68353271484375,
      "logps/rejected": -340.5440979003906,
      "loss": 0.2715,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.3515108823776245,
      "rewards/margins": 4.014352321624756,
      "rewards/rejected": -5.36586332321167,
      "step": 22060
    },
    {
      "epoch": 1.299167426671766,
      "grad_norm": 1.212309718132019,
      "learning_rate": 2.8359321369030106e-05,
      "logits/chosen": 3.6761550903320312,
      "logits/rejected": 3.7265422344207764,
      "logps/chosen": -377.51165771484375,
      "logps/rejected": -343.9664611816406,
      "loss": 0.2232,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.2639042139053345,
      "rewards/margins": 4.17519998550415,
      "rewards/rejected": -5.4391045570373535,
      "step": 22080
    },
    {
      "epoch": 1.3003442087611425,
      "grad_norm": 2.6464123725891113,
      "learning_rate": 2.833970775718349e-05,
      "logits/chosen": 4.234219551086426,
      "logits/rejected": 4.128445625305176,
      "logps/chosen": -453.4071350097656,
      "logps/rejected": -367.9202880859375,
      "loss": 0.2258,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.9847967624664307,
      "rewards/margins": 3.7403995990753174,
      "rewards/rejected": -5.725196361541748,
      "step": 22100
    },
    {
      "epoch": 1.3015209908505192,
      "grad_norm": 2.238682746887207,
      "learning_rate": 2.8320094145336868e-05,
      "logits/chosen": 3.6116974353790283,
      "logits/rejected": 3.670177936553955,
      "logps/chosen": -365.11688232421875,
      "logps/rejected": -355.782470703125,
      "loss": 0.2501,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9446643590927124,
      "rewards/margins": 3.606621503829956,
      "rewards/rejected": -5.551285743713379,
      "step": 22120
    },
    {
      "epoch": 1.3026977729398959,
      "grad_norm": 2.1465697288513184,
      "learning_rate": 2.8300480533490244e-05,
      "logits/chosen": 3.6179699897766113,
      "logits/rejected": 3.561349391937256,
      "logps/chosen": -384.0314025878906,
      "logps/rejected": -348.42236328125,
      "loss": 0.2371,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.3485996723175049,
      "rewards/margins": 4.0965728759765625,
      "rewards/rejected": -5.445172309875488,
      "step": 22140
    },
    {
      "epoch": 1.3038745550292725,
      "grad_norm": 0.35378196835517883,
      "learning_rate": 2.8280866921643623e-05,
      "logits/chosen": 3.9845638275146484,
      "logits/rejected": 3.977154493331909,
      "logps/chosen": -395.7080078125,
      "logps/rejected": -349.910888671875,
      "loss": 0.2698,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.8884063959121704,
      "rewards/margins": 3.9092323780059814,
      "rewards/rejected": -5.797638893127441,
      "step": 22160
    },
    {
      "epoch": 1.3050513371186492,
      "grad_norm": 3.153348922729492,
      "learning_rate": 2.8261253309797e-05,
      "logits/chosen": 3.827488422393799,
      "logits/rejected": 3.6351096630096436,
      "logps/chosen": -368.14208984375,
      "logps/rejected": -288.1723327636719,
      "loss": 0.2907,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5298378467559814,
      "rewards/margins": 2.8720688819885254,
      "rewards/rejected": -4.401906490325928,
      "step": 22180
    },
    {
      "epoch": 1.3062281192080256,
      "grad_norm": 0.21092131733894348,
      "learning_rate": 2.824163969795038e-05,
      "logits/chosen": 3.7906131744384766,
      "logits/rejected": 3.658924102783203,
      "logps/chosen": -386.48504638671875,
      "logps/rejected": -296.413818359375,
      "loss": 0.2776,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1238367557525635,
      "rewards/margins": 4.365964889526367,
      "rewards/rejected": -5.48980188369751,
      "step": 22200
    },
    {
      "epoch": 1.3074049012974023,
      "grad_norm": 0.2701422870159149,
      "learning_rate": 2.8222026086103758e-05,
      "logits/chosen": 3.9463703632354736,
      "logits/rejected": 3.9075992107391357,
      "logps/chosen": -437.74688720703125,
      "logps/rejected": -369.0453186035156,
      "loss": 0.1957,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.345566987991333,
      "rewards/margins": 4.311646461486816,
      "rewards/rejected": -5.65721321105957,
      "step": 22220
    },
    {
      "epoch": 1.308581683386779,
      "grad_norm": 0.217336043715477,
      "learning_rate": 2.8203393154849467e-05,
      "logits/chosen": 3.5768980979919434,
      "logits/rejected": 3.5041298866271973,
      "logps/chosen": -410.13330078125,
      "logps/rejected": -329.49102783203125,
      "loss": 0.3319,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8798316717147827,
      "rewards/margins": 3.562425136566162,
      "rewards/rejected": -5.442256450653076,
      "step": 22240
    },
    {
      "epoch": 1.3097584654761554,
      "grad_norm": 2.015997886657715,
      "learning_rate": 2.8183779543002846e-05,
      "logits/chosen": 3.7448010444641113,
      "logits/rejected": 3.872257709503174,
      "logps/chosen": -360.273681640625,
      "logps/rejected": -342.991943359375,
      "loss": 0.2047,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.120995283126831,
      "rewards/margins": 3.8564934730529785,
      "rewards/rejected": -5.9774885177612305,
      "step": 22260
    },
    {
      "epoch": 1.310935247565532,
      "grad_norm": 2.69869065284729,
      "learning_rate": 2.8164165931156222e-05,
      "logits/chosen": 3.8559346199035645,
      "logits/rejected": 3.709300994873047,
      "logps/chosen": -376.25592041015625,
      "logps/rejected": -284.72503662109375,
      "loss": 0.3376,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.7457516193389893,
      "rewards/margins": 3.4872641563415527,
      "rewards/rejected": -5.233016014099121,
      "step": 22280
    },
    {
      "epoch": 1.3121120296549087,
      "grad_norm": 2.4370179176330566,
      "learning_rate": 2.8144552319309602e-05,
      "logits/chosen": 3.976781129837036,
      "logits/rejected": 3.9424972534179688,
      "logps/chosen": -437.9657287597656,
      "logps/rejected": -373.8670959472656,
      "loss": 0.5279,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.1309001445770264,
      "rewards/margins": 3.176502227783203,
      "rewards/rejected": -5.30740213394165,
      "step": 22300
    },
    {
      "epoch": 1.3132888117442851,
      "grad_norm": 2.044059991836548,
      "learning_rate": 2.8124938707462985e-05,
      "logits/chosen": 3.938336133956909,
      "logits/rejected": 3.7499756813049316,
      "logps/chosen": -436.62164306640625,
      "logps/rejected": -334.7713928222656,
      "loss": 0.2249,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7828312516212463,
      "rewards/margins": 4.154187202453613,
      "rewards/rejected": -4.937018394470215,
      "step": 22320
    },
    {
      "epoch": 1.3144655938336618,
      "grad_norm": 3.184321880340576,
      "learning_rate": 2.8105325095616357e-05,
      "logits/chosen": 3.6871280670166016,
      "logits/rejected": 3.787015438079834,
      "logps/chosen": -398.49078369140625,
      "logps/rejected": -357.6416015625,
      "loss": 0.2801,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5996174812316895,
      "rewards/margins": 4.288847923278809,
      "rewards/rejected": -5.888465881347656,
      "step": 22340
    },
    {
      "epoch": 1.3156423759230385,
      "grad_norm": 0.5544073581695557,
      "learning_rate": 2.808571148376974e-05,
      "logits/chosen": 3.8672499656677246,
      "logits/rejected": 3.927441120147705,
      "logps/chosen": -383.8280334472656,
      "logps/rejected": -305.6075744628906,
      "loss": 0.3407,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.548545479774475,
      "rewards/margins": 3.583590269088745,
      "rewards/rejected": -5.13213586807251,
      "step": 22360
    },
    {
      "epoch": 1.3168191580124151,
      "grad_norm": 1.9091863632202148,
      "learning_rate": 2.8066097871923113e-05,
      "logits/chosen": 3.81769061088562,
      "logits/rejected": 3.7771706581115723,
      "logps/chosen": -372.8543701171875,
      "logps/rejected": -339.45440673828125,
      "loss": 0.2559,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3396499156951904,
      "rewards/margins": 3.9451522827148438,
      "rewards/rejected": -5.284802436828613,
      "step": 22380
    },
    {
      "epoch": 1.3179959401017918,
      "grad_norm": 2.7719204425811768,
      "learning_rate": 2.8046484260076496e-05,
      "logits/chosen": 3.7552711963653564,
      "logits/rejected": 3.7730941772460938,
      "logps/chosen": -385.2833251953125,
      "logps/rejected": -356.48980712890625,
      "loss": 0.3689,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6433045864105225,
      "rewards/margins": 2.940913677215576,
      "rewards/rejected": -4.5842180252075195,
      "step": 22400
    },
    {
      "epoch": 1.3191727221911682,
      "grad_norm": 2.633396863937378,
      "learning_rate": 2.8026870648229875e-05,
      "logits/chosen": 3.983065366744995,
      "logits/rejected": 3.948046922683716,
      "logps/chosen": -378.2624206542969,
      "logps/rejected": -375.0679931640625,
      "loss": 0.3259,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.028188705444336,
      "rewards/margins": 3.5860953330993652,
      "rewards/rejected": -5.614284038543701,
      "step": 22420
    },
    {
      "epoch": 1.3203495042805449,
      "grad_norm": 5.502708911895752,
      "learning_rate": 2.800725703638325e-05,
      "logits/chosen": 4.288970470428467,
      "logits/rejected": 4.049319267272949,
      "logps/chosen": -442.94775390625,
      "logps/rejected": -381.43511962890625,
      "loss": 0.2142,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.7665306329727173,
      "rewards/margins": 4.659337043762207,
      "rewards/rejected": -6.425866603851318,
      "step": 22440
    },
    {
      "epoch": 1.3215262863699215,
      "grad_norm": 2.1129798889160156,
      "learning_rate": 2.798764342453663e-05,
      "logits/chosen": 3.700366497039795,
      "logits/rejected": 3.563356876373291,
      "logps/chosen": -383.13726806640625,
      "logps/rejected": -328.0420227050781,
      "loss": 0.2454,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.82952082157135,
      "rewards/margins": 3.8310394287109375,
      "rewards/rejected": -5.6605610847473145,
      "step": 22460
    },
    {
      "epoch": 1.322703068459298,
      "grad_norm": 3.8326878547668457,
      "learning_rate": 2.796802981269001e-05,
      "logits/chosen": 3.4857306480407715,
      "logits/rejected": 3.3980395793914795,
      "logps/chosen": -376.15716552734375,
      "logps/rejected": -305.45159912109375,
      "loss": 0.3066,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.302337169647217,
      "rewards/margins": 3.3853042125701904,
      "rewards/rejected": -5.687641143798828,
      "step": 22480
    },
    {
      "epoch": 1.3238798505486746,
      "grad_norm": 4.225225925445557,
      "learning_rate": 2.7948416200843386e-05,
      "logits/chosen": 3.944103956222534,
      "logits/rejected": 3.91033673286438,
      "logps/chosen": -411.1356506347656,
      "logps/rejected": -338.0338439941406,
      "loss": 0.2333,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.281782627105713,
      "rewards/margins": 4.056063652038574,
      "rewards/rejected": -6.337846279144287,
      "step": 22500
    },
    {
      "epoch": 1.3250566326380513,
      "grad_norm": 3.0676515102386475,
      "learning_rate": 2.7928802588996765e-05,
      "logits/chosen": 3.764066219329834,
      "logits/rejected": 3.7203736305236816,
      "logps/chosen": -409.526611328125,
      "logps/rejected": -359.12677001953125,
      "loss": 0.2532,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9922029972076416,
      "rewards/margins": 4.154384136199951,
      "rewards/rejected": -6.146587371826172,
      "step": 22520
    },
    {
      "epoch": 1.3262334147274277,
      "grad_norm": 0.2446245700120926,
      "learning_rate": 2.790918897715014e-05,
      "logits/chosen": 3.5189623832702637,
      "logits/rejected": 3.600806713104248,
      "logps/chosen": -377.1900634765625,
      "logps/rejected": -358.48834228515625,
      "loss": 0.4546,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.7984554767608643,
      "rewards/margins": 2.959725856781006,
      "rewards/rejected": -5.758181571960449,
      "step": 22540
    },
    {
      "epoch": 1.3274101968168044,
      "grad_norm": 3.916243553161621,
      "learning_rate": 2.788957536530352e-05,
      "logits/chosen": 3.3094100952148438,
      "logits/rejected": 3.3260459899902344,
      "logps/chosen": -366.0016174316406,
      "logps/rejected": -334.3739929199219,
      "loss": 0.386,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.334094762802124,
      "rewards/margins": 3.2307167053222656,
      "rewards/rejected": -5.5648112297058105,
      "step": 22560
    },
    {
      "epoch": 1.328586978906181,
      "grad_norm": 0.17742811143398285,
      "learning_rate": 2.7869961753456904e-05,
      "logits/chosen": 3.7603180408477783,
      "logits/rejected": 3.847170352935791,
      "logps/chosen": -413.52008056640625,
      "logps/rejected": -371.112060546875,
      "loss": 0.4308,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.2347874641418457,
      "rewards/margins": 3.899440288543701,
      "rewards/rejected": -6.134228229522705,
      "step": 22580
    },
    {
      "epoch": 1.3297637609955577,
      "grad_norm": 0.512808620929718,
      "learning_rate": 2.7850348141610276e-05,
      "logits/chosen": 3.411245346069336,
      "logits/rejected": 3.4144415855407715,
      "logps/chosen": -386.59417724609375,
      "logps/rejected": -295.3719482421875,
      "loss": 0.3221,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9570763111114502,
      "rewards/margins": 2.8230974674224854,
      "rewards/rejected": -4.780173301696777,
      "step": 22600
    },
    {
      "epoch": 1.3309405430849344,
      "grad_norm": 3.3848800659179688,
      "learning_rate": 2.783073452976366e-05,
      "logits/chosen": 3.7955689430236816,
      "logits/rejected": 3.7716732025146484,
      "logps/chosen": -389.79522705078125,
      "logps/rejected": -317.6775817871094,
      "loss": 0.2276,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8872095346450806,
      "rewards/margins": 4.648594379425049,
      "rewards/rejected": -6.535803318023682,
      "step": 22620
    },
    {
      "epoch": 1.3321173251743108,
      "grad_norm": 0.3678276836872101,
      "learning_rate": 2.781112091791704e-05,
      "logits/chosen": 3.8144760131835938,
      "logits/rejected": 3.692739486694336,
      "logps/chosen": -388.13934326171875,
      "logps/rejected": -306.6107177734375,
      "loss": 0.4233,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.9975311756134033,
      "rewards/margins": 3.552760362625122,
      "rewards/rejected": -5.550291538238525,
      "step": 22640
    },
    {
      "epoch": 1.3332941072636875,
      "grad_norm": 1.1554737091064453,
      "learning_rate": 2.7791507306070415e-05,
      "logits/chosen": 3.5643222332000732,
      "logits/rejected": 3.7154335975646973,
      "logps/chosen": -350.61279296875,
      "logps/rejected": -311.27301025390625,
      "loss": 0.2873,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.9228603839874268,
      "rewards/margins": 3.0102107524871826,
      "rewards/rejected": -4.933071136474609,
      "step": 22660
    },
    {
      "epoch": 1.3344708893530641,
      "grad_norm": 2.2467997074127197,
      "learning_rate": 2.7771893694223794e-05,
      "logits/chosen": 3.8264174461364746,
      "logits/rejected": 3.5733611583709717,
      "logps/chosen": -386.9810485839844,
      "logps/rejected": -312.29345703125,
      "loss": 0.3897,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.946028709411621,
      "rewards/margins": 2.9453628063201904,
      "rewards/rejected": -4.891391754150391,
      "step": 22680
    },
    {
      "epoch": 1.3356476714424406,
      "grad_norm": 3.785792827606201,
      "learning_rate": 2.775228008237717e-05,
      "logits/chosen": 3.693485975265503,
      "logits/rejected": 3.6731085777282715,
      "logps/chosen": -377.97332763671875,
      "logps/rejected": -350.235595703125,
      "loss": 0.2886,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.3791066408157349,
      "rewards/margins": 4.160915374755859,
      "rewards/rejected": -5.5400214195251465,
      "step": 22700
    },
    {
      "epoch": 1.3368244535318172,
      "grad_norm": 4.6689019203186035,
      "learning_rate": 2.773266647053055e-05,
      "logits/chosen": 3.7313218116760254,
      "logits/rejected": 3.631617784500122,
      "logps/chosen": -342.81109619140625,
      "logps/rejected": -325.47784423828125,
      "loss": 0.3433,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6841281652450562,
      "rewards/margins": 3.459913730621338,
      "rewards/rejected": -5.144042015075684,
      "step": 22720
    },
    {
      "epoch": 1.3380012356211939,
      "grad_norm": 4.146289348602295,
      "learning_rate": 2.771305285868393e-05,
      "logits/chosen": 3.76861310005188,
      "logits/rejected": 3.5581002235412598,
      "logps/chosen": -367.03717041015625,
      "logps/rejected": -323.95159912109375,
      "loss": 0.3578,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1013236045837402,
      "rewards/margins": 3.241847276687622,
      "rewards/rejected": -5.343171119689941,
      "step": 22740
    },
    {
      "epoch": 1.3391780177105703,
      "grad_norm": 1.368634819984436,
      "learning_rate": 2.7693439246837305e-05,
      "logits/chosen": 3.563079833984375,
      "logits/rejected": 3.489968776702881,
      "logps/chosen": -365.16827392578125,
      "logps/rejected": -327.9888916015625,
      "loss": 0.3546,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.133319616317749,
      "rewards/margins": 4.029733657836914,
      "rewards/rejected": -6.163053035736084,
      "step": 22760
    },
    {
      "epoch": 1.340354799799947,
      "grad_norm": 4.506606578826904,
      "learning_rate": 2.7673825634990684e-05,
      "logits/chosen": 4.083468437194824,
      "logits/rejected": 3.8968682289123535,
      "logps/chosen": -422.4996643066406,
      "logps/rejected": -331.86920166015625,
      "loss": 0.2723,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.382759928703308,
      "rewards/margins": 4.549376487731934,
      "rewards/rejected": -5.932136535644531,
      "step": 22780
    },
    {
      "epoch": 1.3415315818893236,
      "grad_norm": 34.97275161743164,
      "learning_rate": 2.7654212023144067e-05,
      "logits/chosen": 3.9473319053649902,
      "logits/rejected": 3.6826834678649902,
      "logps/chosen": -452.02410888671875,
      "logps/rejected": -355.6296081542969,
      "loss": 0.4197,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.5216386318206787,
      "rewards/margins": 3.833073854446411,
      "rewards/rejected": -5.35471248626709,
      "step": 22800
    },
    {
      "epoch": 1.3427083639787003,
      "grad_norm": 1.1167943477630615,
      "learning_rate": 2.763459841129744e-05,
      "logits/chosen": 4.046476364135742,
      "logits/rejected": 3.8695082664489746,
      "logps/chosen": -353.549072265625,
      "logps/rejected": -304.3454284667969,
      "loss": 0.4457,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4629262685775757,
      "rewards/margins": 3.122421979904175,
      "rewards/rejected": -4.585348129272461,
      "step": 22820
    },
    {
      "epoch": 1.343885146068077,
      "grad_norm": 0.733797550201416,
      "learning_rate": 2.7614984799450823e-05,
      "logits/chosen": 3.6967926025390625,
      "logits/rejected": 3.5725836753845215,
      "logps/chosen": -377.9847106933594,
      "logps/rejected": -333.8423767089844,
      "loss": 0.2489,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.9203407764434814,
      "rewards/margins": 3.569671630859375,
      "rewards/rejected": -5.490012168884277,
      "step": 22840
    },
    {
      "epoch": 1.3450619281574534,
      "grad_norm": 0.14748527109622955,
      "learning_rate": 2.7595371187604195e-05,
      "logits/chosen": 3.5128085613250732,
      "logits/rejected": 3.5229620933532715,
      "logps/chosen": -383.2243347167969,
      "logps/rejected": -297.282470703125,
      "loss": 0.3175,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.66902756690979,
      "rewards/margins": 2.7590363025665283,
      "rewards/rejected": -4.428063869476318,
      "step": 22860
    },
    {
      "epoch": 1.34623871024683,
      "grad_norm": 7.421146869659424,
      "learning_rate": 2.7575757575757578e-05,
      "logits/chosen": 4.176254749298096,
      "logits/rejected": 4.0215744972229,
      "logps/chosen": -417.63885498046875,
      "logps/rejected": -353.23150634765625,
      "loss": 0.4241,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9301464557647705,
      "rewards/margins": 3.3185863494873047,
      "rewards/rejected": -5.248733043670654,
      "step": 22880
    },
    {
      "epoch": 1.3474154923362067,
      "grad_norm": 7.851537704467773,
      "learning_rate": 2.7556143963910957e-05,
      "logits/chosen": 3.706015110015869,
      "logits/rejected": 3.7115142345428467,
      "logps/chosen": -410.4300231933594,
      "logps/rejected": -383.78704833984375,
      "loss": 0.3629,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.624837875366211,
      "rewards/margins": 4.047957420349121,
      "rewards/rejected": -5.672795295715332,
      "step": 22900
    },
    {
      "epoch": 1.3485922744255832,
      "grad_norm": 1.7702804803848267,
      "learning_rate": 2.7536530352064334e-05,
      "logits/chosen": 3.7171998023986816,
      "logits/rejected": 3.6590676307678223,
      "logps/chosen": -415.5399475097656,
      "logps/rejected": -329.4067687988281,
      "loss": 0.3496,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6078888177871704,
      "rewards/margins": 3.714578628540039,
      "rewards/rejected": -5.322467803955078,
      "step": 22920
    },
    {
      "epoch": 1.3497690565149598,
      "grad_norm": 0.9574561715126038,
      "learning_rate": 2.7516916740217713e-05,
      "logits/chosen": 3.7435965538024902,
      "logits/rejected": 3.573486804962158,
      "logps/chosen": -338.4632873535156,
      "logps/rejected": -325.06494140625,
      "loss": 0.3085,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8649237155914307,
      "rewards/margins": 3.347853899002075,
      "rewards/rejected": -5.212777614593506,
      "step": 22940
    },
    {
      "epoch": 1.3509458386043365,
      "grad_norm": 2.849040985107422,
      "learning_rate": 2.7497303128371092e-05,
      "logits/chosen": 3.604506015777588,
      "logits/rejected": 3.600801467895508,
      "logps/chosen": -323.44805908203125,
      "logps/rejected": -337.60748291015625,
      "loss": 0.482,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.0793657302856445,
      "rewards/margins": 2.7548770904541016,
      "rewards/rejected": -4.834243297576904,
      "step": 22960
    },
    {
      "epoch": 1.352122620693713,
      "grad_norm": 1.171265959739685,
      "learning_rate": 2.747768951652447e-05,
      "logits/chosen": 3.765101671218872,
      "logits/rejected": 3.5696449279785156,
      "logps/chosen": -432.516357421875,
      "logps/rejected": -322.3564147949219,
      "loss": 0.2356,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8950364589691162,
      "rewards/margins": 4.114807605743408,
      "rewards/rejected": -6.0098443031311035,
      "step": 22980
    },
    {
      "epoch": 1.3532994027830896,
      "grad_norm": 4.776363849639893,
      "learning_rate": 2.7458075904677848e-05,
      "logits/chosen": 3.59724760055542,
      "logits/rejected": 3.7039425373077393,
      "logps/chosen": -353.2226257324219,
      "logps/rejected": -308.3240966796875,
      "loss": 0.4272,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.278445243835449,
      "rewards/margins": 3.235966444015503,
      "rewards/rejected": -5.514411449432373,
      "step": 23000
    },
    {
      "epoch": 1.3544761848724662,
      "grad_norm": 3.56423282623291,
      "learning_rate": 2.7438462292831224e-05,
      "logits/chosen": 3.5803349018096924,
      "logits/rejected": 3.4050087928771973,
      "logps/chosen": -348.760009765625,
      "logps/rejected": -272.1148986816406,
      "loss": 0.4107,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8450294733047485,
      "rewards/margins": 3.3917136192321777,
      "rewards/rejected": -5.236742973327637,
      "step": 23020
    },
    {
      "epoch": 1.355652966961843,
      "grad_norm": 1.0832523107528687,
      "learning_rate": 2.7418848680984603e-05,
      "logits/chosen": 3.80214262008667,
      "logits/rejected": 3.6724350452423096,
      "logps/chosen": -365.553466796875,
      "logps/rejected": -370.73419189453125,
      "loss": 0.3225,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.2932274341583252,
      "rewards/margins": 3.709508180618286,
      "rewards/rejected": -5.002735614776611,
      "step": 23040
    },
    {
      "epoch": 1.3568297490512196,
      "grad_norm": 1.610068917274475,
      "learning_rate": 2.7399235069137986e-05,
      "logits/chosen": 3.826014280319214,
      "logits/rejected": 3.8597404956817627,
      "logps/chosen": -379.6768798828125,
      "logps/rejected": -346.85894775390625,
      "loss": 0.3211,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4906795024871826,
      "rewards/margins": 3.5289485454559326,
      "rewards/rejected": -5.019628047943115,
      "step": 23060
    },
    {
      "epoch": 1.358006531140596,
      "grad_norm": 0.17850908637046814,
      "learning_rate": 2.737962145729136e-05,
      "logits/chosen": 3.657474994659424,
      "logits/rejected": 3.7875983715057373,
      "logps/chosen": -376.0342102050781,
      "logps/rejected": -335.2901611328125,
      "loss": 0.2366,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.5007299184799194,
      "rewards/margins": 3.9073798656463623,
      "rewards/rejected": -5.408109664916992,
      "step": 23080
    },
    {
      "epoch": 1.3591833132299727,
      "grad_norm": 4.6650896072387695,
      "learning_rate": 2.736000784544474e-05,
      "logits/chosen": 3.659741163253784,
      "logits/rejected": 3.701237916946411,
      "logps/chosen": -377.13055419921875,
      "logps/rejected": -314.6263427734375,
      "loss": 0.2722,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6067308187484741,
      "rewards/margins": 3.186703681945801,
      "rewards/rejected": -4.793435096740723,
      "step": 23100
    },
    {
      "epoch": 1.3603600953193493,
      "grad_norm": 2.3221521377563477,
      "learning_rate": 2.734039423359812e-05,
      "logits/chosen": 3.6304211616516113,
      "logits/rejected": 3.572099208831787,
      "logps/chosen": -374.44720458984375,
      "logps/rejected": -316.78515625,
      "loss": 0.3311,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.198216438293457,
      "rewards/margins": 3.606975555419922,
      "rewards/rejected": -4.805192470550537,
      "step": 23120
    },
    {
      "epoch": 1.3615368774087258,
      "grad_norm": 1.302445411682129,
      "learning_rate": 2.7320780621751497e-05,
      "logits/chosen": 3.9541823863983154,
      "logits/rejected": 3.8741931915283203,
      "logps/chosen": -455.896484375,
      "logps/rejected": -343.8601379394531,
      "loss": 0.3499,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.3786243200302124,
      "rewards/margins": 3.5580544471740723,
      "rewards/rejected": -4.936678886413574,
      "step": 23140
    },
    {
      "epoch": 1.3627136594981024,
      "grad_norm": 5.630150318145752,
      "learning_rate": 2.7301167009904876e-05,
      "logits/chosen": 3.418213367462158,
      "logits/rejected": 3.58967924118042,
      "logps/chosen": -442.9942932128906,
      "logps/rejected": -364.03985595703125,
      "loss": 0.419,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.14736008644104,
      "rewards/margins": 3.6458194255828857,
      "rewards/rejected": -4.793179035186768,
      "step": 23160
    },
    {
      "epoch": 1.363890441587479,
      "grad_norm": 2.7193570137023926,
      "learning_rate": 2.7281553398058253e-05,
      "logits/chosen": 3.5290920734405518,
      "logits/rejected": 3.563716173171997,
      "logps/chosen": -354.9506530761719,
      "logps/rejected": -310.0555114746094,
      "loss": 0.3482,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5950202941894531,
      "rewards/margins": 3.3661017417907715,
      "rewards/rejected": -4.961122035980225,
      "step": 23180
    },
    {
      "epoch": 1.3650672236768555,
      "grad_norm": 0.9788419604301453,
      "learning_rate": 2.7261939786211632e-05,
      "logits/chosen": 3.859370470046997,
      "logits/rejected": 3.9227371215820312,
      "logps/chosen": -365.5707092285156,
      "logps/rejected": -347.1041259765625,
      "loss": 0.2281,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.9869565963745117,
      "rewards/margins": 3.8475708961486816,
      "rewards/rejected": -5.834527969360352,
      "step": 23200
    },
    {
      "epoch": 1.3662440057662322,
      "grad_norm": 4.937718391418457,
      "learning_rate": 2.724232617436501e-05,
      "logits/chosen": 3.890437364578247,
      "logits/rejected": 3.8827011585235596,
      "logps/chosen": -418.05718994140625,
      "logps/rejected": -356.72210693359375,
      "loss": 0.4207,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.955359697341919,
      "rewards/margins": 3.056532621383667,
      "rewards/rejected": -5.011892795562744,
      "step": 23220
    },
    {
      "epoch": 1.3674207878556088,
      "grad_norm": 0.018495725467801094,
      "learning_rate": 2.7222712562518387e-05,
      "logits/chosen": 3.85978364944458,
      "logits/rejected": 3.9140853881835938,
      "logps/chosen": -377.8957214355469,
      "logps/rejected": -328.5411376953125,
      "loss": 0.3043,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.244786024093628,
      "rewards/margins": 3.5153145790100098,
      "rewards/rejected": -4.760100364685059,
      "step": 23240
    },
    {
      "epoch": 1.3685975699449855,
      "grad_norm": 0.6937834024429321,
      "learning_rate": 2.7203098950671767e-05,
      "logits/chosen": 3.8493614196777344,
      "logits/rejected": 3.920931339263916,
      "logps/chosen": -422.35906982421875,
      "logps/rejected": -366.79193115234375,
      "loss": 0.2856,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.8145942687988281,
      "rewards/margins": 3.8043487071990967,
      "rewards/rejected": -5.618943214416504,
      "step": 23260
    },
    {
      "epoch": 1.3697743520343622,
      "grad_norm": 0.8751033544540405,
      "learning_rate": 2.718348533882515e-05,
      "logits/chosen": 3.5760655403137207,
      "logits/rejected": 3.5529675483703613,
      "logps/chosen": -327.9700622558594,
      "logps/rejected": -324.01422119140625,
      "loss": 0.3092,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0944230556488037,
      "rewards/margins": 2.8906283378601074,
      "rewards/rejected": -4.98505163192749,
      "step": 23280
    },
    {
      "epoch": 1.3709511341237386,
      "grad_norm": 3.5706331729888916,
      "learning_rate": 2.7163871726978522e-05,
      "logits/chosen": 3.451136350631714,
      "logits/rejected": 3.5248959064483643,
      "logps/chosen": -371.70391845703125,
      "logps/rejected": -330.22607421875,
      "loss": 0.3688,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7876136302947998,
      "rewards/margins": 4.185240745544434,
      "rewards/rejected": -5.972855091094971,
      "step": 23300
    },
    {
      "epoch": 1.3721279162131153,
      "grad_norm": 4.013345718383789,
      "learning_rate": 2.7144258115131905e-05,
      "logits/chosen": 3.670290470123291,
      "logits/rejected": 3.6725471019744873,
      "logps/chosen": -376.0684814453125,
      "logps/rejected": -276.86944580078125,
      "loss": 0.2948,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0140795707702637,
      "rewards/margins": 3.691920518875122,
      "rewards/rejected": -5.706000328063965,
      "step": 23320
    },
    {
      "epoch": 1.373304698302492,
      "grad_norm": 0.4760132431983948,
      "learning_rate": 2.7124644503285278e-05,
      "logits/chosen": 3.650857925415039,
      "logits/rejected": 3.6019577980041504,
      "logps/chosen": -395.0940856933594,
      "logps/rejected": -373.55792236328125,
      "loss": 0.2555,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9200233221054077,
      "rewards/margins": 3.632896900177002,
      "rewards/rejected": -5.552919864654541,
      "step": 23340
    },
    {
      "epoch": 1.3744814803918683,
      "grad_norm": 1.4491676092147827,
      "learning_rate": 2.710503089143866e-05,
      "logits/chosen": 3.4827752113342285,
      "logits/rejected": 3.5593483448028564,
      "logps/chosen": -369.34991455078125,
      "logps/rejected": -329.65667724609375,
      "loss": 0.2571,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.08530592918396,
      "rewards/margins": 3.0123040676116943,
      "rewards/rejected": -5.097609519958496,
      "step": 23360
    },
    {
      "epoch": 1.375658262481245,
      "grad_norm": 10.626690864562988,
      "learning_rate": 2.708541727959204e-05,
      "logits/chosen": 3.29472017288208,
      "logits/rejected": 3.191714286804199,
      "logps/chosen": -392.85736083984375,
      "logps/rejected": -304.26165771484375,
      "loss": 0.3106,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.4242801666259766,
      "rewards/margins": 3.0988292694091797,
      "rewards/rejected": -5.523109436035156,
      "step": 23380
    },
    {
      "epoch": 1.3768350445706217,
      "grad_norm": 3.45089054107666,
      "learning_rate": 2.7065803667745416e-05,
      "logits/chosen": 3.637425184249878,
      "logits/rejected": 3.479818820953369,
      "logps/chosen": -431.13720703125,
      "logps/rejected": -390.81634521484375,
      "loss": 0.501,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -3.02388072013855,
      "rewards/margins": 3.8564841747283936,
      "rewards/rejected": -6.880364894866943,
      "step": 23400
    },
    {
      "epoch": 1.378011826659998,
      "grad_norm": 2.7369563579559326,
      "learning_rate": 2.7046190055898796e-05,
      "logits/chosen": 3.6606032848358154,
      "logits/rejected": 3.5934994220733643,
      "logps/chosen": -411.9478454589844,
      "logps/rejected": -322.5323486328125,
      "loss": 0.2586,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.5776406526565552,
      "rewards/margins": 3.855372190475464,
      "rewards/rejected": -5.433012962341309,
      "step": 23420
    },
    {
      "epoch": 1.3791886087493748,
      "grad_norm": 5.500553131103516,
      "learning_rate": 2.7026576444052175e-05,
      "logits/chosen": 3.800309419631958,
      "logits/rejected": 3.8069064617156982,
      "logps/chosen": -411.34619140625,
      "logps/rejected": -352.19195556640625,
      "loss": 0.446,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5316860675811768,
      "rewards/margins": 3.9867687225341797,
      "rewards/rejected": -6.518454551696777,
      "step": 23440
    },
    {
      "epoch": 1.3803653908387514,
      "grad_norm": 8.13012409210205,
      "learning_rate": 2.700696283220555e-05,
      "logits/chosen": 3.7856056690216064,
      "logits/rejected": 3.788827896118164,
      "logps/chosen": -388.22259521484375,
      "logps/rejected": -357.88861083984375,
      "loss": 0.3593,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.011080503463745,
      "rewards/margins": 3.2376606464385986,
      "rewards/rejected": -5.248741626739502,
      "step": 23460
    },
    {
      "epoch": 1.381542172928128,
      "grad_norm": 5.452252388000488,
      "learning_rate": 2.698734922035893e-05,
      "logits/chosen": 3.234875440597534,
      "logits/rejected": 3.4096553325653076,
      "logps/chosen": -317.8181457519531,
      "logps/rejected": -309.447998046875,
      "loss": 0.5181,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.1049487590789795,
      "rewards/margins": 3.0365729331970215,
      "rewards/rejected": -5.141521453857422,
      "step": 23480
    },
    {
      "epoch": 1.3827189550175047,
      "grad_norm": 1.2174267768859863,
      "learning_rate": 2.6967735608512306e-05,
      "logits/chosen": 3.7363216876983643,
      "logits/rejected": 3.8314552307128906,
      "logps/chosen": -371.4170227050781,
      "logps/rejected": -294.73614501953125,
      "loss": 0.2491,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.5908828973770142,
      "rewards/margins": 3.602092742919922,
      "rewards/rejected": -5.192975044250488,
      "step": 23500
    },
    {
      "epoch": 1.3838957371068812,
      "grad_norm": 3.1434381008148193,
      "learning_rate": 2.6948121996665686e-05,
      "logits/chosen": 3.6356194019317627,
      "logits/rejected": 3.706108808517456,
      "logps/chosen": -397.57611083984375,
      "logps/rejected": -342.35235595703125,
      "loss": 0.1542,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5550806522369385,
      "rewards/margins": 4.515261650085449,
      "rewards/rejected": -6.070342063903809,
      "step": 23520
    },
    {
      "epoch": 1.3850725191962578,
      "grad_norm": 1.6193188428878784,
      "learning_rate": 2.692850838481907e-05,
      "logits/chosen": 4.022937774658203,
      "logits/rejected": 3.9833271503448486,
      "logps/chosen": -433.509765625,
      "logps/rejected": -335.525634765625,
      "loss": 0.2643,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8719489574432373,
      "rewards/margins": 3.496014356613159,
      "rewards/rejected": -5.367962837219238,
      "step": 23540
    },
    {
      "epoch": 1.3862493012856345,
      "grad_norm": 1.1105724573135376,
      "learning_rate": 2.690889477297244e-05,
      "logits/chosen": 3.815582752227783,
      "logits/rejected": 3.808274030685425,
      "logps/chosen": -365.10858154296875,
      "logps/rejected": -339.5002746582031,
      "loss": 0.3443,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.816983938217163,
      "rewards/margins": 3.2176156044006348,
      "rewards/rejected": -5.034599304199219,
      "step": 23560
    },
    {
      "epoch": 1.387426083375011,
      "grad_norm": 5.28724479675293,
      "learning_rate": 2.6889281161125824e-05,
      "logits/chosen": 3.4415664672851562,
      "logits/rejected": 3.3973636627197266,
      "logps/chosen": -360.4959716796875,
      "logps/rejected": -345.27813720703125,
      "loss": 0.5306,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.6645455360412598,
      "rewards/margins": 3.3847358226776123,
      "rewards/rejected": -6.049281120300293,
      "step": 23580
    },
    {
      "epoch": 1.3886028654643876,
      "grad_norm": 2.9852232933044434,
      "learning_rate": 2.6869667549279204e-05,
      "logits/chosen": 3.786740779876709,
      "logits/rejected": 3.6869277954101562,
      "logps/chosen": -433.5270080566406,
      "logps/rejected": -329.2629699707031,
      "loss": 0.2422,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.725547432899475,
      "rewards/margins": 4.305054664611816,
      "rewards/rejected": -6.03060245513916,
      "step": 23600
    },
    {
      "epoch": 1.3897796475537643,
      "grad_norm": 2.06441330909729,
      "learning_rate": 2.685005393743258e-05,
      "logits/chosen": 3.802295684814453,
      "logits/rejected": 3.752951145172119,
      "logps/chosen": -392.3855285644531,
      "logps/rejected": -356.17694091796875,
      "loss": 0.3925,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7870018482208252,
      "rewards/margins": 2.5335853099823,
      "rewards/rejected": -4.320587158203125,
      "step": 23620
    },
    {
      "epoch": 1.3909564296431407,
      "grad_norm": 1.1041115522384644,
      "learning_rate": 2.683044032558596e-05,
      "logits/chosen": 3.841264009475708,
      "logits/rejected": 3.769465923309326,
      "logps/chosen": -411.08123779296875,
      "logps/rejected": -334.69580078125,
      "loss": 0.305,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9055551290512085,
      "rewards/margins": 4.001326560974121,
      "rewards/rejected": -4.906881809234619,
      "step": 23640
    },
    {
      "epoch": 1.3921332117325174,
      "grad_norm": 3.526449203491211,
      "learning_rate": 2.6810826713739335e-05,
      "logits/chosen": 3.678558826446533,
      "logits/rejected": 3.6198859214782715,
      "logps/chosen": -418.54168701171875,
      "logps/rejected": -366.82928466796875,
      "loss": 0.2742,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.7909743785858154,
      "rewards/margins": 3.34423828125,
      "rewards/rejected": -5.1352128982543945,
      "step": 23660
    },
    {
      "epoch": 1.393309993821894,
      "grad_norm": 7.111184120178223,
      "learning_rate": 2.6791213101892715e-05,
      "logits/chosen": 3.818662166595459,
      "logits/rejected": 3.6820571422576904,
      "logps/chosen": -356.01226806640625,
      "logps/rejected": -311.90087890625,
      "loss": 0.2494,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9037675857543945,
      "rewards/margins": 3.1566615104675293,
      "rewards/rejected": -5.060429573059082,
      "step": 23680
    },
    {
      "epoch": 1.3944867759112707,
      "grad_norm": 3.0536105632781982,
      "learning_rate": 2.6771599490046094e-05,
      "logits/chosen": 4.05463171005249,
      "logits/rejected": 4.065598487854004,
      "logps/chosen": -409.74090576171875,
      "logps/rejected": -346.8340759277344,
      "loss": 0.372,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8569755554199219,
      "rewards/margins": 3.1993584632873535,
      "rewards/rejected": -5.056334018707275,
      "step": 23700
    },
    {
      "epoch": 1.3956635580006473,
      "grad_norm": 1.791226863861084,
      "learning_rate": 2.675198587819947e-05,
      "logits/chosen": 3.9907619953155518,
      "logits/rejected": 3.8389782905578613,
      "logps/chosen": -429.99761962890625,
      "logps/rejected": -355.0275573730469,
      "loss": 0.2554,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.604504942893982,
      "rewards/margins": 3.6747002601623535,
      "rewards/rejected": -5.279204845428467,
      "step": 23720
    },
    {
      "epoch": 1.3968403400900238,
      "grad_norm": 1.522841215133667,
      "learning_rate": 2.673237226635285e-05,
      "logits/chosen": 3.8925576210021973,
      "logits/rejected": 3.8262839317321777,
      "logps/chosen": -433.9513244628906,
      "logps/rejected": -325.57183837890625,
      "loss": 0.193,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.904228925704956,
      "rewards/margins": 3.6017227172851562,
      "rewards/rejected": -5.505951881408691,
      "step": 23740
    },
    {
      "epoch": 1.3980171221794004,
      "grad_norm": 4.521274089813232,
      "learning_rate": 2.6712758654506225e-05,
      "logits/chosen": 3.697617292404175,
      "logits/rejected": 3.6892971992492676,
      "logps/chosen": -395.4894714355469,
      "logps/rejected": -306.9286804199219,
      "loss": 0.2222,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.82541823387146,
      "rewards/margins": 3.557082414627075,
      "rewards/rejected": -5.382500648498535,
      "step": 23760
    },
    {
      "epoch": 1.399193904268777,
      "grad_norm": 6.237145900726318,
      "learning_rate": 2.6693145042659605e-05,
      "logits/chosen": 3.5873191356658936,
      "logits/rejected": 3.7110352516174316,
      "logps/chosen": -372.01007080078125,
      "logps/rejected": -349.1185607910156,
      "loss": 0.2982,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.141160249710083,
      "rewards/margins": 3.8609859943389893,
      "rewards/rejected": -6.002146244049072,
      "step": 23780
    },
    {
      "epoch": 1.4003706863581535,
      "grad_norm": 3.703767776489258,
      "learning_rate": 2.6673531430812988e-05,
      "logits/chosen": 3.7102839946746826,
      "logits/rejected": 3.7613747119903564,
      "logps/chosen": -400.9591979980469,
      "logps/rejected": -337.84088134765625,
      "loss": 0.1949,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7305902242660522,
      "rewards/margins": 4.901808738708496,
      "rewards/rejected": -6.632399559020996,
      "step": 23800
    },
    {
      "epoch": 1.4015474684475302,
      "grad_norm": 2.4163424968719482,
      "learning_rate": 2.665391781896636e-05,
      "logits/chosen": 3.7153725624084473,
      "logits/rejected": 3.5656185150146484,
      "logps/chosen": -411.1078186035156,
      "logps/rejected": -367.75701904296875,
      "loss": 0.5373,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.835935115814209,
      "rewards/margins": 2.8985233306884766,
      "rewards/rejected": -5.7344584465026855,
      "step": 23820
    },
    {
      "epoch": 1.4027242505369069,
      "grad_norm": 3.7896862030029297,
      "learning_rate": 2.6634304207119743e-05,
      "logits/chosen": 3.502631425857544,
      "logits/rejected": 3.548288345336914,
      "logps/chosen": -383.43157958984375,
      "logps/rejected": -346.0239562988281,
      "loss": 0.2759,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.075963258743286,
      "rewards/margins": 4.085962295532227,
      "rewards/rejected": -6.161925315856934,
      "step": 23840
    },
    {
      "epoch": 1.4039010326262833,
      "grad_norm": 5.8252763748168945,
      "learning_rate": 2.6614690595273123e-05,
      "logits/chosen": 3.691516160964966,
      "logits/rejected": 3.606066942214966,
      "logps/chosen": -377.8722229003906,
      "logps/rejected": -356.7135009765625,
      "loss": 0.4037,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.648345947265625,
      "rewards/margins": 2.7713613510131836,
      "rewards/rejected": -5.419707298278809,
      "step": 23860
    },
    {
      "epoch": 1.40507781471566,
      "grad_norm": 0.7630687952041626,
      "learning_rate": 2.65950769834265e-05,
      "logits/chosen": 3.692737579345703,
      "logits/rejected": 3.666814088821411,
      "logps/chosen": -387.1964111328125,
      "logps/rejected": -329.3948669433594,
      "loss": 0.2365,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.216073751449585,
      "rewards/margins": 4.131260871887207,
      "rewards/rejected": -6.347335338592529,
      "step": 23880
    },
    {
      "epoch": 1.4062545968050366,
      "grad_norm": 3.826235294342041,
      "learning_rate": 2.6575463371579878e-05,
      "logits/chosen": 3.511751651763916,
      "logits/rejected": 3.3957507610321045,
      "logps/chosen": -363.2066345214844,
      "logps/rejected": -354.09014892578125,
      "loss": 0.2182,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.0634796619415283,
      "rewards/margins": 3.976111650466919,
      "rewards/rejected": -6.039591312408447,
      "step": 23900
    },
    {
      "epoch": 1.4074313788944133,
      "grad_norm": 1.079957127571106,
      "learning_rate": 2.6555849759733254e-05,
      "logits/chosen": 3.7827706336975098,
      "logits/rejected": 3.6475162506103516,
      "logps/chosen": -389.1839294433594,
      "logps/rejected": -336.2200012207031,
      "loss": 0.3713,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8558557033538818,
      "rewards/margins": 4.1725945472717285,
      "rewards/rejected": -6.028450012207031,
      "step": 23920
    },
    {
      "epoch": 1.40860816098379,
      "grad_norm": 4.176441669464111,
      "learning_rate": 2.6536236147886634e-05,
      "logits/chosen": 3.7240073680877686,
      "logits/rejected": 3.5766124725341797,
      "logps/chosen": -396.47760009765625,
      "logps/rejected": -403.6385498046875,
      "loss": 0.3343,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7209844589233398,
      "rewards/margins": 3.4169154167175293,
      "rewards/rejected": -5.137899398803711,
      "step": 23940
    },
    {
      "epoch": 1.4097849430731664,
      "grad_norm": 3.2764065265655518,
      "learning_rate": 2.6516622536040013e-05,
      "logits/chosen": 3.5895190238952637,
      "logits/rejected": 3.454486131668091,
      "logps/chosen": -355.1148986816406,
      "logps/rejected": -328.006591796875,
      "loss": 0.3703,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3021440505981445,
      "rewards/margins": 2.911085605621338,
      "rewards/rejected": -5.213229656219482,
      "step": 23960
    },
    {
      "epoch": 1.410961725162543,
      "grad_norm": 4.032600402832031,
      "learning_rate": 2.649700892419339e-05,
      "logits/chosen": 4.0297346115112305,
      "logits/rejected": 3.76774263381958,
      "logps/chosen": -416.86517333984375,
      "logps/rejected": -338.867919921875,
      "loss": 0.3987,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.5872265100479126,
      "rewards/margins": 3.3834171295166016,
      "rewards/rejected": -4.970643997192383,
      "step": 23980
    },
    {
      "epoch": 1.4121385072519197,
      "grad_norm": 1.2648663520812988,
      "learning_rate": 2.647739531234677e-05,
      "logits/chosen": 3.9526138305664062,
      "logits/rejected": 4.011091709136963,
      "logps/chosen": -377.61199951171875,
      "logps/rejected": -384.8780822753906,
      "loss": 0.3323,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.589705228805542,
      "rewards/margins": 3.0517172813415527,
      "rewards/rejected": -4.641422271728516,
      "step": 24000
    },
    {
      "epoch": 1.4133152893412961,
      "grad_norm": 1.6012822389602661,
      "learning_rate": 2.645778170050015e-05,
      "logits/chosen": 3.317894458770752,
      "logits/rejected": 3.305913209915161,
      "logps/chosen": -332.31134033203125,
      "logps/rejected": -318.2425231933594,
      "loss": 0.2874,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1368657350540161,
      "rewards/margins": 3.1990761756896973,
      "rewards/rejected": -4.335942268371582,
      "step": 24020
    },
    {
      "epoch": 1.4144920714306728,
      "grad_norm": 0.2448064535856247,
      "learning_rate": 2.6438168088653524e-05,
      "logits/chosen": 3.5090861320495605,
      "logits/rejected": 3.687981367111206,
      "logps/chosen": -377.47991943359375,
      "logps/rejected": -353.087158203125,
      "loss": 0.3239,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8703739643096924,
      "rewards/margins": 2.7917094230651855,
      "rewards/rejected": -4.662083625793457,
      "step": 24040
    },
    {
      "epoch": 1.4156688535200495,
      "grad_norm": 3.9539623260498047,
      "learning_rate": 2.6418554476806907e-05,
      "logits/chosen": 3.8019871711730957,
      "logits/rejected": 3.6110999584198,
      "logps/chosen": -357.3811340332031,
      "logps/rejected": -302.0408020019531,
      "loss": 0.2792,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.6461414098739624,
      "rewards/margins": 3.601139783859253,
      "rewards/rejected": -5.247281074523926,
      "step": 24060
    },
    {
      "epoch": 1.416845635609426,
      "grad_norm": 1.0076650381088257,
      "learning_rate": 2.639894086496028e-05,
      "logits/chosen": 3.571366548538208,
      "logits/rejected": 3.6808013916015625,
      "logps/chosen": -406.931396484375,
      "logps/rejected": -345.39410400390625,
      "loss": 0.2601,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.6240959167480469,
      "rewards/margins": 3.981503963470459,
      "rewards/rejected": -5.605599880218506,
      "step": 24080
    },
    {
      "epoch": 1.4180224176988026,
      "grad_norm": 1.1595122814178467,
      "learning_rate": 2.6379327253113662e-05,
      "logits/chosen": 3.546807050704956,
      "logits/rejected": 3.591137409210205,
      "logps/chosen": -330.6291198730469,
      "logps/rejected": -329.47564697265625,
      "loss": 0.4265,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8569934368133545,
      "rewards/margins": 3.042532205581665,
      "rewards/rejected": -4.8995256423950195,
      "step": 24100
    },
    {
      "epoch": 1.4191991997881792,
      "grad_norm": 0.7502118349075317,
      "learning_rate": 2.635971364126704e-05,
      "logits/chosen": 3.747053623199463,
      "logits/rejected": 3.5476272106170654,
      "logps/chosen": -395.613037109375,
      "logps/rejected": -339.5429382324219,
      "loss": 0.5211,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.3591880798339844,
      "rewards/margins": 3.9600653648376465,
      "rewards/rejected": -5.319253921508789,
      "step": 24120
    },
    {
      "epoch": 1.4203759818775559,
      "grad_norm": 4.718430042266846,
      "learning_rate": 2.6340100029420418e-05,
      "logits/chosen": 3.6523079872131348,
      "logits/rejected": 3.600191831588745,
      "logps/chosen": -409.23199462890625,
      "logps/rejected": -362.95623779296875,
      "loss": 0.4148,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.114884614944458,
      "rewards/margins": 3.2213943004608154,
      "rewards/rejected": -5.336278915405273,
      "step": 24140
    },
    {
      "epoch": 1.4215527639669325,
      "grad_norm": 2.4834632873535156,
      "learning_rate": 2.6320486417573797e-05,
      "logits/chosen": 3.796393871307373,
      "logits/rejected": 3.772122859954834,
      "logps/chosen": -416.5535583496094,
      "logps/rejected": -344.6074523925781,
      "loss": 0.4759,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.0206034183502197,
      "rewards/margins": 2.8319151401519775,
      "rewards/rejected": -3.852518081665039,
      "step": 24160
    },
    {
      "epoch": 1.422729546056309,
      "grad_norm": 2.516887664794922,
      "learning_rate": 2.6300872805727176e-05,
      "logits/chosen": 3.7017159461975098,
      "logits/rejected": 3.7806103229522705,
      "logps/chosen": -419.0519104003906,
      "logps/rejected": -355.9270324707031,
      "loss": 0.1467,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -1.3675110340118408,
      "rewards/margins": 4.2445478439331055,
      "rewards/rejected": -5.612059593200684,
      "step": 24180
    },
    {
      "epoch": 1.4239063281456856,
      "grad_norm": 2.7283079624176025,
      "learning_rate": 2.6281259193880553e-05,
      "logits/chosen": 3.8090317249298096,
      "logits/rejected": 3.774343967437744,
      "logps/chosen": -373.677001953125,
      "logps/rejected": -310.745849609375,
      "loss": 0.2681,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.2900397777557373,
      "rewards/margins": 3.420712947845459,
      "rewards/rejected": -4.710752964019775,
      "step": 24200
    },
    {
      "epoch": 1.4250831102350623,
      "grad_norm": 4.487687110900879,
      "learning_rate": 2.6261645582033932e-05,
      "logits/chosen": 3.679377794265747,
      "logits/rejected": 3.5807366371154785,
      "logps/chosen": -427.9169006347656,
      "logps/rejected": -387.4630432128906,
      "loss": 0.3878,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.0407681465148926,
      "rewards/margins": 4.6755218505859375,
      "rewards/rejected": -6.716290473937988,
      "step": 24220
    },
    {
      "epoch": 1.4262598923244387,
      "grad_norm": 5.535156726837158,
      "learning_rate": 2.6242031970187308e-05,
      "logits/chosen": 3.592512607574463,
      "logits/rejected": 3.6427924633026123,
      "logps/chosen": -381.60809326171875,
      "logps/rejected": -353.89129638671875,
      "loss": 0.3507,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.415269374847412,
      "rewards/margins": 3.579493761062622,
      "rewards/rejected": -5.9947638511657715,
      "step": 24240
    },
    {
      "epoch": 1.4274366744138154,
      "grad_norm": 1.3215734958648682,
      "learning_rate": 2.6222418358340687e-05,
      "logits/chosen": 3.1177027225494385,
      "logits/rejected": 3.0760912895202637,
      "logps/chosen": -352.800048828125,
      "logps/rejected": -332.7081604003906,
      "loss": 0.4012,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.064861297607422,
      "rewards/margins": 3.1275649070739746,
      "rewards/rejected": -5.192426681518555,
      "step": 24260
    },
    {
      "epoch": 1.428613456503192,
      "grad_norm": 34.95887756347656,
      "learning_rate": 2.620280474649407e-05,
      "logits/chosen": 3.221348524093628,
      "logits/rejected": 3.1635982990264893,
      "logps/chosen": -375.5445251464844,
      "logps/rejected": -324.37884521484375,
      "loss": 0.2732,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.716505527496338,
      "rewards/margins": 3.107555389404297,
      "rewards/rejected": -5.824060440063477,
      "step": 24280
    },
    {
      "epoch": 1.4297902385925685,
      "grad_norm": 2.1305065155029297,
      "learning_rate": 2.6183191134647443e-05,
      "logits/chosen": 3.3207125663757324,
      "logits/rejected": 3.344198703765869,
      "logps/chosen": -385.4779968261719,
      "logps/rejected": -349.52557373046875,
      "loss": 0.2699,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1127326488494873,
      "rewards/margins": 4.04352331161499,
      "rewards/rejected": -6.156256675720215,
      "step": 24300
    },
    {
      "epoch": 1.4309670206819451,
      "grad_norm": 4.461707592010498,
      "learning_rate": 2.6163577522800826e-05,
      "logits/chosen": 3.6084964275360107,
      "logits/rejected": 3.6546542644500732,
      "logps/chosen": -370.1680908203125,
      "logps/rejected": -335.7088623046875,
      "loss": 0.3683,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.4184699058532715,
      "rewards/margins": 3.0340070724487305,
      "rewards/rejected": -5.452476978302002,
      "step": 24320
    },
    {
      "epoch": 1.4321438027713218,
      "grad_norm": 4.576028823852539,
      "learning_rate": 2.6143963910954205e-05,
      "logits/chosen": 3.739853620529175,
      "logits/rejected": 3.5355212688446045,
      "logps/chosen": -422.0087890625,
      "logps/rejected": -322.1260986328125,
      "loss": 0.241,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8401851654052734,
      "rewards/margins": 3.8622119426727295,
      "rewards/rejected": -5.702397346496582,
      "step": 24340
    },
    {
      "epoch": 1.4333205848606985,
      "grad_norm": 3.4642579555511475,
      "learning_rate": 2.612435029910758e-05,
      "logits/chosen": 3.8367550373077393,
      "logits/rejected": 3.707665205001831,
      "logps/chosen": -434.2403259277344,
      "logps/rejected": -352.6636657714844,
      "loss": 0.2709,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.10018253326416,
      "rewards/margins": 3.9195663928985596,
      "rewards/rejected": -6.019747734069824,
      "step": 24360
    },
    {
      "epoch": 1.4344973669500751,
      "grad_norm": 2.692615270614624,
      "learning_rate": 2.6105717367853293e-05,
      "logits/chosen": 3.381237506866455,
      "logits/rejected": 3.4504752159118652,
      "logps/chosen": -377.77337646484375,
      "logps/rejected": -322.0917663574219,
      "loss": 0.3701,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.621626377105713,
      "rewards/margins": 3.246305465698242,
      "rewards/rejected": -5.867932319641113,
      "step": 24380
    },
    {
      "epoch": 1.4356741490394516,
      "grad_norm": 1.931078314781189,
      "learning_rate": 2.608610375600667e-05,
      "logits/chosen": 3.442486524581909,
      "logits/rejected": 3.2563958168029785,
      "logps/chosen": -403.34100341796875,
      "logps/rejected": -399.61492919921875,
      "loss": 0.283,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.7065529823303223,
      "rewards/margins": 3.9532318115234375,
      "rewards/rejected": -6.659785270690918,
      "step": 24400
    },
    {
      "epoch": 1.4368509311288282,
      "grad_norm": 0.432813435792923,
      "learning_rate": 2.606649014416005e-05,
      "logits/chosen": 3.1189444065093994,
      "logits/rejected": 3.1434154510498047,
      "logps/chosen": -352.0033264160156,
      "logps/rejected": -334.56719970703125,
      "loss": 0.2619,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.37715482711792,
      "rewards/margins": 3.057609796524048,
      "rewards/rejected": -5.4347639083862305,
      "step": 24420
    },
    {
      "epoch": 1.4380277132182049,
      "grad_norm": 6.3394670486450195,
      "learning_rate": 2.6046876532313425e-05,
      "logits/chosen": 3.511849880218506,
      "logits/rejected": 3.5398037433624268,
      "logps/chosen": -407.37744140625,
      "logps/rejected": -340.72625732421875,
      "loss": 0.3911,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6320216655731201,
      "rewards/margins": 3.333528518676758,
      "rewards/rejected": -4.965549468994141,
      "step": 24440
    },
    {
      "epoch": 1.4392044953075813,
      "grad_norm": 0.4860348105430603,
      "learning_rate": 2.6027262920466804e-05,
      "logits/chosen": 3.494572877883911,
      "logits/rejected": 3.5088462829589844,
      "logps/chosen": -404.54388427734375,
      "logps/rejected": -369.06109619140625,
      "loss": 0.1972,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.1121373176574707,
      "rewards/margins": 3.955068588256836,
      "rewards/rejected": -6.067205905914307,
      "step": 24460
    },
    {
      "epoch": 1.440381277396958,
      "grad_norm": 0.7169202566146851,
      "learning_rate": 2.6007649308620187e-05,
      "logits/chosen": 3.6065878868103027,
      "logits/rejected": 3.6391406059265137,
      "logps/chosen": -404.5296936035156,
      "logps/rejected": -365.46636962890625,
      "loss": 0.3652,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.315328359603882,
      "rewards/margins": 3.29357647895813,
      "rewards/rejected": -5.608904838562012,
      "step": 24480
    },
    {
      "epoch": 1.4415580594863346,
      "grad_norm": 1.758507490158081,
      "learning_rate": 2.598803569677356e-05,
      "logits/chosen": 3.5608654022216797,
      "logits/rejected": 3.6287646293640137,
      "logps/chosen": -355.475341796875,
      "logps/rejected": -331.8580627441406,
      "loss": 0.3244,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.3988735675811768,
      "rewards/margins": 4.091623783111572,
      "rewards/rejected": -6.490496635437012,
      "step": 24500
    },
    {
      "epoch": 1.442734841575711,
      "grad_norm": 2.6629691123962402,
      "learning_rate": 2.5968422084926942e-05,
      "logits/chosen": 3.568676471710205,
      "logits/rejected": 3.478515625,
      "logps/chosen": -377.2842712402344,
      "logps/rejected": -302.1708679199219,
      "loss": 0.3716,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.664353609085083,
      "rewards/margins": 4.127241134643555,
      "rewards/rejected": -6.791594505310059,
      "step": 24520
    },
    {
      "epoch": 1.4439116236650877,
      "grad_norm": 25.346508026123047,
      "learning_rate": 2.5948808473080322e-05,
      "logits/chosen": 3.67236590385437,
      "logits/rejected": 3.5964980125427246,
      "logps/chosen": -466.86358642578125,
      "logps/rejected": -386.77752685546875,
      "loss": 0.474,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -3.318249464035034,
      "rewards/margins": 3.685565233230591,
      "rewards/rejected": -7.003814697265625,
      "step": 24540
    },
    {
      "epoch": 1.4450884057544644,
      "grad_norm": 0.48173364996910095,
      "learning_rate": 2.5929194861233698e-05,
      "logits/chosen": 3.3969006538391113,
      "logits/rejected": 3.537438154220581,
      "logps/chosen": -407.90948486328125,
      "logps/rejected": -333.31634521484375,
      "loss": 0.3164,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.2400927543640137,
      "rewards/margins": 3.962815046310425,
      "rewards/rejected": -6.202908039093018,
      "step": 24560
    },
    {
      "epoch": 1.446265187843841,
      "grad_norm": 8.212769508361816,
      "learning_rate": 2.5909581249387077e-05,
      "logits/chosen": 3.76837420463562,
      "logits/rejected": 3.5905730724334717,
      "logps/chosen": -403.1629638671875,
      "logps/rejected": -337.65887451171875,
      "loss": 0.3803,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.076143264770508,
      "rewards/margins": 2.8145253658294678,
      "rewards/rejected": -5.890668869018555,
      "step": 24580
    },
    {
      "epoch": 1.4474419699332177,
      "grad_norm": 2.242788314819336,
      "learning_rate": 2.5889967637540453e-05,
      "logits/chosen": 3.658048152923584,
      "logits/rejected": 3.5988056659698486,
      "logps/chosen": -388.68133544921875,
      "logps/rejected": -323.054443359375,
      "loss": 0.189,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.8648662567138672,
      "rewards/margins": 4.252438545227051,
      "rewards/rejected": -6.117304801940918,
      "step": 24600
    },
    {
      "epoch": 1.4486187520225942,
      "grad_norm": 1.5675513744354248,
      "learning_rate": 2.5870354025693833e-05,
      "logits/chosen": 3.6039035320281982,
      "logits/rejected": 3.709399700164795,
      "logps/chosen": -375.8025207519531,
      "logps/rejected": -373.53985595703125,
      "loss": 0.2992,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.770714282989502,
      "rewards/margins": 3.617523193359375,
      "rewards/rejected": -6.388237953186035,
      "step": 24620
    },
    {
      "epoch": 1.4497955341119708,
      "grad_norm": 9.028027534484863,
      "learning_rate": 2.5850740413847212e-05,
      "logits/chosen": 3.452824354171753,
      "logits/rejected": 3.3668293952941895,
      "logps/chosen": -378.01275634765625,
      "logps/rejected": -377.6829528808594,
      "loss": 0.2949,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.59055757522583,
      "rewards/margins": 4.147271633148193,
      "rewards/rejected": -6.737829685211182,
      "step": 24640
    },
    {
      "epoch": 1.4509723162013475,
      "grad_norm": 4.763092041015625,
      "learning_rate": 2.5831126802000588e-05,
      "logits/chosen": 3.534552812576294,
      "logits/rejected": 3.6231250762939453,
      "logps/chosen": -435.9244689941406,
      "logps/rejected": -372.51275634765625,
      "loss": 0.2964,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.812553882598877,
      "rewards/margins": 4.138322353363037,
      "rewards/rejected": -6.950875759124756,
      "step": 24660
    },
    {
      "epoch": 1.452149098290724,
      "grad_norm": 6.64996862411499,
      "learning_rate": 2.5811513190153968e-05,
      "logits/chosen": 3.8901264667510986,
      "logits/rejected": 3.82116436958313,
      "logps/chosen": -445.38726806640625,
      "logps/rejected": -338.3060302734375,
      "loss": 0.3799,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8798243999481201,
      "rewards/margins": 3.678974151611328,
      "rewards/rejected": -5.558798789978027,
      "step": 24680
    },
    {
      "epoch": 1.4533258803801006,
      "grad_norm": 6.420583248138428,
      "learning_rate": 2.579189957830735e-05,
      "logits/chosen": 3.6951205730438232,
      "logits/rejected": 3.795905590057373,
      "logps/chosen": -431.90435791015625,
      "logps/rejected": -351.34722900390625,
      "loss": 0.2118,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.942469596862793,
      "rewards/margins": 4.205841064453125,
      "rewards/rejected": -6.148310661315918,
      "step": 24700
    },
    {
      "epoch": 1.4545026624694772,
      "grad_norm": 3.144416570663452,
      "learning_rate": 2.5772285966460723e-05,
      "logits/chosen": 3.9258930683135986,
      "logits/rejected": 3.9426193237304688,
      "logps/chosen": -410.33233642578125,
      "logps/rejected": -311.02874755859375,
      "loss": 0.3942,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.196949005126953,
      "rewards/margins": 3.403644561767578,
      "rewards/rejected": -5.6005940437316895,
      "step": 24720
    },
    {
      "epoch": 1.455679444558854,
      "grad_norm": 4.338685989379883,
      "learning_rate": 2.5752672354614106e-05,
      "logits/chosen": 3.5778121948242188,
      "logits/rejected": 3.732832670211792,
      "logps/chosen": -364.37115478515625,
      "logps/rejected": -348.60174560546875,
      "loss": 0.3768,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.0292441844940186,
      "rewards/margins": 3.5949034690856934,
      "rewards/rejected": -5.624147891998291,
      "step": 24740
    },
    {
      "epoch": 1.4568562266482303,
      "grad_norm": 1.1353392601013184,
      "learning_rate": 2.573305874276748e-05,
      "logits/chosen": 3.667421340942383,
      "logits/rejected": 3.561283826828003,
      "logps/chosen": -351.5205993652344,
      "logps/rejected": -273.6790466308594,
      "loss": 0.2763,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.4833214282989502,
      "rewards/margins": 3.4848854541778564,
      "rewards/rejected": -4.968206882476807,
      "step": 24760
    },
    {
      "epoch": 1.458033008737607,
      "grad_norm": 1.2714576721191406,
      "learning_rate": 2.571344513092086e-05,
      "logits/chosen": 3.3657054901123047,
      "logits/rejected": 3.386190414428711,
      "logps/chosen": -341.8888244628906,
      "logps/rejected": -326.8831481933594,
      "loss": 0.2204,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8025703430175781,
      "rewards/margins": 3.241638660430908,
      "rewards/rejected": -5.044208526611328,
      "step": 24780
    },
    {
      "epoch": 1.4592097908269837,
      "grad_norm": 2.7012250423431396,
      "learning_rate": 2.569383151907424e-05,
      "logits/chosen": 3.815053939819336,
      "logits/rejected": 3.6518874168395996,
      "logps/chosen": -391.8251037597656,
      "logps/rejected": -345.9664306640625,
      "loss": 0.3143,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9902740716934204,
      "rewards/margins": 3.4215569496154785,
      "rewards/rejected": -5.411830902099609,
      "step": 24800
    },
    {
      "epoch": 1.4603865729163603,
      "grad_norm": 1.5761758089065552,
      "learning_rate": 2.5674217907227617e-05,
      "logits/chosen": 3.8195433616638184,
      "logits/rejected": 3.6799392700195312,
      "logps/chosen": -366.3205261230469,
      "logps/rejected": -321.53558349609375,
      "loss": 0.3961,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.8582820892333984,
      "rewards/margins": 3.534905195236206,
      "rewards/rejected": -5.393187522888184,
      "step": 24820
    },
    {
      "epoch": 1.4615633550057368,
      "grad_norm": 0.5175995230674744,
      "learning_rate": 2.5654604295380996e-05,
      "logits/chosen": 3.620664119720459,
      "logits/rejected": 3.616650342941284,
      "logps/chosen": -415.83642578125,
      "logps/rejected": -334.7120666503906,
      "loss": 0.3225,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7787479162216187,
      "rewards/margins": 3.871251344680786,
      "rewards/rejected": -5.649999141693115,
      "step": 24840
    },
    {
      "epoch": 1.4627401370951134,
      "grad_norm": 2.812854528427124,
      "learning_rate": 2.5634990683534376e-05,
      "logits/chosen": 3.501241683959961,
      "logits/rejected": 3.448268413543701,
      "logps/chosen": -399.22015380859375,
      "logps/rejected": -340.5794372558594,
      "loss": 0.2716,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.7442861795425415,
      "rewards/margins": 4.30563497543335,
      "rewards/rejected": -6.049921035766602,
      "step": 24860
    },
    {
      "epoch": 1.46391691918449,
      "grad_norm": 1.0894180536270142,
      "learning_rate": 2.5615377071687752e-05,
      "logits/chosen": 3.9762215614318848,
      "logits/rejected": 3.8009533882141113,
      "logps/chosen": -467.6998596191406,
      "logps/rejected": -360.64031982421875,
      "loss": 0.2897,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7977778911590576,
      "rewards/margins": 3.9358322620391846,
      "rewards/rejected": -5.7336106300354,
      "step": 24880
    },
    {
      "epoch": 1.4650937012738665,
      "grad_norm": 7.288024425506592,
      "learning_rate": 2.559576345984113e-05,
      "logits/chosen": 3.508096694946289,
      "logits/rejected": 3.3831381797790527,
      "logps/chosen": -354.68218994140625,
      "logps/rejected": -276.94818115234375,
      "loss": 0.1988,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7552220821380615,
      "rewards/margins": 4.025027275085449,
      "rewards/rejected": -5.780250072479248,
      "step": 24900
    },
    {
      "epoch": 1.4662704833632432,
      "grad_norm": 9.30566692352295,
      "learning_rate": 2.5576149847994507e-05,
      "logits/chosen": 3.6089890003204346,
      "logits/rejected": 3.5743980407714844,
      "logps/chosen": -383.4789123535156,
      "logps/rejected": -327.78887939453125,
      "loss": 0.2759,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5634262561798096,
      "rewards/margins": 3.71636962890625,
      "rewards/rejected": -5.2797956466674805,
      "step": 24920
    },
    {
      "epoch": 1.4674472654526198,
      "grad_norm": 3.7557315826416016,
      "learning_rate": 2.5556536236147887e-05,
      "logits/chosen": 3.675121784210205,
      "logits/rejected": 3.6284852027893066,
      "logps/chosen": -420.83740234375,
      "logps/rejected": -331.48614501953125,
      "loss": 0.2406,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8258997201919556,
      "rewards/margins": 4.304055690765381,
      "rewards/rejected": -6.129954814910889,
      "step": 24940
    },
    {
      "epoch": 1.4686240475419965,
      "grad_norm": 1.7974886894226074,
      "learning_rate": 2.553692262430127e-05,
      "logits/chosen": 3.700200319290161,
      "logits/rejected": 3.7273647785186768,
      "logps/chosen": -382.8682556152344,
      "logps/rejected": -344.506591796875,
      "loss": 0.2222,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.4782816171646118,
      "rewards/margins": 4.398881435394287,
      "rewards/rejected": -5.877163410186768,
      "step": 24960
    },
    {
      "epoch": 1.469800829631373,
      "grad_norm": 4.585050106048584,
      "learning_rate": 2.5517309012454642e-05,
      "logits/chosen": 3.6260955333709717,
      "logits/rejected": 3.7284903526306152,
      "logps/chosen": -381.0190124511719,
      "logps/rejected": -353.2021484375,
      "loss": 0.3442,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1739680767059326,
      "rewards/margins": 4.323119640350342,
      "rewards/rejected": -6.4970879554748535,
      "step": 24980
    },
    {
      "epoch": 1.4709776117207496,
      "grad_norm": 3.259071111679077,
      "learning_rate": 2.5497695400608025e-05,
      "logits/chosen": 3.4700489044189453,
      "logits/rejected": 3.5702342987060547,
      "logps/chosen": -337.67584228515625,
      "logps/rejected": -280.8815612792969,
      "loss": 0.2016,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.4877822399139404,
      "rewards/margins": 3.5847878456115723,
      "rewards/rejected": -5.072570323944092,
      "step": 25000
    },
    {
      "epoch": 1.4709776117207496,
      "eval_logits/chosen": 3.3939805030822754,
      "eval_logits/rejected": 3.4003477096557617,
      "eval_logps/chosen": -379.03814697265625,
      "eval_logps/rejected": -350.4439697265625,
      "eval_loss": 0.5300824642181396,
      "eval_rewards/accuracies": 0.7881174087524414,
      "eval_rewards/chosen": -2.4457461833953857,
      "eval_rewards/margins": 2.9753293991088867,
      "eval_rewards/rejected": -5.421075344085693,
      "eval_runtime": 3546.207,
      "eval_samples_per_second": 3.152,
      "eval_steps_per_second": 3.152,
      "step": 25000
    },
    {
      "epoch": 1.4721543938101262,
      "grad_norm": 6.500960350036621,
      "learning_rate": 2.5478081788761404e-05,
      "logits/chosen": 4.058929443359375,
      "logits/rejected": 4.024923801422119,
      "logps/chosen": -448.75579833984375,
      "logps/rejected": -369.51239013671875,
      "loss": 0.2355,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9040019512176514,
      "rewards/margins": 4.189766883850098,
      "rewards/rejected": -6.093769073486328,
      "step": 25020
    },
    {
      "epoch": 1.473331175899503,
      "grad_norm": 2.1200060844421387,
      "learning_rate": 2.545846817691478e-05,
      "logits/chosen": 3.835522413253784,
      "logits/rejected": 3.839421033859253,
      "logps/chosen": -355.0268249511719,
      "logps/rejected": -327.2610778808594,
      "loss": 0.2216,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.8225469589233398,
      "rewards/margins": 3.564549684524536,
      "rewards/rejected": -5.387096881866455,
      "step": 25040
    },
    {
      "epoch": 1.4745079579888793,
      "grad_norm": 1.656050443649292,
      "learning_rate": 2.543885456506816e-05,
      "logits/chosen": 3.418109178543091,
      "logits/rejected": 3.521601438522339,
      "logps/chosen": -358.6785583496094,
      "logps/rejected": -357.88763427734375,
      "loss": 0.4139,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.0807981491088867,
      "rewards/margins": 3.409278154373169,
      "rewards/rejected": -5.490076065063477,
      "step": 25060
    },
    {
      "epoch": 1.475684740078256,
      "grad_norm": 5.022115230560303,
      "learning_rate": 2.5419240953221536e-05,
      "logits/chosen": 3.7175796031951904,
      "logits/rejected": 3.695624828338623,
      "logps/chosen": -341.0022888183594,
      "logps/rejected": -276.76629638671875,
      "loss": 0.552,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8158057928085327,
      "rewards/margins": 3.3530662059783936,
      "rewards/rejected": -5.168871879577637,
      "step": 25080
    },
    {
      "epoch": 1.4768615221676327,
      "grad_norm": 6.215338230133057,
      "learning_rate": 2.5399627341374915e-05,
      "logits/chosen": 3.8135292530059814,
      "logits/rejected": 3.9151787757873535,
      "logps/chosen": -413.2418518066406,
      "logps/rejected": -340.82183837890625,
      "loss": 0.3407,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.640485167503357,
      "rewards/margins": 3.7335305213928223,
      "rewards/rejected": -5.374015808105469,
      "step": 25100
    },
    {
      "epoch": 1.478038304257009,
      "grad_norm": 15.385207176208496,
      "learning_rate": 2.5380013729528295e-05,
      "logits/chosen": 3.897681713104248,
      "logits/rejected": 3.863234281539917,
      "logps/chosen": -398.10382080078125,
      "logps/rejected": -338.15386962890625,
      "loss": 0.3278,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.1987988948822021,
      "rewards/margins": 3.705487012863159,
      "rewards/rejected": -4.9042863845825195,
      "step": 25120
    },
    {
      "epoch": 1.4792150863463858,
      "grad_norm": 3.5516092777252197,
      "learning_rate": 2.536040011768167e-05,
      "logits/chosen": 3.779270887374878,
      "logits/rejected": 3.7626495361328125,
      "logps/chosen": -352.5331115722656,
      "logps/rejected": -339.3260192871094,
      "loss": 0.2352,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.6538461446762085,
      "rewards/margins": 4.141878604888916,
      "rewards/rejected": -5.795724391937256,
      "step": 25140
    },
    {
      "epoch": 1.4803918684357624,
      "grad_norm": 6.613853931427002,
      "learning_rate": 2.534078650583505e-05,
      "logits/chosen": 3.555492877960205,
      "logits/rejected": 3.7126011848449707,
      "logps/chosen": -390.4818420410156,
      "logps/rejected": -320.2691955566406,
      "loss": 0.3298,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.7117729187011719,
      "rewards/margins": 3.4886956214904785,
      "rewards/rejected": -5.20046854019165,
      "step": 25160
    },
    {
      "epoch": 1.481568650525139,
      "grad_norm": 4.268652439117432,
      "learning_rate": 2.5321172893988433e-05,
      "logits/chosen": 3.7957046031951904,
      "logits/rejected": 3.8543457984924316,
      "logps/chosen": -386.1636657714844,
      "logps/rejected": -326.69268798828125,
      "loss": 0.3223,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.3081556558609009,
      "rewards/margins": 4.142961502075195,
      "rewards/rejected": -5.451116561889648,
      "step": 25180
    },
    {
      "epoch": 1.4827454326145155,
      "grad_norm": 0.7292174100875854,
      "learning_rate": 2.5301559282141806e-05,
      "logits/chosen": 3.8107333183288574,
      "logits/rejected": 3.8000826835632324,
      "logps/chosen": -398.1111755371094,
      "logps/rejected": -311.365966796875,
      "loss": 0.1722,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.6555836200714111,
      "rewards/margins": 4.442095756530762,
      "rewards/rejected": -6.097679138183594,
      "step": 25200
    },
    {
      "epoch": 1.4839222147038922,
      "grad_norm": 0.3033580183982849,
      "learning_rate": 2.528194567029519e-05,
      "logits/chosen": 3.733254909515381,
      "logits/rejected": 3.655688524246216,
      "logps/chosen": -342.58624267578125,
      "logps/rejected": -311.45330810546875,
      "loss": 0.3285,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.3772404193878174,
      "rewards/margins": 3.7316060066223145,
      "rewards/rejected": -6.108846187591553,
      "step": 25220
    },
    {
      "epoch": 1.4850989967932688,
      "grad_norm": 2.5342495441436768,
      "learning_rate": 2.526233205844856e-05,
      "logits/chosen": 3.6672606468200684,
      "logits/rejected": 3.776578426361084,
      "logps/chosen": -437.7265625,
      "logps/rejected": -343.8729553222656,
      "loss": 0.2589,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.9180173873901367,
      "rewards/margins": 4.802718162536621,
      "rewards/rejected": -6.7207350730896,
      "step": 25240
    },
    {
      "epoch": 1.4862757788826455,
      "grad_norm": 1.9042832851409912,
      "learning_rate": 2.5242718446601944e-05,
      "logits/chosen": 3.706484317779541,
      "logits/rejected": 3.6416678428649902,
      "logps/chosen": -369.5746154785156,
      "logps/rejected": -335.0972900390625,
      "loss": 0.2862,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.7803587913513184,
      "rewards/margins": 3.7828285694122314,
      "rewards/rejected": -6.563187599182129,
      "step": 25260
    },
    {
      "epoch": 1.487452560972022,
      "grad_norm": 1.2851437330245972,
      "learning_rate": 2.5223104834755323e-05,
      "logits/chosen": 3.553048610687256,
      "logits/rejected": 3.547316312789917,
      "logps/chosen": -424.6431579589844,
      "logps/rejected": -409.52777099609375,
      "loss": 0.3854,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1935219764709473,
      "rewards/margins": 4.206905364990234,
      "rewards/rejected": -6.400427341461182,
      "step": 25280
    },
    {
      "epoch": 1.4886293430613986,
      "grad_norm": 3.7322819232940674,
      "learning_rate": 2.52034912229087e-05,
      "logits/chosen": 3.624122142791748,
      "logits/rejected": 3.6511504650115967,
      "logps/chosen": -394.3664245605469,
      "logps/rejected": -319.9468688964844,
      "loss": 0.2059,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.011038303375244,
      "rewards/margins": 3.943371534347534,
      "rewards/rejected": -5.954410076141357,
      "step": 25300
    },
    {
      "epoch": 1.4898061251507753,
      "grad_norm": 6.847368240356445,
      "learning_rate": 2.518387761106208e-05,
      "logits/chosen": 3.517817258834839,
      "logits/rejected": 3.559640884399414,
      "logps/chosen": -378.3858947753906,
      "logps/rejected": -309.34210205078125,
      "loss": 0.3594,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1517767906188965,
      "rewards/margins": 3.229050397872925,
      "rewards/rejected": -5.3808274269104,
      "step": 25320
    },
    {
      "epoch": 1.4909829072401517,
      "grad_norm": 1.9696080684661865,
      "learning_rate": 2.5164263999215458e-05,
      "logits/chosen": 3.772303819656372,
      "logits/rejected": 3.7114453315734863,
      "logps/chosen": -415.76495361328125,
      "logps/rejected": -372.8704833984375,
      "loss": 0.5265,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.413444995880127,
      "rewards/margins": 3.7828052043914795,
      "rewards/rejected": -6.196249961853027,
      "step": 25340
    },
    {
      "epoch": 1.4921596893295284,
      "grad_norm": 0.6978523135185242,
      "learning_rate": 2.5144650387368834e-05,
      "logits/chosen": 3.585768461227417,
      "logits/rejected": 3.776179790496826,
      "logps/chosen": -408.2441711425781,
      "logps/rejected": -346.5774841308594,
      "loss": 0.392,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.036374568939209,
      "rewards/margins": 3.7469444274902344,
      "rewards/rejected": -5.783318996429443,
      "step": 25360
    },
    {
      "epoch": 1.493336471418905,
      "grad_norm": 0.6066138744354248,
      "learning_rate": 2.5125036775522214e-05,
      "logits/chosen": 3.9155056476593018,
      "logits/rejected": 3.815359115600586,
      "logps/chosen": -403.2084045410156,
      "logps/rejected": -350.9267578125,
      "loss": 0.2803,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.2944536209106445,
      "rewards/margins": 3.703925609588623,
      "rewards/rejected": -5.998379707336426,
      "step": 25380
    },
    {
      "epoch": 1.4945132535082817,
      "grad_norm": 1.5031332969665527,
      "learning_rate": 2.510542316367559e-05,
      "logits/chosen": 3.8361289501190186,
      "logits/rejected": 3.808035373687744,
      "logps/chosen": -371.5429382324219,
      "logps/rejected": -322.93707275390625,
      "loss": 0.3142,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.1792235374450684,
      "rewards/margins": 3.4914252758026123,
      "rewards/rejected": -5.670648574829102,
      "step": 25400
    },
    {
      "epoch": 1.4956900355976583,
      "grad_norm": 1.5894596576690674,
      "learning_rate": 2.508580955182897e-05,
      "logits/chosen": 3.4821648597717285,
      "logits/rejected": 3.559804916381836,
      "logps/chosen": -380.7987365722656,
      "logps/rejected": -324.8522033691406,
      "loss": 0.2805,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.052438259124756,
      "rewards/margins": 3.86669921875,
      "rewards/rejected": -5.919137001037598,
      "step": 25420
    },
    {
      "epoch": 1.4968668176870348,
      "grad_norm": 0.842541515827179,
      "learning_rate": 2.5066195939982352e-05,
      "logits/chosen": 3.492729663848877,
      "logits/rejected": 3.5336861610412598,
      "logps/chosen": -363.4367980957031,
      "logps/rejected": -323.15411376953125,
      "loss": 0.1692,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.772099733352661,
      "rewards/margins": 3.8293094635009766,
      "rewards/rejected": -6.601409912109375,
      "step": 25440
    },
    {
      "epoch": 1.4980435997764114,
      "grad_norm": 1.2643705606460571,
      "learning_rate": 2.5046582328135725e-05,
      "logits/chosen": 3.9175868034362793,
      "logits/rejected": 3.806786298751831,
      "logps/chosen": -464.98870849609375,
      "logps/rejected": -377.5142822265625,
      "loss": 0.2876,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.46692156791687,
      "rewards/margins": 4.205195903778076,
      "rewards/rejected": -6.672118186950684,
      "step": 25460
    },
    {
      "epoch": 1.499220381865788,
      "grad_norm": 3.0151889324188232,
      "learning_rate": 2.5026968716289107e-05,
      "logits/chosen": 3.791661024093628,
      "logits/rejected": 3.6900038719177246,
      "logps/chosen": -430.4269104003906,
      "logps/rejected": -404.33306884765625,
      "loss": 0.3998,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.00989031791687,
      "rewards/margins": 4.948976039886475,
      "rewards/rejected": -6.958866119384766,
      "step": 25480
    },
    {
      "epoch": 1.5003971639551645,
      "grad_norm": 3.7374074459075928,
      "learning_rate": 2.5007355104442487e-05,
      "logits/chosen": 3.869903087615967,
      "logits/rejected": 3.8454315662384033,
      "logps/chosen": -392.59796142578125,
      "logps/rejected": -313.30938720703125,
      "loss": 0.2055,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.9690420627593994,
      "rewards/margins": 4.268290996551514,
      "rewards/rejected": -6.237332820892334,
      "step": 25500
    },
    {
      "epoch": 1.5015739460445412,
      "grad_norm": 0.5641962289810181,
      "learning_rate": 2.4987741492595863e-05,
      "logits/chosen": 3.7381935119628906,
      "logits/rejected": 3.608788013458252,
      "logps/chosen": -417.134033203125,
      "logps/rejected": -311.33905029296875,
      "loss": 0.2077,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.5493102073669434,
      "rewards/margins": 4.312983512878418,
      "rewards/rejected": -5.8622941970825195,
      "step": 25520
    },
    {
      "epoch": 1.5027507281339179,
      "grad_norm": 2.9191925525665283,
      "learning_rate": 2.4968127880749242e-05,
      "logits/chosen": 3.750814437866211,
      "logits/rejected": 3.7177627086639404,
      "logps/chosen": -360.90008544921875,
      "logps/rejected": -371.37176513671875,
      "loss": 0.1782,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.7867350578308105,
      "rewards/margins": 4.409436225891113,
      "rewards/rejected": -7.196170806884766,
      "step": 25540
    },
    {
      "epoch": 1.5039275102232943,
      "grad_norm": 1.0310049057006836,
      "learning_rate": 2.4948514268902622e-05,
      "logits/chosen": 3.763545274734497,
      "logits/rejected": 3.731177568435669,
      "logps/chosen": -406.48529052734375,
      "logps/rejected": -336.9964904785156,
      "loss": 0.1886,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.3687262535095215,
      "rewards/margins": 4.194517612457275,
      "rewards/rejected": -6.563243865966797,
      "step": 25560
    },
    {
      "epoch": 1.505104292312671,
      "grad_norm": 5.096530914306641,
      "learning_rate": 2.4928900657055998e-05,
      "logits/chosen": 3.397674560546875,
      "logits/rejected": 3.4040706157684326,
      "logps/chosen": -380.4908752441406,
      "logps/rejected": -339.5300598144531,
      "loss": 0.3656,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2713968753814697,
      "rewards/margins": 3.8020126819610596,
      "rewards/rejected": -6.073409080505371,
      "step": 25580
    },
    {
      "epoch": 1.5062810744020476,
      "grad_norm": 2.1090071201324463,
      "learning_rate": 2.4909287045209377e-05,
      "logits/chosen": 3.5355911254882812,
      "logits/rejected": 3.51786732673645,
      "logps/chosen": -421.591552734375,
      "logps/rejected": -347.51214599609375,
      "loss": 0.2104,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.1772369146347046,
      "rewards/margins": 5.0701003074646,
      "rewards/rejected": -6.2473368644714355,
      "step": 25600
    },
    {
      "epoch": 1.507457856491424,
      "grad_norm": 3.8013551235198975,
      "learning_rate": 2.4889673433362757e-05,
      "logits/chosen": 3.654745578765869,
      "logits/rejected": 3.6999428272247314,
      "logps/chosen": -394.61492919921875,
      "logps/rejected": -335.90081787109375,
      "loss": 0.614,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.30692720413208,
      "rewards/margins": 2.585970878601074,
      "rewards/rejected": -4.892898082733154,
      "step": 25620
    },
    {
      "epoch": 1.508634638580801,
      "grad_norm": 2.1518478393554688,
      "learning_rate": 2.4870059821516133e-05,
      "logits/chosen": 3.5655605792999268,
      "logits/rejected": 3.494166612625122,
      "logps/chosen": -390.30364990234375,
      "logps/rejected": -332.8934020996094,
      "loss": 0.245,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.4674603939056396,
      "rewards/margins": 3.9526114463806152,
      "rewards/rejected": -5.420071601867676,
      "step": 25640
    },
    {
      "epoch": 1.5098114206701774,
      "grad_norm": 3.2281882762908936,
      "learning_rate": 2.4850446209669512e-05,
      "logits/chosen": 3.5023276805877686,
      "logits/rejected": 3.5418975353240967,
      "logps/chosen": -384.96051025390625,
      "logps/rejected": -346.3094177246094,
      "loss": 0.2918,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8169667720794678,
      "rewards/margins": 3.487550735473633,
      "rewards/rejected": -5.3045172691345215,
      "step": 25660
    },
    {
      "epoch": 1.510988202759554,
      "grad_norm": 2.5477423667907715,
      "learning_rate": 2.4830832597822888e-05,
      "logits/chosen": 3.7159106731414795,
      "logits/rejected": 3.745479106903076,
      "logps/chosen": -376.3424072265625,
      "logps/rejected": -334.3416442871094,
      "loss": 0.2681,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.0354959964752197,
      "rewards/margins": 4.118424415588379,
      "rewards/rejected": -5.153919696807861,
      "step": 25680
    },
    {
      "epoch": 1.5121649848489307,
      "grad_norm": 0.8672751188278198,
      "learning_rate": 2.481121898597627e-05,
      "logits/chosen": 3.8551833629608154,
      "logits/rejected": 3.7679524421691895,
      "logps/chosen": -409.7679138183594,
      "logps/rejected": -336.29693603515625,
      "loss": 0.3667,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8649765253067017,
      "rewards/margins": 4.021590709686279,
      "rewards/rejected": -4.886567115783691,
      "step": 25700
    },
    {
      "epoch": 1.5133417669383071,
      "grad_norm": 1.5739774703979492,
      "learning_rate": 2.4791605374129647e-05,
      "logits/chosen": 3.6650307178497314,
      "logits/rejected": 3.661492109298706,
      "logps/chosen": -402.0863037109375,
      "logps/rejected": -315.0899353027344,
      "loss": 0.6923,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.675684928894043,
      "rewards/margins": 2.8037822246551514,
      "rewards/rejected": -4.479466915130615,
      "step": 25720
    },
    {
      "epoch": 1.5145185490276838,
      "grad_norm": 1.0162336826324463,
      "learning_rate": 2.4771991762283026e-05,
      "logits/chosen": 3.698469638824463,
      "logits/rejected": 3.5474772453308105,
      "logps/chosen": -355.38043212890625,
      "logps/rejected": -336.47296142578125,
      "loss": 0.3246,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3275789022445679,
      "rewards/margins": 3.5102386474609375,
      "rewards/rejected": -4.837817668914795,
      "step": 25740
    },
    {
      "epoch": 1.5156953311170605,
      "grad_norm": 0.6822739839553833,
      "learning_rate": 2.4752378150436402e-05,
      "logits/chosen": 3.9491515159606934,
      "logits/rejected": 3.705646514892578,
      "logps/chosen": -423.7632751464844,
      "logps/rejected": -363.07135009765625,
      "loss": 0.379,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.1487683057785034,
      "rewards/margins": 3.9085094928741455,
      "rewards/rejected": -5.057277679443359,
      "step": 25760
    },
    {
      "epoch": 1.516872113206437,
      "grad_norm": 1.0969226360321045,
      "learning_rate": 2.4732764538589785e-05,
      "logits/chosen": 3.6595866680145264,
      "logits/rejected": 3.7704920768737793,
      "logps/chosen": -392.8786926269531,
      "logps/rejected": -358.571044921875,
      "loss": 0.2218,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.208701729774475,
      "rewards/margins": 4.3632917404174805,
      "rewards/rejected": -5.571993350982666,
      "step": 25780
    },
    {
      "epoch": 1.5180488952958135,
      "grad_norm": 5.114955425262451,
      "learning_rate": 2.471315092674316e-05,
      "logits/chosen": 3.953604221343994,
      "logits/rejected": 3.8459548950195312,
      "logps/chosen": -404.1521911621094,
      "logps/rejected": -360.0948486328125,
      "loss": 0.39,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5161397457122803,
      "rewards/margins": 3.738617420196533,
      "rewards/rejected": -5.254756927490234,
      "step": 25800
    },
    {
      "epoch": 1.5192256773851902,
      "grad_norm": 3.1158478260040283,
      "learning_rate": 2.469353731489654e-05,
      "logits/chosen": 3.8955695629119873,
      "logits/rejected": 3.7762742042541504,
      "logps/chosen": -406.8677673339844,
      "logps/rejected": -352.25897216796875,
      "loss": 0.3774,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8796565532684326,
      "rewards/margins": 3.895305633544922,
      "rewards/rejected": -5.774961948394775,
      "step": 25820
    },
    {
      "epoch": 1.5204024594745666,
      "grad_norm": 1.44098699092865,
      "learning_rate": 2.4673923703049917e-05,
      "logits/chosen": 3.6419010162353516,
      "logits/rejected": 3.4999001026153564,
      "logps/chosen": -363.9283447265625,
      "logps/rejected": -322.9416809082031,
      "loss": 0.2914,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.7661011219024658,
      "rewards/margins": 3.501513719558716,
      "rewards/rejected": -5.267614841461182,
      "step": 25840
    },
    {
      "epoch": 1.5215792415639435,
      "grad_norm": 3.509587049484253,
      "learning_rate": 2.4654310091203296e-05,
      "logits/chosen": 3.797609806060791,
      "logits/rejected": 3.639441728591919,
      "logps/chosen": -392.3901062011719,
      "logps/rejected": -330.22637939453125,
      "loss": 0.3601,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.73761785030365,
      "rewards/margins": 3.8614959716796875,
      "rewards/rejected": -5.599113464355469,
      "step": 25860
    },
    {
      "epoch": 1.52275602365332,
      "grad_norm": 5.130529403686523,
      "learning_rate": 2.4634696479356676e-05,
      "logits/chosen": 3.7387633323669434,
      "logits/rejected": 3.5465493202209473,
      "logps/chosen": -381.550537109375,
      "logps/rejected": -314.1038513183594,
      "loss": 0.3592,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.006967782974243,
      "rewards/margins": 3.1130805015563965,
      "rewards/rejected": -5.120048522949219,
      "step": 25880
    },
    {
      "epoch": 1.5239328057426966,
      "grad_norm": 4.295003414154053,
      "learning_rate": 2.4615082867510052e-05,
      "logits/chosen": 3.370723247528076,
      "logits/rejected": 3.400134563446045,
      "logps/chosen": -330.96697998046875,
      "logps/rejected": -300.2813415527344,
      "loss": 0.2438,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.7025238275527954,
      "rewards/margins": 3.5324063301086426,
      "rewards/rejected": -5.234930515289307,
      "step": 25900
    },
    {
      "epoch": 1.5251095878320733,
      "grad_norm": 2.886644124984741,
      "learning_rate": 2.459546925566343e-05,
      "logits/chosen": 3.347959041595459,
      "logits/rejected": 3.488203525543213,
      "logps/chosen": -331.2815246582031,
      "logps/rejected": -272.6201477050781,
      "loss": 0.358,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8592264652252197,
      "rewards/margins": 2.773510456085205,
      "rewards/rejected": -4.632737159729004,
      "step": 25920
    },
    {
      "epoch": 1.5262863699214497,
      "grad_norm": 7.288730144500732,
      "learning_rate": 2.457585564381681e-05,
      "logits/chosen": 3.623361587524414,
      "logits/rejected": 3.6353511810302734,
      "logps/chosen": -382.5312194824219,
      "logps/rejected": -342.9822082519531,
      "loss": 0.2563,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1369855403900146,
      "rewards/margins": 4.470810413360596,
      "rewards/rejected": -5.6077961921691895,
      "step": 25940
    },
    {
      "epoch": 1.5274631520108264,
      "grad_norm": 1.0608062744140625,
      "learning_rate": 2.455624203197019e-05,
      "logits/chosen": 3.9886367321014404,
      "logits/rejected": 3.759441375732422,
      "logps/chosen": -431.38165283203125,
      "logps/rejected": -291.6236572265625,
      "loss": 0.3479,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.7816803455352783,
      "rewards/margins": 3.4483864307403564,
      "rewards/rejected": -5.230067253112793,
      "step": 25960
    },
    {
      "epoch": 1.528639934100203,
      "grad_norm": 2.0916430950164795,
      "learning_rate": 2.4536628420123566e-05,
      "logits/chosen": 3.609800338745117,
      "logits/rejected": 3.6462676525115967,
      "logps/chosen": -364.32879638671875,
      "logps/rejected": -292.0838317871094,
      "loss": 0.4143,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6973518133163452,
      "rewards/margins": 3.3825714588165283,
      "rewards/rejected": -5.079923152923584,
      "step": 25980
    },
    {
      "epoch": 1.5298167161895795,
      "grad_norm": 1.1629102230072021,
      "learning_rate": 2.4517014808276945e-05,
      "logits/chosen": 3.4597392082214355,
      "logits/rejected": 3.637861728668213,
      "logps/chosen": -381.38055419921875,
      "logps/rejected": -413.95587158203125,
      "loss": 0.4086,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.5645724534988403,
      "rewards/margins": 3.489253282546997,
      "rewards/rejected": -5.053826332092285,
      "step": 26000
    },
    {
      "epoch": 1.5309934982789561,
      "grad_norm": 1.0723084211349487,
      "learning_rate": 2.4497401196430325e-05,
      "logits/chosen": 3.9171395301818848,
      "logits/rejected": 3.6668529510498047,
      "logps/chosen": -388.3243713378906,
      "logps/rejected": -321.1138610839844,
      "loss": 0.3409,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.071397304534912,
      "rewards/margins": 3.7521698474884033,
      "rewards/rejected": -5.823566913604736,
      "step": 26020
    },
    {
      "epoch": 1.5321702803683328,
      "grad_norm": 4.078895092010498,
      "learning_rate": 2.4477787584583704e-05,
      "logits/chosen": 3.6763317584991455,
      "logits/rejected": 3.4625751972198486,
      "logps/chosen": -370.65032958984375,
      "logps/rejected": -315.9942321777344,
      "loss": 0.3677,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9206069707870483,
      "rewards/margins": 3.328618288040161,
      "rewards/rejected": -5.24922513961792,
      "step": 26040
    },
    {
      "epoch": 1.5333470624577092,
      "grad_norm": 2.481365203857422,
      "learning_rate": 2.445817397273708e-05,
      "logits/chosen": 3.802030563354492,
      "logits/rejected": 3.7306766510009766,
      "logps/chosen": -387.01177978515625,
      "logps/rejected": -352.31988525390625,
      "loss": 0.2379,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4505366086959839,
      "rewards/margins": 3.953200578689575,
      "rewards/rejected": -5.4037370681762695,
      "step": 26060
    },
    {
      "epoch": 1.5345238445470861,
      "grad_norm": 3.146061897277832,
      "learning_rate": 2.443856036089046e-05,
      "logits/chosen": 3.748563289642334,
      "logits/rejected": 3.8120460510253906,
      "logps/chosen": -382.8124084472656,
      "logps/rejected": -358.18017578125,
      "loss": 0.2976,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.8899925351142883,
      "rewards/margins": 3.5293128490448,
      "rewards/rejected": -4.419305801391602,
      "step": 26080
    },
    {
      "epoch": 1.5357006266364626,
      "grad_norm": 2.228989839553833,
      "learning_rate": 2.441894674904384e-05,
      "logits/chosen": 3.5373451709747314,
      "logits/rejected": 3.512700319290161,
      "logps/chosen": -354.267578125,
      "logps/rejected": -321.02984619140625,
      "loss": 0.3845,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6177657842636108,
      "rewards/margins": 2.713768720626831,
      "rewards/rejected": -4.331534385681152,
      "step": 26100
    },
    {
      "epoch": 1.5368774087258392,
      "grad_norm": 3.4118170738220215,
      "learning_rate": 2.4399333137197215e-05,
      "logits/chosen": 3.641848087310791,
      "logits/rejected": 3.566035509109497,
      "logps/chosen": -376.4418640136719,
      "logps/rejected": -350.58099365234375,
      "loss": 0.403,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4989571571350098,
      "rewards/margins": 2.7795612812042236,
      "rewards/rejected": -4.2785186767578125,
      "step": 26120
    },
    {
      "epoch": 1.5380541908152159,
      "grad_norm": 2.238018274307251,
      "learning_rate": 2.4379719525350595e-05,
      "logits/chosen": 3.866424083709717,
      "logits/rejected": 3.849216938018799,
      "logps/chosen": -379.76568603515625,
      "logps/rejected": -314.62969970703125,
      "loss": 0.1961,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0690844058990479,
      "rewards/margins": 3.684542179107666,
      "rewards/rejected": -4.753626823425293,
      "step": 26140
    },
    {
      "epoch": 1.5392309729045923,
      "grad_norm": 3.7288198471069336,
      "learning_rate": 2.436010591350397e-05,
      "logits/chosen": 3.721980333328247,
      "logits/rejected": 3.69620943069458,
      "logps/chosen": -365.6626892089844,
      "logps/rejected": -342.4453125,
      "loss": 0.311,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.1100952625274658,
      "rewards/margins": 3.661743640899658,
      "rewards/rejected": -4.771839141845703,
      "step": 26160
    },
    {
      "epoch": 1.540407754993969,
      "grad_norm": 0.67735356092453,
      "learning_rate": 2.4340492301657354e-05,
      "logits/chosen": 3.8641021251678467,
      "logits/rejected": 3.981442928314209,
      "logps/chosen": -405.399658203125,
      "logps/rejected": -339.79052734375,
      "loss": 0.2497,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -0.8195812106132507,
      "rewards/margins": 3.573141098022461,
      "rewards/rejected": -4.392722129821777,
      "step": 26180
    },
    {
      "epoch": 1.5415845370833456,
      "grad_norm": 2.9894840717315674,
      "learning_rate": 2.432087868981073e-05,
      "logits/chosen": 3.9090797901153564,
      "logits/rejected": 3.632106304168701,
      "logps/chosen": -387.1202697753906,
      "logps/rejected": -292.0085754394531,
      "loss": 0.3118,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3393535614013672,
      "rewards/margins": 3.1347427368164062,
      "rewards/rejected": -4.474095821380615,
      "step": 26200
    },
    {
      "epoch": 1.542761319172722,
      "grad_norm": 1.8385964632034302,
      "learning_rate": 2.430126507796411e-05,
      "logits/chosen": 3.601167678833008,
      "logits/rejected": 3.617974042892456,
      "logps/chosen": -397.93084716796875,
      "logps/rejected": -321.18988037109375,
      "loss": 0.2945,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.40014418959617615,
      "rewards/margins": 4.118784427642822,
      "rewards/rejected": -4.518927574157715,
      "step": 26220
    },
    {
      "epoch": 1.5439381012620987,
      "grad_norm": 3.165531635284424,
      "learning_rate": 2.4281651466117485e-05,
      "logits/chosen": 3.876575469970703,
      "logits/rejected": 3.926058292388916,
      "logps/chosen": -392.9493408203125,
      "logps/rejected": -334.3990783691406,
      "loss": 0.4364,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.3060500621795654,
      "rewards/margins": 3.642092227935791,
      "rewards/rejected": -4.948141574859619,
      "step": 26240
    },
    {
      "epoch": 1.5451148833514754,
      "grad_norm": 0.9776137471199036,
      "learning_rate": 2.4262037854270868e-05,
      "logits/chosen": 3.5615105628967285,
      "logits/rejected": 3.521049976348877,
      "logps/chosen": -359.7124938964844,
      "logps/rejected": -325.748779296875,
      "loss": 0.358,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.5322996377944946,
      "rewards/margins": 3.0045228004455566,
      "rewards/rejected": -4.536822319030762,
      "step": 26260
    },
    {
      "epoch": 1.5462916654408518,
      "grad_norm": 1.2928696870803833,
      "learning_rate": 2.4242424242424244e-05,
      "logits/chosen": 3.9482269287109375,
      "logits/rejected": 3.8036201000213623,
      "logps/chosen": -382.76373291015625,
      "logps/rejected": -325.77130126953125,
      "loss": 0.2641,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.246946096420288,
      "rewards/margins": 4.440188407897949,
      "rewards/rejected": -5.687134265899658,
      "step": 26280
    },
    {
      "epoch": 1.5474684475302287,
      "grad_norm": 2.450237512588501,
      "learning_rate": 2.4222810630577623e-05,
      "logits/chosen": 3.7224936485290527,
      "logits/rejected": 3.7971367835998535,
      "logps/chosen": -376.80218505859375,
      "logps/rejected": -367.09075927734375,
      "loss": 0.3042,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8111121654510498,
      "rewards/margins": 3.9864959716796875,
      "rewards/rejected": -5.797608375549316,
      "step": 26300
    },
    {
      "epoch": 1.5486452296196052,
      "grad_norm": 27.96958351135254,
      "learning_rate": 2.4203197018731e-05,
      "logits/chosen": 3.6292240619659424,
      "logits/rejected": 3.7001450061798096,
      "logps/chosen": -378.3313903808594,
      "logps/rejected": -301.5555725097656,
      "loss": 0.2395,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.5876994132995605,
      "rewards/margins": 3.2648391723632812,
      "rewards/rejected": -4.852538108825684,
      "step": 26320
    },
    {
      "epoch": 1.5498220117089818,
      "grad_norm": 3.817540168762207,
      "learning_rate": 2.418358340688438e-05,
      "logits/chosen": 3.5316853523254395,
      "logits/rejected": 3.675261974334717,
      "logps/chosen": -397.6329040527344,
      "logps/rejected": -311.86236572265625,
      "loss": 0.3089,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7594181299209595,
      "rewards/margins": 3.718825578689575,
      "rewards/rejected": -5.478243827819824,
      "step": 26340
    },
    {
      "epoch": 1.5509987937983585,
      "grad_norm": 1.1305575370788574,
      "learning_rate": 2.4163969795037758e-05,
      "logits/chosen": 3.7589659690856934,
      "logits/rejected": 3.8213272094726562,
      "logps/chosen": -406.0001525878906,
      "logps/rejected": -375.8544006347656,
      "loss": 0.2914,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.031583309173584,
      "rewards/margins": 3.844757556915283,
      "rewards/rejected": -5.876340389251709,
      "step": 26360
    },
    {
      "epoch": 1.552175575887735,
      "grad_norm": 2.2326509952545166,
      "learning_rate": 2.4144356183191134e-05,
      "logits/chosen": 3.484630584716797,
      "logits/rejected": 3.5611133575439453,
      "logps/chosen": -406.8139953613281,
      "logps/rejected": -316.27252197265625,
      "loss": 0.3233,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.5227508544921875,
      "rewards/margins": 3.95267915725708,
      "rewards/rejected": -5.475430011749268,
      "step": 26380
    },
    {
      "epoch": 1.5533523579771116,
      "grad_norm": 0.2585912048816681,
      "learning_rate": 2.4124742571344514e-05,
      "logits/chosen": 3.7745909690856934,
      "logits/rejected": 3.616940975189209,
      "logps/chosen": -400.619873046875,
      "logps/rejected": -338.939453125,
      "loss": 0.2752,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9503271579742432,
      "rewards/margins": 4.062794208526611,
      "rewards/rejected": -6.013121604919434,
      "step": 26400
    },
    {
      "epoch": 1.5545291400664882,
      "grad_norm": 3.094109058380127,
      "learning_rate": 2.4105128959497893e-05,
      "logits/chosen": 3.6270358562469482,
      "logits/rejected": 3.6871986389160156,
      "logps/chosen": -417.71356201171875,
      "logps/rejected": -328.4699401855469,
      "loss": 0.3272,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1492373943328857,
      "rewards/margins": 3.8313026428222656,
      "rewards/rejected": -5.980539798736572,
      "step": 26420
    },
    {
      "epoch": 1.5557059221558647,
      "grad_norm": 2.318673610687256,
      "learning_rate": 2.4085515347651273e-05,
      "logits/chosen": 4.155763149261475,
      "logits/rejected": 3.938037395477295,
      "logps/chosen": -425.54669189453125,
      "logps/rejected": -338.0627136230469,
      "loss": 0.2691,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.882315993309021,
      "rewards/margins": 4.438751220703125,
      "rewards/rejected": -6.321066856384277,
      "step": 26440
    },
    {
      "epoch": 1.5568827042452413,
      "grad_norm": 1.8898168802261353,
      "learning_rate": 2.406590173580465e-05,
      "logits/chosen": 3.4963059425354004,
      "logits/rejected": 3.529574155807495,
      "logps/chosen": -398.8493347167969,
      "logps/rejected": -369.30389404296875,
      "loss": 0.2123,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3646411895751953,
      "rewards/margins": 4.309714317321777,
      "rewards/rejected": -5.674355506896973,
      "step": 26460
    },
    {
      "epoch": 1.558059486334618,
      "grad_norm": 2.392026901245117,
      "learning_rate": 2.4046288123958028e-05,
      "logits/chosen": 3.274151563644409,
      "logits/rejected": 3.376077175140381,
      "logps/chosen": -370.37738037109375,
      "logps/rejected": -307.71221923828125,
      "loss": 0.2939,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.261075019836426,
      "rewards/margins": 3.897160053253174,
      "rewards/rejected": -6.158234596252441,
      "step": 26480
    },
    {
      "epoch": 1.5592362684239944,
      "grad_norm": 4.157493591308594,
      "learning_rate": 2.4026674512111407e-05,
      "logits/chosen": 3.7451939582824707,
      "logits/rejected": 3.6535160541534424,
      "logps/chosen": -389.84698486328125,
      "logps/rejected": -379.6507263183594,
      "loss": 0.4518,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.389585018157959,
      "rewards/margins": 3.367011308670044,
      "rewards/rejected": -5.756596565246582,
      "step": 26500
    },
    {
      "epoch": 1.5604130505133713,
      "grad_norm": 4.603585243225098,
      "learning_rate": 2.4007060900264787e-05,
      "logits/chosen": 3.8158061504364014,
      "logits/rejected": 3.6239593029022217,
      "logps/chosen": -392.88323974609375,
      "logps/rejected": -358.3885192871094,
      "loss": 0.2919,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.7462167739868164,
      "rewards/margins": 4.27396297454834,
      "rewards/rejected": -7.020179748535156,
      "step": 26520
    },
    {
      "epoch": 1.5615898326027478,
      "grad_norm": 2.486888885498047,
      "learning_rate": 2.3987447288418163e-05,
      "logits/chosen": 3.479583263397217,
      "logits/rejected": 3.3846611976623535,
      "logps/chosen": -368.2845153808594,
      "logps/rejected": -329.45184326171875,
      "loss": 0.286,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.121246576309204,
      "rewards/margins": 4.057055950164795,
      "rewards/rejected": -6.178302764892578,
      "step": 26540
    },
    {
      "epoch": 1.5627666146921244,
      "grad_norm": 2.642165184020996,
      "learning_rate": 2.3967833676571542e-05,
      "logits/chosen": 3.541109085083008,
      "logits/rejected": 3.5163331031799316,
      "logps/chosen": -418.89190673828125,
      "logps/rejected": -411.8380432128906,
      "loss": 0.4313,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.573906660079956,
      "rewards/margins": 4.340603351593018,
      "rewards/rejected": -6.914510250091553,
      "step": 26560
    },
    {
      "epoch": 1.563943396781501,
      "grad_norm": 1.525638222694397,
      "learning_rate": 2.394822006472492e-05,
      "logits/chosen": 4.023217678070068,
      "logits/rejected": 3.8289318084716797,
      "logps/chosen": -443.85540771484375,
      "logps/rejected": -331.79718017578125,
      "loss": 0.2776,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.85873544216156,
      "rewards/margins": 3.5958352088928223,
      "rewards/rejected": -5.454570293426514,
      "step": 26580
    },
    {
      "epoch": 1.5651201788708775,
      "grad_norm": 6.190469741821289,
      "learning_rate": 2.3928606452878298e-05,
      "logits/chosen": 3.5442137718200684,
      "logits/rejected": 3.505882740020752,
      "logps/chosen": -381.63787841796875,
      "logps/rejected": -333.91522216796875,
      "loss": 0.4879,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.19684100151062,
      "rewards/margins": 2.794539451599121,
      "rewards/rejected": -4.9913811683654785,
      "step": 26600
    },
    {
      "epoch": 1.5662969609602542,
      "grad_norm": 0.4903973937034607,
      "learning_rate": 2.3908992841031677e-05,
      "logits/chosen": 3.514730453491211,
      "logits/rejected": 3.5586159229278564,
      "logps/chosen": -381.49200439453125,
      "logps/rejected": -340.43890380859375,
      "loss": 0.236,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.2691256999969482,
      "rewards/margins": 3.473273515701294,
      "rewards/rejected": -5.7423996925354,
      "step": 26620
    },
    {
      "epoch": 1.5674737430496308,
      "grad_norm": 0.5091862082481384,
      "learning_rate": 2.3889379229185053e-05,
      "logits/chosen": 3.4887681007385254,
      "logits/rejected": 3.338289976119995,
      "logps/chosen": -398.09454345703125,
      "logps/rejected": -356.20843505859375,
      "loss": 0.1724,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.3662383556365967,
      "rewards/margins": 4.18033504486084,
      "rewards/rejected": -6.546573638916016,
      "step": 26640
    },
    {
      "epoch": 1.5686505251390073,
      "grad_norm": 1.371965765953064,
      "learning_rate": 2.3869765617338433e-05,
      "logits/chosen": 3.7881627082824707,
      "logits/rejected": 3.582624912261963,
      "logps/chosen": -426.5780334472656,
      "logps/rejected": -321.3338928222656,
      "loss": 0.2598,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.1702468395233154,
      "rewards/margins": 4.617918968200684,
      "rewards/rejected": -6.7881669998168945,
      "step": 26660
    },
    {
      "epoch": 1.5698273072283842,
      "grad_norm": 1.1941051483154297,
      "learning_rate": 2.3850152005491812e-05,
      "logits/chosen": 3.5336341857910156,
      "logits/rejected": 3.4785823822021484,
      "logps/chosen": -410.599609375,
      "logps/rejected": -327.02239990234375,
      "loss": 0.2611,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.6670690774917603,
      "rewards/margins": 4.456178188323975,
      "rewards/rejected": -6.123247146606445,
      "step": 26680
    },
    {
      "epoch": 1.5710040893177606,
      "grad_norm": 5.375471591949463,
      "learning_rate": 2.383053839364519e-05,
      "logits/chosen": 3.369743824005127,
      "logits/rejected": 3.3218472003936768,
      "logps/chosen": -342.1236267089844,
      "logps/rejected": -348.2571716308594,
      "loss": 0.3691,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.0501396656036377,
      "rewards/margins": 3.2638981342315674,
      "rewards/rejected": -5.314037799835205,
      "step": 26700
    },
    {
      "epoch": 1.572180871407137,
      "grad_norm": 0.8782963752746582,
      "learning_rate": 2.3810924781798568e-05,
      "logits/chosen": 3.8389198780059814,
      "logits/rejected": 3.7112255096435547,
      "logps/chosen": -419.30267333984375,
      "logps/rejected": -349.0732116699219,
      "loss": 0.2363,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.471760869026184,
      "rewards/margins": 4.099581718444824,
      "rewards/rejected": -5.571342945098877,
      "step": 26720
    },
    {
      "epoch": 1.573357653496514,
      "grad_norm": 4.176543712615967,
      "learning_rate": 2.3791311169951947e-05,
      "logits/chosen": 3.2872231006622314,
      "logits/rejected": 3.479640245437622,
      "logps/chosen": -369.8720397949219,
      "logps/rejected": -330.2486572265625,
      "loss": 0.344,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.067176580429077,
      "rewards/margins": 3.5466346740722656,
      "rewards/rejected": -5.6138105392456055,
      "step": 26740
    },
    {
      "epoch": 1.5745344355858903,
      "grad_norm": 1.0329087972640991,
      "learning_rate": 2.3771697558105326e-05,
      "logits/chosen": 3.5311837196350098,
      "logits/rejected": 3.4360218048095703,
      "logps/chosen": -422.86859130859375,
      "logps/rejected": -340.83782958984375,
      "loss": 0.2625,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.103079080581665,
      "rewards/margins": 5.4709954261779785,
      "rewards/rejected": -6.574074745178223,
      "step": 26760
    },
    {
      "epoch": 1.575711217675267,
      "grad_norm": 9.188688278198242,
      "learning_rate": 2.3752083946258706e-05,
      "logits/chosen": 3.9227569103240967,
      "logits/rejected": 3.8879570960998535,
      "logps/chosen": -463.4676818847656,
      "logps/rejected": -356.5935974121094,
      "loss": 0.2856,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.8985726833343506,
      "rewards/margins": 4.115294933319092,
      "rewards/rejected": -6.013867378234863,
      "step": 26780
    },
    {
      "epoch": 1.5768879997646437,
      "grad_norm": 4.131195068359375,
      "learning_rate": 2.3732470334412082e-05,
      "logits/chosen": 4.066100120544434,
      "logits/rejected": 3.9635283946990967,
      "logps/chosen": -390.8893127441406,
      "logps/rejected": -344.89263916015625,
      "loss": 0.2896,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.039173126220703,
      "rewards/margins": 3.702601194381714,
      "rewards/rejected": -5.741774559020996,
      "step": 26800
    },
    {
      "epoch": 1.57806478185402,
      "grad_norm": 4.290042877197266,
      "learning_rate": 2.371285672256546e-05,
      "logits/chosen": 3.691455841064453,
      "logits/rejected": 3.552886962890625,
      "logps/chosen": -403.1669006347656,
      "logps/rejected": -315.1444396972656,
      "loss": 0.3935,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.8610165119171143,
      "rewards/margins": 3.975490093231201,
      "rewards/rejected": -5.836506366729736,
      "step": 26820
    },
    {
      "epoch": 1.5792415639433968,
      "grad_norm": 3.4084434509277344,
      "learning_rate": 2.369324311071884e-05,
      "logits/chosen": 3.6325676441192627,
      "logits/rejected": 3.6473095417022705,
      "logps/chosen": -367.138916015625,
      "logps/rejected": -318.8231201171875,
      "loss": 0.3854,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4291324615478516,
      "rewards/margins": 3.2989227771759033,
      "rewards/rejected": -5.728055000305176,
      "step": 26840
    },
    {
      "epoch": 1.5804183460327734,
      "grad_norm": 4.220425128936768,
      "learning_rate": 2.3673629498872217e-05,
      "logits/chosen": 3.123828649520874,
      "logits/rejected": 3.2787299156188965,
      "logps/chosen": -380.52203369140625,
      "logps/rejected": -305.28173828125,
      "loss": 0.3066,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9065593481063843,
      "rewards/margins": 4.314986228942871,
      "rewards/rejected": -6.221545219421387,
      "step": 26860
    },
    {
      "epoch": 1.5815951281221499,
      "grad_norm": 4.509390354156494,
      "learning_rate": 2.3654015887025596e-05,
      "logits/chosen": 3.4023425579071045,
      "logits/rejected": 3.442373752593994,
      "logps/chosen": -335.374755859375,
      "logps/rejected": -337.45361328125,
      "loss": 0.4367,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5525078773498535,
      "rewards/margins": 3.1618447303771973,
      "rewards/rejected": -5.714352607727051,
      "step": 26880
    },
    {
      "epoch": 1.5827719102115267,
      "grad_norm": 20.889516830444336,
      "learning_rate": 2.3634402275178976e-05,
      "logits/chosen": 3.7807705402374268,
      "logits/rejected": 3.792414903640747,
      "logps/chosen": -407.43310546875,
      "logps/rejected": -356.27978515625,
      "loss": 0.412,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4631705284118652,
      "rewards/margins": 3.403268814086914,
      "rewards/rejected": -5.866438865661621,
      "step": 26900
    },
    {
      "epoch": 1.5839486923009032,
      "grad_norm": 1.3143320083618164,
      "learning_rate": 2.3614788663332355e-05,
      "logits/chosen": 3.4052600860595703,
      "logits/rejected": 3.506537675857544,
      "logps/chosen": -394.9082946777344,
      "logps/rejected": -332.443115234375,
      "loss": 0.3857,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9767322540283203,
      "rewards/margins": 3.2339911460876465,
      "rewards/rejected": -5.210723876953125,
      "step": 26920
    },
    {
      "epoch": 1.5851254743902796,
      "grad_norm": 0.3317025601863861,
      "learning_rate": 2.359517505148573e-05,
      "logits/chosen": 3.669442653656006,
      "logits/rejected": 3.736881732940674,
      "logps/chosen": -430.64727783203125,
      "logps/rejected": -294.15728759765625,
      "loss": 0.2455,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.938633918762207,
      "rewards/margins": 3.734555721282959,
      "rewards/rejected": -5.673190116882324,
      "step": 26940
    },
    {
      "epoch": 1.5863022564796565,
      "grad_norm": 3.6117327213287354,
      "learning_rate": 2.357556143963911e-05,
      "logits/chosen": 3.6838951110839844,
      "logits/rejected": 3.7288978099823,
      "logps/chosen": -416.689453125,
      "logps/rejected": -303.21600341796875,
      "loss": 0.3032,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2502083778381348,
      "rewards/margins": 3.9798035621643066,
      "rewards/rejected": -6.230011940002441,
      "step": 26960
    },
    {
      "epoch": 1.587479038569033,
      "grad_norm": 2.0274016857147217,
      "learning_rate": 2.3555947827792487e-05,
      "logits/chosen": 3.5671775341033936,
      "logits/rejected": 3.4732577800750732,
      "logps/chosen": -354.0206298828125,
      "logps/rejected": -308.4037780761719,
      "loss": 0.2343,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.827574372291565,
      "rewards/margins": 3.9251437187194824,
      "rewards/rejected": -5.752718448638916,
      "step": 26980
    },
    {
      "epoch": 1.5886558206584096,
      "grad_norm": 1.5659165382385254,
      "learning_rate": 2.353633421594587e-05,
      "logits/chosen": 3.8667633533477783,
      "logits/rejected": 3.7118847370147705,
      "logps/chosen": -400.7768859863281,
      "logps/rejected": -337.0865173339844,
      "loss": 0.221,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.4630532264709473,
      "rewards/margins": 4.181046009063721,
      "rewards/rejected": -6.64409875869751,
      "step": 27000
    },
    {
      "epoch": 1.5898326027477863,
      "grad_norm": 4.116972923278809,
      "learning_rate": 2.3516720604099245e-05,
      "logits/chosen": 3.7689578533172607,
      "logits/rejected": 3.6864471435546875,
      "logps/chosen": -418.560546875,
      "logps/rejected": -292.08880615234375,
      "loss": 0.3454,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.0640265941619873,
      "rewards/margins": 3.618959903717041,
      "rewards/rejected": -5.682986736297607,
      "step": 27020
    },
    {
      "epoch": 1.5910093848371627,
      "grad_norm": 0.360363632440567,
      "learning_rate": 2.3497106992252625e-05,
      "logits/chosen": 3.5007412433624268,
      "logits/rejected": 3.4442474842071533,
      "logps/chosen": -370.37451171875,
      "logps/rejected": -310.05322265625,
      "loss": 0.2605,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.9568884372711182,
      "rewards/margins": 3.872570514678955,
      "rewards/rejected": -5.829458713531494,
      "step": 27040
    },
    {
      "epoch": 1.5921861669265394,
      "grad_norm": 3.1198103427886963,
      "learning_rate": 2.3477493380406e-05,
      "logits/chosen": 3.815945863723755,
      "logits/rejected": 3.9637527465820312,
      "logps/chosen": -364.3636779785156,
      "logps/rejected": -318.74456787109375,
      "loss": 0.2224,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.3829493522644043,
      "rewards/margins": 4.370362281799316,
      "rewards/rejected": -6.753312110900879,
      "step": 27060
    },
    {
      "epoch": 1.593362949015916,
      "grad_norm": 2.15901780128479,
      "learning_rate": 2.3457879768559384e-05,
      "logits/chosen": 3.7949352264404297,
      "logits/rejected": 3.793038845062256,
      "logps/chosen": -386.16864013671875,
      "logps/rejected": -361.36871337890625,
      "loss": 0.44,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.1146345138549805,
      "rewards/margins": 3.387547731399536,
      "rewards/rejected": -5.502181529998779,
      "step": 27080
    },
    {
      "epoch": 1.5945397311052925,
      "grad_norm": 2.043323040008545,
      "learning_rate": 2.343826615671276e-05,
      "logits/chosen": 3.2792983055114746,
      "logits/rejected": 3.349438428878784,
      "logps/chosen": -358.4957580566406,
      "logps/rejected": -331.9864501953125,
      "loss": 0.5091,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4450736045837402,
      "rewards/margins": 3.3915984630584717,
      "rewards/rejected": -5.836672306060791,
      "step": 27100
    },
    {
      "epoch": 1.5957165131946693,
      "grad_norm": 1.957014799118042,
      "learning_rate": 2.341865254486614e-05,
      "logits/chosen": 3.788515090942383,
      "logits/rejected": 3.749715805053711,
      "logps/chosen": -399.40582275390625,
      "logps/rejected": -344.112548828125,
      "loss": 0.2314,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -1.7987079620361328,
      "rewards/margins": 4.103590965270996,
      "rewards/rejected": -5.902298927307129,
      "step": 27120
    },
    {
      "epoch": 1.5968932952840458,
      "grad_norm": 2.8216958045959473,
      "learning_rate": 2.3399038933019515e-05,
      "logits/chosen": 3.7881221771240234,
      "logits/rejected": 3.7073874473571777,
      "logps/chosen": -397.9594421386719,
      "logps/rejected": -354.08319091796875,
      "loss": 0.2684,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.9736387729644775,
      "rewards/margins": 3.8762364387512207,
      "rewards/rejected": -6.849874973297119,
      "step": 27140
    },
    {
      "epoch": 1.5980700773734222,
      "grad_norm": 0.5917731523513794,
      "learning_rate": 2.3379425321172895e-05,
      "logits/chosen": 3.5334372520446777,
      "logits/rejected": 3.4244117736816406,
      "logps/chosen": -386.3218078613281,
      "logps/rejected": -316.31048583984375,
      "loss": 0.3388,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.7325048446655273,
      "rewards/margins": 3.9019927978515625,
      "rewards/rejected": -6.634497165679932,
      "step": 27160
    },
    {
      "epoch": 1.599246859462799,
      "grad_norm": 4.059861660003662,
      "learning_rate": 2.3359811709326274e-05,
      "logits/chosen": 3.8491759300231934,
      "logits/rejected": 3.8189074993133545,
      "logps/chosen": -430.3763122558594,
      "logps/rejected": -366.8146667480469,
      "loss": 0.5878,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.5135858058929443,
      "rewards/margins": 3.652156114578247,
      "rewards/rejected": -6.165741920471191,
      "step": 27180
    },
    {
      "epoch": 1.6004236415521755,
      "grad_norm": 0.9115064144134521,
      "learning_rate": 2.334019809747965e-05,
      "logits/chosen": 3.522520065307617,
      "logits/rejected": 3.6176133155822754,
      "logps/chosen": -388.3699035644531,
      "logps/rejected": -293.0225830078125,
      "loss": 0.3804,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1804516315460205,
      "rewards/margins": 3.6387252807617188,
      "rewards/rejected": -5.819177150726318,
      "step": 27200
    },
    {
      "epoch": 1.6016004236415522,
      "grad_norm": 0.4481906592845917,
      "learning_rate": 2.332058448563303e-05,
      "logits/chosen": 4.089167594909668,
      "logits/rejected": 4.072709560394287,
      "logps/chosen": -471.11285400390625,
      "logps/rejected": -398.3175354003906,
      "loss": 0.1691,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.2226719856262207,
      "rewards/margins": 4.591989040374756,
      "rewards/rejected": -6.814661502838135,
      "step": 27220
    },
    {
      "epoch": 1.6027772057309289,
      "grad_norm": 9.010392189025879,
      "learning_rate": 2.330097087378641e-05,
      "logits/chosen": 3.4746367931365967,
      "logits/rejected": 3.601308822631836,
      "logps/chosen": -366.58575439453125,
      "logps/rejected": -352.30096435546875,
      "loss": 0.2469,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.8659825325012207,
      "rewards/margins": 3.7781906127929688,
      "rewards/rejected": -6.644174098968506,
      "step": 27240
    },
    {
      "epoch": 1.6039539878203053,
      "grad_norm": 2.2671704292297363,
      "learning_rate": 2.328135726193979e-05,
      "logits/chosen": 3.395704746246338,
      "logits/rejected": 3.3061842918395996,
      "logps/chosen": -389.7707824707031,
      "logps/rejected": -362.10345458984375,
      "loss": 0.3502,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.8800835609436035,
      "rewards/margins": 4.199047565460205,
      "rewards/rejected": -7.079131126403809,
      "step": 27260
    },
    {
      "epoch": 1.605130769909682,
      "grad_norm": 2.5339744091033936,
      "learning_rate": 2.3261743650093164e-05,
      "logits/chosen": 3.5548157691955566,
      "logits/rejected": 3.639772415161133,
      "logps/chosen": -368.70831298828125,
      "logps/rejected": -323.09979248046875,
      "loss": 0.3175,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.544410228729248,
      "rewards/margins": 3.3890063762664795,
      "rewards/rejected": -5.933416366577148,
      "step": 27280
    },
    {
      "epoch": 1.6063075519990586,
      "grad_norm": 0.6516532301902771,
      "learning_rate": 2.3242130038246544e-05,
      "logits/chosen": 3.6842472553253174,
      "logits/rejected": 3.7008986473083496,
      "logps/chosen": -368.0428161621094,
      "logps/rejected": -303.62493896484375,
      "loss": 0.1955,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.3255984783172607,
      "rewards/margins": 3.7724156379699707,
      "rewards/rejected": -6.098013877868652,
      "step": 27300
    },
    {
      "epoch": 1.607484334088435,
      "grad_norm": 9.346776008605957,
      "learning_rate": 2.3222516426399923e-05,
      "logits/chosen": 3.408726453781128,
      "logits/rejected": 3.5205237865448,
      "logps/chosen": -391.2796630859375,
      "logps/rejected": -331.5605773925781,
      "loss": 0.2914,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.633025646209717,
      "rewards/margins": 4.079958915710449,
      "rewards/rejected": -6.712985038757324,
      "step": 27320
    },
    {
      "epoch": 1.608661116177812,
      "grad_norm": 3.2358312606811523,
      "learning_rate": 2.3202902814553303e-05,
      "logits/chosen": 3.796208143234253,
      "logits/rejected": 3.6530919075012207,
      "logps/chosen": -437.3525390625,
      "logps/rejected": -390.96771240234375,
      "loss": 0.4603,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0688436031341553,
      "rewards/margins": 4.757513523101807,
      "rewards/rejected": -6.826356410980225,
      "step": 27340
    },
    {
      "epoch": 1.6098378982671884,
      "grad_norm": 10.11148738861084,
      "learning_rate": 2.318328920270668e-05,
      "logits/chosen": 3.9708244800567627,
      "logits/rejected": 3.9125454425811768,
      "logps/chosen": -419.6549377441406,
      "logps/rejected": -315.33135986328125,
      "loss": 0.3676,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.4956631660461426,
      "rewards/margins": 3.252190351486206,
      "rewards/rejected": -5.747853755950928,
      "step": 27360
    },
    {
      "epoch": 1.6110146803565648,
      "grad_norm": 1.2483218908309937,
      "learning_rate": 2.3163675590860058e-05,
      "logits/chosen": 4.148340225219727,
      "logits/rejected": 3.8890769481658936,
      "logps/chosen": -480.39556884765625,
      "logps/rejected": -388.22210693359375,
      "loss": 0.2477,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.5796396732330322,
      "rewards/margins": 3.6781814098358154,
      "rewards/rejected": -5.257821083068848,
      "step": 27380
    },
    {
      "epoch": 1.6121914624459417,
      "grad_norm": 2.3171727657318115,
      "learning_rate": 2.3144061979013438e-05,
      "logits/chosen": 3.8241474628448486,
      "logits/rejected": 3.744562864303589,
      "logps/chosen": -425.6419982910156,
      "logps/rejected": -307.3760681152344,
      "loss": 0.2873,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.121901512145996,
      "rewards/margins": 3.6118106842041016,
      "rewards/rejected": -5.733713150024414,
      "step": 27400
    },
    {
      "epoch": 1.6133682445353181,
      "grad_norm": 3.821748733520508,
      "learning_rate": 2.3124448367166814e-05,
      "logits/chosen": 3.8260669708251953,
      "logits/rejected": 3.6286025047302246,
      "logps/chosen": -408.9549865722656,
      "logps/rejected": -325.29144287109375,
      "loss": 0.3671,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.1680328845977783,
      "rewards/margins": 3.513293743133545,
      "rewards/rejected": -5.681326866149902,
      "step": 27420
    },
    {
      "epoch": 1.6145450266246948,
      "grad_norm": 5.956927299499512,
      "learning_rate": 2.3104834755320193e-05,
      "logits/chosen": 3.541839122772217,
      "logits/rejected": 3.4803497791290283,
      "logps/chosen": -391.0094299316406,
      "logps/rejected": -372.45477294921875,
      "loss": 0.4447,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9644496440887451,
      "rewards/margins": 3.6758103370666504,
      "rewards/rejected": -5.640259742736816,
      "step": 27440
    },
    {
      "epoch": 1.6157218087140715,
      "grad_norm": 5.159703731536865,
      "learning_rate": 2.308522114347357e-05,
      "logits/chosen": 4.024636268615723,
      "logits/rejected": 3.9642887115478516,
      "logps/chosen": -427.51055908203125,
      "logps/rejected": -359.12115478515625,
      "loss": 0.4523,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.879366397857666,
      "rewards/margins": 3.1301536560058594,
      "rewards/rejected": -6.009520530700684,
      "step": 27460
    },
    {
      "epoch": 1.6168985908034479,
      "grad_norm": 6.421140670776367,
      "learning_rate": 2.3065607531626952e-05,
      "logits/chosen": 3.6257452964782715,
      "logits/rejected": 3.5863044261932373,
      "logps/chosen": -347.4244689941406,
      "logps/rejected": -327.21307373046875,
      "loss": 0.3608,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7736676931381226,
      "rewards/margins": 3.03538179397583,
      "rewards/rejected": -4.809049606323242,
      "step": 27480
    },
    {
      "epoch": 1.6180753728928245,
      "grad_norm": 1.4540400505065918,
      "learning_rate": 2.3045993919780328e-05,
      "logits/chosen": 4.011039733886719,
      "logits/rejected": 3.80816650390625,
      "logps/chosen": -436.12811279296875,
      "logps/rejected": -355.5401306152344,
      "loss": 0.2284,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.375315546989441,
      "rewards/margins": 4.71588659286499,
      "rewards/rejected": -6.091202735900879,
      "step": 27500
    },
    {
      "epoch": 1.6192521549822012,
      "grad_norm": 1.670042634010315,
      "learning_rate": 2.3026380307933707e-05,
      "logits/chosen": 3.457012176513672,
      "logits/rejected": 3.442234754562378,
      "logps/chosen": -394.6402282714844,
      "logps/rejected": -300.06573486328125,
      "loss": 0.2607,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.5719887018203735,
      "rewards/margins": 3.956578016281128,
      "rewards/rejected": -5.528566837310791,
      "step": 27520
    },
    {
      "epoch": 1.6204289370715776,
      "grad_norm": 7.325734615325928,
      "learning_rate": 2.3006766696087083e-05,
      "logits/chosen": 3.9955050945281982,
      "logits/rejected": 3.9995689392089844,
      "logps/chosen": -413.18865966796875,
      "logps/rejected": -350.0115661621094,
      "loss": 0.2738,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.72909414768219,
      "rewards/margins": 3.9563403129577637,
      "rewards/rejected": -5.685434818267822,
      "step": 27540
    },
    {
      "epoch": 1.6216057191609545,
      "grad_norm": 2.8427252769470215,
      "learning_rate": 2.2987153084240466e-05,
      "logits/chosen": 3.7569777965545654,
      "logits/rejected": 3.5806725025177,
      "logps/chosen": -360.847900390625,
      "logps/rejected": -325.51788330078125,
      "loss": 0.3671,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.014902353286743,
      "rewards/margins": 2.926701545715332,
      "rewards/rejected": -4.941603660583496,
      "step": 27560
    },
    {
      "epoch": 1.622782501250331,
      "grad_norm": 3.8947789669036865,
      "learning_rate": 2.2967539472393842e-05,
      "logits/chosen": 3.686509609222412,
      "logits/rejected": 3.5511951446533203,
      "logps/chosen": -407.67352294921875,
      "logps/rejected": -324.52166748046875,
      "loss": 0.2451,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.9521007537841797,
      "rewards/margins": 4.115069389343262,
      "rewards/rejected": -6.0671706199646,
      "step": 27580
    },
    {
      "epoch": 1.6239592833397074,
      "grad_norm": 1.736474633216858,
      "learning_rate": 2.2947925860547222e-05,
      "logits/chosen": 3.5049595832824707,
      "logits/rejected": 3.6127266883850098,
      "logps/chosen": -384.12872314453125,
      "logps/rejected": -330.52740478515625,
      "loss": 0.3065,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.25966477394104,
      "rewards/margins": 3.626316785812378,
      "rewards/rejected": -5.885982036590576,
      "step": 27600
    },
    {
      "epoch": 1.6251360654290843,
      "grad_norm": 0.3126063048839569,
      "learning_rate": 2.292929292929293e-05,
      "logits/chosen": 3.969705104827881,
      "logits/rejected": 3.7625203132629395,
      "logps/chosen": -430.90478515625,
      "logps/rejected": -365.5970153808594,
      "loss": 0.2564,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -1.7576086521148682,
      "rewards/margins": 4.209305286407471,
      "rewards/rejected": -5.96691370010376,
      "step": 27620
    },
    {
      "epoch": 1.6263128475184607,
      "grad_norm": 1.1630067825317383,
      "learning_rate": 2.290967931744631e-05,
      "logits/chosen": 3.679616928100586,
      "logits/rejected": 3.6946334838867188,
      "logps/chosen": -407.4728698730469,
      "logps/rejected": -320.1753845214844,
      "loss": 0.3152,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.1857218742370605,
      "rewards/margins": 3.7585983276367188,
      "rewards/rejected": -5.944319725036621,
      "step": 27640
    },
    {
      "epoch": 1.6274896296078374,
      "grad_norm": 1.6070226430892944,
      "learning_rate": 2.2890065705599686e-05,
      "logits/chosen": 3.7135777473449707,
      "logits/rejected": 3.6636135578155518,
      "logps/chosen": -464.82177734375,
      "logps/rejected": -354.6495361328125,
      "loss": 0.3414,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.4612696170806885,
      "rewards/margins": 4.658270359039307,
      "rewards/rejected": -6.119539737701416,
      "step": 27660
    },
    {
      "epoch": 1.628666411697214,
      "grad_norm": 1.90971839427948,
      "learning_rate": 2.287045209375307e-05,
      "logits/chosen": 3.3056857585906982,
      "logits/rejected": 3.2622532844543457,
      "logps/chosen": -371.204345703125,
      "logps/rejected": -332.7066345214844,
      "loss": 0.2862,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.007843017578125,
      "rewards/margins": 3.4460041522979736,
      "rewards/rejected": -5.453847408294678,
      "step": 27680
    },
    {
      "epoch": 1.6298431937865905,
      "grad_norm": 2.4904751777648926,
      "learning_rate": 2.2850838481906445e-05,
      "logits/chosen": 3.7708163261413574,
      "logits/rejected": 3.801905870437622,
      "logps/chosen": -376.47821044921875,
      "logps/rejected": -349.65167236328125,
      "loss": 0.2496,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.102219820022583,
      "rewards/margins": 3.7657463550567627,
      "rewards/rejected": -5.867966651916504,
      "step": 27700
    },
    {
      "epoch": 1.6310199758759671,
      "grad_norm": 3.2691683769226074,
      "learning_rate": 2.2831224870059824e-05,
      "logits/chosen": 3.6449763774871826,
      "logits/rejected": 3.591576099395752,
      "logps/chosen": -386.4022216796875,
      "logps/rejected": -334.85028076171875,
      "loss": 0.2895,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9632272720336914,
      "rewards/margins": 3.661658525466919,
      "rewards/rejected": -5.624885082244873,
      "step": 27720
    },
    {
      "epoch": 1.6321967579653438,
      "grad_norm": 8.733185768127441,
      "learning_rate": 2.28116112582132e-05,
      "logits/chosen": 3.9956016540527344,
      "logits/rejected": 3.840433120727539,
      "logps/chosen": -422.65966796875,
      "logps/rejected": -381.26483154296875,
      "loss": 0.2665,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9761459827423096,
      "rewards/margins": 4.368509292602539,
      "rewards/rejected": -6.344655513763428,
      "step": 27740
    },
    {
      "epoch": 1.6333735400547202,
      "grad_norm": 1.171929955482483,
      "learning_rate": 2.279199764636658e-05,
      "logits/chosen": 3.533292770385742,
      "logits/rejected": 3.362743377685547,
      "logps/chosen": -366.7353210449219,
      "logps/rejected": -366.2710266113281,
      "loss": 0.2707,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2961947917938232,
      "rewards/margins": 3.495246171951294,
      "rewards/rejected": -5.791440486907959,
      "step": 27760
    },
    {
      "epoch": 1.6345503221440971,
      "grad_norm": 1.3785260915756226,
      "learning_rate": 2.277238403451996e-05,
      "logits/chosen": 3.843440532684326,
      "logits/rejected": 3.6449618339538574,
      "logps/chosen": -408.6988220214844,
      "logps/rejected": -355.680419921875,
      "loss": 0.4132,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.5952582359313965,
      "rewards/margins": 3.280359983444214,
      "rewards/rejected": -5.8756184577941895,
      "step": 27780
    },
    {
      "epoch": 1.6357271042334736,
      "grad_norm": 25.388303756713867,
      "learning_rate": 2.2752770422673335e-05,
      "logits/chosen": 3.5340371131896973,
      "logits/rejected": 3.449791669845581,
      "logps/chosen": -384.96087646484375,
      "logps/rejected": -302.4996032714844,
      "loss": 0.5814,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.482943296432495,
      "rewards/margins": 2.828136444091797,
      "rewards/rejected": -5.311079978942871,
      "step": 27800
    },
    {
      "epoch": 1.6369038863228502,
      "grad_norm": 0.6704440116882324,
      "learning_rate": 2.2733156810826714e-05,
      "logits/chosen": 3.8898112773895264,
      "logits/rejected": 3.8105807304382324,
      "logps/chosen": -387.59014892578125,
      "logps/rejected": -362.83636474609375,
      "loss": 0.557,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.771693229675293,
      "rewards/margins": 3.1228623390197754,
      "rewards/rejected": -4.894555568695068,
      "step": 27820
    },
    {
      "epoch": 1.6380806684122269,
      "grad_norm": 1.3233948945999146,
      "learning_rate": 2.2713543198980094e-05,
      "logits/chosen": 3.554093599319458,
      "logits/rejected": 3.6242408752441406,
      "logps/chosen": -356.3718566894531,
      "logps/rejected": -321.409912109375,
      "loss": 0.4622,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5201448202133179,
      "rewards/margins": 3.641171932220459,
      "rewards/rejected": -5.161317348480225,
      "step": 27840
    },
    {
      "epoch": 1.6392574505016033,
      "grad_norm": 1.5319348573684692,
      "learning_rate": 2.2693929587133473e-05,
      "logits/chosen": 3.6534934043884277,
      "logits/rejected": 3.5314865112304688,
      "logps/chosen": -378.6627502441406,
      "logps/rejected": -310.3133850097656,
      "loss": 0.2847,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.9056316614151,
      "rewards/margins": 3.549647569656372,
      "rewards/rejected": -5.455279350280762,
      "step": 27860
    },
    {
      "epoch": 1.64043423259098,
      "grad_norm": 0.30246424674987793,
      "learning_rate": 2.267431597528685e-05,
      "logits/chosen": 3.9579684734344482,
      "logits/rejected": 3.8756916522979736,
      "logps/chosen": -422.55596923828125,
      "logps/rejected": -363.29437255859375,
      "loss": 0.1886,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.1545042991638184,
      "rewards/margins": 3.7433571815490723,
      "rewards/rejected": -5.897861480712891,
      "step": 27880
    },
    {
      "epoch": 1.6416110146803566,
      "grad_norm": 5.30596923828125,
      "learning_rate": 2.265470236344023e-05,
      "logits/chosen": 3.181105136871338,
      "logits/rejected": 3.227799654006958,
      "logps/chosen": -352.4513244628906,
      "logps/rejected": -330.8320007324219,
      "loss": 0.574,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.5864861011505127,
      "rewards/margins": 2.216653823852539,
      "rewards/rejected": -4.803139686584473,
      "step": 27900
    },
    {
      "epoch": 1.642787796769733,
      "grad_norm": 4.136631488800049,
      "learning_rate": 2.2635088751593608e-05,
      "logits/chosen": 3.8052849769592285,
      "logits/rejected": 3.7984073162078857,
      "logps/chosen": -392.6524658203125,
      "logps/rejected": -336.22039794921875,
      "loss": 0.2739,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.1596506834030151,
      "rewards/margins": 3.4101004600524902,
      "rewards/rejected": -4.569751262664795,
      "step": 27920
    },
    {
      "epoch": 1.6439645788591097,
      "grad_norm": 1.7379764318466187,
      "learning_rate": 2.2615475139746988e-05,
      "logits/chosen": 3.548297882080078,
      "logits/rejected": 3.471747875213623,
      "logps/chosen": -363.75653076171875,
      "logps/rejected": -305.20318603515625,
      "loss": 0.1356,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -1.842715859413147,
      "rewards/margins": 3.9344875812530518,
      "rewards/rejected": -5.777203559875488,
      "step": 27940
    },
    {
      "epoch": 1.6451413609484864,
      "grad_norm": 2.1555066108703613,
      "learning_rate": 2.2595861527900364e-05,
      "logits/chosen": 3.753058910369873,
      "logits/rejected": 3.796696424484253,
      "logps/chosen": -385.1121826171875,
      "logps/rejected": -343.58245849609375,
      "loss": 0.2966,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7658946514129639,
      "rewards/margins": 3.7359652519226074,
      "rewards/rejected": -5.50186014175415,
      "step": 27960
    },
    {
      "epoch": 1.6463181430378628,
      "grad_norm": 0.7719305157661438,
      "learning_rate": 2.2576247916053743e-05,
      "logits/chosen": 3.674898147583008,
      "logits/rejected": 3.60530161857605,
      "logps/chosen": -351.2701110839844,
      "logps/rejected": -302.6651306152344,
      "loss": 0.2317,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0239157676696777,
      "rewards/margins": 3.941033124923706,
      "rewards/rejected": -5.964949607849121,
      "step": 27980
    },
    {
      "epoch": 1.6474949251272397,
      "grad_norm": 4.924473285675049,
      "learning_rate": 2.2556634304207123e-05,
      "logits/chosen": 3.6390907764434814,
      "logits/rejected": 3.6031174659729004,
      "logps/chosen": -351.80889892578125,
      "logps/rejected": -384.0350036621094,
      "loss": 0.4721,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.378929853439331,
      "rewards/margins": 2.531094551086426,
      "rewards/rejected": -4.910024642944336,
      "step": 28000
    },
    {
      "epoch": 1.6486717072166162,
      "grad_norm": 4.279636383056641,
      "learning_rate": 2.25370206923605e-05,
      "logits/chosen": 3.9838943481445312,
      "logits/rejected": 3.781141757965088,
      "logps/chosen": -431.61083984375,
      "logps/rejected": -376.0293884277344,
      "loss": 0.353,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7798519134521484,
      "rewards/margins": 3.9988090991973877,
      "rewards/rejected": -5.778660774230957,
      "step": 28020
    },
    {
      "epoch": 1.6498484893059928,
      "grad_norm": 3.4953272342681885,
      "learning_rate": 2.2517407080513878e-05,
      "logits/chosen": 3.821622848510742,
      "logits/rejected": 3.7950236797332764,
      "logps/chosen": -435.02166748046875,
      "logps/rejected": -364.7796630859375,
      "loss": 0.2204,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.8485021591186523,
      "rewards/margins": 3.959643602371216,
      "rewards/rejected": -5.808145523071289,
      "step": 28040
    },
    {
      "epoch": 1.6510252713953695,
      "grad_norm": 5.167657375335693,
      "learning_rate": 2.2497793468667254e-05,
      "logits/chosen": 3.836362361907959,
      "logits/rejected": 3.8465652465820312,
      "logps/chosen": -411.75213623046875,
      "logps/rejected": -372.2034912109375,
      "loss": 0.2577,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.647472620010376,
      "rewards/margins": 4.0543694496154785,
      "rewards/rejected": -5.701842308044434,
      "step": 28060
    },
    {
      "epoch": 1.652202053484746,
      "grad_norm": 1.7482057809829712,
      "learning_rate": 2.2478179856820637e-05,
      "logits/chosen": 3.8878173828125,
      "logits/rejected": 3.7776312828063965,
      "logps/chosen": -401.7209777832031,
      "logps/rejected": -355.14495849609375,
      "loss": 0.2624,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.521841287612915,
      "rewards/margins": 4.747765064239502,
      "rewards/rejected": -6.269606113433838,
      "step": 28080
    },
    {
      "epoch": 1.6533788355741226,
      "grad_norm": 16.09391212463379,
      "learning_rate": 2.2458566244974013e-05,
      "logits/chosen": 3.6094558238983154,
      "logits/rejected": 3.5659523010253906,
      "logps/chosen": -404.43743896484375,
      "logps/rejected": -336.23016357421875,
      "loss": 0.3163,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.6438201665878296,
      "rewards/margins": 4.13078498840332,
      "rewards/rejected": -5.7746052742004395,
      "step": 28100
    },
    {
      "epoch": 1.6545556176634992,
      "grad_norm": 2.0937373638153076,
      "learning_rate": 2.2438952633127392e-05,
      "logits/chosen": 3.7499427795410156,
      "logits/rejected": 3.6125855445861816,
      "logps/chosen": -433.70501708984375,
      "logps/rejected": -365.27496337890625,
      "loss": 0.3448,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.4229371547698975,
      "rewards/margins": 4.263623237609863,
      "rewards/rejected": -6.686560153961182,
      "step": 28120
    },
    {
      "epoch": 1.6557323997528757,
      "grad_norm": 0.8681989312171936,
      "learning_rate": 2.241933902128077e-05,
      "logits/chosen": 3.768596649169922,
      "logits/rejected": 3.591081142425537,
      "logps/chosen": -415.3324279785156,
      "logps/rejected": -329.481689453125,
      "loss": 0.3606,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.289422035217285,
      "rewards/margins": 3.6213669776916504,
      "rewards/rejected": -5.910788536071777,
      "step": 28140
    },
    {
      "epoch": 1.6569091818422523,
      "grad_norm": 0.7758868336677551,
      "learning_rate": 2.239972540943415e-05,
      "logits/chosen": 3.629094362258911,
      "logits/rejected": 3.7553811073303223,
      "logps/chosen": -414.73126220703125,
      "logps/rejected": -369.4336853027344,
      "loss": 0.2583,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -0.8742479085922241,
      "rewards/margins": 4.892928600311279,
      "rewards/rejected": -5.767176628112793,
      "step": 28160
    },
    {
      "epoch": 1.658085963931629,
      "grad_norm": 4.125510215759277,
      "learning_rate": 2.2380111797587527e-05,
      "logits/chosen": 3.722263813018799,
      "logits/rejected": 3.7342770099639893,
      "logps/chosen": -412.94915771484375,
      "logps/rejected": -336.1222229003906,
      "loss": 0.2675,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.0228328704833984,
      "rewards/margins": 3.60046124458313,
      "rewards/rejected": -5.623294353485107,
      "step": 28180
    },
    {
      "epoch": 1.6592627460210054,
      "grad_norm": 8.262531280517578,
      "learning_rate": 2.2360498185740907e-05,
      "logits/chosen": 3.756157636642456,
      "logits/rejected": 3.653332233428955,
      "logps/chosen": -406.8626403808594,
      "logps/rejected": -346.57891845703125,
      "loss": 0.3046,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9956295490264893,
      "rewards/margins": 4.350424289703369,
      "rewards/rejected": -6.346054553985596,
      "step": 28200
    },
    {
      "epoch": 1.6604395281103823,
      "grad_norm": 6.763479232788086,
      "learning_rate": 2.2340884573894283e-05,
      "logits/chosen": 3.7662405967712402,
      "logits/rejected": 3.701138973236084,
      "logps/chosen": -410.1025390625,
      "logps/rejected": -358.1110534667969,
      "loss": 0.3542,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.286113739013672,
      "rewards/margins": 3.7041468620300293,
      "rewards/rejected": -5.990260124206543,
      "step": 28220
    },
    {
      "epoch": 1.6616163101997588,
      "grad_norm": 4.823002815246582,
      "learning_rate": 2.2321270962047662e-05,
      "logits/chosen": 3.7283153533935547,
      "logits/rejected": 3.5985991954803467,
      "logps/chosen": -412.33526611328125,
      "logps/rejected": -351.20184326171875,
      "loss": 0.3564,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.6832504272460938,
      "rewards/margins": 3.301140308380127,
      "rewards/rejected": -5.984391212463379,
      "step": 28240
    },
    {
      "epoch": 1.6627930922891354,
      "grad_norm": 4.564289093017578,
      "learning_rate": 2.230165735020104e-05,
      "logits/chosen": 3.6483256816864014,
      "logits/rejected": 3.6751270294189453,
      "logps/chosen": -381.77606201171875,
      "logps/rejected": -345.633056640625,
      "loss": 0.2384,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0929789543151855,
      "rewards/margins": 4.026238918304443,
      "rewards/rejected": -6.119217872619629,
      "step": 28260
    },
    {
      "epoch": 1.663969874378512,
      "grad_norm": 4.63822078704834,
      "learning_rate": 2.2282043738354418e-05,
      "logits/chosen": 3.610264301300049,
      "logits/rejected": 3.514490842819214,
      "logps/chosen": -399.81744384765625,
      "logps/rejected": -323.27142333984375,
      "loss": 0.2169,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.8354976177215576,
      "rewards/margins": 3.870560884475708,
      "rewards/rejected": -5.706058502197266,
      "step": 28280
    },
    {
      "epoch": 1.6651466564678885,
      "grad_norm": 0.04916178062558174,
      "learning_rate": 2.2262430126507797e-05,
      "logits/chosen": 3.637908935546875,
      "logits/rejected": 3.6705031394958496,
      "logps/chosen": -398.5860290527344,
      "logps/rejected": -351.6866760253906,
      "loss": 0.2161,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0170512199401855,
      "rewards/margins": 4.380921363830566,
      "rewards/rejected": -6.397972583770752,
      "step": 28300
    },
    {
      "epoch": 1.6663234385572652,
      "grad_norm": 2.0827794075012207,
      "learning_rate": 2.2242816514661176e-05,
      "logits/chosen": 3.7928664684295654,
      "logits/rejected": 3.8545291423797607,
      "logps/chosen": -391.43145751953125,
      "logps/rejected": -348.0199279785156,
      "loss": 0.1504,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -1.9157148599624634,
      "rewards/margins": 4.776375770568848,
      "rewards/rejected": -6.6920905113220215,
      "step": 28320
    },
    {
      "epoch": 1.6675002206466418,
      "grad_norm": 4.8917694091796875,
      "learning_rate": 2.2223202902814556e-05,
      "logits/chosen": 3.556626796722412,
      "logits/rejected": 3.540484666824341,
      "logps/chosen": -429.24212646484375,
      "logps/rejected": -377.8614807128906,
      "loss": 0.329,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9445936679840088,
      "rewards/margins": 4.630281925201416,
      "rewards/rejected": -6.5748748779296875,
      "step": 28340
    },
    {
      "epoch": 1.6686770027360183,
      "grad_norm": 1.2013639211654663,
      "learning_rate": 2.2203589290967932e-05,
      "logits/chosen": 3.658341884613037,
      "logits/rejected": 3.655371904373169,
      "logps/chosen": -415.15069580078125,
      "logps/rejected": -336.88702392578125,
      "loss": 0.2812,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.394294261932373,
      "rewards/margins": 3.4140594005584717,
      "rewards/rejected": -5.808354377746582,
      "step": 28360
    },
    {
      "epoch": 1.669853784825395,
      "grad_norm": 5.30055046081543,
      "learning_rate": 2.218397567912131e-05,
      "logits/chosen": 3.767467975616455,
      "logits/rejected": 3.581411838531494,
      "logps/chosen": -372.885009765625,
      "logps/rejected": -278.337158203125,
      "loss": 0.5736,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.1958351135253906,
      "rewards/margins": 2.6166586875915527,
      "rewards/rejected": -5.812494277954102,
      "step": 28380
    },
    {
      "epoch": 1.6710305669147716,
      "grad_norm": 6.359170913696289,
      "learning_rate": 2.216436206727469e-05,
      "logits/chosen": 3.3260066509246826,
      "logits/rejected": 3.421706438064575,
      "logps/chosen": -333.1717834472656,
      "logps/rejected": -318.38812255859375,
      "loss": 0.3722,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.157914638519287,
      "rewards/margins": 4.0749006271362305,
      "rewards/rejected": -6.232815742492676,
      "step": 28400
    },
    {
      "epoch": 1.672207349004148,
      "grad_norm": 0.7792908549308777,
      "learning_rate": 2.214474845542807e-05,
      "logits/chosen": 3.6363720893859863,
      "logits/rejected": 3.6031551361083984,
      "logps/chosen": -408.54461669921875,
      "logps/rejected": -365.798828125,
      "loss": 0.2109,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.2768445014953613,
      "rewards/margins": 4.3767499923706055,
      "rewards/rejected": -6.653594970703125,
      "step": 28420
    },
    {
      "epoch": 1.673384131093525,
      "grad_norm": 3.702759027481079,
      "learning_rate": 2.2125134843581446e-05,
      "logits/chosen": 3.7671120166778564,
      "logits/rejected": 3.7915637493133545,
      "logps/chosen": -437.27447509765625,
      "logps/rejected": -345.1844482421875,
      "loss": 0.4322,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.499290704727173,
      "rewards/margins": 3.508342742919922,
      "rewards/rejected": -6.007633686065674,
      "step": 28440
    },
    {
      "epoch": 1.6745609131829013,
      "grad_norm": 2.563793182373047,
      "learning_rate": 2.2105521231734826e-05,
      "logits/chosen": 4.018401145935059,
      "logits/rejected": 3.8583083152770996,
      "logps/chosen": -436.6549377441406,
      "logps/rejected": -325.47930908203125,
      "loss": 0.2866,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2865982055664062,
      "rewards/margins": 3.7779362201690674,
      "rewards/rejected": -6.0645341873168945,
      "step": 28460
    },
    {
      "epoch": 1.675737695272278,
      "grad_norm": 0.912319004535675,
      "learning_rate": 2.2085907619888205e-05,
      "logits/chosen": 4.062836170196533,
      "logits/rejected": 3.917255401611328,
      "logps/chosen": -438.4244079589844,
      "logps/rejected": -365.02838134765625,
      "loss": 0.1704,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -2.4148030281066895,
      "rewards/margins": 3.991887331008911,
      "rewards/rejected": -6.4066901206970215,
      "step": 28480
    },
    {
      "epoch": 1.6769144773616547,
      "grad_norm": 1.6394802331924438,
      "learning_rate": 2.206629400804158e-05,
      "logits/chosen": 3.389287233352661,
      "logits/rejected": 3.3973777294158936,
      "logps/chosen": -377.1137390136719,
      "logps/rejected": -355.4796447753906,
      "loss": 0.3166,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8004995584487915,
      "rewards/margins": 3.6097240447998047,
      "rewards/rejected": -5.410223960876465,
      "step": 28500
    },
    {
      "epoch": 1.678091259451031,
      "grad_norm": 1.7863982915878296,
      "learning_rate": 2.204668039619496e-05,
      "logits/chosen": 3.8278841972351074,
      "logits/rejected": 3.6994502544403076,
      "logps/chosen": -375.24310302734375,
      "logps/rejected": -354.670654296875,
      "loss": 0.2656,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9637657403945923,
      "rewards/margins": 4.0623579025268555,
      "rewards/rejected": -6.026124000549316,
      "step": 28520
    },
    {
      "epoch": 1.6792680415404078,
      "grad_norm": 1.5901693105697632,
      "learning_rate": 2.2027066784348337e-05,
      "logits/chosen": 3.6305339336395264,
      "logits/rejected": 3.5764153003692627,
      "logps/chosen": -386.6260986328125,
      "logps/rejected": -327.32208251953125,
      "loss": 0.2468,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -2.184047222137451,
      "rewards/margins": 3.636833667755127,
      "rewards/rejected": -5.820880889892578,
      "step": 28540
    },
    {
      "epoch": 1.6804448236297844,
      "grad_norm": 1.8867332935333252,
      "learning_rate": 2.200745317250172e-05,
      "logits/chosen": 3.7576980590820312,
      "logits/rejected": 3.618415355682373,
      "logps/chosen": -405.42303466796875,
      "logps/rejected": -315.73388671875,
      "loss": 0.2916,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.444122791290283,
      "rewards/margins": 3.898383378982544,
      "rewards/rejected": -6.34250545501709,
      "step": 28560
    },
    {
      "epoch": 1.6816216057191609,
      "grad_norm": 1.175675392150879,
      "learning_rate": 2.1987839560655095e-05,
      "logits/chosen": 3.674233913421631,
      "logits/rejected": 3.653754711151123,
      "logps/chosen": -403.7093811035156,
      "logps/rejected": -303.1282653808594,
      "loss": 0.2244,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4017012119293213,
      "rewards/margins": 4.488112449645996,
      "rewards/rejected": -6.889813423156738,
      "step": 28580
    },
    {
      "epoch": 1.6827983878085375,
      "grad_norm": 2.561762809753418,
      "learning_rate": 2.1968225948808475e-05,
      "logits/chosen": 3.494539976119995,
      "logits/rejected": 3.3496735095977783,
      "logps/chosen": -342.30096435546875,
      "logps/rejected": -275.047607421875,
      "loss": 0.3152,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.3531508445739746,
      "rewards/margins": 3.333197832107544,
      "rewards/rejected": -5.686348915100098,
      "step": 28600
    },
    {
      "epoch": 1.6839751698979142,
      "grad_norm": 0.25924912095069885,
      "learning_rate": 2.194861233696185e-05,
      "logits/chosen": 3.4114813804626465,
      "logits/rejected": 3.4582934379577637,
      "logps/chosen": -384.47491455078125,
      "logps/rejected": -310.8699035644531,
      "loss": 0.2664,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.288102149963379,
      "rewards/margins": 4.481024265289307,
      "rewards/rejected": -6.769126892089844,
      "step": 28620
    },
    {
      "epoch": 1.6851519519872906,
      "grad_norm": 3.597297430038452,
      "learning_rate": 2.1928998725115234e-05,
      "logits/chosen": 3.594407558441162,
      "logits/rejected": 3.574688673019409,
      "logps/chosen": -383.00189208984375,
      "logps/rejected": -371.8908386230469,
      "loss": 0.2889,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.500889778137207,
      "rewards/margins": 4.257991790771484,
      "rewards/rejected": -6.758881568908691,
      "step": 28640
    },
    {
      "epoch": 1.6863287340766675,
      "grad_norm": 6.547763347625732,
      "learning_rate": 2.190938511326861e-05,
      "logits/chosen": 3.435065746307373,
      "logits/rejected": 3.3433098793029785,
      "logps/chosen": -401.76580810546875,
      "logps/rejected": -353.4967041015625,
      "loss": 0.3742,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.5844192504882812,
      "rewards/margins": 4.006640911102295,
      "rewards/rejected": -6.591059684753418,
      "step": 28660
    },
    {
      "epoch": 1.687505516166044,
      "grad_norm": 2.452573776245117,
      "learning_rate": 2.188977150142199e-05,
      "logits/chosen": 3.5359089374542236,
      "logits/rejected": 3.5600388050079346,
      "logps/chosen": -384.76898193359375,
      "logps/rejected": -340.3061218261719,
      "loss": 0.2558,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.342163562774658,
      "rewards/margins": 4.107159614562988,
      "rewards/rejected": -6.449324131011963,
      "step": 28680
    },
    {
      "epoch": 1.6886822982554206,
      "grad_norm": 3.263040781021118,
      "learning_rate": 2.1870157889575365e-05,
      "logits/chosen": 3.4622199535369873,
      "logits/rejected": 3.516371250152588,
      "logps/chosen": -366.5146484375,
      "logps/rejected": -311.55218505859375,
      "loss": 0.4166,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.2537922859191895,
      "rewards/margins": 3.3883159160614014,
      "rewards/rejected": -5.642107963562012,
      "step": 28700
    },
    {
      "epoch": 1.6898590803447973,
      "grad_norm": 4.24646520614624,
      "learning_rate": 2.1850544277728745e-05,
      "logits/chosen": 3.841949462890625,
      "logits/rejected": 3.908360242843628,
      "logps/chosen": -411.14715576171875,
      "logps/rejected": -335.4190673828125,
      "loss": 0.3392,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9356119632720947,
      "rewards/margins": 3.5755603313446045,
      "rewards/rejected": -5.511172294616699,
      "step": 28720
    },
    {
      "epoch": 1.6910358624341737,
      "grad_norm": 1.1555941104888916,
      "learning_rate": 2.1830930665882124e-05,
      "logits/chosen": 3.7897567749023438,
      "logits/rejected": 3.8201241493225098,
      "logps/chosen": -391.0244140625,
      "logps/rejected": -355.3115539550781,
      "loss": 0.2581,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.4385706186294556,
      "rewards/margins": 3.6168148517608643,
      "rewards/rejected": -5.055386066436768,
      "step": 28740
    },
    {
      "epoch": 1.6922126445235504,
      "grad_norm": 1.6587426662445068,
      "learning_rate": 2.18113170540355e-05,
      "logits/chosen": 3.713444471359253,
      "logits/rejected": 3.623633623123169,
      "logps/chosen": -420.89849853515625,
      "logps/rejected": -366.9154357910156,
      "loss": 0.2553,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.47879159450531,
      "rewards/margins": 4.603952884674072,
      "rewards/rejected": -6.082744598388672,
      "step": 28760
    },
    {
      "epoch": 1.693389426612927,
      "grad_norm": 2.116713285446167,
      "learning_rate": 2.179170344218888e-05,
      "logits/chosen": 3.610898971557617,
      "logits/rejected": 3.7634129524230957,
      "logps/chosen": -386.21954345703125,
      "logps/rejected": -340.116455078125,
      "loss": 0.3206,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8881393671035767,
      "rewards/margins": 3.774994373321533,
      "rewards/rejected": -5.663133144378662,
      "step": 28780
    },
    {
      "epoch": 1.6945662087023035,
      "grad_norm": 2.410360813140869,
      "learning_rate": 2.177208983034226e-05,
      "logits/chosen": 3.8317368030548096,
      "logits/rejected": 3.709160327911377,
      "logps/chosen": -434.24688720703125,
      "logps/rejected": -347.49151611328125,
      "loss": 0.5935,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.35107159614563,
      "rewards/margins": 3.440687656402588,
      "rewards/rejected": -5.791759014129639,
      "step": 28800
    },
    {
      "epoch": 1.6957429907916801,
      "grad_norm": 6.130795001983643,
      "learning_rate": 2.175247621849564e-05,
      "logits/chosen": 3.679464340209961,
      "logits/rejected": 3.6545376777648926,
      "logps/chosen": -411.58563232421875,
      "logps/rejected": -348.8417053222656,
      "loss": 0.3962,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.2344045639038086,
      "rewards/margins": 3.5440750122070312,
      "rewards/rejected": -5.77847957611084,
      "step": 28820
    },
    {
      "epoch": 1.6969197728810568,
      "grad_norm": 1.0945098400115967,
      "learning_rate": 2.1732862606649014e-05,
      "logits/chosen": 3.627072811126709,
      "logits/rejected": 3.4264252185821533,
      "logps/chosen": -371.66070556640625,
      "logps/rejected": -339.47906494140625,
      "loss": 0.2617,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.782525658607483,
      "rewards/margins": 4.428933620452881,
      "rewards/rejected": -6.211459159851074,
      "step": 28840
    },
    {
      "epoch": 1.6980965549704332,
      "grad_norm": 1.8342326879501343,
      "learning_rate": 2.1713248994802394e-05,
      "logits/chosen": 3.8104605674743652,
      "logits/rejected": 3.966949462890625,
      "logps/chosen": -413.56549072265625,
      "logps/rejected": -360.6705017089844,
      "loss": 0.4127,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7260843515396118,
      "rewards/margins": 3.0238051414489746,
      "rewards/rejected": -4.749889373779297,
      "step": 28860
    },
    {
      "epoch": 1.69927333705981,
      "grad_norm": 7.923094749450684,
      "learning_rate": 2.1693635382955773e-05,
      "logits/chosen": 3.692180633544922,
      "logits/rejected": 3.6783714294433594,
      "logps/chosen": -359.4648742675781,
      "logps/rejected": -307.73309326171875,
      "loss": 0.3263,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.646559953689575,
      "rewards/margins": 3.7836291790008545,
      "rewards/rejected": -6.430189609527588,
      "step": 28880
    },
    {
      "epoch": 1.7004501191491865,
      "grad_norm": 2.116184949874878,
      "learning_rate": 2.1674021771109153e-05,
      "logits/chosen": 3.403135299682617,
      "logits/rejected": 3.4874534606933594,
      "logps/chosen": -375.4384765625,
      "logps/rejected": -371.3038635253906,
      "loss": 0.2445,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8237674236297607,
      "rewards/margins": 4.390059947967529,
      "rewards/rejected": -6.213826656341553,
      "step": 28900
    },
    {
      "epoch": 1.7016269012385632,
      "grad_norm": 0.786090075969696,
      "learning_rate": 2.165440815926253e-05,
      "logits/chosen": 3.5896942615509033,
      "logits/rejected": 3.5063281059265137,
      "logps/chosen": -399.1393127441406,
      "logps/rejected": -369.2386779785156,
      "loss": 0.278,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0726089477539062,
      "rewards/margins": 4.302643299102783,
      "rewards/rejected": -6.375251770019531,
      "step": 28920
    },
    {
      "epoch": 1.7028036833279399,
      "grad_norm": 5.024888515472412,
      "learning_rate": 2.1634794547415908e-05,
      "logits/chosen": 3.586933135986328,
      "logits/rejected": 3.5313308238983154,
      "logps/chosen": -366.60626220703125,
      "logps/rejected": -318.49444580078125,
      "loss": 0.272,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9542410373687744,
      "rewards/margins": 3.8627967834472656,
      "rewards/rejected": -5.817038059234619,
      "step": 28940
    },
    {
      "epoch": 1.7039804654173163,
      "grad_norm": 7.710811614990234,
      "learning_rate": 2.1615180935569288e-05,
      "logits/chosen": 3.783844470977783,
      "logits/rejected": 3.8449180126190186,
      "logps/chosen": -405.2283935546875,
      "logps/rejected": -333.822509765625,
      "loss": 0.4017,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4087462425231934,
      "rewards/margins": 3.255195140838623,
      "rewards/rejected": -5.663941383361816,
      "step": 28960
    },
    {
      "epoch": 1.705157247506693,
      "grad_norm": 0.40703871846199036,
      "learning_rate": 2.1595567323722664e-05,
      "logits/chosen": 4.1232476234436035,
      "logits/rejected": 3.8419203758239746,
      "logps/chosen": -431.2749938964844,
      "logps/rejected": -313.7773132324219,
      "loss": 0.2655,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.563843011856079,
      "rewards/margins": 3.7415592670440674,
      "rewards/rejected": -5.305402755737305,
      "step": 28980
    },
    {
      "epoch": 1.7063340295960696,
      "grad_norm": 3.9223365783691406,
      "learning_rate": 2.1575953711876043e-05,
      "logits/chosen": 3.457845687866211,
      "logits/rejected": 3.5091426372528076,
      "logps/chosen": -377.4882507324219,
      "logps/rejected": -288.5750427246094,
      "loss": 0.2994,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7462457418441772,
      "rewards/margins": 3.190307140350342,
      "rewards/rejected": -4.936553001403809,
      "step": 29000
    },
    {
      "epoch": 1.707510811685446,
      "grad_norm": 5.287951946258545,
      "learning_rate": 2.155634010002942e-05,
      "logits/chosen": 3.775219440460205,
      "logits/rejected": 3.7405147552490234,
      "logps/chosen": -382.32080078125,
      "logps/rejected": -308.5463562011719,
      "loss": 0.3078,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.1344940662384033,
      "rewards/margins": 3.8645215034484863,
      "rewards/rejected": -5.999015808105469,
      "step": 29020
    },
    {
      "epoch": 1.7086875937748227,
      "grad_norm": 4.300562381744385,
      "learning_rate": 2.1536726488182802e-05,
      "logits/chosen": 4.10715389251709,
      "logits/rejected": 3.8002753257751465,
      "logps/chosen": -427.2184143066406,
      "logps/rejected": -352.3594970703125,
      "loss": 0.2875,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.8280246257781982,
      "rewards/margins": 3.8435657024383545,
      "rewards/rejected": -5.671590328216553,
      "step": 29040
    },
    {
      "epoch": 1.7098643758641994,
      "grad_norm": 7.174847602844238,
      "learning_rate": 2.1517112876336178e-05,
      "logits/chosen": 3.776963710784912,
      "logits/rejected": 3.624955654144287,
      "logps/chosen": -410.2691345214844,
      "logps/rejected": -351.19781494140625,
      "loss": 0.386,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.296654462814331,
      "rewards/margins": 3.49757719039917,
      "rewards/rejected": -5.794231414794922,
      "step": 29060
    },
    {
      "epoch": 1.7110411579535758,
      "grad_norm": 1.5629608631134033,
      "learning_rate": 2.1497499264489557e-05,
      "logits/chosen": 3.5977580547332764,
      "logits/rejected": 3.6796867847442627,
      "logps/chosen": -404.88128662109375,
      "logps/rejected": -388.4685363769531,
      "loss": 0.3228,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7051918506622314,
      "rewards/margins": 3.956855297088623,
      "rewards/rejected": -5.662047386169434,
      "step": 29080
    },
    {
      "epoch": 1.7122179400429527,
      "grad_norm": 2.2919039726257324,
      "learning_rate": 2.1477885652642933e-05,
      "logits/chosen": 3.876634120941162,
      "logits/rejected": 3.925870418548584,
      "logps/chosen": -403.42364501953125,
      "logps/rejected": -309.3478698730469,
      "loss": 0.3169,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.584533452987671,
      "rewards/margins": 4.079843044281006,
      "rewards/rejected": -5.664376258850098,
      "step": 29100
    },
    {
      "epoch": 1.7133947221323291,
      "grad_norm": 4.330835342407227,
      "learning_rate": 2.1458272040796316e-05,
      "logits/chosen": 3.709009885787964,
      "logits/rejected": 3.7695815563201904,
      "logps/chosen": -418.97265625,
      "logps/rejected": -368.12493896484375,
      "loss": 0.2899,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.0115163326263428,
      "rewards/margins": 4.862042427062988,
      "rewards/rejected": -6.873559474945068,
      "step": 29120
    },
    {
      "epoch": 1.7145715042217058,
      "grad_norm": 6.741470813751221,
      "learning_rate": 2.1438658428949692e-05,
      "logits/chosen": 3.7760021686553955,
      "logits/rejected": 3.6901488304138184,
      "logps/chosen": -380.38531494140625,
      "logps/rejected": -307.90283203125,
      "loss": 0.3285,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.379244089126587,
      "rewards/margins": 3.733076810836792,
      "rewards/rejected": -6.112320899963379,
      "step": 29140
    },
    {
      "epoch": 1.7157482863110824,
      "grad_norm": 1.6204324960708618,
      "learning_rate": 2.1419044817103072e-05,
      "logits/chosen": 3.9105682373046875,
      "logits/rejected": 3.8441109657287598,
      "logps/chosen": -394.48480224609375,
      "logps/rejected": -353.05511474609375,
      "loss": 0.3748,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.666339635848999,
      "rewards/margins": 3.332550525665283,
      "rewards/rejected": -5.998889923095703,
      "step": 29160
    },
    {
      "epoch": 1.7169250684004589,
      "grad_norm": 5.682645320892334,
      "learning_rate": 2.1399431205256448e-05,
      "logits/chosen": 3.8464436531066895,
      "logits/rejected": 3.618861436843872,
      "logps/chosen": -426.32568359375,
      "logps/rejected": -370.53912353515625,
      "loss": 0.2833,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8835560083389282,
      "rewards/margins": 4.490143775939941,
      "rewards/rejected": -6.373700141906738,
      "step": 29180
    },
    {
      "epoch": 1.7181018504898355,
      "grad_norm": 2.1214771270751953,
      "learning_rate": 2.1379817593409827e-05,
      "logits/chosen": 3.512531280517578,
      "logits/rejected": 3.5784926414489746,
      "logps/chosen": -420.9153747558594,
      "logps/rejected": -359.25408935546875,
      "loss": 0.3691,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.263918399810791,
      "rewards/margins": 4.304277420043945,
      "rewards/rejected": -6.568195343017578,
      "step": 29200
    },
    {
      "epoch": 1.7192786325792122,
      "grad_norm": 2.3897387981414795,
      "learning_rate": 2.1360203981563207e-05,
      "logits/chosen": 3.637356996536255,
      "logits/rejected": 3.7564988136291504,
      "logps/chosen": -394.96112060546875,
      "logps/rejected": -385.9394226074219,
      "loss": 0.3201,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.622737407684326,
      "rewards/margins": 3.2447593212127686,
      "rewards/rejected": -5.867496490478516,
      "step": 29220
    },
    {
      "epoch": 1.7204554146685886,
      "grad_norm": 0.39533695578575134,
      "learning_rate": 2.1340590369716583e-05,
      "logits/chosen": 3.744227647781372,
      "logits/rejected": 3.5369479656219482,
      "logps/chosen": -380.68341064453125,
      "logps/rejected": -348.3091735839844,
      "loss": 0.267,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.6577231884002686,
      "rewards/margins": 3.831191301345825,
      "rewards/rejected": -6.488914489746094,
      "step": 29240
    },
    {
      "epoch": 1.7216321967579653,
      "grad_norm": 0.3457432687282562,
      "learning_rate": 2.1320976757869962e-05,
      "logits/chosen": 3.739619016647339,
      "logits/rejected": 3.6442153453826904,
      "logps/chosen": -405.57110595703125,
      "logps/rejected": -317.83331298828125,
      "loss": 0.4757,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.4867892265319824,
      "rewards/margins": 3.8173224925994873,
      "rewards/rejected": -6.304112434387207,
      "step": 29260
    },
    {
      "epoch": 1.722808978847342,
      "grad_norm": 6.663801670074463,
      "learning_rate": 2.130136314602334e-05,
      "logits/chosen": 3.774345874786377,
      "logits/rejected": 3.748351573944092,
      "logps/chosen": -410.3102111816406,
      "logps/rejected": -343.65472412109375,
      "loss": 0.2832,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7256715297698975,
      "rewards/margins": 3.899113893508911,
      "rewards/rejected": -5.62478494644165,
      "step": 29280
    },
    {
      "epoch": 1.7239857609367184,
      "grad_norm": 6.918081283569336,
      "learning_rate": 2.128174953417672e-05,
      "logits/chosen": 3.5932300090789795,
      "logits/rejected": 3.5276103019714355,
      "logps/chosen": -390.40020751953125,
      "logps/rejected": -350.025634765625,
      "loss": 0.2843,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8743112087249756,
      "rewards/margins": 4.065065383911133,
      "rewards/rejected": -5.9393768310546875,
      "step": 29300
    },
    {
      "epoch": 1.7251625430260953,
      "grad_norm": 3.246311664581299,
      "learning_rate": 2.1262135922330097e-05,
      "logits/chosen": 3.751650333404541,
      "logits/rejected": 3.7280495166778564,
      "logps/chosen": -411.73175048828125,
      "logps/rejected": -369.13311767578125,
      "loss": 0.2481,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.8276021480560303,
      "rewards/margins": 4.896544456481934,
      "rewards/rejected": -6.724146842956543,
      "step": 29320
    },
    {
      "epoch": 1.7263393251154717,
      "grad_norm": 6.322326183319092,
      "learning_rate": 2.1242522310483476e-05,
      "logits/chosen": 3.7930359840393066,
      "logits/rejected": 3.8273158073425293,
      "logps/chosen": -397.22296142578125,
      "logps/rejected": -364.0644226074219,
      "loss": 0.2502,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2884552478790283,
      "rewards/margins": 3.9029910564422607,
      "rewards/rejected": -6.191446781158447,
      "step": 29340
    },
    {
      "epoch": 1.7275161072048484,
      "grad_norm": 5.748400688171387,
      "learning_rate": 2.1222908698636856e-05,
      "logits/chosen": 3.8976757526397705,
      "logits/rejected": 3.8116753101348877,
      "logps/chosen": -417.2181091308594,
      "logps/rejected": -439.40875244140625,
      "loss": 0.1985,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.923388123512268,
      "rewards/margins": 4.548984050750732,
      "rewards/rejected": -6.472372531890869,
      "step": 29360
    },
    {
      "epoch": 1.728692889294225,
      "grad_norm": 0.9465106725692749,
      "learning_rate": 2.1203295086790235e-05,
      "logits/chosen": 3.6083004474639893,
      "logits/rejected": 3.700955629348755,
      "logps/chosen": -378.8222961425781,
      "logps/rejected": -327.21807861328125,
      "loss": 0.4089,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.392444133758545,
      "rewards/margins": 3.2877349853515625,
      "rewards/rejected": -5.680179119110107,
      "step": 29380
    },
    {
      "epoch": 1.7298696713836015,
      "grad_norm": 4.737270832061768,
      "learning_rate": 2.118368147494361e-05,
      "logits/chosen": 3.879044771194458,
      "logits/rejected": 3.7839787006378174,
      "logps/chosen": -396.0536193847656,
      "logps/rejected": -361.0860595703125,
      "loss": 0.257,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.498110294342041,
      "rewards/margins": 3.6668701171875,
      "rewards/rejected": -6.164980888366699,
      "step": 29400
    },
    {
      "epoch": 1.7310464534729781,
      "grad_norm": 1.5251532793045044,
      "learning_rate": 2.116406786309699e-05,
      "logits/chosen": 3.4595775604248047,
      "logits/rejected": 3.445751667022705,
      "logps/chosen": -383.0726623535156,
      "logps/rejected": -337.7508544921875,
      "loss": 0.4519,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.9053118228912354,
      "rewards/margins": 2.9704294204711914,
      "rewards/rejected": -4.875741004943848,
      "step": 29420
    },
    {
      "epoch": 1.7322232355623548,
      "grad_norm": 1.8400156497955322,
      "learning_rate": 2.1144454251250367e-05,
      "logits/chosen": 3.433791399002075,
      "logits/rejected": 3.377254009246826,
      "logps/chosen": -395.0683288574219,
      "logps/rejected": -294.43670654296875,
      "loss": 0.3782,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.3054609298706055,
      "rewards/margins": 3.6215126514434814,
      "rewards/rejected": -5.926973342895508,
      "step": 29440
    },
    {
      "epoch": 1.7334000176517312,
      "grad_norm": 1.277652621269226,
      "learning_rate": 2.112484063940375e-05,
      "logits/chosen": 3.6445088386535645,
      "logits/rejected": 3.6153578758239746,
      "logps/chosen": -408.0982971191406,
      "logps/rejected": -363.86138916015625,
      "loss": 0.2659,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -1.6840864419937134,
      "rewards/margins": 3.9600181579589844,
      "rewards/rejected": -5.644104480743408,
      "step": 29460
    },
    {
      "epoch": 1.734576799741108,
      "grad_norm": 5.407154560089111,
      "learning_rate": 2.1105227027557126e-05,
      "logits/chosen": 3.8135948181152344,
      "logits/rejected": 3.877373456954956,
      "logps/chosen": -417.05035400390625,
      "logps/rejected": -398.37017822265625,
      "loss": 0.3259,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.529139995574951,
      "rewards/margins": 3.5445969104766846,
      "rewards/rejected": -6.073736667633057,
      "step": 29480
    },
    {
      "epoch": 1.7357535818304846,
      "grad_norm": 4.960060119628906,
      "learning_rate": 2.1085613415710505e-05,
      "logits/chosen": 3.816930055618286,
      "logits/rejected": 3.730679750442505,
      "logps/chosen": -429.49090576171875,
      "logps/rejected": -334.2369384765625,
      "loss": 0.3693,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1021389961242676,
      "rewards/margins": 3.6853866577148438,
      "rewards/rejected": -5.7875261306762695,
      "step": 29500
    },
    {
      "epoch": 1.736930363919861,
      "grad_norm": 2.376370668411255,
      "learning_rate": 2.106599980386388e-05,
      "logits/chosen": 3.8141398429870605,
      "logits/rejected": 3.6535823345184326,
      "logps/chosen": -409.6869201660156,
      "logps/rejected": -334.56756591796875,
      "loss": 0.2982,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.226043939590454,
      "rewards/margins": 3.5036933422088623,
      "rewards/rejected": -5.729737758636475,
      "step": 29520
    },
    {
      "epoch": 1.7381071460092379,
      "grad_norm": 1.5780932903289795,
      "learning_rate": 2.104638619201726e-05,
      "logits/chosen": 3.5244381427764893,
      "logits/rejected": 3.332252025604248,
      "logps/chosen": -349.22235107421875,
      "logps/rejected": -330.759033203125,
      "loss": 0.2081,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.7646360397338867,
      "rewards/margins": 3.989192485809326,
      "rewards/rejected": -6.753828525543213,
      "step": 29540
    },
    {
      "epoch": 1.7392839280986143,
      "grad_norm": 0.7994126081466675,
      "learning_rate": 2.102677258017064e-05,
      "logits/chosen": 3.413017988204956,
      "logits/rejected": 3.601334810256958,
      "logps/chosen": -367.1292419433594,
      "logps/rejected": -348.0382385253906,
      "loss": 0.2227,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.6849159002304077,
      "rewards/margins": 3.870452404022217,
      "rewards/rejected": -5.555367946624756,
      "step": 29560
    },
    {
      "epoch": 1.740460710187991,
      "grad_norm": 0.8780919313430786,
      "learning_rate": 2.1007158968324016e-05,
      "logits/chosen": 3.4865097999572754,
      "logits/rejected": 3.31117582321167,
      "logps/chosen": -388.44171142578125,
      "logps/rejected": -302.3772277832031,
      "loss": 0.3077,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2836380004882812,
      "rewards/margins": 3.9917283058166504,
      "rewards/rejected": -6.275366306304932,
      "step": 29580
    },
    {
      "epoch": 1.7416374922773676,
      "grad_norm": 3.0270371437072754,
      "learning_rate": 2.0987545356477395e-05,
      "logits/chosen": 3.754096269607544,
      "logits/rejected": 3.8824667930603027,
      "logps/chosen": -404.2251892089844,
      "logps/rejected": -376.1871643066406,
      "loss": 0.3137,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.507585287094116,
      "rewards/margins": 3.875171661376953,
      "rewards/rejected": -6.38275671005249,
      "step": 29600
    },
    {
      "epoch": 1.742814274366744,
      "grad_norm": 1.503770112991333,
      "learning_rate": 2.0967931744630775e-05,
      "logits/chosen": 3.4173991680145264,
      "logits/rejected": 3.5633602142333984,
      "logps/chosen": -434.1124572753906,
      "logps/rejected": -351.9377136230469,
      "loss": 0.3347,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.0975637435913086,
      "rewards/margins": 3.4842591285705566,
      "rewards/rejected": -5.581823348999023,
      "step": 29620
    },
    {
      "epoch": 1.7439910564561207,
      "grad_norm": 5.1807708740234375,
      "learning_rate": 2.0948318132784154e-05,
      "logits/chosen": 3.6513333320617676,
      "logits/rejected": 3.3455874919891357,
      "logps/chosen": -401.0113220214844,
      "logps/rejected": -365.76947021484375,
      "loss": 0.3963,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -3.0016121864318848,
      "rewards/margins": 3.617708683013916,
      "rewards/rejected": -6.619320869445801,
      "step": 29640
    },
    {
      "epoch": 1.7451678385454974,
      "grad_norm": 2.6780896186828613,
      "learning_rate": 2.092870452093753e-05,
      "logits/chosen": 3.530034303665161,
      "logits/rejected": 3.3031907081604004,
      "logps/chosen": -389.3561096191406,
      "logps/rejected": -331.8407287597656,
      "loss": 0.3823,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.627610445022583,
      "rewards/margins": 3.6460697650909424,
      "rewards/rejected": -6.273680210113525,
      "step": 29660
    },
    {
      "epoch": 1.7463446206348738,
      "grad_norm": 8.776126861572266,
      "learning_rate": 2.090909090909091e-05,
      "logits/chosen": 3.8333797454833984,
      "logits/rejected": 3.928440570831299,
      "logps/chosen": -439.05914306640625,
      "logps/rejected": -397.251953125,
      "loss": 0.2841,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.581960678100586,
      "rewards/margins": 4.063016414642334,
      "rewards/rejected": -6.644977569580078,
      "step": 29680
    },
    {
      "epoch": 1.7475214027242505,
      "grad_norm": 1.1462600231170654,
      "learning_rate": 2.088947729724429e-05,
      "logits/chosen": 3.554680585861206,
      "logits/rejected": 3.644862651824951,
      "logps/chosen": -380.63787841796875,
      "logps/rejected": -328.78509521484375,
      "loss": 0.4606,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.788649797439575,
      "rewards/margins": 2.813192844390869,
      "rewards/rejected": -5.601842880249023,
      "step": 29700
    },
    {
      "epoch": 1.7486981848136272,
      "grad_norm": 5.632265567779541,
      "learning_rate": 2.086986368539767e-05,
      "logits/chosen": 3.4751086235046387,
      "logits/rejected": 3.345714569091797,
      "logps/chosen": -394.85601806640625,
      "logps/rejected": -364.1380920410156,
      "loss": 0.2882,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.0292000770568848,
      "rewards/margins": 4.1016154289245605,
      "rewards/rejected": -6.130815029144287,
      "step": 29720
    },
    {
      "epoch": 1.7498749669030036,
      "grad_norm": 2.7987821102142334,
      "learning_rate": 2.0850250073551045e-05,
      "logits/chosen": 3.390375852584839,
      "logits/rejected": 3.1921815872192383,
      "logps/chosen": -383.40496826171875,
      "logps/rejected": -334.4870910644531,
      "loss": 0.36,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.0646069049835205,
      "rewards/margins": 3.5690808296203613,
      "rewards/rejected": -5.6336870193481445,
      "step": 29740
    },
    {
      "epoch": 1.7510517489923805,
      "grad_norm": 3.1046574115753174,
      "learning_rate": 2.0830636461704424e-05,
      "logits/chosen": 3.6903858184814453,
      "logits/rejected": 3.6832237243652344,
      "logps/chosen": -360.86431884765625,
      "logps/rejected": -312.38836669921875,
      "loss": 0.3498,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -2.259502649307251,
      "rewards/margins": 3.578007459640503,
      "rewards/rejected": -5.837510108947754,
      "step": 29760
    },
    {
      "epoch": 1.752228531081757,
      "grad_norm": 0.5541808009147644,
      "learning_rate": 2.0811022849857803e-05,
      "logits/chosen": 3.9107863903045654,
      "logits/rejected": 3.757843017578125,
      "logps/chosen": -410.25958251953125,
      "logps/rejected": -363.4437561035156,
      "loss": 0.4008,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.5382466316223145,
      "rewards/margins": 3.6883442401885986,
      "rewards/rejected": -6.226590633392334,
      "step": 29780
    },
    {
      "epoch": 1.7534053131711336,
      "grad_norm": 9.131150245666504,
      "learning_rate": 2.079140923801118e-05,
      "logits/chosen": 3.5525660514831543,
      "logits/rejected": 3.3688175678253174,
      "logps/chosen": -369.3536376953125,
      "logps/rejected": -330.04205322265625,
      "loss": 0.319,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.259859561920166,
      "rewards/margins": 3.2117645740509033,
      "rewards/rejected": -5.471623420715332,
      "step": 29800
    },
    {
      "epoch": 1.7545820952605102,
      "grad_norm": 0.9194148182868958,
      "learning_rate": 2.077179562616456e-05,
      "logits/chosen": 3.454827070236206,
      "logits/rejected": 3.4724173545837402,
      "logps/chosen": -366.1687316894531,
      "logps/rejected": -319.7690124511719,
      "loss": 0.2483,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -2.2344329357147217,
      "rewards/margins": 3.8765156269073486,
      "rewards/rejected": -6.110948085784912,
      "step": 29820
    },
    {
      "epoch": 1.7557588773498867,
      "grad_norm": 5.933416843414307,
      "learning_rate": 2.0752182014317935e-05,
      "logits/chosen": 3.6953487396240234,
      "logits/rejected": 3.728456497192383,
      "logps/chosen": -403.4931640625,
      "logps/rejected": -390.0007019042969,
      "loss": 0.3469,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.0881507396698,
      "rewards/margins": 3.6275100708007812,
      "rewards/rejected": -5.715661525726318,
      "step": 29840
    },
    {
      "epoch": 1.7569356594392633,
      "grad_norm": 1.2859344482421875,
      "learning_rate": 2.0732568402471318e-05,
      "logits/chosen": 3.6033802032470703,
      "logits/rejected": 3.559842348098755,
      "logps/chosen": -440.42236328125,
      "logps/rejected": -367.0599060058594,
      "loss": 0.319,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.4311633110046387,
      "rewards/margins": 3.7897789478302,
      "rewards/rejected": -6.220942497253418,
      "step": 29860
    },
    {
      "epoch": 1.75811244152864,
      "grad_norm": 3.772369146347046,
      "learning_rate": 2.0712954790624694e-05,
      "logits/chosen": 3.648621082305908,
      "logits/rejected": 3.7800488471984863,
      "logps/chosen": -427.5616760253906,
      "logps/rejected": -348.9654235839844,
      "loss": 0.3298,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.5036778450012207,
      "rewards/margins": 3.5381197929382324,
      "rewards/rejected": -6.041797637939453,
      "step": 29880
    },
    {
      "epoch": 1.7592892236180164,
      "grad_norm": 0.5237482190132141,
      "learning_rate": 2.0693341178778073e-05,
      "logits/chosen": 3.6896870136260986,
      "logits/rejected": 3.673840284347534,
      "logps/chosen": -367.8601379394531,
      "logps/rejected": -338.79937744140625,
      "loss": 0.2983,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.6439616680145264,
      "rewards/margins": 3.111300468444824,
      "rewards/rejected": -5.75526237487793,
      "step": 29900
    },
    {
      "epoch": 1.760466005707393,
      "grad_norm": 0.1712881177663803,
      "learning_rate": 2.067372756693145e-05,
      "logits/chosen": 3.625309705734253,
      "logits/rejected": 3.5275497436523438,
      "logps/chosen": -381.1818542480469,
      "logps/rejected": -276.42108154296875,
      "loss": 0.3,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.6999225616455078,
      "rewards/margins": 3.5118401050567627,
      "rewards/rejected": -5.21176290512085,
      "step": 29920
    },
    {
      "epoch": 1.7616427877967697,
      "grad_norm": 5.490727424621582,
      "learning_rate": 2.0654113955084832e-05,
      "logits/chosen": 3.681671142578125,
      "logits/rejected": 3.627243757247925,
      "logps/chosen": -393.05316162109375,
      "logps/rejected": -410.7391052246094,
      "loss": 0.2957,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.073019504547119,
      "rewards/margins": 4.483216762542725,
      "rewards/rejected": -6.55623722076416,
      "step": 29940
    },
    {
      "epoch": 1.7628195698861462,
      "grad_norm": 1.9056686162948608,
      "learning_rate": 2.0634500343238208e-05,
      "logits/chosen": 3.592344284057617,
      "logits/rejected": 3.6505825519561768,
      "logps/chosen": -371.67864990234375,
      "logps/rejected": -300.44775390625,
      "loss": 0.2945,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9108673334121704,
      "rewards/margins": 3.572901487350464,
      "rewards/rejected": -5.483769416809082,
      "step": 29960
    },
    {
      "epoch": 1.763996351975523,
      "grad_norm": 1.3466349840164185,
      "learning_rate": 2.0614886731391588e-05,
      "logits/chosen": 3.680225372314453,
      "logits/rejected": 3.6985630989074707,
      "logps/chosen": -389.8701477050781,
      "logps/rejected": -342.0902099609375,
      "loss": 0.2934,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.5178364515304565,
      "rewards/margins": 3.891085147857666,
      "rewards/rejected": -5.408921718597412,
      "step": 29980
    },
    {
      "epoch": 1.7651731340648995,
      "grad_norm": 4.638200759887695,
      "learning_rate": 2.0595273119544964e-05,
      "logits/chosen": 3.7402946949005127,
      "logits/rejected": 3.6970455646514893,
      "logps/chosen": -423.5067443847656,
      "logps/rejected": -357.3579406738281,
      "loss": 0.3911,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.132655382156372,
      "rewards/margins": 3.9252827167510986,
      "rewards/rejected": -6.0579376220703125,
      "step": 30000
    },
    {
      "epoch": 1.7651731340648995,
      "eval_logits/chosen": 3.308021306991577,
      "eval_logits/rejected": 3.3051705360412598,
      "eval_logps/chosen": -380.4150085449219,
      "eval_logps/rejected": -349.81939697265625,
      "eval_loss": 0.5158228874206543,
      "eval_rewards/accuracies": 0.7874910235404968,
      "eval_rewards/chosen": -2.583434820175171,
      "eval_rewards/margins": 2.775186538696289,
      "eval_rewards/rejected": -5.358621120452881,
      "eval_runtime": 3547.5876,
      "eval_samples_per_second": 3.15,
      "eval_steps_per_second": 3.15,
      "step": 30000
    }
  ],
  "logging_steps": 20,
  "max_steps": 50985,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 5000,
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
