{
  "best_metric": 0.6243801116943359,
  "best_model_checkpoint": "checkpoints/microsoft/Phi-3-mini-4k-instructm1-ultra/checkpoint-20000",
  "epoch": 0.9844094158760629,
  "eval_steps": 10000,
  "global_step": 20000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0009844094158760629,
      "grad_norm": 2.71203351020813,
      "learning_rate": 4.998523331364442e-05,
      "logits/chosen": 2.957465648651123,
      "logits/rejected": 2.984595537185669,
      "logps/chosen": -267.97735595703125,
      "logps/rejected": -253.0709228515625,
      "loss": 0.6853,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -0.022350430488586426,
      "rewards/margins": 0.01709343120455742,
      "rewards/rejected": -0.039443857967853546,
      "step": 20
    },
    {
      "epoch": 0.0019688188317521257,
      "grad_norm": 2.7438340187072754,
      "learning_rate": 4.9968825884360446e-05,
      "logits/chosen": 2.6072800159454346,
      "logits/rejected": 2.6713223457336426,
      "logps/chosen": -235.44088745117188,
      "logps/rejected": -195.17422485351562,
      "loss": 0.6942,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": -0.06300482898950577,
      "rewards/margins": 0.003117100102826953,
      "rewards/rejected": -0.06612193584442139,
      "step": 40
    },
    {
      "epoch": 0.0029532282476281884,
      "grad_norm": 2.246617555618286,
      "learning_rate": 4.995323882654066e-05,
      "logits/chosen": 2.7237296104431152,
      "logits/rejected": 2.778411388397217,
      "logps/chosen": -251.4857940673828,
      "logps/rejected": -244.90145874023438,
      "loss": 0.673,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.139781191945076,
      "rewards/margins": 0.06582178175449371,
      "rewards/rejected": -0.2056029736995697,
      "step": 60
    },
    {
      "epoch": 0.0039376376635042514,
      "grad_norm": 1.7988168001174927,
      "learning_rate": 4.993683139725668e-05,
      "logits/chosen": 2.4376144409179688,
      "logits/rejected": 2.6283864974975586,
      "logps/chosen": -222.1396026611328,
      "logps/rejected": -210.89697265625,
      "loss": 0.624,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.3247653841972351,
      "rewards/margins": 0.22392527759075165,
      "rewards/rejected": -0.548690676689148,
      "step": 80
    },
    {
      "epoch": 0.0049220470793803145,
      "grad_norm": 3.7210533618927,
      "learning_rate": 4.9920423967972705e-05,
      "logits/chosen": 2.3742244243621826,
      "logits/rejected": 2.514650821685791,
      "logps/chosen": -255.36001586914062,
      "logps/rejected": -240.88601684570312,
      "loss": 0.6382,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.5465198755264282,
      "rewards/margins": 0.34793010354042053,
      "rewards/rejected": -0.8944498896598816,
      "step": 100
    },
    {
      "epoch": 0.005906456495256377,
      "grad_norm": 1.9198540449142456,
      "learning_rate": 4.990401653868872e-05,
      "logits/chosen": 2.6019928455352783,
      "logits/rejected": 2.7245466709136963,
      "logps/chosen": -258.64544677734375,
      "logps/rejected": -233.7217254638672,
      "loss": 0.6471,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.4515560269355774,
      "rewards/margins": 0.28154096007347107,
      "rewards/rejected": -0.7330969572067261,
      "step": 120
    },
    {
      "epoch": 0.00689086591113244,
      "grad_norm": 2.0685722827911377,
      "learning_rate": 4.9887609109404745e-05,
      "logits/chosen": 2.5532052516937256,
      "logits/rejected": 2.4377951622009277,
      "logps/chosen": -253.4102325439453,
      "logps/rejected": -251.7006378173828,
      "loss": 0.672,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.5395873188972473,
      "rewards/margins": 0.26644378900527954,
      "rewards/rejected": -0.8060310482978821,
      "step": 140
    },
    {
      "epoch": 0.007875275327008503,
      "grad_norm": 2.5778238773345947,
      "learning_rate": 4.987120168012076e-05,
      "logits/chosen": 2.3495163917541504,
      "logits/rejected": 2.384897470474243,
      "logps/chosen": -255.5848846435547,
      "logps/rejected": -243.0070343017578,
      "loss": 0.613,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.7487354874610901,
      "rewards/margins": 0.61981600522995,
      "rewards/rejected": -1.36855149269104,
      "step": 160
    },
    {
      "epoch": 0.008859684742884566,
      "grad_norm": 2.1219918727874756,
      "learning_rate": 4.985561462230098e-05,
      "logits/chosen": 2.0913593769073486,
      "logits/rejected": 2.2501895427703857,
      "logps/chosen": -230.892333984375,
      "logps/rejected": -217.5729522705078,
      "loss": 0.7514,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.8956815004348755,
      "rewards/margins": 0.2529618442058563,
      "rewards/rejected": -1.1486433744430542,
      "step": 180
    },
    {
      "epoch": 0.009844094158760629,
      "grad_norm": 1.8984770774841309,
      "learning_rate": 4.9839207193017004e-05,
      "logits/chosen": 2.4384918212890625,
      "logits/rejected": 2.662536144256592,
      "logps/chosen": -253.5559539794922,
      "logps/rejected": -250.6572265625,
      "loss": 0.5801,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.49692314863204956,
      "rewards/margins": 0.6071321368217468,
      "rewards/rejected": -1.1040552854537964,
      "step": 200
    },
    {
      "epoch": 0.010828503574636692,
      "grad_norm": 1.3409961462020874,
      "learning_rate": 4.982279976373302e-05,
      "logits/chosen": 2.362621784210205,
      "logits/rejected": 2.4722158908843994,
      "logps/chosen": -241.6057586669922,
      "logps/rejected": -247.58590698242188,
      "loss": 0.6651,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.671251118183136,
      "rewards/margins": 0.4809889793395996,
      "rewards/rejected": -1.1522401571273804,
      "step": 220
    },
    {
      "epoch": 0.011812912990512753,
      "grad_norm": 2.4130611419677734,
      "learning_rate": 4.9806392334449044e-05,
      "logits/chosen": 2.2305967807769775,
      "logits/rejected": 2.2844862937927246,
      "logps/chosen": -222.8115234375,
      "logps/rejected": -226.50570678710938,
      "loss": 0.699,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.7420638203620911,
      "rewards/margins": 0.24797359108924866,
      "rewards/rejected": -0.9900373220443726,
      "step": 240
    },
    {
      "epoch": 0.012797322406388817,
      "grad_norm": 2.045304298400879,
      "learning_rate": 4.978998490516506e-05,
      "logits/chosen": 2.2728257179260254,
      "logits/rejected": 2.3907454013824463,
      "logps/chosen": -221.0391387939453,
      "logps/rejected": -235.89382934570312,
      "loss": 0.6788,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.44855862855911255,
      "rewards/margins": 0.24933162331581116,
      "rewards/rejected": -0.6978902816772461,
      "step": 260
    },
    {
      "epoch": 0.01378173182226488,
      "grad_norm": 2.067974805831909,
      "learning_rate": 4.9773577475881085e-05,
      "logits/chosen": 2.6952147483825684,
      "logits/rejected": 2.7579855918884277,
      "logps/chosen": -232.84030151367188,
      "logps/rejected": -249.1961669921875,
      "loss": 0.647,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.3608093857765198,
      "rewards/margins": 0.3432233929634094,
      "rewards/rejected": -0.7040327787399292,
      "step": 280
    },
    {
      "epoch": 0.014766141238140943,
      "grad_norm": 2.8637819290161133,
      "learning_rate": 4.97571700465971e-05,
      "logits/chosen": 2.43499493598938,
      "logits/rejected": 2.5934321880340576,
      "logps/chosen": -276.724365234375,
      "logps/rejected": -278.9312744140625,
      "loss": 0.6299,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.5770549774169922,
      "rewards/margins": 0.45372405648231506,
      "rewards/rejected": -1.0307788848876953,
      "step": 300
    },
    {
      "epoch": 0.015750550654017006,
      "grad_norm": 3.1083242893218994,
      "learning_rate": 4.974076261731312e-05,
      "logits/chosen": 2.431627035140991,
      "logits/rejected": 2.4374799728393555,
      "logps/chosen": -265.8416442871094,
      "logps/rejected": -251.27304077148438,
      "loss": 0.6681,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.6403684020042419,
      "rewards/margins": 0.379196435213089,
      "rewards/rejected": -1.0195648670196533,
      "step": 320
    },
    {
      "epoch": 0.016734960069893067,
      "grad_norm": 5.453766822814941,
      "learning_rate": 4.972435518802914e-05,
      "logits/chosen": 2.2643933296203613,
      "logits/rejected": 2.501317024230957,
      "logps/chosen": -254.0827178955078,
      "logps/rejected": -272.36920166015625,
      "loss": 0.5062,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.6988680958747864,
      "rewards/margins": 0.9775550961494446,
      "rewards/rejected": -1.6764230728149414,
      "step": 340
    },
    {
      "epoch": 0.017719369485769132,
      "grad_norm": 2.396991729736328,
      "learning_rate": 4.970876813020936e-05,
      "logits/chosen": 2.2209582328796387,
      "logits/rejected": 2.3463728427886963,
      "logps/chosen": -277.43804931640625,
      "logps/rejected": -283.10247802734375,
      "loss": 0.563,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.7634962201118469,
      "rewards/margins": 0.6582193970680237,
      "rewards/rejected": -1.421715497970581,
      "step": 360
    },
    {
      "epoch": 0.018703778901645193,
      "grad_norm": 2.953885555267334,
      "learning_rate": 4.9692360700925384e-05,
      "logits/chosen": 2.4989962577819824,
      "logits/rejected": 2.641308546066284,
      "logps/chosen": -249.40927124023438,
      "logps/rejected": -270.5180358886719,
      "loss": 0.5769,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.8061347007751465,
      "rewards/margins": 0.6546062231063843,
      "rewards/rejected": -1.4607410430908203,
      "step": 380
    },
    {
      "epoch": 0.019688188317521258,
      "grad_norm": 5.946464538574219,
      "learning_rate": 4.96759532716414e-05,
      "logits/chosen": 2.2198493480682373,
      "logits/rejected": 2.3273022174835205,
      "logps/chosen": -264.0502014160156,
      "logps/rejected": -263.82330322265625,
      "loss": 0.6104,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.4441148042678833,
      "rewards/margins": 1.1626255512237549,
      "rewards/rejected": -2.6067404747009277,
      "step": 400
    },
    {
      "epoch": 0.02067259773339732,
      "grad_norm": 2.563537836074829,
      "learning_rate": 4.9659545842357425e-05,
      "logits/chosen": 2.369321346282959,
      "logits/rejected": 2.5406789779663086,
      "logps/chosen": -268.41473388671875,
      "logps/rejected": -260.13043212890625,
      "loss": 0.6722,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4398581981658936,
      "rewards/margins": 0.8584903478622437,
      "rewards/rejected": -2.2983486652374268,
      "step": 420
    },
    {
      "epoch": 0.021657007149273384,
      "grad_norm": 3.462710380554199,
      "learning_rate": 4.964313841307344e-05,
      "logits/chosen": 2.5895707607269287,
      "logits/rejected": 2.738248348236084,
      "logps/chosen": -260.02386474609375,
      "logps/rejected": -270.4794006347656,
      "loss": 0.5402,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0673513412475586,
      "rewards/margins": 1.0011574029922485,
      "rewards/rejected": -2.0685088634490967,
      "step": 440
    },
    {
      "epoch": 0.022641416565149446,
      "grad_norm": 1.7112706899642944,
      "learning_rate": 4.962673098378946e-05,
      "logits/chosen": 2.376201629638672,
      "logits/rejected": 2.481182813644409,
      "logps/chosen": -285.43170166015625,
      "logps/rejected": -246.5431671142578,
      "loss": 0.5183,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3695669174194336,
      "rewards/margins": 1.0670984983444214,
      "rewards/rejected": -2.4366652965545654,
      "step": 460
    },
    {
      "epoch": 0.023625825981025507,
      "grad_norm": 5.52561092376709,
      "learning_rate": 4.961032355450548e-05,
      "logits/chosen": 2.428779125213623,
      "logits/rejected": 2.6656243801116943,
      "logps/chosen": -255.6117401123047,
      "logps/rejected": -277.45123291015625,
      "loss": 0.6417,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1785393953323364,
      "rewards/margins": 1.0549558401107788,
      "rewards/rejected": -2.2334952354431152,
      "step": 480
    },
    {
      "epoch": 0.024610235396901572,
      "grad_norm": 2.403618097305298,
      "learning_rate": 4.95939161252215e-05,
      "logits/chosen": 2.5448076725006104,
      "logits/rejected": 2.632227659225464,
      "logps/chosen": -263.38421630859375,
      "logps/rejected": -272.90545654296875,
      "loss": 0.5546,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1240938901901245,
      "rewards/margins": 1.1621812582015991,
      "rewards/rejected": -2.2862751483917236,
      "step": 500
    },
    {
      "epoch": 0.025594644812777633,
      "grad_norm": 1.8814581632614136,
      "learning_rate": 4.957750869593752e-05,
      "logits/chosen": 2.351773500442505,
      "logits/rejected": 2.378462314605713,
      "logps/chosen": -236.628662109375,
      "logps/rejected": -243.06640625,
      "loss": 0.6569,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.276062250137329,
      "rewards/margins": 0.9595931768417358,
      "rewards/rejected": -2.2356553077697754,
      "step": 520
    },
    {
      "epoch": 0.026579054228653698,
      "grad_norm": 4.471168518066406,
      "learning_rate": 4.956110126665354e-05,
      "logits/chosen": 2.33103609085083,
      "logits/rejected": 2.561854600906372,
      "logps/chosen": -250.54183959960938,
      "logps/rejected": -265.36260986328125,
      "loss": 0.5634,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.3540189266204834,
      "rewards/margins": 1.3338117599487305,
      "rewards/rejected": -2.6878304481506348,
      "step": 540
    },
    {
      "epoch": 0.02756346364452976,
      "grad_norm": 5.519854545593262,
      "learning_rate": 4.954469383736956e-05,
      "logits/chosen": 2.284345865249634,
      "logits/rejected": 2.378077983856201,
      "logps/chosen": -267.4544677734375,
      "logps/rejected": -244.1553497314453,
      "loss": 0.68,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.7042869329452515,
      "rewards/margins": 0.9809419512748718,
      "rewards/rejected": -2.6852290630340576,
      "step": 560
    },
    {
      "epoch": 0.028547873060405824,
      "grad_norm": 5.389985084533691,
      "learning_rate": 4.9528286408085586e-05,
      "logits/chosen": 2.581638813018799,
      "logits/rejected": 2.5745980739593506,
      "logps/chosen": -267.60028076171875,
      "logps/rejected": -266.5680236816406,
      "loss": 0.5897,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.7134769558906555,
      "rewards/margins": 0.8340872526168823,
      "rewards/rejected": -1.547564148902893,
      "step": 580
    },
    {
      "epoch": 0.029532282476281885,
      "grad_norm": 1.9290492534637451,
      "learning_rate": 4.95118789788016e-05,
      "logits/chosen": 2.417025089263916,
      "logits/rejected": 2.648923873901367,
      "logps/chosen": -256.1499938964844,
      "logps/rejected": -265.0333251953125,
      "loss": 0.5045,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.532476007938385,
      "rewards/margins": 1.365614414215088,
      "rewards/rejected": -1.8980903625488281,
      "step": 600
    },
    {
      "epoch": 0.030516691892157947,
      "grad_norm": 2.6975619792938232,
      "learning_rate": 4.949547154951763e-05,
      "logits/chosen": 2.5723235607147217,
      "logits/rejected": 2.691554307937622,
      "logps/chosen": -264.1063537597656,
      "logps/rejected": -273.65863037109375,
      "loss": 0.5605,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.2042014598846436,
      "rewards/margins": 1.230505347251892,
      "rewards/rejected": -2.434706687927246,
      "step": 620
    },
    {
      "epoch": 0.03150110130803401,
      "grad_norm": 5.387156963348389,
      "learning_rate": 4.9479064120233644e-05,
      "logits/chosen": 2.4431443214416504,
      "logits/rejected": 2.561652421951294,
      "logps/chosen": -249.3222198486328,
      "logps/rejected": -269.1903076171875,
      "loss": 0.6022,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.7498327493667603,
      "rewards/margins": 1.163905382156372,
      "rewards/rejected": -2.9137377738952637,
      "step": 640
    },
    {
      "epoch": 0.03248551072391007,
      "grad_norm": 1.6515297889709473,
      "learning_rate": 4.946265669094967e-05,
      "logits/chosen": 2.4054107666015625,
      "logits/rejected": 2.641200065612793,
      "logps/chosen": -260.9745788574219,
      "logps/rejected": -264.9809875488281,
      "loss": 0.617,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3518955707550049,
      "rewards/margins": 1.186448335647583,
      "rewards/rejected": -2.538343667984009,
      "step": 660
    },
    {
      "epoch": 0.033469920139786134,
      "grad_norm": 4.28360652923584,
      "learning_rate": 4.9446249261665684e-05,
      "logits/chosen": 2.2673768997192383,
      "logits/rejected": 2.4357762336730957,
      "logps/chosen": -254.33609008789062,
      "logps/rejected": -253.210693359375,
      "loss": 0.5815,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.8288921117782593,
      "rewards/margins": 1.3003956079483032,
      "rewards/rejected": -3.1292879581451416,
      "step": 680
    },
    {
      "epoch": 0.0344543295556622,
      "grad_norm": 3.2858097553253174,
      "learning_rate": 4.942984183238171e-05,
      "logits/chosen": 2.2785234451293945,
      "logits/rejected": 2.296766519546509,
      "logps/chosen": -290.493896484375,
      "logps/rejected": -275.0403137207031,
      "loss": 0.6062,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.8134806156158447,
      "rewards/margins": 1.04676353931427,
      "rewards/rejected": -2.8602442741394043,
      "step": 700
    },
    {
      "epoch": 0.035438738971538264,
      "grad_norm": 4.598387718200684,
      "learning_rate": 4.9413434403097725e-05,
      "logits/chosen": 2.3753366470336914,
      "logits/rejected": 2.470299243927002,
      "logps/chosen": -228.4347381591797,
      "logps/rejected": -229.09292602539062,
      "loss": 0.5752,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.1419488191604614,
      "rewards/margins": 0.9887348413467407,
      "rewards/rejected": -2.130683422088623,
      "step": 720
    },
    {
      "epoch": 0.036423148387414325,
      "grad_norm": 2.478616714477539,
      "learning_rate": 4.939702697381374e-05,
      "logits/chosen": 2.718623399734497,
      "logits/rejected": 2.894758939743042,
      "logps/chosen": -275.6309509277344,
      "logps/rejected": -253.80197143554688,
      "loss": 0.6133,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.2880866527557373,
      "rewards/margins": 0.8106021881103516,
      "rewards/rejected": -2.0986886024475098,
      "step": 740
    },
    {
      "epoch": 0.03740755780329039,
      "grad_norm": 1.4550713300704956,
      "learning_rate": 4.9380619544529765e-05,
      "logits/chosen": 2.1166043281555176,
      "logits/rejected": 2.199932813644409,
      "logps/chosen": -245.86843872070312,
      "logps/rejected": -293.8370361328125,
      "loss": 0.4045,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.1029365062713623,
      "rewards/margins": 1.6451518535614014,
      "rewards/rejected": -2.748088836669922,
      "step": 760
    },
    {
      "epoch": 0.03839196721916645,
      "grad_norm": 2.8968253135681152,
      "learning_rate": 4.936421211524578e-05,
      "logits/chosen": 2.127570629119873,
      "logits/rejected": 2.350264072418213,
      "logps/chosen": -273.7164611816406,
      "logps/rejected": -240.95260620117188,
      "loss": 0.598,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.5890719890594482,
      "rewards/margins": 1.2077096700668335,
      "rewards/rejected": -2.796781539916992,
      "step": 780
    },
    {
      "epoch": 0.039376376635042516,
      "grad_norm": 2.0047082901000977,
      "learning_rate": 4.9347804685961805e-05,
      "logits/chosen": 2.258089303970337,
      "logits/rejected": 2.5423436164855957,
      "logps/chosen": -266.8034973144531,
      "logps/rejected": -283.7034912109375,
      "loss": 0.3804,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -0.9637292623519897,
      "rewards/margins": 1.892869234085083,
      "rewards/rejected": -2.856598377227783,
      "step": 800
    },
    {
      "epoch": 0.04036078605091858,
      "grad_norm": 0.5514822006225586,
      "learning_rate": 4.933139725667782e-05,
      "logits/chosen": 2.5489048957824707,
      "logits/rejected": 2.886042833328247,
      "logps/chosen": -278.0829772949219,
      "logps/rejected": -291.66290283203125,
      "loss": 0.4241,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.7919099926948547,
      "rewards/margins": 1.5265675783157349,
      "rewards/rejected": -2.3184776306152344,
      "step": 820
    },
    {
      "epoch": 0.04134519546679464,
      "grad_norm": 2.629704475402832,
      "learning_rate": 4.9314989827393846e-05,
      "logits/chosen": 1.9175176620483398,
      "logits/rejected": 2.1342339515686035,
      "logps/chosen": -251.4705352783203,
      "logps/rejected": -300.7830505371094,
      "loss": 0.543,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.270581603050232,
      "rewards/margins": 1.3736134767532349,
      "rewards/rejected": -2.644195079803467,
      "step": 840
    },
    {
      "epoch": 0.0423296048826707,
      "grad_norm": 0.8785568475723267,
      "learning_rate": 4.929858239810986e-05,
      "logits/chosen": 2.1660099029541016,
      "logits/rejected": 2.5007872581481934,
      "logps/chosen": -252.76113891601562,
      "logps/rejected": -251.338134765625,
      "loss": 0.534,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3935775756835938,
      "rewards/margins": 1.4424333572387695,
      "rewards/rejected": -2.8360111713409424,
      "step": 860
    },
    {
      "epoch": 0.04331401429854677,
      "grad_norm": 3.5176632404327393,
      "learning_rate": 4.9282174968825886e-05,
      "logits/chosen": 2.251955509185791,
      "logits/rejected": 2.4091057777404785,
      "logps/chosen": -253.6544189453125,
      "logps/rejected": -258.8145446777344,
      "loss": 0.6527,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.6684770584106445,
      "rewards/margins": 1.3155384063720703,
      "rewards/rejected": -2.984015464782715,
      "step": 880
    },
    {
      "epoch": 0.04429842371442283,
      "grad_norm": 2.5119519233703613,
      "learning_rate": 4.926576753954191e-05,
      "logits/chosen": 2.250187397003174,
      "logits/rejected": 2.3689188957214355,
      "logps/chosen": -233.4984893798828,
      "logps/rejected": -243.5924835205078,
      "loss": 0.6161,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2118438482284546,
      "rewards/margins": 1.1259794235229492,
      "rewards/rejected": -2.3378233909606934,
      "step": 900
    },
    {
      "epoch": 0.04528283313029889,
      "grad_norm": 6.041410446166992,
      "learning_rate": 4.924936011025793e-05,
      "logits/chosen": 2.12790584564209,
      "logits/rejected": 2.446956157684326,
      "logps/chosen": -275.72601318359375,
      "logps/rejected": -275.1249084472656,
      "loss": 0.482,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.2129273414611816,
      "rewards/margins": 1.545534610748291,
      "rewards/rejected": -3.7584617137908936,
      "step": 920
    },
    {
      "epoch": 0.04626724254617495,
      "grad_norm": 2.7822885513305664,
      "learning_rate": 4.923295268097395e-05,
      "logits/chosen": 1.9821796417236328,
      "logits/rejected": 2.236785888671875,
      "logps/chosen": -258.8658752441406,
      "logps/rejected": -247.75570678710938,
      "loss": 0.4708,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.692116141319275,
      "rewards/margins": 1.6046984195709229,
      "rewards/rejected": -3.2968146800994873,
      "step": 940
    },
    {
      "epoch": 0.047251651962051014,
      "grad_norm": 1.7044917345046997,
      "learning_rate": 4.921654525168997e-05,
      "logits/chosen": 2.345560312271118,
      "logits/rejected": 2.693082571029663,
      "logps/chosen": -276.9158630371094,
      "logps/rejected": -289.357666015625,
      "loss": 0.4852,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.006042242050171,
      "rewards/margins": 1.8485130071640015,
      "rewards/rejected": -3.854555130004883,
      "step": 960
    },
    {
      "epoch": 0.04823606137792708,
      "grad_norm": 7.3362836837768555,
      "learning_rate": 4.920013782240599e-05,
      "logits/chosen": 2.1915462017059326,
      "logits/rejected": 2.4762954711914062,
      "logps/chosen": -268.3058776855469,
      "logps/rejected": -267.0329284667969,
      "loss": 0.5541,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -3.19197416305542,
      "rewards/margins": 1.420030951499939,
      "rewards/rejected": -4.612005710601807,
      "step": 980
    },
    {
      "epoch": 0.049220470793803144,
      "grad_norm": 2.3766956329345703,
      "learning_rate": 4.918373039312201e-05,
      "logits/chosen": 2.3782334327697754,
      "logits/rejected": 2.7426536083221436,
      "logps/chosen": -276.7232360839844,
      "logps/rejected": -267.64239501953125,
      "loss": 0.4333,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.399421215057373,
      "rewards/margins": 2.047513961791992,
      "rewards/rejected": -4.446935176849365,
      "step": 1000
    },
    {
      "epoch": 0.050204880209679205,
      "grad_norm": 1.6685163974761963,
      "learning_rate": 4.916732296383803e-05,
      "logits/chosen": 2.4907572269439697,
      "logits/rejected": 2.6196694374084473,
      "logps/chosen": -299.77178955078125,
      "logps/rejected": -264.61383056640625,
      "loss": 0.6864,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.674938917160034,
      "rewards/margins": 1.1394709348678589,
      "rewards/rejected": -3.8144092559814453,
      "step": 1020
    },
    {
      "epoch": 0.051189289625555266,
      "grad_norm": 2.4211888313293457,
      "learning_rate": 4.915091553455405e-05,
      "logits/chosen": 2.1393914222717285,
      "logits/rejected": 2.411090850830078,
      "logps/chosen": -258.1197509765625,
      "logps/rejected": -278.13934326171875,
      "loss": 0.6338,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.1966702938079834,
      "rewards/margins": 1.5742019414901733,
      "rewards/rejected": -3.7708725929260254,
      "step": 1040
    },
    {
      "epoch": 0.052173699041431335,
      "grad_norm": 2.7177345752716064,
      "learning_rate": 4.9134508105270065e-05,
      "logits/chosen": 2.264094352722168,
      "logits/rejected": 2.5420496463775635,
      "logps/chosen": -255.6722869873047,
      "logps/rejected": -272.81671142578125,
      "loss": 0.4133,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.404299259185791,
      "rewards/margins": 1.642256498336792,
      "rewards/rejected": -4.046555519104004,
      "step": 1060
    },
    {
      "epoch": 0.053158108457307396,
      "grad_norm": 0.5468194484710693,
      "learning_rate": 4.911810067598609e-05,
      "logits/chosen": 2.4164395332336426,
      "logits/rejected": 2.540501117706299,
      "logps/chosen": -265.07421875,
      "logps/rejected": -251.40737915039062,
      "loss": 0.7806,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.7468371391296387,
      "rewards/margins": 1.1435751914978027,
      "rewards/rejected": -3.8904125690460205,
      "step": 1080
    },
    {
      "epoch": 0.05414251787318346,
      "grad_norm": 2.205416202545166,
      "learning_rate": 4.9101693246702105e-05,
      "logits/chosen": 2.7001681327819824,
      "logits/rejected": 2.7890095710754395,
      "logps/chosen": -274.0343322753906,
      "logps/rejected": -278.33807373046875,
      "loss": 0.535,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6661708354949951,
      "rewards/margins": 1.728287935256958,
      "rewards/rejected": -3.394458293914795,
      "step": 1100
    },
    {
      "epoch": 0.05512692728905952,
      "grad_norm": 2.2264351844787598,
      "learning_rate": 4.908528581741813e-05,
      "logits/chosen": 2.8444759845733643,
      "logits/rejected": 3.1297993659973145,
      "logps/chosen": -265.3133239746094,
      "logps/rejected": -239.87405395507812,
      "loss": 0.5426,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.5576133728027344,
      "rewards/margins": 1.5159374475479126,
      "rewards/rejected": -3.0735507011413574,
      "step": 1120
    },
    {
      "epoch": 0.05611133670493558,
      "grad_norm": 1.5898354053497314,
      "learning_rate": 4.9068878388134146e-05,
      "logits/chosen": 2.5913541316986084,
      "logits/rejected": 2.8800666332244873,
      "logps/chosen": -240.79287719726562,
      "logps/rejected": -252.5976104736328,
      "loss": 0.5549,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3070050477981567,
      "rewards/margins": 1.2974380254745483,
      "rewards/rejected": -2.604443073272705,
      "step": 1140
    },
    {
      "epoch": 0.05709574612081165,
      "grad_norm": 1.675034999847412,
      "learning_rate": 4.905247095885017e-05,
      "logits/chosen": 2.7241384983062744,
      "logits/rejected": 2.973426342010498,
      "logps/chosen": -268.7751770019531,
      "logps/rejected": -274.64691162109375,
      "loss": 0.4844,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4201836585998535,
      "rewards/margins": 1.7050931453704834,
      "rewards/rejected": -3.125277042388916,
      "step": 1160
    },
    {
      "epoch": 0.05808015553668771,
      "grad_norm": 2.169741630554199,
      "learning_rate": 4.9036063529566186e-05,
      "logits/chosen": 2.752088785171509,
      "logits/rejected": 2.7817625999450684,
      "logps/chosen": -257.67681884765625,
      "logps/rejected": -262.5139465332031,
      "loss": 0.4997,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.4794937372207642,
      "rewards/margins": 1.5027501583099365,
      "rewards/rejected": -2.982243537902832,
      "step": 1180
    },
    {
      "epoch": 0.05906456495256377,
      "grad_norm": 5.669976711273193,
      "learning_rate": 4.901965610028221e-05,
      "logits/chosen": 2.376389980316162,
      "logits/rejected": 2.5262458324432373,
      "logps/chosen": -256.4397888183594,
      "logps/rejected": -247.95932006835938,
      "loss": 0.5887,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.1459519863128662,
      "rewards/margins": 1.43767511844635,
      "rewards/rejected": -2.583627223968506,
      "step": 1200
    },
    {
      "epoch": 0.06004897436843983,
      "grad_norm": 1.4546889066696167,
      "learning_rate": 4.9003248670998233e-05,
      "logits/chosen": 2.4436495304107666,
      "logits/rejected": 2.71165132522583,
      "logps/chosen": -273.58111572265625,
      "logps/rejected": -254.9241180419922,
      "loss": 0.5589,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4228025674819946,
      "rewards/margins": 1.3430746793746948,
      "rewards/rejected": -2.7658772468566895,
      "step": 1220
    },
    {
      "epoch": 0.061033383784315894,
      "grad_norm": 9.64658260345459,
      "learning_rate": 4.898684124171425e-05,
      "logits/chosen": 2.7500216960906982,
      "logits/rejected": 2.743867874145508,
      "logps/chosen": -249.08102416992188,
      "logps/rejected": -264.47320556640625,
      "loss": 0.75,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.2458996772766113,
      "rewards/margins": 1.8144340515136719,
      "rewards/rejected": -4.060334205627441,
      "step": 1240
    },
    {
      "epoch": 0.06201779320019196,
      "grad_norm": 2.621650218963623,
      "learning_rate": 4.8970433812430274e-05,
      "logits/chosen": 2.8286757469177246,
      "logits/rejected": 3.0275588035583496,
      "logps/chosen": -282.743896484375,
      "logps/rejected": -273.7216491699219,
      "loss": 0.4926,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6172282695770264,
      "rewards/margins": 1.5925953388214111,
      "rewards/rejected": -3.2098240852355957,
      "step": 1260
    },
    {
      "epoch": 0.06300220261606802,
      "grad_norm": 4.102959632873535,
      "learning_rate": 4.895402638314629e-05,
      "logits/chosen": 2.3930258750915527,
      "logits/rejected": 2.5497870445251465,
      "logps/chosen": -255.5419921875,
      "logps/rejected": -267.52655029296875,
      "loss": 0.55,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8951470851898193,
      "rewards/margins": 1.5559980869293213,
      "rewards/rejected": -3.4511451721191406,
      "step": 1280
    },
    {
      "epoch": 0.06398661203194408,
      "grad_norm": 1.027270793914795,
      "learning_rate": 4.8937618953862314e-05,
      "logits/chosen": 2.5495033264160156,
      "logits/rejected": 2.761465311050415,
      "logps/chosen": -241.05307006835938,
      "logps/rejected": -228.32333374023438,
      "loss": 0.5379,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4430906772613525,
      "rewards/margins": 1.4064524173736572,
      "rewards/rejected": -2.8495430946350098,
      "step": 1300
    },
    {
      "epoch": 0.06497102144782015,
      "grad_norm": 4.522170543670654,
      "learning_rate": 4.892121152457833e-05,
      "logits/chosen": 2.8608040809631348,
      "logits/rejected": 3.076110363006592,
      "logps/chosen": -261.5962219238281,
      "logps/rejected": -262.3864440917969,
      "loss": 0.516,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.25034499168396,
      "rewards/margins": 1.797487497329712,
      "rewards/rejected": -3.047832489013672,
      "step": 1320
    },
    {
      "epoch": 0.06595543086369621,
      "grad_norm": 0.6361497640609741,
      "learning_rate": 4.8904804095294355e-05,
      "logits/chosen": 2.4649338722229004,
      "logits/rejected": 2.710526943206787,
      "logps/chosen": -267.7846374511719,
      "logps/rejected": -285.7303466796875,
      "loss": 0.5302,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.112313747406006,
      "rewards/margins": 1.6230356693267822,
      "rewards/rejected": -3.735349178314209,
      "step": 1340
    },
    {
      "epoch": 0.06693984027957227,
      "grad_norm": 5.8255696296691895,
      "learning_rate": 4.888839666601037e-05,
      "logits/chosen": 2.4108474254608154,
      "logits/rejected": 2.531240701675415,
      "logps/chosen": -234.1631317138672,
      "logps/rejected": -276.0281982421875,
      "loss": 0.5868,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6688426733016968,
      "rewards/margins": 1.4515814781188965,
      "rewards/rejected": -3.120424270629883,
      "step": 1360
    },
    {
      "epoch": 0.06792424969544834,
      "grad_norm": 2.568772315979004,
      "learning_rate": 4.887198923672639e-05,
      "logits/chosen": 2.621612548828125,
      "logits/rejected": 2.705559492111206,
      "logps/chosen": -268.0343017578125,
      "logps/rejected": -262.0182800292969,
      "loss": 0.5126,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5689207315444946,
      "rewards/margins": 1.627697229385376,
      "rewards/rejected": -3.196617841720581,
      "step": 1380
    },
    {
      "epoch": 0.0689086591113244,
      "grad_norm": 0.5911327004432678,
      "learning_rate": 4.885558180744241e-05,
      "logits/chosen": 2.7870707511901855,
      "logits/rejected": 3.040189027786255,
      "logps/chosen": -272.0833740234375,
      "logps/rejected": -279.6481628417969,
      "loss": 0.5646,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4166054725646973,
      "rewards/margins": 1.7682647705078125,
      "rewards/rejected": -3.1848702430725098,
      "step": 1400
    },
    {
      "epoch": 0.06989306852720047,
      "grad_norm": 7.128690719604492,
      "learning_rate": 4.883917437815843e-05,
      "logits/chosen": 2.48014497756958,
      "logits/rejected": 2.7383689880371094,
      "logps/chosen": -247.9403533935547,
      "logps/rejected": -233.21963500976562,
      "loss": 0.7119,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.6263935565948486,
      "rewards/margins": 1.0877196788787842,
      "rewards/rejected": -2.714113235473633,
      "step": 1420
    },
    {
      "epoch": 0.07087747794307653,
      "grad_norm": 3.681431531906128,
      "learning_rate": 4.882276694887445e-05,
      "logits/chosen": 2.681915760040283,
      "logits/rejected": 3.006716251373291,
      "logps/chosen": -276.23846435546875,
      "logps/rejected": -258.8401794433594,
      "loss": 0.5078,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6199426651000977,
      "rewards/margins": 1.5916974544525146,
      "rewards/rejected": -3.2116401195526123,
      "step": 1440
    },
    {
      "epoch": 0.07186188735895259,
      "grad_norm": 1.990920901298523,
      "learning_rate": 4.880635951959047e-05,
      "logits/chosen": 2.3310770988464355,
      "logits/rejected": 2.597259998321533,
      "logps/chosen": -253.2692413330078,
      "logps/rejected": -273.86517333984375,
      "loss": 0.5067,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8464723825454712,
      "rewards/margins": 2.063124656677246,
      "rewards/rejected": -3.9095966815948486,
      "step": 1460
    },
    {
      "epoch": 0.07284629677482865,
      "grad_norm": 1.071596384048462,
      "learning_rate": 4.878995209030649e-05,
      "logits/chosen": 2.164618968963623,
      "logits/rejected": 2.379417896270752,
      "logps/chosen": -242.55642700195312,
      "logps/rejected": -282.41339111328125,
      "loss": 0.3396,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9962114095687866,
      "rewards/margins": 2.7475974559783936,
      "rewards/rejected": -4.743809223175049,
      "step": 1480
    },
    {
      "epoch": 0.07383070619070471,
      "grad_norm": 5.258837699890137,
      "learning_rate": 4.877354466102252e-05,
      "logits/chosen": 2.228733777999878,
      "logits/rejected": 2.3969995975494385,
      "logps/chosen": -274.38348388671875,
      "logps/rejected": -286.6042175292969,
      "loss": 0.7724,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.9220423698425293,
      "rewards/margins": 1.8045551776885986,
      "rewards/rejected": -4.726597785949707,
      "step": 1500
    },
    {
      "epoch": 0.07481511560658077,
      "grad_norm": 1.4173402786254883,
      "learning_rate": 4.8757137231738533e-05,
      "logits/chosen": 1.9988272190093994,
      "logits/rejected": 2.188943386077881,
      "logps/chosen": -269.17822265625,
      "logps/rejected": -298.7480773925781,
      "loss": 0.5053,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.2717559337615967,
      "rewards/margins": 2.2409274578094482,
      "rewards/rejected": -4.512683868408203,
      "step": 1520
    },
    {
      "epoch": 0.07579952502245683,
      "grad_norm": 2.735447883605957,
      "learning_rate": 4.874072980245456e-05,
      "logits/chosen": 2.2297191619873047,
      "logits/rejected": 2.3379106521606445,
      "logps/chosen": -249.39352416992188,
      "logps/rejected": -277.8771667480469,
      "loss": 0.5766,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9174093008041382,
      "rewards/margins": 1.4685207605361938,
      "rewards/rejected": -3.385930299758911,
      "step": 1540
    },
    {
      "epoch": 0.0767839344383329,
      "grad_norm": 4.480234622955322,
      "learning_rate": 4.8724322373170574e-05,
      "logits/chosen": 2.48600172996521,
      "logits/rejected": 2.706766366958618,
      "logps/chosen": -291.9150695800781,
      "logps/rejected": -257.1388244628906,
      "loss": 0.642,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.7068722248077393,
      "rewards/margins": 1.2488391399383545,
      "rewards/rejected": -2.955711603164673,
      "step": 1560
    },
    {
      "epoch": 0.07776834385420897,
      "grad_norm": 2.961287498474121,
      "learning_rate": 4.87079149438866e-05,
      "logits/chosen": 2.590200901031494,
      "logits/rejected": 2.6554300785064697,
      "logps/chosen": -263.08837890625,
      "logps/rejected": -254.0570068359375,
      "loss": 0.5811,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6712608337402344,
      "rewards/margins": 1.1909879446029663,
      "rewards/rejected": -2.8622488975524902,
      "step": 1580
    },
    {
      "epoch": 0.07875275327008503,
      "grad_norm": 5.92030668258667,
      "learning_rate": 4.8691507514602614e-05,
      "logits/chosen": 2.537936210632324,
      "logits/rejected": 2.639927387237549,
      "logps/chosen": -234.15975952148438,
      "logps/rejected": -244.8415985107422,
      "loss": 0.483,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5121067762374878,
      "rewards/margins": 1.7466542720794678,
      "rewards/rejected": -3.258761167526245,
      "step": 1600
    },
    {
      "epoch": 0.0797371626859611,
      "grad_norm": 1.627044677734375,
      "learning_rate": 4.867510008531864e-05,
      "logits/chosen": 2.5322482585906982,
      "logits/rejected": 2.5987913608551025,
      "logps/chosen": -229.144287109375,
      "logps/rejected": -251.3967742919922,
      "loss": 0.6238,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.060746669769287,
      "rewards/margins": 1.1975163221359253,
      "rewards/rejected": -3.2582626342773438,
      "step": 1620
    },
    {
      "epoch": 0.08072157210183716,
      "grad_norm": 7.998782634735107,
      "learning_rate": 4.8658692656034655e-05,
      "logits/chosen": 2.336716413497925,
      "logits/rejected": 2.4253475666046143,
      "logps/chosen": -266.347412109375,
      "logps/rejected": -290.0816955566406,
      "loss": 0.5906,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.2945656776428223,
      "rewards/margins": 1.794110894203186,
      "rewards/rejected": -4.088676929473877,
      "step": 1640
    },
    {
      "epoch": 0.08170598151771322,
      "grad_norm": 3.5540430545806885,
      "learning_rate": 4.864228522675067e-05,
      "logits/chosen": 2.4000000953674316,
      "logits/rejected": 2.494839906692505,
      "logps/chosen": -275.6419677734375,
      "logps/rejected": -259.1249084472656,
      "loss": 0.7048,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.553417205810547,
      "rewards/margins": 1.2859617471694946,
      "rewards/rejected": -3.839378833770752,
      "step": 1660
    },
    {
      "epoch": 0.08269039093358928,
      "grad_norm": 8.274666786193848,
      "learning_rate": 4.8625877797466695e-05,
      "logits/chosen": 2.568599224090576,
      "logits/rejected": 2.6900241374969482,
      "logps/chosen": -263.2433166503906,
      "logps/rejected": -248.45883178710938,
      "loss": 0.6438,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8336045742034912,
      "rewards/margins": 1.4049975872039795,
      "rewards/rejected": -3.23860239982605,
      "step": 1680
    },
    {
      "epoch": 0.08367480034946534,
      "grad_norm": 1.7196276187896729,
      "learning_rate": 4.860947036818271e-05,
      "logits/chosen": 2.6154608726501465,
      "logits/rejected": 2.723827362060547,
      "logps/chosen": -267.4786071777344,
      "logps/rejected": -256.82147216796875,
      "loss": 0.4988,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.1843535900115967,
      "rewards/margins": 1.393821358680725,
      "rewards/rejected": -2.5781750679016113,
      "step": 1700
    },
    {
      "epoch": 0.0846592097653414,
      "grad_norm": 1.1711008548736572,
      "learning_rate": 4.8593062938898736e-05,
      "logits/chosen": 2.5792768001556396,
      "logits/rejected": 2.7199251651763916,
      "logps/chosen": -271.76763916015625,
      "logps/rejected": -245.5318603515625,
      "loss": 0.4801,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.9273278117179871,
      "rewards/margins": 1.466055154800415,
      "rewards/rejected": -2.393383026123047,
      "step": 1720
    },
    {
      "epoch": 0.08564361918121746,
      "grad_norm": 1.3751307725906372,
      "learning_rate": 4.857665550961475e-05,
      "logits/chosen": 2.3573286533355713,
      "logits/rejected": 2.633430004119873,
      "logps/chosen": -248.59814453125,
      "logps/rejected": -268.4717102050781,
      "loss": 0.521,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6755987405776978,
      "rewards/margins": 1.709665298461914,
      "rewards/rejected": -3.3852646350860596,
      "step": 1740
    },
    {
      "epoch": 0.08662802859709354,
      "grad_norm": 3.0787088871002197,
      "learning_rate": 4.856106845179498e-05,
      "logits/chosen": 2.4370527267456055,
      "logits/rejected": 2.548576831817627,
      "logps/chosen": -251.82559204101562,
      "logps/rejected": -282.93804931640625,
      "loss": 0.5272,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.311042070388794,
      "rewards/margins": 1.71029794216156,
      "rewards/rejected": -4.021340370178223,
      "step": 1760
    },
    {
      "epoch": 0.0876124380129696,
      "grad_norm": 6.315274715423584,
      "learning_rate": 4.8544661022510994e-05,
      "logits/chosen": 2.3436012268066406,
      "logits/rejected": 2.3816709518432617,
      "logps/chosen": -255.44357299804688,
      "logps/rejected": -255.2277069091797,
      "loss": 0.7248,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.479050874710083,
      "rewards/margins": 1.3060808181762695,
      "rewards/rejected": -3.7851319313049316,
      "step": 1780
    },
    {
      "epoch": 0.08859684742884566,
      "grad_norm": 3.073537826538086,
      "learning_rate": 4.852825359322701e-05,
      "logits/chosen": 2.3219192028045654,
      "logits/rejected": 2.4234185218811035,
      "logps/chosen": -284.054443359375,
      "logps/rejected": -269.3030700683594,
      "loss": 0.6047,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.1503546237945557,
      "rewards/margins": 1.6943382024765015,
      "rewards/rejected": -3.8446929454803467,
      "step": 1800
    },
    {
      "epoch": 0.08958125684472172,
      "grad_norm": 4.378035068511963,
      "learning_rate": 4.8511846163943035e-05,
      "logits/chosen": 2.5639872550964355,
      "logits/rejected": 2.6978282928466797,
      "logps/chosen": -258.6694030761719,
      "logps/rejected": -252.36892700195312,
      "loss": 0.4673,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.2500319480895996,
      "rewards/margins": 1.7670958042144775,
      "rewards/rejected": -4.017127990722656,
      "step": 1820
    },
    {
      "epoch": 0.09056566626059778,
      "grad_norm": 2.5818586349487305,
      "learning_rate": 4.849543873465905e-05,
      "logits/chosen": 1.9935792684555054,
      "logits/rejected": 2.3645195960998535,
      "logps/chosen": -268.453125,
      "logps/rejected": -292.67315673828125,
      "loss": 0.6138,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9584672451019287,
      "rewards/margins": 1.9753284454345703,
      "rewards/rejected": -3.93379545211792,
      "step": 1840
    },
    {
      "epoch": 0.09155007567647384,
      "grad_norm": 1.9426735639572144,
      "learning_rate": 4.8479031305375075e-05,
      "logits/chosen": 2.652336597442627,
      "logits/rejected": 2.6613357067108154,
      "logps/chosen": -244.660400390625,
      "logps/rejected": -256.03753662109375,
      "loss": 0.5006,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.585827350616455,
      "rewards/margins": 1.8091413974761963,
      "rewards/rejected": -3.3949685096740723,
      "step": 1860
    },
    {
      "epoch": 0.0925344850923499,
      "grad_norm": 2.7374963760375977,
      "learning_rate": 4.846262387609109e-05,
      "logits/chosen": 2.2260758876800537,
      "logits/rejected": 2.4491307735443115,
      "logps/chosen": -261.9305725097656,
      "logps/rejected": -280.97198486328125,
      "loss": 0.5783,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.4208300113677979,
      "rewards/margins": 1.4709430932998657,
      "rewards/rejected": -2.891772747039795,
      "step": 1880
    },
    {
      "epoch": 0.09351889450822597,
      "grad_norm": 2.7123653888702393,
      "learning_rate": 4.8446216446807116e-05,
      "logits/chosen": 2.6467959880828857,
      "logits/rejected": 2.941843032836914,
      "logps/chosen": -275.9566650390625,
      "logps/rejected": -252.08737182617188,
      "loss": 0.6122,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4845268726348877,
      "rewards/margins": 1.5584148168563843,
      "rewards/rejected": -3.0429415702819824,
      "step": 1900
    },
    {
      "epoch": 0.09450330392410203,
      "grad_norm": 3.5510241985321045,
      "learning_rate": 4.842980901752314e-05,
      "logits/chosen": 2.6035401821136475,
      "logits/rejected": 2.72294020652771,
      "logps/chosen": -270.8245544433594,
      "logps/rejected": -271.7959289550781,
      "loss": 0.4151,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5989384651184082,
      "rewards/margins": 1.7097482681274414,
      "rewards/rejected": -3.3086867332458496,
      "step": 1920
    },
    {
      "epoch": 0.0954877133399781,
      "grad_norm": 1.5431091785430908,
      "learning_rate": 4.8413401588239156e-05,
      "logits/chosen": 2.344284772872925,
      "logits/rejected": 2.387192487716675,
      "logps/chosen": -257.7273254394531,
      "logps/rejected": -279.25006103515625,
      "loss": 0.5061,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.007363796234131,
      "rewards/margins": 2.063735246658325,
      "rewards/rejected": -4.071099281311035,
      "step": 1940
    },
    {
      "epoch": 0.09647212275585416,
      "grad_norm": 2.421689033508301,
      "learning_rate": 4.839699415895518e-05,
      "logits/chosen": 2.33792781829834,
      "logits/rejected": 2.6357555389404297,
      "logps/chosen": -303.611083984375,
      "logps/rejected": -295.2250671386719,
      "loss": 0.6283,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.244040012359619,
      "rewards/margins": 1.7048215866088867,
      "rewards/rejected": -3.948862075805664,
      "step": 1960
    },
    {
      "epoch": 0.09745653217173023,
      "grad_norm": 2.793452024459839,
      "learning_rate": 4.83805867296712e-05,
      "logits/chosen": 2.513852834701538,
      "logits/rejected": 2.6495299339294434,
      "logps/chosen": -245.0143585205078,
      "logps/rejected": -285.9942932128906,
      "loss": 0.4399,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9939546585083008,
      "rewards/margins": 1.9018633365631104,
      "rewards/rejected": -3.895817518234253,
      "step": 1980
    },
    {
      "epoch": 0.09844094158760629,
      "grad_norm": 1.5821905136108398,
      "learning_rate": 4.836417930038722e-05,
      "logits/chosen": 2.327094554901123,
      "logits/rejected": 2.4954943656921387,
      "logps/chosen": -271.75396728515625,
      "logps/rejected": -300.265380859375,
      "loss": 0.563,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.900485634803772,
      "rewards/margins": 2.1039626598358154,
      "rewards/rejected": -4.004448413848877,
      "step": 2000
    },
    {
      "epoch": 0.09942535100348235,
      "grad_norm": 7.269622325897217,
      "learning_rate": 4.834777187110324e-05,
      "logits/chosen": 2.543468952178955,
      "logits/rejected": 2.6523241996765137,
      "logps/chosen": -269.3299865722656,
      "logps/rejected": -289.16766357421875,
      "loss": 0.7224,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.0438358783721924,
      "rewards/margins": 1.0692437887191772,
      "rewards/rejected": -3.113079786300659,
      "step": 2020
    },
    {
      "epoch": 0.10040976041935841,
      "grad_norm": 6.986440181732178,
      "learning_rate": 4.833136444181926e-05,
      "logits/chosen": 2.4223380088806152,
      "logits/rejected": 2.485330581665039,
      "logps/chosen": -256.6787109375,
      "logps/rejected": -282.4667663574219,
      "loss": 0.6062,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.5386343002319336,
      "rewards/margins": 1.1573275327682495,
      "rewards/rejected": -2.6959614753723145,
      "step": 2040
    },
    {
      "epoch": 0.10139416983523447,
      "grad_norm": 0.7225004434585571,
      "learning_rate": 4.831495701253528e-05,
      "logits/chosen": 2.4550633430480957,
      "logits/rejected": 2.4696338176727295,
      "logps/chosen": -266.1634521484375,
      "logps/rejected": -265.22650146484375,
      "loss": 0.5036,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5088022947311401,
      "rewards/margins": 1.2611563205718994,
      "rewards/rejected": -2.769958734512329,
      "step": 2060
    },
    {
      "epoch": 0.10237857925111053,
      "grad_norm": 5.09525728225708,
      "learning_rate": 4.8298549583251294e-05,
      "logits/chosen": 2.719700813293457,
      "logits/rejected": 2.7103309631347656,
      "logps/chosen": -226.9517059326172,
      "logps/rejected": -253.4032440185547,
      "loss": 0.5555,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.9553601145744324,
      "rewards/margins": 1.3553855419158936,
      "rewards/rejected": -2.3107457160949707,
      "step": 2080
    },
    {
      "epoch": 0.1033629886669866,
      "grad_norm": 4.545104026794434,
      "learning_rate": 4.828214215396732e-05,
      "logits/chosen": 2.546619415283203,
      "logits/rejected": 2.778205156326294,
      "logps/chosen": -263.0766906738281,
      "logps/rejected": -275.8046569824219,
      "loss": 0.3465,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.2709264755249023,
      "rewards/margins": 2.1498122215270996,
      "rewards/rejected": -3.4207382202148438,
      "step": 2100
    },
    {
      "epoch": 0.10434739808286267,
      "grad_norm": 3.596216917037964,
      "learning_rate": 4.8265734724683335e-05,
      "logits/chosen": 2.529120922088623,
      "logits/rejected": 2.861457109451294,
      "logps/chosen": -291.65740966796875,
      "logps/rejected": -260.4627380371094,
      "loss": 0.54,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4882805347442627,
      "rewards/margins": 1.3807988166809082,
      "rewards/rejected": -2.869079113006592,
      "step": 2120
    },
    {
      "epoch": 0.10533180749873873,
      "grad_norm": 1.8163155317306519,
      "learning_rate": 4.824932729539936e-05,
      "logits/chosen": 2.6997060775756836,
      "logits/rejected": 3.0523879528045654,
      "logps/chosen": -265.04327392578125,
      "logps/rejected": -270.14453125,
      "loss": 0.3676,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9404944181442261,
      "rewards/margins": 1.8551216125488281,
      "rewards/rejected": -2.7956161499023438,
      "step": 2140
    },
    {
      "epoch": 0.10631621691461479,
      "grad_norm": 1.9267014265060425,
      "learning_rate": 4.8232919866115375e-05,
      "logits/chosen": 2.519235849380493,
      "logits/rejected": 2.668088436126709,
      "logps/chosen": -266.79241943359375,
      "logps/rejected": -288.05865478515625,
      "loss": 0.5662,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.387740135192871,
      "rewards/margins": 1.6282837390899658,
      "rewards/rejected": -3.016024112701416,
      "step": 2160
    },
    {
      "epoch": 0.10730062633049085,
      "grad_norm": 2.4916932582855225,
      "learning_rate": 4.82165124368314e-05,
      "logits/chosen": 2.80352520942688,
      "logits/rejected": 2.912789821624756,
      "logps/chosen": -262.55255126953125,
      "logps/rejected": -263.09808349609375,
      "loss": 0.5712,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.380778193473816,
      "rewards/margins": 1.540701985359192,
      "rewards/rejected": -2.9214799404144287,
      "step": 2180
    },
    {
      "epoch": 0.10828503574636691,
      "grad_norm": 2.4782135486602783,
      "learning_rate": 4.820010500754742e-05,
      "logits/chosen": 2.736891508102417,
      "logits/rejected": 2.91357159614563,
      "logps/chosen": -274.01593017578125,
      "logps/rejected": -259.009765625,
      "loss": 0.4224,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8776994943618774,
      "rewards/margins": 1.9334911108016968,
      "rewards/rejected": -3.8111908435821533,
      "step": 2200
    },
    {
      "epoch": 0.10926944516224298,
      "grad_norm": 4.806924819946289,
      "learning_rate": 4.818369757826344e-05,
      "logits/chosen": 2.348078727722168,
      "logits/rejected": 2.6178176403045654,
      "logps/chosen": -274.8361511230469,
      "logps/rejected": -273.58514404296875,
      "loss": 0.5894,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.586181640625,
      "rewards/margins": 1.474812388420105,
      "rewards/rejected": -3.0609939098358154,
      "step": 2220
    },
    {
      "epoch": 0.11025385457811904,
      "grad_norm": 2.1326167583465576,
      "learning_rate": 4.816729014897946e-05,
      "logits/chosen": 2.5167384147644043,
      "logits/rejected": 2.766936779022217,
      "logps/chosen": -267.30279541015625,
      "logps/rejected": -271.993896484375,
      "loss": 0.5458,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6271976232528687,
      "rewards/margins": 1.4426016807556152,
      "rewards/rejected": -3.0697989463806152,
      "step": 2240
    },
    {
      "epoch": 0.1112382639939951,
      "grad_norm": 4.0214080810546875,
      "learning_rate": 4.815088271969548e-05,
      "logits/chosen": 2.476165294647217,
      "logits/rejected": 2.8223979473114014,
      "logps/chosen": -307.13336181640625,
      "logps/rejected": -294.9253845214844,
      "loss": 0.5448,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.192562460899353,
      "rewards/margins": 1.8977352380752563,
      "rewards/rejected": -3.0902976989746094,
      "step": 2260
    },
    {
      "epoch": 0.11222267340987116,
      "grad_norm": 2.534609317779541,
      "learning_rate": 4.8134475290411503e-05,
      "logits/chosen": 2.4637534618377686,
      "logits/rejected": 2.8435873985290527,
      "logps/chosen": -251.47653198242188,
      "logps/rejected": -265.4389343261719,
      "loss": 0.4051,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.352189540863037,
      "rewards/margins": 1.8528915643692017,
      "rewards/rejected": -3.2050812244415283,
      "step": 2280
    },
    {
      "epoch": 0.11320708282574724,
      "grad_norm": 1.0550881624221802,
      "learning_rate": 4.811806786112752e-05,
      "logits/chosen": 2.266584873199463,
      "logits/rejected": 2.4755947589874268,
      "logps/chosen": -252.92138671875,
      "logps/rejected": -273.74652099609375,
      "loss": 0.6396,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.8866859674453735,
      "rewards/margins": 1.5925861597061157,
      "rewards/rejected": -3.4792721271514893,
      "step": 2300
    },
    {
      "epoch": 0.1141914922416233,
      "grad_norm": 1.4173239469528198,
      "learning_rate": 4.8101660431843544e-05,
      "logits/chosen": 2.4764745235443115,
      "logits/rejected": 2.6661903858184814,
      "logps/chosen": -247.38784790039062,
      "logps/rejected": -288.37689208984375,
      "loss": 0.5459,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7742574214935303,
      "rewards/margins": 1.9402271509170532,
      "rewards/rejected": -3.714484691619873,
      "step": 2320
    },
    {
      "epoch": 0.11517590165749936,
      "grad_norm": 1.9311765432357788,
      "learning_rate": 4.808525300255956e-05,
      "logits/chosen": 2.421719789505005,
      "logits/rejected": 2.6248486042022705,
      "logps/chosen": -252.50259399414062,
      "logps/rejected": -241.36483764648438,
      "loss": 0.5754,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.803039789199829,
      "rewards/margins": 1.4378535747528076,
      "rewards/rejected": -3.2408931255340576,
      "step": 2340
    },
    {
      "epoch": 0.11616031107337542,
      "grad_norm": 6.316269397735596,
      "learning_rate": 4.8068845573275584e-05,
      "logits/chosen": 2.720500946044922,
      "logits/rejected": 2.7090256214141846,
      "logps/chosen": -259.16571044921875,
      "logps/rejected": -253.04244995117188,
      "loss": 0.6038,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.0207762718200684,
      "rewards/margins": 1.5859466791152954,
      "rewards/rejected": -3.6067230701446533,
      "step": 2360
    },
    {
      "epoch": 0.11714472048925148,
      "grad_norm": 2.876382827758789,
      "learning_rate": 4.80524381439916e-05,
      "logits/chosen": 2.8158812522888184,
      "logits/rejected": 2.9291319847106934,
      "logps/chosen": -274.82147216796875,
      "logps/rejected": -318.9334716796875,
      "loss": 0.4445,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.0544958114624023,
      "rewards/margins": 2.396358013153076,
      "rewards/rejected": -4.450854301452637,
      "step": 2380
    },
    {
      "epoch": 0.11812912990512754,
      "grad_norm": 4.944293975830078,
      "learning_rate": 4.803603071470762e-05,
      "logits/chosen": 2.039700746536255,
      "logits/rejected": 2.2854835987091064,
      "logps/chosen": -276.41876220703125,
      "logps/rejected": -300.3310546875,
      "loss": 0.5098,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.3069958686828613,
      "rewards/margins": 2.3662619590759277,
      "rewards/rejected": -4.673257827758789,
      "step": 2400
    },
    {
      "epoch": 0.1191135393210036,
      "grad_norm": 2.551008939743042,
      "learning_rate": 4.801962328542364e-05,
      "logits/chosen": 2.7183279991149902,
      "logits/rejected": 2.777094602584839,
      "logps/chosen": -272.8254699707031,
      "logps/rejected": -242.88217163085938,
      "loss": 0.7955,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.6810638904571533,
      "rewards/margins": 1.3384450674057007,
      "rewards/rejected": -4.019508361816406,
      "step": 2420
    },
    {
      "epoch": 0.12009794873687966,
      "grad_norm": 2.39548921585083,
      "learning_rate": 4.800321585613966e-05,
      "logits/chosen": 2.812147378921509,
      "logits/rejected": 2.8974549770355225,
      "logps/chosen": -275.53338623046875,
      "logps/rejected": -265.59832763671875,
      "loss": 0.5131,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.5510451793670654,
      "rewards/margins": 1.6144208908081055,
      "rewards/rejected": -3.165466070175171,
      "step": 2440
    },
    {
      "epoch": 0.12108235815275573,
      "grad_norm": 2.070521593093872,
      "learning_rate": 4.798680842685568e-05,
      "logits/chosen": 2.668266773223877,
      "logits/rejected": 2.804715633392334,
      "logps/chosen": -273.2133483886719,
      "logps/rejected": -258.2117614746094,
      "loss": 0.6037,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.807408332824707,
      "rewards/margins": 1.2003157138824463,
      "rewards/rejected": -3.007723808288574,
      "step": 2460
    },
    {
      "epoch": 0.12206676756863179,
      "grad_norm": 6.07421875,
      "learning_rate": 4.79704009975717e-05,
      "logits/chosen": 2.501497745513916,
      "logits/rejected": 2.736452579498291,
      "logps/chosen": -251.01303100585938,
      "logps/rejected": -253.0935516357422,
      "loss": 0.671,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.6819874048233032,
      "rewards/margins": 1.2948553562164307,
      "rewards/rejected": -2.9768428802490234,
      "step": 2480
    },
    {
      "epoch": 0.12305117698450786,
      "grad_norm": 2.034165382385254,
      "learning_rate": 4.795399356828772e-05,
      "logits/chosen": 2.8008744716644287,
      "logits/rejected": 3.0399460792541504,
      "logps/chosen": -258.55816650390625,
      "logps/rejected": -248.6284942626953,
      "loss": 0.5726,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.4996545314788818,
      "rewards/margins": 1.1781374216079712,
      "rewards/rejected": -2.6777918338775635,
      "step": 2500
    },
    {
      "epoch": 0.12403558640038392,
      "grad_norm": 3.889397621154785,
      "learning_rate": 4.7937586139003746e-05,
      "logits/chosen": 2.7396769523620605,
      "logits/rejected": 2.9923899173736572,
      "logps/chosen": -266.063232421875,
      "logps/rejected": -251.5142059326172,
      "loss": 0.5499,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3902209997177124,
      "rewards/margins": 1.3497507572174072,
      "rewards/rejected": -2.73997163772583,
      "step": 2520
    },
    {
      "epoch": 0.12501999581625997,
      "grad_norm": 1.2507187128067017,
      "learning_rate": 4.792117870971976e-05,
      "logits/chosen": 2.669851779937744,
      "logits/rejected": 3.165377378463745,
      "logps/chosen": -248.77645874023438,
      "logps/rejected": -287.83612060546875,
      "loss": 0.4944,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2260081768035889,
      "rewards/margins": 1.7727245092391968,
      "rewards/rejected": -2.998732566833496,
      "step": 2540
    },
    {
      "epoch": 0.12600440523213605,
      "grad_norm": 1.429506778717041,
      "learning_rate": 4.7904771280435787e-05,
      "logits/chosen": 2.320613145828247,
      "logits/rejected": 2.5937211513519287,
      "logps/chosen": -236.7256317138672,
      "logps/rejected": -259.018310546875,
      "loss": 0.6252,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6249682903289795,
      "rewards/margins": 0.9183136224746704,
      "rewards/rejected": -2.5432815551757812,
      "step": 2560
    },
    {
      "epoch": 0.12698881464801212,
      "grad_norm": 1.3205673694610596,
      "learning_rate": 4.7888363851151803e-05,
      "logits/chosen": 2.816528081893921,
      "logits/rejected": 3.0931501388549805,
      "logps/chosen": -255.9192657470703,
      "logps/rejected": -283.25640869140625,
      "loss": 0.6131,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.1540340185165405,
      "rewards/margins": 1.2639027833938599,
      "rewards/rejected": -2.4179368019104004,
      "step": 2580
    },
    {
      "epoch": 0.12797322406388817,
      "grad_norm": 4.267360687255859,
      "learning_rate": 4.787195642186783e-05,
      "logits/chosen": 2.8838820457458496,
      "logits/rejected": 2.9343013763427734,
      "logps/chosen": -230.8509521484375,
      "logps/rejected": -239.56021118164062,
      "loss": 0.5188,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -0.9709455370903015,
      "rewards/margins": 1.190024733543396,
      "rewards/rejected": -2.1609702110290527,
      "step": 2600
    },
    {
      "epoch": 0.12895763347976424,
      "grad_norm": 7.153651714324951,
      "learning_rate": 4.7855548992583844e-05,
      "logits/chosen": 2.562856435775757,
      "logits/rejected": 2.6229987144470215,
      "logps/chosen": -251.44140625,
      "logps/rejected": -275.05059814453125,
      "loss": 0.5209,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.62007737159729,
      "rewards/margins": 1.319557547569275,
      "rewards/rejected": -2.9396345615386963,
      "step": 2620
    },
    {
      "epoch": 0.1299420428956403,
      "grad_norm": 1.8930342197418213,
      "learning_rate": 4.783914156329987e-05,
      "logits/chosen": 2.4820449352264404,
      "logits/rejected": 2.627901554107666,
      "logps/chosen": -255.45361328125,
      "logps/rejected": -268.85748291015625,
      "loss": 0.5088,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7984602451324463,
      "rewards/margins": 2.1692442893981934,
      "rewards/rejected": -3.9677040576934814,
      "step": 2640
    },
    {
      "epoch": 0.13092645231151637,
      "grad_norm": 0.9950579404830933,
      "learning_rate": 4.7822734134015884e-05,
      "logits/chosen": 2.248216390609741,
      "logits/rejected": 2.549591064453125,
      "logps/chosen": -268.8477478027344,
      "logps/rejected": -277.1531677246094,
      "loss": 0.3458,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -1.536232590675354,
      "rewards/margins": 2.646357774734497,
      "rewards/rejected": -4.182589530944824,
      "step": 2660
    },
    {
      "epoch": 0.13191086172739241,
      "grad_norm": 0.8335129618644714,
      "learning_rate": 4.780632670473191e-05,
      "logits/chosen": 2.3310556411743164,
      "logits/rejected": 2.6384987831115723,
      "logps/chosen": -280.5112609863281,
      "logps/rejected": -294.00616455078125,
      "loss": 0.8156,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.783656597137451,
      "rewards/margins": 1.5707074403762817,
      "rewards/rejected": -4.354363918304443,
      "step": 2680
    },
    {
      "epoch": 0.1328952711432685,
      "grad_norm": 2.7465531826019287,
      "learning_rate": 4.7789919275447925e-05,
      "logits/chosen": 2.502588987350464,
      "logits/rejected": 2.6085925102233887,
      "logps/chosen": -258.933349609375,
      "logps/rejected": -289.3664245605469,
      "loss": 0.5353,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.119063138961792,
      "rewards/margins": 2.0168514251708984,
      "rewards/rejected": -4.135914325714111,
      "step": 2700
    },
    {
      "epoch": 0.13387968055914454,
      "grad_norm": 5.867446422576904,
      "learning_rate": 4.777351184616394e-05,
      "logits/chosen": 2.3193016052246094,
      "logits/rejected": 2.394693374633789,
      "logps/chosen": -292.4942932128906,
      "logps/rejected": -253.52352905273438,
      "loss": 0.5482,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8078324794769287,
      "rewards/margins": 1.2931106090545654,
      "rewards/rejected": -3.100943088531494,
      "step": 2720
    },
    {
      "epoch": 0.1348640899750206,
      "grad_norm": 3.4535670280456543,
      "learning_rate": 4.7757104416879965e-05,
      "logits/chosen": 2.5078177452087402,
      "logits/rejected": 2.6675124168395996,
      "logps/chosen": -259.10711669921875,
      "logps/rejected": -262.42755126953125,
      "loss": 0.688,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7463750839233398,
      "rewards/margins": 1.3828753232955933,
      "rewards/rejected": -3.1292505264282227,
      "step": 2740
    },
    {
      "epoch": 0.1358484993908967,
      "grad_norm": 4.038395881652832,
      "learning_rate": 4.774069698759598e-05,
      "logits/chosen": 2.493910312652588,
      "logits/rejected": 2.616379499435425,
      "logps/chosen": -258.448486328125,
      "logps/rejected": -248.8740234375,
      "loss": 0.5782,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.2696020603179932,
      "rewards/margins": 1.3007800579071045,
      "rewards/rejected": -2.5703818798065186,
      "step": 2760
    },
    {
      "epoch": 0.13683290880677274,
      "grad_norm": 2.6174778938293457,
      "learning_rate": 4.7724289558312006e-05,
      "logits/chosen": 2.741915225982666,
      "logits/rejected": 3.1652352809906006,
      "logps/chosen": -245.8569793701172,
      "logps/rejected": -266.42718505859375,
      "loss": 0.6092,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.616432547569275,
      "rewards/margins": 1.3518775701522827,
      "rewards/rejected": -2.9683103561401367,
      "step": 2780
    },
    {
      "epoch": 0.1378173182226488,
      "grad_norm": 1.2904300689697266,
      "learning_rate": 4.770788212902802e-05,
      "logits/chosen": 2.591431140899658,
      "logits/rejected": 2.9119009971618652,
      "logps/chosen": -254.889404296875,
      "logps/rejected": -296.1539306640625,
      "loss": 0.6601,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.3629505634307861,
      "rewards/margins": 1.2122937440872192,
      "rewards/rejected": -2.575244188308716,
      "step": 2800
    },
    {
      "epoch": 0.13880172763852486,
      "grad_norm": 1.0588568449020386,
      "learning_rate": 4.7691474699744046e-05,
      "logits/chosen": 2.633810043334961,
      "logits/rejected": 2.849862575531006,
      "logps/chosen": -276.79754638671875,
      "logps/rejected": -256.9104919433594,
      "loss": 0.5213,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.523712396621704,
      "rewards/margins": 1.2731655836105347,
      "rewards/rejected": -2.7968783378601074,
      "step": 2820
    },
    {
      "epoch": 0.13978613705440093,
      "grad_norm": 2.2107043266296387,
      "learning_rate": 4.767506727046007e-05,
      "logits/chosen": 2.7493834495544434,
      "logits/rejected": 2.926820755004883,
      "logps/chosen": -249.0394287109375,
      "logps/rejected": -280.4253845214844,
      "loss": 0.5797,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.517513632774353,
      "rewards/margins": 1.3054627180099487,
      "rewards/rejected": -2.822976589202881,
      "step": 2840
    },
    {
      "epoch": 0.14077054647027698,
      "grad_norm": NaN,
      "learning_rate": 4.765948021264028e-05,
      "logits/chosen": 2.4515976905822754,
      "logits/rejected": 2.6837635040283203,
      "logps/chosen": -277.31842041015625,
      "logps/rejected": -272.7309875488281,
      "loss": 0.5015,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8197705745697021,
      "rewards/margins": 1.9910567998886108,
      "rewards/rejected": -3.8108277320861816,
      "step": 2860
    },
    {
      "epoch": 0.14175495588615306,
      "grad_norm": 2.144284248352051,
      "learning_rate": 4.7643072783356305e-05,
      "logits/chosen": 2.3132050037384033,
      "logits/rejected": 2.472811222076416,
      "logps/chosen": -285.48248291015625,
      "logps/rejected": -333.0269470214844,
      "loss": 0.4823,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8630828857421875,
      "rewards/margins": 2.253638505935669,
      "rewards/rejected": -4.1167216300964355,
      "step": 2880
    },
    {
      "epoch": 0.1427393653020291,
      "grad_norm": 1.6818774938583374,
      "learning_rate": 4.762666535407232e-05,
      "logits/chosen": 2.203580141067505,
      "logits/rejected": 2.300489664077759,
      "logps/chosen": -289.3780212402344,
      "logps/rejected": -283.32769775390625,
      "loss": 0.4963,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.0822768211364746,
      "rewards/margins": 1.406750202178955,
      "rewards/rejected": -3.4890265464782715,
      "step": 2900
    },
    {
      "epoch": 0.14372377471790518,
      "grad_norm": 3.7136478424072266,
      "learning_rate": 4.7610257924788345e-05,
      "logits/chosen": 2.504523277282715,
      "logits/rejected": 2.723620891571045,
      "logps/chosen": -270.64434814453125,
      "logps/rejected": -263.48406982421875,
      "loss": 0.3949,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9669430255889893,
      "rewards/margins": 1.8947184085845947,
      "rewards/rejected": -3.861661195755005,
      "step": 2920
    },
    {
      "epoch": 0.14470818413378123,
      "grad_norm": 0.7162715792655945,
      "learning_rate": 4.759385049550437e-05,
      "logits/chosen": 2.543548345565796,
      "logits/rejected": 2.7030906677246094,
      "logps/chosen": -275.2283630371094,
      "logps/rejected": -274.20916748046875,
      "loss": 0.5027,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3752648830413818,
      "rewards/margins": 1.521785020828247,
      "rewards/rejected": -2.897050142288208,
      "step": 2940
    },
    {
      "epoch": 0.1456925935496573,
      "grad_norm": 0.45078712701797485,
      "learning_rate": 4.757744306622039e-05,
      "logits/chosen": 2.446927547454834,
      "logits/rejected": 2.6862549781799316,
      "logps/chosen": -249.72265625,
      "logps/rejected": -247.8470458984375,
      "loss": 0.4444,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4024425745010376,
      "rewards/margins": 1.9675629138946533,
      "rewards/rejected": -3.3700053691864014,
      "step": 2960
    },
    {
      "epoch": 0.14667700296553338,
      "grad_norm": 1.953315258026123,
      "learning_rate": 4.756103563693641e-05,
      "logits/chosen": 2.4206178188323975,
      "logits/rejected": 2.565659999847412,
      "logps/chosen": -256.34783935546875,
      "logps/rejected": -251.9097137451172,
      "loss": 0.5981,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.0954015254974365,
      "rewards/margins": 1.676042914390564,
      "rewards/rejected": -3.771444797515869,
      "step": 2980
    },
    {
      "epoch": 0.14766141238140942,
      "grad_norm": 1.5480130910873413,
      "learning_rate": 4.7544628207652426e-05,
      "logits/chosen": 2.641350746154785,
      "logits/rejected": 2.7205100059509277,
      "logps/chosen": -269.4098205566406,
      "logps/rejected": -298.7823181152344,
      "loss": 0.5516,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.9707839488983154,
      "rewards/margins": 1.7038103342056274,
      "rewards/rejected": -3.6745944023132324,
      "step": 3000
    },
    {
      "epoch": 0.1486458217972855,
      "grad_norm": 3.08597993850708,
      "learning_rate": 4.752822077836845e-05,
      "logits/chosen": 2.628995418548584,
      "logits/rejected": 2.738821029663086,
      "logps/chosen": -264.4588317871094,
      "logps/rejected": -270.5894775390625,
      "loss": 0.5647,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0289900302886963,
      "rewards/margins": 1.245601773262024,
      "rewards/rejected": -3.2745919227600098,
      "step": 3020
    },
    {
      "epoch": 0.14963023121316155,
      "grad_norm": 1.3363136053085327,
      "learning_rate": 4.751181334908447e-05,
      "logits/chosen": 2.8394155502319336,
      "logits/rejected": 3.0318005084991455,
      "logps/chosen": -256.51104736328125,
      "logps/rejected": -281.9520568847656,
      "loss": 0.6634,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.9376939535140991,
      "rewards/margins": 1.1694997549057007,
      "rewards/rejected": -3.1071934700012207,
      "step": 3040
    },
    {
      "epoch": 0.15061464062903762,
      "grad_norm": 1.3853161334991455,
      "learning_rate": 4.749540591980049e-05,
      "logits/chosen": 2.755844831466675,
      "logits/rejected": 2.819411039352417,
      "logps/chosen": -276.4646911621094,
      "logps/rejected": -273.16387939453125,
      "loss": 0.5632,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.896653175354004,
      "rewards/margins": 1.4586222171783447,
      "rewards/rejected": -3.3552753925323486,
      "step": 3060
    },
    {
      "epoch": 0.15159905004491367,
      "grad_norm": 1.0001095533370972,
      "learning_rate": 4.747899849051651e-05,
      "logits/chosen": 2.7222065925598145,
      "logits/rejected": 2.927884101867676,
      "logps/chosen": -261.56890869140625,
      "logps/rejected": -285.36151123046875,
      "loss": 0.4823,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.1328001022338867,
      "rewards/margins": 2.028812885284424,
      "rewards/rejected": -4.1616129875183105,
      "step": 3080
    },
    {
      "epoch": 0.15258345946078974,
      "grad_norm": 1.0689932107925415,
      "learning_rate": 4.746259106123253e-05,
      "logits/chosen": 2.545408248901367,
      "logits/rejected": 2.9730939865112305,
      "logps/chosen": -267.03704833984375,
      "logps/rejected": -278.98516845703125,
      "loss": 0.3577,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.680107831954956,
      "rewards/margins": 2.1838669776916504,
      "rewards/rejected": -3.8639748096466064,
      "step": 3100
    },
    {
      "epoch": 0.1535678688766658,
      "grad_norm": 6.034335613250732,
      "learning_rate": 4.744618363194855e-05,
      "logits/chosen": 2.69816255569458,
      "logits/rejected": 2.6696155071258545,
      "logps/chosen": -283.5035705566406,
      "logps/rejected": -286.8294982910156,
      "loss": 0.533,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.051406145095825,
      "rewards/margins": 1.782785177230835,
      "rewards/rejected": -3.8341915607452393,
      "step": 3120
    },
    {
      "epoch": 0.15455227829254187,
      "grad_norm": 0.8354977369308472,
      "learning_rate": 4.7429776202664564e-05,
      "logits/chosen": 2.692378282546997,
      "logits/rejected": 2.9935359954833984,
      "logps/chosen": -233.7174072265625,
      "logps/rejected": -255.47412109375,
      "loss": 0.5088,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6495742797851562,
      "rewards/margins": 1.9236202239990234,
      "rewards/rejected": -3.573194980621338,
      "step": 3140
    },
    {
      "epoch": 0.15553668770841794,
      "grad_norm": 0.9304417371749878,
      "learning_rate": 4.741336877338059e-05,
      "logits/chosen": 2.659255266189575,
      "logits/rejected": 2.9051454067230225,
      "logps/chosen": -267.4059753417969,
      "logps/rejected": -295.61444091796875,
      "loss": 0.555,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7690712213516235,
      "rewards/margins": 2.063904285430908,
      "rewards/rejected": -3.8329758644104004,
      "step": 3160
    },
    {
      "epoch": 0.156521097124294,
      "grad_norm": 5.206103801727295,
      "learning_rate": 4.7396961344096605e-05,
      "logits/chosen": 2.624328851699829,
      "logits/rejected": 2.7709269523620605,
      "logps/chosen": -267.37567138671875,
      "logps/rejected": -230.17056274414062,
      "loss": 0.4806,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.234917402267456,
      "rewards/margins": 1.5436890125274658,
      "rewards/rejected": -2.778606653213501,
      "step": 3180
    },
    {
      "epoch": 0.15750550654017006,
      "grad_norm": 2.111172914505005,
      "learning_rate": 4.738055391481263e-05,
      "logits/chosen": 2.7643373012542725,
      "logits/rejected": 2.9336090087890625,
      "logps/chosen": -275.51495361328125,
      "logps/rejected": -288.67041015625,
      "loss": 0.4205,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5510900020599365,
      "rewards/margins": 2.0271127223968506,
      "rewards/rejected": -3.5782032012939453,
      "step": 3200
    },
    {
      "epoch": 0.1584899159560461,
      "grad_norm": 3.0191049575805664,
      "learning_rate": 4.736414648552865e-05,
      "logits/chosen": 2.7501561641693115,
      "logits/rejected": 2.805056095123291,
      "logps/chosen": -270.29974365234375,
      "logps/rejected": -292.6277770996094,
      "loss": 0.4593,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.315366506576538,
      "rewards/margins": 2.058976888656616,
      "rewards/rejected": -3.3743438720703125,
      "step": 3220
    },
    {
      "epoch": 0.1594743253719222,
      "grad_norm": 1.608564853668213,
      "learning_rate": 4.734773905624467e-05,
      "logits/chosen": 2.510094165802002,
      "logits/rejected": 2.9019558429718018,
      "logps/chosen": -256.7758483886719,
      "logps/rejected": -259.4638366699219,
      "loss": 0.6355,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.098158836364746,
      "rewards/margins": 1.5039829015731812,
      "rewards/rejected": -3.6021416187286377,
      "step": 3240
    },
    {
      "epoch": 0.16045873478779824,
      "grad_norm": 1.3744362592697144,
      "learning_rate": 4.733133162696069e-05,
      "logits/chosen": 2.54089617729187,
      "logits/rejected": 2.8815038204193115,
      "logps/chosen": -249.9801025390625,
      "logps/rejected": -248.7748565673828,
      "loss": 0.5373,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.7632681131362915,
      "rewards/margins": 1.4988874197006226,
      "rewards/rejected": -3.262155532836914,
      "step": 3260
    },
    {
      "epoch": 0.1614431442036743,
      "grad_norm": 2.77455735206604,
      "learning_rate": 4.731492419767671e-05,
      "logits/chosen": 2.5682778358459473,
      "logits/rejected": 2.9240520000457764,
      "logps/chosen": -262.315185546875,
      "logps/rejected": -259.86199951171875,
      "loss": 0.3721,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6750764846801758,
      "rewards/margins": 2.837162494659424,
      "rewards/rejected": -4.512238502502441,
      "step": 3280
    },
    {
      "epoch": 0.16242755361955036,
      "grad_norm": 1.0422508716583252,
      "learning_rate": 4.729851676839273e-05,
      "logits/chosen": 2.841453790664673,
      "logits/rejected": 2.8472914695739746,
      "logps/chosen": -242.8604736328125,
      "logps/rejected": -270.7453308105469,
      "loss": 0.3019,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6766226291656494,
      "rewards/margins": 2.6784920692443848,
      "rewards/rejected": -4.355114936828613,
      "step": 3300
    },
    {
      "epoch": 0.16341196303542643,
      "grad_norm": 2.063361644744873,
      "learning_rate": 4.728210933910875e-05,
      "logits/chosen": 2.5629148483276367,
      "logits/rejected": 2.627530574798584,
      "logps/chosen": -263.34326171875,
      "logps/rejected": -307.7711181640625,
      "loss": 0.4073,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.2745938301086426,
      "rewards/margins": 2.766592025756836,
      "rewards/rejected": -5.041186332702637,
      "step": 3320
    },
    {
      "epoch": 0.1643963724513025,
      "grad_norm": 1.7316088676452637,
      "learning_rate": 4.7265701909824773e-05,
      "logits/chosen": 2.6727001667022705,
      "logits/rejected": 2.9863550662994385,
      "logps/chosen": -264.427978515625,
      "logps/rejected": -271.9377136230469,
      "loss": 0.7838,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.6484320163726807,
      "rewards/margins": 1.9081642627716064,
      "rewards/rejected": -4.556596279144287,
      "step": 3340
    },
    {
      "epoch": 0.16538078186717856,
      "grad_norm": 4.707118988037109,
      "learning_rate": 4.724929448054079e-05,
      "logits/chosen": 2.731011152267456,
      "logits/rejected": 2.820267915725708,
      "logps/chosen": -253.7454376220703,
      "logps/rejected": -262.5460205078125,
      "loss": 0.6627,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.876260757446289,
      "rewards/margins": 1.863787293434143,
      "rewards/rejected": -3.7400479316711426,
      "step": 3360
    },
    {
      "epoch": 0.16636519128305463,
      "grad_norm": 2.342385768890381,
      "learning_rate": 4.7232887051256814e-05,
      "logits/chosen": 2.720801591873169,
      "logits/rejected": 2.9318814277648926,
      "logps/chosen": -272.44207763671875,
      "logps/rejected": -276.0945129394531,
      "loss": 0.5708,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.725433588027954,
      "rewards/margins": 1.6984485387802124,
      "rewards/rejected": -3.423882007598877,
      "step": 3380
    },
    {
      "epoch": 0.16734960069893068,
      "grad_norm": 1.1732149124145508,
      "learning_rate": 4.721647962197283e-05,
      "logits/chosen": 2.484055280685425,
      "logits/rejected": 2.6863162517547607,
      "logps/chosen": -258.5237121582031,
      "logps/rejected": -292.90521240234375,
      "loss": 0.4371,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.186030149459839,
      "rewards/margins": 2.6289050579071045,
      "rewards/rejected": -4.814935207366943,
      "step": 3400
    },
    {
      "epoch": 0.16833401011480675,
      "grad_norm": 5.713702201843262,
      "learning_rate": 4.7200072192688854e-05,
      "logits/chosen": 2.5678791999816895,
      "logits/rejected": 2.7514960765838623,
      "logps/chosen": -263.860595703125,
      "logps/rejected": -287.75189208984375,
      "loss": 0.5209,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.03279185295105,
      "rewards/margins": 2.546952486038208,
      "rewards/rejected": -4.579744338989258,
      "step": 3420
    },
    {
      "epoch": 0.1693184195306828,
      "grad_norm": 4.0403313636779785,
      "learning_rate": 4.718366476340487e-05,
      "logits/chosen": 2.4135565757751465,
      "logits/rejected": 2.7555341720581055,
      "logps/chosen": -268.5791015625,
      "logps/rejected": -272.49664306640625,
      "loss": 0.5344,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9347461462020874,
      "rewards/margins": 2.2279980182647705,
      "rewards/rejected": -4.162744045257568,
      "step": 3440
    },
    {
      "epoch": 0.17030282894655888,
      "grad_norm": 2.707700252532959,
      "learning_rate": 4.716725733412089e-05,
      "logits/chosen": 2.9704043865203857,
      "logits/rejected": 3.079962730407715,
      "logps/chosen": -258.5309753417969,
      "logps/rejected": -266.30096435546875,
      "loss": 0.5102,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.124352216720581,
      "rewards/margins": 2.0299973487854004,
      "rewards/rejected": -4.154349327087402,
      "step": 3460
    },
    {
      "epoch": 0.17128723836243492,
      "grad_norm": 1.7559865713119507,
      "learning_rate": 4.715084990483691e-05,
      "logits/chosen": 2.3952698707580566,
      "logits/rejected": 2.5636045932769775,
      "logps/chosen": -241.5177001953125,
      "logps/rejected": -241.2952423095703,
      "loss": 0.4611,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7039426565170288,
      "rewards/margins": 1.7958481311798096,
      "rewards/rejected": -3.499790906906128,
      "step": 3480
    },
    {
      "epoch": 0.172271647778311,
      "grad_norm": 1.1155086755752563,
      "learning_rate": 4.713444247555293e-05,
      "logits/chosen": 2.457693576812744,
      "logits/rejected": 2.7628750801086426,
      "logps/chosen": -238.6877899169922,
      "logps/rejected": -234.5486297607422,
      "loss": 0.4721,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.12843918800354,
      "rewards/margins": 1.9706144332885742,
      "rewards/rejected": -3.0990536212921143,
      "step": 3500
    },
    {
      "epoch": 0.17325605719418707,
      "grad_norm": 2.591268539428711,
      "learning_rate": 4.711803504626895e-05,
      "logits/chosen": 2.630143165588379,
      "logits/rejected": 2.8037142753601074,
      "logps/chosen": -271.2999267578125,
      "logps/rejected": -286.6842041015625,
      "loss": 0.3976,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5483934879302979,
      "rewards/margins": 2.766974449157715,
      "rewards/rejected": -4.315368175506592,
      "step": 3520
    },
    {
      "epoch": 0.17424046661006312,
      "grad_norm": 2.968928575515747,
      "learning_rate": 4.7101627616984976e-05,
      "logits/chosen": 2.600562810897827,
      "logits/rejected": 2.8141627311706543,
      "logps/chosen": -271.84027099609375,
      "logps/rejected": -276.25897216796875,
      "loss": 0.5534,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8584568500518799,
      "rewards/margins": 2.249000072479248,
      "rewards/rejected": -4.107457160949707,
      "step": 3540
    },
    {
      "epoch": 0.1752248760259392,
      "grad_norm": 2.6939358711242676,
      "learning_rate": 4.708522018770099e-05,
      "logits/chosen": 2.778850555419922,
      "logits/rejected": 2.969324827194214,
      "logps/chosen": -251.5979766845703,
      "logps/rejected": -238.02932739257812,
      "loss": 0.5623,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.627197504043579,
      "rewards/margins": 1.7188266515731812,
      "rewards/rejected": -3.34602427482605,
      "step": 3560
    },
    {
      "epoch": 0.17620928544181524,
      "grad_norm": 6.72184419631958,
      "learning_rate": 4.7068812758417016e-05,
      "logits/chosen": 2.654454231262207,
      "logits/rejected": 2.794882297515869,
      "logps/chosen": -257.614501953125,
      "logps/rejected": -243.58334350585938,
      "loss": 0.5802,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.603236436843872,
      "rewards/margins": 1.4940941333770752,
      "rewards/rejected": -3.097330093383789,
      "step": 3580
    },
    {
      "epoch": 0.17719369485769132,
      "grad_norm": 3.1291255950927734,
      "learning_rate": 4.705240532913303e-05,
      "logits/chosen": 2.692946672439575,
      "logits/rejected": 2.8325130939483643,
      "logps/chosen": -252.94778442382812,
      "logps/rejected": -278.4327087402344,
      "loss": 0.4815,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3191343545913696,
      "rewards/margins": 1.5290464162826538,
      "rewards/rejected": -2.8481807708740234,
      "step": 3600
    },
    {
      "epoch": 0.17817810427356737,
      "grad_norm": 7.1377482414245605,
      "learning_rate": 4.7035997899849057e-05,
      "logits/chosen": 2.6188905239105225,
      "logits/rejected": 2.9223923683166504,
      "logps/chosen": -273.48785400390625,
      "logps/rejected": -277.21405029296875,
      "loss": 0.423,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7948147058486938,
      "rewards/margins": 2.2440686225891113,
      "rewards/rejected": -4.038883209228516,
      "step": 3620
    },
    {
      "epoch": 0.17916251368944344,
      "grad_norm": 1.5464330911636353,
      "learning_rate": 4.7019590470565073e-05,
      "logits/chosen": 2.6837329864501953,
      "logits/rejected": 2.8461546897888184,
      "logps/chosen": -264.2942810058594,
      "logps/rejected": -287.6822509765625,
      "loss": 0.4809,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.2161378860473633,
      "rewards/margins": 2.2546093463897705,
      "rewards/rejected": -4.470747470855713,
      "step": 3640
    },
    {
      "epoch": 0.1801469231053195,
      "grad_norm": 2.3513948917388916,
      "learning_rate": 4.70031830412811e-05,
      "logits/chosen": 2.4892001152038574,
      "logits/rejected": 2.7467095851898193,
      "logps/chosen": -249.36227416992188,
      "logps/rejected": -244.2884521484375,
      "loss": 0.6498,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.7773990631103516,
      "rewards/margins": 1.9520494937896729,
      "rewards/rejected": -4.7294487953186035,
      "step": 3660
    },
    {
      "epoch": 0.18113133252119556,
      "grad_norm": 1.661245584487915,
      "learning_rate": 4.6986775611997114e-05,
      "logits/chosen": 2.1445648670196533,
      "logits/rejected": 2.4298574924468994,
      "logps/chosen": -276.79888916015625,
      "logps/rejected": -290.71405029296875,
      "loss": 0.6933,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.636835813522339,
      "rewards/margins": 2.095933198928833,
      "rewards/rejected": -4.732769012451172,
      "step": 3680
    },
    {
      "epoch": 0.18211574193707164,
      "grad_norm": 5.70734977722168,
      "learning_rate": 4.697036818271314e-05,
      "logits/chosen": 2.4294095039367676,
      "logits/rejected": 2.689549684524536,
      "logps/chosen": -261.4041748046875,
      "logps/rejected": -272.85369873046875,
      "loss": 0.4213,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1495654582977295,
      "rewards/margins": 2.691648244857788,
      "rewards/rejected": -4.841214179992676,
      "step": 3700
    },
    {
      "epoch": 0.1831001513529477,
      "grad_norm": 4.320248603820801,
      "learning_rate": 4.6953960753429154e-05,
      "logits/chosen": 2.228977680206299,
      "logits/rejected": 2.5073158740997314,
      "logps/chosen": -260.48870849609375,
      "logps/rejected": -306.6586608886719,
      "loss": 0.4055,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9956724643707275,
      "rewards/margins": 2.605402946472168,
      "rewards/rejected": -4.601075649261475,
      "step": 3720
    },
    {
      "epoch": 0.18408456076882376,
      "grad_norm": 7.6400465965271,
      "learning_rate": 4.693755332414517e-05,
      "logits/chosen": 2.224029541015625,
      "logits/rejected": 2.361423969268799,
      "logps/chosen": -281.6673583984375,
      "logps/rejected": -290.5108337402344,
      "loss": 0.5661,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.6439003944396973,
      "rewards/margins": 2.158557176589966,
      "rewards/rejected": -4.802457332611084,
      "step": 3740
    },
    {
      "epoch": 0.1850689701846998,
      "grad_norm": 1.9237614870071411,
      "learning_rate": 4.6921145894861195e-05,
      "logits/chosen": 2.2201669216156006,
      "logits/rejected": 2.5810484886169434,
      "logps/chosen": -259.5057373046875,
      "logps/rejected": -265.25909423828125,
      "loss": 0.5515,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.408562421798706,
      "rewards/margins": 1.9081623554229736,
      "rewards/rejected": -4.316725254058838,
      "step": 3760
    },
    {
      "epoch": 0.18605337960057589,
      "grad_norm": 1.2350019216537476,
      "learning_rate": 4.690473846557721e-05,
      "logits/chosen": 2.241299867630005,
      "logits/rejected": 2.5592200756073,
      "logps/chosen": -229.9230499267578,
      "logps/rejected": -276.1248474121094,
      "loss": 0.4376,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6649987697601318,
      "rewards/margins": 2.2489383220672607,
      "rewards/rejected": -3.9139373302459717,
      "step": 3780
    },
    {
      "epoch": 0.18703778901645193,
      "grad_norm": 3.972991704940796,
      "learning_rate": 4.6888331036293235e-05,
      "logits/chosen": 2.3796489238739014,
      "logits/rejected": 2.6169631481170654,
      "logps/chosen": -244.2610626220703,
      "logps/rejected": -276.2510681152344,
      "loss": 0.5055,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.5368447303771973,
      "rewards/margins": 1.956496000289917,
      "rewards/rejected": -4.493340492248535,
      "step": 3800
    },
    {
      "epoch": 0.188022198432328,
      "grad_norm": 6.7936224937438965,
      "learning_rate": 4.687192360700925e-05,
      "logits/chosen": 2.49652099609375,
      "logits/rejected": 2.468371868133545,
      "logps/chosen": -242.6614532470703,
      "logps/rejected": -228.6466522216797,
      "loss": 0.6559,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.1804237365722656,
      "rewards/margins": 1.4542009830474854,
      "rewards/rejected": -3.634624481201172,
      "step": 3820
    },
    {
      "epoch": 0.18900660784820406,
      "grad_norm": 0.8874610066413879,
      "learning_rate": 4.6855516177725276e-05,
      "logits/chosen": 2.603355884552002,
      "logits/rejected": 2.762970447540283,
      "logps/chosen": -271.12188720703125,
      "logps/rejected": -258.76348876953125,
      "loss": 0.5857,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.8041855096817017,
      "rewards/margins": 1.6782299280166626,
      "rewards/rejected": -3.4824154376983643,
      "step": 3840
    },
    {
      "epoch": 0.18999101726408013,
      "grad_norm": 6.566442012786865,
      "learning_rate": 4.68391087484413e-05,
      "logits/chosen": 2.4847559928894043,
      "logits/rejected": 2.5677428245544434,
      "logps/chosen": -251.8523712158203,
      "logps/rejected": -230.427734375,
      "loss": 0.7153,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.215430736541748,
      "rewards/margins": 1.6115491390228271,
      "rewards/rejected": -3.826979875564575,
      "step": 3860
    },
    {
      "epoch": 0.1909754266799562,
      "grad_norm": 3.1097469329833984,
      "learning_rate": 4.6822701319157316e-05,
      "logits/chosen": 2.4809300899505615,
      "logits/rejected": 2.6607258319854736,
      "logps/chosen": -242.2543487548828,
      "logps/rejected": -262.60235595703125,
      "loss": 0.5234,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6599833965301514,
      "rewards/margins": 1.5417659282684326,
      "rewards/rejected": -3.201749324798584,
      "step": 3880
    },
    {
      "epoch": 0.19195983609583225,
      "grad_norm": 2.888888359069824,
      "learning_rate": 4.680629388987334e-05,
      "logits/chosen": 2.4060583114624023,
      "logits/rejected": 2.520097017288208,
      "logps/chosen": -262.16253662109375,
      "logps/rejected": -277.587158203125,
      "loss": 0.5447,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.3938037157058716,
      "rewards/margins": 1.908111333847046,
      "rewards/rejected": -3.301914930343628,
      "step": 3900
    },
    {
      "epoch": 0.19294424551170833,
      "grad_norm": 1.3784831762313843,
      "learning_rate": 4.6789886460589357e-05,
      "logits/chosen": 2.663738965988159,
      "logits/rejected": 2.7765872478485107,
      "logps/chosen": -246.83975219726562,
      "logps/rejected": -259.8677673339844,
      "loss": 0.4226,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6463396549224854,
      "rewards/margins": 2.022148609161377,
      "rewards/rejected": -3.6684882640838623,
      "step": 3920
    },
    {
      "epoch": 0.19392865492758438,
      "grad_norm": 1.2771927118301392,
      "learning_rate": 4.677347903130538e-05,
      "logits/chosen": 2.418086528778076,
      "logits/rejected": 2.588836193084717,
      "logps/chosen": -251.57052612304688,
      "logps/rejected": -264.79254150390625,
      "loss": 0.4865,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.42046856880188,
      "rewards/margins": 1.7524436712265015,
      "rewards/rejected": -4.17291259765625,
      "step": 3940
    },
    {
      "epoch": 0.19491306434346045,
      "grad_norm": 2.4281294345855713,
      "learning_rate": 4.67570716020214e-05,
      "logits/chosen": 2.6845388412475586,
      "logits/rejected": 2.932833194732666,
      "logps/chosen": -269.39984130859375,
      "logps/rejected": -260.95135498046875,
      "loss": 0.8469,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.6736600399017334,
      "rewards/margins": 1.6963907480239868,
      "rewards/rejected": -4.370050430297852,
      "step": 3960
    },
    {
      "epoch": 0.1958974737593365,
      "grad_norm": 2.090132236480713,
      "learning_rate": 4.674066417273742e-05,
      "logits/chosen": 2.54203462600708,
      "logits/rejected": 2.767709255218506,
      "logps/chosen": -248.40560913085938,
      "logps/rejected": -259.84796142578125,
      "loss": 0.5723,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.1594555377960205,
      "rewards/margins": 1.8383487462997437,
      "rewards/rejected": -3.9978041648864746,
      "step": 3980
    },
    {
      "epoch": 0.19688188317521257,
      "grad_norm": 3.8102943897247314,
      "learning_rate": 4.672425674345344e-05,
      "logits/chosen": 2.4526877403259277,
      "logits/rejected": 2.684650421142578,
      "logps/chosen": -265.5269775390625,
      "logps/rejected": -280.0468444824219,
      "loss": 0.4485,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.646582841873169,
      "rewards/margins": 1.8679125308990479,
      "rewards/rejected": -3.5144951343536377,
      "step": 4000
    },
    {
      "epoch": 0.19786629259108862,
      "grad_norm": 1.6420409679412842,
      "learning_rate": 4.670784931416946e-05,
      "logits/chosen": 2.168308734893799,
      "logits/rejected": 2.33054518699646,
      "logps/chosen": -273.435302734375,
      "logps/rejected": -282.5680847167969,
      "loss": 0.6783,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.1656975746154785,
      "rewards/margins": 1.6004654169082642,
      "rewards/rejected": -3.766162872314453,
      "step": 4020
    },
    {
      "epoch": 0.1988507020069647,
      "grad_norm": 1.5542389154434204,
      "learning_rate": 4.669144188488548e-05,
      "logits/chosen": 2.5663814544677734,
      "logits/rejected": 2.6008706092834473,
      "logps/chosen": -288.7398681640625,
      "logps/rejected": -277.7669372558594,
      "loss": 0.5292,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.7710587978363037,
      "rewards/margins": 1.9949676990509033,
      "rewards/rejected": -3.766026258468628,
      "step": 4040
    },
    {
      "epoch": 0.19983511142284077,
      "grad_norm": 1.976110816001892,
      "learning_rate": 4.6675034455601495e-05,
      "logits/chosen": 2.5530123710632324,
      "logits/rejected": 2.682403087615967,
      "logps/chosen": -284.5920104980469,
      "logps/rejected": -279.25738525390625,
      "loss": 0.5479,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7467153072357178,
      "rewards/margins": 1.378313422203064,
      "rewards/rejected": -3.125028610229492,
      "step": 4060
    },
    {
      "epoch": 0.20081952083871682,
      "grad_norm": 3.3956832885742188,
      "learning_rate": 4.665862702631752e-05,
      "logits/chosen": 2.533212184906006,
      "logits/rejected": 2.752988338470459,
      "logps/chosen": -248.34738159179688,
      "logps/rejected": -246.97705078125,
      "loss": 0.4633,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8949075937271118,
      "rewards/margins": 2.0477404594421387,
      "rewards/rejected": -3.942647933959961,
      "step": 4080
    },
    {
      "epoch": 0.2018039302545929,
      "grad_norm": 5.750332832336426,
      "learning_rate": 4.6642219597033535e-05,
      "logits/chosen": 2.496577739715576,
      "logits/rejected": 2.6285033226013184,
      "logps/chosen": -266.643310546875,
      "logps/rejected": -272.73443603515625,
      "loss": 0.5313,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8310260772705078,
      "rewards/margins": 1.7387834787368774,
      "rewards/rejected": -3.5698094367980957,
      "step": 4100
    },
    {
      "epoch": 0.20278833967046894,
      "grad_norm": 3.055884838104248,
      "learning_rate": 4.662581216774956e-05,
      "logits/chosen": 2.613495349884033,
      "logits/rejected": 2.7357170581817627,
      "logps/chosen": -261.2760009765625,
      "logps/rejected": -251.919189453125,
      "loss": 0.5165,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.9209511280059814,
      "rewards/margins": 1.7795597314834595,
      "rewards/rejected": -3.7005112171173096,
      "step": 4120
    },
    {
      "epoch": 0.20377274908634502,
      "grad_norm": 1.3246952295303345,
      "learning_rate": 4.6609404738465576e-05,
      "logits/chosen": 2.4607529640197754,
      "logits/rejected": 2.7640249729156494,
      "logps/chosen": -266.802978515625,
      "logps/rejected": -259.72088623046875,
      "loss": 0.5885,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.7379204034805298,
      "rewards/margins": 1.5241882801055908,
      "rewards/rejected": -3.262108564376831,
      "step": 4140
    },
    {
      "epoch": 0.20475715850222106,
      "grad_norm": 5.936122417449951,
      "learning_rate": 4.65929973091816e-05,
      "logits/chosen": 2.7155613899230957,
      "logits/rejected": 2.9371845722198486,
      "logps/chosen": -270.83929443359375,
      "logps/rejected": -253.47036743164062,
      "loss": 0.5292,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.567489504814148,
      "rewards/margins": 1.6444603204727173,
      "rewards/rejected": -3.2119498252868652,
      "step": 4160
    },
    {
      "epoch": 0.20574156791809714,
      "grad_norm": 3.449235677719116,
      "learning_rate": 4.657658987989762e-05,
      "logits/chosen": 2.649440050125122,
      "logits/rejected": 2.9157068729400635,
      "logps/chosen": -258.55145263671875,
      "logps/rejected": -217.271484375,
      "loss": 0.7253,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.876429557800293,
      "rewards/margins": 1.3639317750930786,
      "rewards/rejected": -3.240360975265503,
      "step": 4180
    },
    {
      "epoch": 0.2067259773339732,
      "grad_norm": 1.0504668951034546,
      "learning_rate": 4.656018245061364e-05,
      "logits/chosen": 2.6978847980499268,
      "logits/rejected": 2.9401354789733887,
      "logps/chosen": -254.18359375,
      "logps/rejected": -257.2160949707031,
      "loss": 0.5676,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.444480061531067,
      "rewards/margins": 1.718164086341858,
      "rewards/rejected": -3.162644386291504,
      "step": 4200
    },
    {
      "epoch": 0.20771038674984926,
      "grad_norm": 1.8489339351654053,
      "learning_rate": 4.654377502132966e-05,
      "logits/chosen": 2.6898951530456543,
      "logits/rejected": 2.862520933151245,
      "logps/chosen": -266.462158203125,
      "logps/rejected": -284.3258972167969,
      "loss": 0.4352,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.119263768196106,
      "rewards/margins": 1.8296356201171875,
      "rewards/rejected": -2.948899269104004,
      "step": 4220
    },
    {
      "epoch": 0.20869479616572534,
      "grad_norm": 0.7345584034919739,
      "learning_rate": 4.652736759204568e-05,
      "logits/chosen": 2.748783588409424,
      "logits/rejected": 2.9088027477264404,
      "logps/chosen": -251.66226196289062,
      "logps/rejected": -257.45989990234375,
      "loss": 0.6163,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.8451988697052002,
      "rewards/margins": 1.4475964307785034,
      "rewards/rejected": -3.2927956581115723,
      "step": 4240
    },
    {
      "epoch": 0.20967920558160139,
      "grad_norm": 1.1787267923355103,
      "learning_rate": 4.6510960162761704e-05,
      "logits/chosen": 2.634770631790161,
      "logits/rejected": 2.790895938873291,
      "logps/chosen": -231.4545440673828,
      "logps/rejected": -260.3920593261719,
      "loss": 0.5166,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.5025970935821533,
      "rewards/margins": 1.2149111032485962,
      "rewards/rejected": -2.71750807762146,
      "step": 4260
    },
    {
      "epoch": 0.21066361499747746,
      "grad_norm": 5.109335899353027,
      "learning_rate": 4.649455273347772e-05,
      "logits/chosen": 2.502267599105835,
      "logits/rejected": 3.018357753753662,
      "logps/chosen": -283.5736999511719,
      "logps/rejected": -270.4673156738281,
      "loss": 0.5036,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.221975088119507,
      "rewards/margins": 2.005690336227417,
      "rewards/rejected": -4.227665424346924,
      "step": 4280
    },
    {
      "epoch": 0.2116480244133535,
      "grad_norm": 1.9468919038772583,
      "learning_rate": 4.6478145304193744e-05,
      "logits/chosen": 2.6172404289245605,
      "logits/rejected": 2.9237914085388184,
      "logps/chosen": -236.9021759033203,
      "logps/rejected": -253.40982055664062,
      "loss": 0.6652,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.094644784927368,
      "rewards/margins": 1.7636512517929077,
      "rewards/rejected": -3.8582959175109863,
      "step": 4300
    },
    {
      "epoch": 0.21263243382922958,
      "grad_norm": 1.253745198249817,
      "learning_rate": 4.646173787490976e-05,
      "logits/chosen": 2.5900204181671143,
      "logits/rejected": 2.9098854064941406,
      "logps/chosen": -233.40383911132812,
      "logps/rejected": -236.186279296875,
      "loss": 0.4264,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.3789671659469604,
      "rewards/margins": 1.8685357570648193,
      "rewards/rejected": -3.2475028038024902,
      "step": 4320
    },
    {
      "epoch": 0.21361684324510563,
      "grad_norm": 1.0734994411468506,
      "learning_rate": 4.6445330445625785e-05,
      "logits/chosen": 2.6051135063171387,
      "logits/rejected": 2.890389919281006,
      "logps/chosen": -268.7638854980469,
      "logps/rejected": -291.35614013671875,
      "loss": 0.431,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.470179557800293,
      "rewards/margins": 1.9043365716934204,
      "rewards/rejected": -3.374516010284424,
      "step": 4340
    },
    {
      "epoch": 0.2146012526609817,
      "grad_norm": 1.8003129959106445,
      "learning_rate": 4.64289230163418e-05,
      "logits/chosen": 2.800100803375244,
      "logits/rejected": 3.019587993621826,
      "logps/chosen": -256.9284973144531,
      "logps/rejected": -286.9908142089844,
      "loss": 0.3796,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.025951623916626,
      "rewards/margins": 2.3683102130889893,
      "rewards/rejected": -3.394261598587036,
      "step": 4360
    },
    {
      "epoch": 0.21558566207685775,
      "grad_norm": 1.633623480796814,
      "learning_rate": 4.641251558705782e-05,
      "logits/chosen": 2.800633430480957,
      "logits/rejected": 3.048266649246216,
      "logps/chosen": -255.4046173095703,
      "logps/rejected": -252.55349731445312,
      "loss": 0.4791,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.29374361038208,
      "rewards/margins": 1.9600518941879272,
      "rewards/rejected": -3.2537951469421387,
      "step": 4380
    },
    {
      "epoch": 0.21657007149273383,
      "grad_norm": 2.0000193119049072,
      "learning_rate": 4.639610815777384e-05,
      "logits/chosen": 2.7955517768859863,
      "logits/rejected": 3.0111355781555176,
      "logps/chosen": -282.6715393066406,
      "logps/rejected": -276.86083984375,
      "loss": 0.5089,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8725650310516357,
      "rewards/margins": 2.1208553314208984,
      "rewards/rejected": -3.993420362472534,
      "step": 4400
    },
    {
      "epoch": 0.2175544809086099,
      "grad_norm": 0.8103922605514526,
      "learning_rate": 4.637970072848986e-05,
      "logits/chosen": 2.889791965484619,
      "logits/rejected": 3.1517059803009033,
      "logps/chosen": -263.227783203125,
      "logps/rejected": -278.2334899902344,
      "loss": 0.5887,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.9125808477401733,
      "rewards/margins": 1.9295217990875244,
      "rewards/rejected": -3.8421027660369873,
      "step": 4420
    },
    {
      "epoch": 0.21853889032448595,
      "grad_norm": 2.827136993408203,
      "learning_rate": 4.636329329920588e-05,
      "logits/chosen": 2.5924289226531982,
      "logits/rejected": 2.700125217437744,
      "logps/chosen": -269.92919921875,
      "logps/rejected": -273.56298828125,
      "loss": 0.5461,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4598482847213745,
      "rewards/margins": 2.053839683532715,
      "rewards/rejected": -3.513688325881958,
      "step": 4440
    },
    {
      "epoch": 0.21952329974036203,
      "grad_norm": 4.034336566925049,
      "learning_rate": 4.63468858699219e-05,
      "logits/chosen": 2.630014657974243,
      "logits/rejected": 2.892998456954956,
      "logps/chosen": -270.5436096191406,
      "logps/rejected": -252.619384765625,
      "loss": 0.4828,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9235212802886963,
      "rewards/margins": 2.0533013343811035,
      "rewards/rejected": -3.9768226146698,
      "step": 4460
    },
    {
      "epoch": 0.22050770915623807,
      "grad_norm": 2.613551616668701,
      "learning_rate": 4.633047844063792e-05,
      "logits/chosen": 2.7890591621398926,
      "logits/rejected": 2.8960375785827637,
      "logps/chosen": -238.934326171875,
      "logps/rejected": -228.2490234375,
      "loss": 0.506,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6383339166641235,
      "rewards/margins": 1.938750982284546,
      "rewards/rejected": -3.577085018157959,
      "step": 4480
    },
    {
      "epoch": 0.22149211857211415,
      "grad_norm": 2.0460500717163086,
      "learning_rate": 4.6314071011353946e-05,
      "logits/chosen": 2.87324857711792,
      "logits/rejected": 3.2540698051452637,
      "logps/chosen": -263.59124755859375,
      "logps/rejected": -254.3909912109375,
      "loss": 0.5013,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.465718388557434,
      "rewards/margins": 1.7167870998382568,
      "rewards/rejected": -3.1825056076049805,
      "step": 4500
    },
    {
      "epoch": 0.2224765279879902,
      "grad_norm": 3.3157413005828857,
      "learning_rate": 4.629766358206996e-05,
      "logits/chosen": 2.9044411182403564,
      "logits/rejected": 3.1009602546691895,
      "logps/chosen": -275.78118896484375,
      "logps/rejected": -291.0693054199219,
      "loss": 0.4577,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3530209064483643,
      "rewards/margins": 2.1899607181549072,
      "rewards/rejected": -3.5429816246032715,
      "step": 4520
    },
    {
      "epoch": 0.22346093740386627,
      "grad_norm": 4.34009313583374,
      "learning_rate": 4.628125615278599e-05,
      "logits/chosen": 2.8161089420318604,
      "logits/rejected": 2.9629480838775635,
      "logps/chosen": -256.94940185546875,
      "logps/rejected": -279.9385681152344,
      "loss": 0.5789,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6168718338012695,
      "rewards/margins": 1.6229934692382812,
      "rewards/rejected": -3.23986554145813,
      "step": 4540
    },
    {
      "epoch": 0.22444534681974232,
      "grad_norm": 5.049275875091553,
      "learning_rate": 4.6264848723502004e-05,
      "logits/chosen": 2.6715941429138184,
      "logits/rejected": 3.0675971508026123,
      "logps/chosen": -261.6351623535156,
      "logps/rejected": -280.0555419921875,
      "loss": 0.4287,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5846080780029297,
      "rewards/margins": 1.898950219154358,
      "rewards/rejected": -3.483558177947998,
      "step": 4560
    },
    {
      "epoch": 0.2254297562356184,
      "grad_norm": 6.197656154632568,
      "learning_rate": 4.624844129421803e-05,
      "logits/chosen": 2.886195421218872,
      "logits/rejected": 3.0679354667663574,
      "logps/chosen": -262.00128173828125,
      "logps/rejected": -261.37261962890625,
      "loss": 0.4642,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0527267456054688,
      "rewards/margins": 1.874637246131897,
      "rewards/rejected": -3.927363872528076,
      "step": 4580
    },
    {
      "epoch": 0.22641416565149447,
      "grad_norm": 2.8320305347442627,
      "learning_rate": 4.6232033864934044e-05,
      "logits/chosen": 2.8551089763641357,
      "logits/rejected": 3.0331687927246094,
      "logps/chosen": -252.65493774414062,
      "logps/rejected": -264.79107666015625,
      "loss": 0.5139,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.796252965927124,
      "rewards/margins": 2.017756462097168,
      "rewards/rejected": -3.81400990486145,
      "step": 4600
    },
    {
      "epoch": 0.22739857506737052,
      "grad_norm": 1.276672124862671,
      "learning_rate": 4.621562643565007e-05,
      "logits/chosen": 3.1322853565216064,
      "logits/rejected": 3.1766295433044434,
      "logps/chosen": -272.93572998046875,
      "logps/rejected": -256.6850891113281,
      "loss": 0.5878,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.7959524393081665,
      "rewards/margins": 1.6635822057724,
      "rewards/rejected": -3.4595344066619873,
      "step": 4620
    },
    {
      "epoch": 0.2283829844832466,
      "grad_norm": 1.2487173080444336,
      "learning_rate": 4.6199219006366085e-05,
      "logits/chosen": 2.5837013721466064,
      "logits/rejected": 2.8097729682922363,
      "logps/chosen": -256.4270324707031,
      "logps/rejected": -258.0606384277344,
      "loss": 0.5942,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.4415003061294556,
      "rewards/margins": 1.4828112125396729,
      "rewards/rejected": -2.924311399459839,
      "step": 4640
    },
    {
      "epoch": 0.22936739389912264,
      "grad_norm": 4.826664447784424,
      "learning_rate": 4.61828115770821e-05,
      "logits/chosen": 2.875368595123291,
      "logits/rejected": 3.136630058288574,
      "logps/chosen": -261.7200012207031,
      "logps/rejected": -258.91815185546875,
      "loss": 0.4449,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.1497178077697754,
      "rewards/margins": 1.9788055419921875,
      "rewards/rejected": -4.128523826599121,
      "step": 4660
    },
    {
      "epoch": 0.23035180331499872,
      "grad_norm": 2.1385555267333984,
      "learning_rate": 4.6166404147798125e-05,
      "logits/chosen": 2.641268253326416,
      "logits/rejected": 2.9302778244018555,
      "logps/chosen": -295.33697509765625,
      "logps/rejected": -276.72747802734375,
      "loss": 0.4981,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9070584774017334,
      "rewards/margins": 2.2714245319366455,
      "rewards/rejected": -4.178483009338379,
      "step": 4680
    },
    {
      "epoch": 0.23133621273087476,
      "grad_norm": 2.362673759460449,
      "learning_rate": 4.614999671851414e-05,
      "logits/chosen": 2.637178897857666,
      "logits/rejected": 2.9459753036499023,
      "logps/chosen": -265.35406494140625,
      "logps/rejected": -265.4243469238281,
      "loss": 0.5864,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0529932975769043,
      "rewards/margins": 1.9130287170410156,
      "rewards/rejected": -3.966021776199341,
      "step": 4700
    },
    {
      "epoch": 0.23232062214675084,
      "grad_norm": 1.8069058656692505,
      "learning_rate": 4.6133589289230165e-05,
      "logits/chosen": 2.6342153549194336,
      "logits/rejected": 2.8124988079071045,
      "logps/chosen": -254.49771118164062,
      "logps/rejected": -248.01766967773438,
      "loss": 0.4308,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0373992919921875,
      "rewards/margins": 2.445296049118042,
      "rewards/rejected": -4.482695579528809,
      "step": 4720
    },
    {
      "epoch": 0.23330503156262689,
      "grad_norm": 3.141077756881714,
      "learning_rate": 4.611718185994618e-05,
      "logits/chosen": 2.4478962421417236,
      "logits/rejected": 2.7110605239868164,
      "logps/chosen": -260.13629150390625,
      "logps/rejected": -264.65924072265625,
      "loss": 0.6465,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.2812461853027344,
      "rewards/margins": 1.3604106903076172,
      "rewards/rejected": -3.6416568756103516,
      "step": 4740
    },
    {
      "epoch": 0.23428944097850296,
      "grad_norm": 2.536259889602661,
      "learning_rate": 4.6100774430662206e-05,
      "logits/chosen": 2.824970245361328,
      "logits/rejected": 3.0742783546447754,
      "logps/chosen": -270.773193359375,
      "logps/rejected": -278.81103515625,
      "loss": 0.3882,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.740415334701538,
      "rewards/margins": 2.314875841140747,
      "rewards/rejected": -4.055291175842285,
      "step": 4760
    },
    {
      "epoch": 0.23527385039437904,
      "grad_norm": 2.0517055988311768,
      "learning_rate": 4.608436700137822e-05,
      "logits/chosen": 2.8845551013946533,
      "logits/rejected": 3.192624568939209,
      "logps/chosen": -279.00537109375,
      "logps/rejected": -261.39862060546875,
      "loss": 0.6245,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.4474925994873047,
      "rewards/margins": 1.5843889713287354,
      "rewards/rejected": -4.031881809234619,
      "step": 4780
    },
    {
      "epoch": 0.23625825981025508,
      "grad_norm": 1.605189561843872,
      "learning_rate": 4.6067959572094246e-05,
      "logits/chosen": 2.456052303314209,
      "logits/rejected": 2.663743495941162,
      "logps/chosen": -261.059814453125,
      "logps/rejected": -286.1708068847656,
      "loss": 0.5498,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.9485368728637695,
      "rewards/margins": 2.0893232822418213,
      "rewards/rejected": -4.037859916687012,
      "step": 4800
    },
    {
      "epoch": 0.23724266922613116,
      "grad_norm": 3.4342615604400635,
      "learning_rate": 4.605155214281027e-05,
      "logits/chosen": 2.608328104019165,
      "logits/rejected": 2.8733928203582764,
      "logps/chosen": -240.6315155029297,
      "logps/rejected": -244.3870086669922,
      "loss": 0.6187,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7439258098602295,
      "rewards/margins": 1.254624366760254,
      "rewards/rejected": -2.9985501766204834,
      "step": 4820
    },
    {
      "epoch": 0.2382270786420072,
      "grad_norm": 1.9876729249954224,
      "learning_rate": 4.603514471352629e-05,
      "logits/chosen": 2.420902967453003,
      "logits/rejected": 2.6370627880096436,
      "logps/chosen": -238.53585815429688,
      "logps/rejected": -270.20428466796875,
      "loss": 0.5265,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.498857855796814,
      "rewards/margins": 2.2270519733428955,
      "rewards/rejected": -3.72590970993042,
      "step": 4840
    },
    {
      "epoch": 0.23921148805788328,
      "grad_norm": 3.1411643028259277,
      "learning_rate": 4.601873728424231e-05,
      "logits/chosen": 2.4612293243408203,
      "logits/rejected": 2.877092123031616,
      "logps/chosen": -249.6715850830078,
      "logps/rejected": -295.95404052734375,
      "loss": 0.4243,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4711527824401855,
      "rewards/margins": 2.5605177879333496,
      "rewards/rejected": -4.031670093536377,
      "step": 4860
    },
    {
      "epoch": 0.24019589747375933,
      "grad_norm": 4.799337863922119,
      "learning_rate": 4.600232985495833e-05,
      "logits/chosen": 2.441145896911621,
      "logits/rejected": 2.6762168407440186,
      "logps/chosen": -258.27716064453125,
      "logps/rejected": -286.2453918457031,
      "loss": 0.4502,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5103857517242432,
      "rewards/margins": 1.7408225536346436,
      "rewards/rejected": -3.251208543777466,
      "step": 4880
    },
    {
      "epoch": 0.2411803068896354,
      "grad_norm": 2.1598830223083496,
      "learning_rate": 4.598592242567435e-05,
      "logits/chosen": 2.398395538330078,
      "logits/rejected": 2.562654495239258,
      "logps/chosen": -236.7672882080078,
      "logps/rejected": -259.2625427246094,
      "loss": 0.6293,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.695043921470642,
      "rewards/margins": 1.4905359745025635,
      "rewards/rejected": -3.185579776763916,
      "step": 4900
    },
    {
      "epoch": 0.24216471630551145,
      "grad_norm": 0.9388608336448669,
      "learning_rate": 4.596951499639037e-05,
      "logits/chosen": 2.3977084159851074,
      "logits/rejected": 2.6600215435028076,
      "logps/chosen": -271.61175537109375,
      "logps/rejected": -276.75152587890625,
      "loss": 0.4464,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8696142435073853,
      "rewards/margins": 2.2705655097961426,
      "rewards/rejected": -4.140179634094238,
      "step": 4920
    },
    {
      "epoch": 0.24314912572138753,
      "grad_norm": 2.0887506008148193,
      "learning_rate": 4.595310756710639e-05,
      "logits/chosen": 2.531069040298462,
      "logits/rejected": 2.7268178462982178,
      "logps/chosen": -262.8230895996094,
      "logps/rejected": -261.14996337890625,
      "loss": 0.4395,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.514927864074707,
      "rewards/margins": 2.166024923324585,
      "rewards/rejected": -4.680953025817871,
      "step": 4940
    },
    {
      "epoch": 0.24413353513726357,
      "grad_norm": 2.2320451736450195,
      "learning_rate": 4.593670013782241e-05,
      "logits/chosen": 2.485156536102295,
      "logits/rejected": 2.594992160797119,
      "logps/chosen": -290.9054260253906,
      "logps/rejected": -295.1378479003906,
      "loss": 0.4781,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.2070047855377197,
      "rewards/margins": 2.1227188110351562,
      "rewards/rejected": -4.329723834991455,
      "step": 4960
    },
    {
      "epoch": 0.24511794455313965,
      "grad_norm": 1.4306344985961914,
      "learning_rate": 4.5920292708538425e-05,
      "logits/chosen": 2.2482573986053467,
      "logits/rejected": 2.3919034004211426,
      "logps/chosen": -291.91851806640625,
      "logps/rejected": -326.08441162109375,
      "loss": 0.3702,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.7344119548797607,
      "rewards/margins": 3.2567248344421387,
      "rewards/rejected": -5.9911370277404785,
      "step": 4980
    },
    {
      "epoch": 0.24610235396901572,
      "grad_norm": 5.003047466278076,
      "learning_rate": 4.590388527925445e-05,
      "logits/chosen": 2.3642868995666504,
      "logits/rejected": 2.555663824081421,
      "logps/chosen": -246.42764282226562,
      "logps/rejected": -279.26776123046875,
      "loss": 0.437,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.3304381370544434,
      "rewards/margins": 2.6647002696990967,
      "rewards/rejected": -4.995138168334961,
      "step": 5000
    },
    {
      "epoch": 0.24708676338489177,
      "grad_norm": 5.001455307006836,
      "learning_rate": 4.5887477849970465e-05,
      "logits/chosen": 2.5769007205963135,
      "logits/rejected": 2.695035457611084,
      "logps/chosen": -293.0196533203125,
      "logps/rejected": -271.875,
      "loss": 0.5842,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.4617648124694824,
      "rewards/margins": 2.2060534954071045,
      "rewards/rejected": -4.667818546295166,
      "step": 5020
    },
    {
      "epoch": 0.24807117280076785,
      "grad_norm": 2.7158193588256836,
      "learning_rate": 4.587107042068649e-05,
      "logits/chosen": 2.6556601524353027,
      "logits/rejected": 2.607309579849243,
      "logps/chosen": -273.7523193359375,
      "logps/rejected": -294.56268310546875,
      "loss": 0.4833,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.255375385284424,
      "rewards/margins": 2.4830565452575684,
      "rewards/rejected": -4.73843240737915,
      "step": 5040
    },
    {
      "epoch": 0.2490555822166439,
      "grad_norm": 2.5547356605529785,
      "learning_rate": 4.5854662991402506e-05,
      "logits/chosen": 2.760309934616089,
      "logits/rejected": 2.9228100776672363,
      "logps/chosen": -277.2403259277344,
      "logps/rejected": -264.23394775390625,
      "loss": 0.4508,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.450338363647461,
      "rewards/margins": 2.74890398979187,
      "rewards/rejected": -5.19924259185791,
      "step": 5060
    },
    {
      "epoch": 0.25003999163251994,
      "grad_norm": 0.9529233574867249,
      "learning_rate": 4.583825556211853e-05,
      "logits/chosen": 2.702465534210205,
      "logits/rejected": 3.0063652992248535,
      "logps/chosen": -291.00823974609375,
      "logps/rejected": -311.9176025390625,
      "loss": 0.3407,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.4859330654144287,
      "rewards/margins": 3.213099956512451,
      "rewards/rejected": -5.699034214019775,
      "step": 5080
    },
    {
      "epoch": 0.251024401048396,
      "grad_norm": 1.59458327293396,
      "learning_rate": 4.5821848132834546e-05,
      "logits/chosen": 2.492394208908081,
      "logits/rejected": 2.654919385910034,
      "logps/chosen": -267.05242919921875,
      "logps/rejected": -269.8493347167969,
      "loss": 0.4226,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.026063919067383,
      "rewards/margins": 2.673933267593384,
      "rewards/rejected": -4.6999969482421875,
      "step": 5100
    },
    {
      "epoch": 0.2520088104642721,
      "grad_norm": 4.929993629455566,
      "learning_rate": 4.580544070355057e-05,
      "logits/chosen": 2.58240008354187,
      "logits/rejected": 2.8606765270233154,
      "logps/chosen": -267.89349365234375,
      "logps/rejected": -274.1934814453125,
      "loss": 0.3933,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.347379207611084,
      "rewards/margins": 2.6917147636413574,
      "rewards/rejected": -5.0390944480896,
      "step": 5120
    },
    {
      "epoch": 0.25299321988014817,
      "grad_norm": 2.5217809677124023,
      "learning_rate": 4.5789033274266594e-05,
      "logits/chosen": 2.5347349643707275,
      "logits/rejected": 2.6962943077087402,
      "logps/chosen": -238.65396118164062,
      "logps/rejected": -282.5057373046875,
      "loss": 0.619,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9969251155853271,
      "rewards/margins": 2.035439968109131,
      "rewards/rejected": -4.032365322113037,
      "step": 5140
    },
    {
      "epoch": 0.25397762929602424,
      "grad_norm": 5.1536760330200195,
      "learning_rate": 4.577262584498261e-05,
      "logits/chosen": 2.7043049335479736,
      "logits/rejected": 2.8074278831481934,
      "logps/chosen": -255.75265502929688,
      "logps/rejected": -250.29226684570312,
      "loss": 0.5266,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.109732985496521,
      "rewards/margins": 1.7373358011245728,
      "rewards/rejected": -2.8470687866210938,
      "step": 5160
    },
    {
      "epoch": 0.25496203871190026,
      "grad_norm": 4.464472770690918,
      "learning_rate": 4.5756218415698634e-05,
      "logits/chosen": 2.551349401473999,
      "logits/rejected": 2.793591022491455,
      "logps/chosen": -245.66299438476562,
      "logps/rejected": -254.6721954345703,
      "loss": 0.5147,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3761370182037354,
      "rewards/margins": 2.309187412261963,
      "rewards/rejected": -3.6853244304656982,
      "step": 5180
    },
    {
      "epoch": 0.25594644812777634,
      "grad_norm": 1.1017955541610718,
      "learning_rate": 4.573981098641465e-05,
      "logits/chosen": 2.4435365200042725,
      "logits/rejected": 2.6555721759796143,
      "logps/chosen": -264.66387939453125,
      "logps/rejected": -283.75762939453125,
      "loss": 0.5967,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.64752197265625,
      "rewards/margins": 2.0853934288024902,
      "rewards/rejected": -3.732915163040161,
      "step": 5200
    },
    {
      "epoch": 0.2569308575436524,
      "grad_norm": 3.0173721313476562,
      "learning_rate": 4.5723403557130674e-05,
      "logits/chosen": 2.531745433807373,
      "logits/rejected": 2.604964256286621,
      "logps/chosen": -259.03509521484375,
      "logps/rejected": -231.0110626220703,
      "loss": 0.6163,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.8488954305648804,
      "rewards/margins": 1.3953810930252075,
      "rewards/rejected": -3.244276762008667,
      "step": 5220
    },
    {
      "epoch": 0.2579152669595285,
      "grad_norm": 1.5013785362243652,
      "learning_rate": 4.570699612784669e-05,
      "logits/chosen": 2.3100688457489014,
      "logits/rejected": 2.6377313137054443,
      "logps/chosen": -246.559326171875,
      "logps/rejected": -261.87274169921875,
      "loss": 0.3881,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.4386011362075806,
      "rewards/margins": 2.44628643989563,
      "rewards/rejected": -3.884887218475342,
      "step": 5240
    },
    {
      "epoch": 0.2588996763754045,
      "grad_norm": 2.4782211780548096,
      "learning_rate": 4.5690588698562715e-05,
      "logits/chosen": 2.6230664253234863,
      "logits/rejected": 2.8556313514709473,
      "logps/chosen": -284.017333984375,
      "logps/rejected": -277.62701416015625,
      "loss": 0.5436,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.1818270683288574,
      "rewards/margins": 2.204345464706421,
      "rewards/rejected": -4.386172294616699,
      "step": 5260
    },
    {
      "epoch": 0.2598840857912806,
      "grad_norm": 5.075871467590332,
      "learning_rate": 4.567418126927873e-05,
      "logits/chosen": 2.274871826171875,
      "logits/rejected": 2.6402556896209717,
      "logps/chosen": -255.6171112060547,
      "logps/rejected": -252.6072998046875,
      "loss": 0.4006,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9870874881744385,
      "rewards/margins": 1.9613533020019531,
      "rewards/rejected": -3.9484405517578125,
      "step": 5280
    },
    {
      "epoch": 0.26086849520715666,
      "grad_norm": 0.8519258499145508,
      "learning_rate": 4.565777383999475e-05,
      "logits/chosen": 2.6823391914367676,
      "logits/rejected": 3.000648021697998,
      "logps/chosen": -292.62823486328125,
      "logps/rejected": -282.01934814453125,
      "loss": 0.6045,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.311398983001709,
      "rewards/margins": 2.0382537841796875,
      "rewards/rejected": -4.3496527671813965,
      "step": 5300
    },
    {
      "epoch": 0.26185290462303273,
      "grad_norm": 1.5505499839782715,
      "learning_rate": 4.564136641071077e-05,
      "logits/chosen": 2.053924798965454,
      "logits/rejected": 2.3447988033294678,
      "logps/chosen": -259.6995849609375,
      "logps/rejected": -290.58416748046875,
      "loss": 0.4551,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.420670986175537,
      "rewards/margins": 2.819960355758667,
      "rewards/rejected": -5.240631580352783,
      "step": 5320
    },
    {
      "epoch": 0.2628373140389088,
      "grad_norm": 1.8936477899551392,
      "learning_rate": 4.562495898142679e-05,
      "logits/chosen": 2.5844085216522217,
      "logits/rejected": 2.864271402359009,
      "logps/chosen": -264.9455871582031,
      "logps/rejected": -256.09747314453125,
      "loss": 0.4952,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.1593544483184814,
      "rewards/margins": 2.546997547149658,
      "rewards/rejected": -4.7063517570495605,
      "step": 5340
    },
    {
      "epoch": 0.26382172345478483,
      "grad_norm": 2.3887200355529785,
      "learning_rate": 4.560855155214281e-05,
      "logits/chosen": 2.5999507904052734,
      "logits/rejected": 2.8769707679748535,
      "logps/chosen": -246.35519409179688,
      "logps/rejected": -292.5760803222656,
      "loss": 0.4961,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.311326742172241,
      "rewards/margins": 2.796034574508667,
      "rewards/rejected": -5.107361793518066,
      "step": 5360
    },
    {
      "epoch": 0.2648061328706609,
      "grad_norm": 0.4998832046985626,
      "learning_rate": 4.559214412285883e-05,
      "logits/chosen": 2.558732509613037,
      "logits/rejected": 2.8091800212860107,
      "logps/chosen": -272.84039306640625,
      "logps/rejected": -305.33685302734375,
      "loss": 0.484,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -3.1297335624694824,
      "rewards/margins": 2.323415756225586,
      "rewards/rejected": -5.453149318695068,
      "step": 5380
    },
    {
      "epoch": 0.265790542286537,
      "grad_norm": 0.4583568274974823,
      "learning_rate": 4.557573669357485e-05,
      "logits/chosen": 2.1143274307250977,
      "logits/rejected": 2.3767447471618652,
      "logps/chosen": -264.9438171386719,
      "logps/rejected": -288.00927734375,
      "loss": 0.6341,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.313783645629883,
      "rewards/margins": 1.947797417640686,
      "rewards/rejected": -5.2615814208984375,
      "step": 5400
    },
    {
      "epoch": 0.26677495170241305,
      "grad_norm": 0.7477439045906067,
      "learning_rate": 4.555932926429087e-05,
      "logits/chosen": 2.3661694526672363,
      "logits/rejected": 2.6711699962615967,
      "logps/chosen": -255.478759765625,
      "logps/rejected": -292.6827087402344,
      "loss": 0.4728,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.7283072471618652,
      "rewards/margins": 3.0005786418914795,
      "rewards/rejected": -5.728886604309082,
      "step": 5420
    },
    {
      "epoch": 0.2677593611182891,
      "grad_norm": 0.3151109218597412,
      "learning_rate": 4.5542921835006893e-05,
      "logits/chosen": 2.8172173500061035,
      "logits/rejected": 2.7756943702697754,
      "logps/chosen": -265.7920227050781,
      "logps/rejected": -290.03656005859375,
      "loss": 0.3917,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.878640651702881,
      "rewards/margins": 3.0521671772003174,
      "rewards/rejected": -5.930808067321777,
      "step": 5440
    },
    {
      "epoch": 0.26874377053416515,
      "grad_norm": 4.136279106140137,
      "learning_rate": 4.552651440572292e-05,
      "logits/chosen": 2.4163148403167725,
      "logits/rejected": 2.675987720489502,
      "logps/chosen": -254.0996551513672,
      "logps/rejected": -272.8876953125,
      "loss": 0.5193,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.5106303691864014,
      "rewards/margins": 2.128159284591675,
      "rewards/rejected": -4.638789653778076,
      "step": 5460
    },
    {
      "epoch": 0.2697281799500412,
      "grad_norm": 4.929341793060303,
      "learning_rate": 4.5510106976438934e-05,
      "logits/chosen": 2.7721104621887207,
      "logits/rejected": 3.0625596046447754,
      "logps/chosen": -255.5966033935547,
      "logps/rejected": -286.51947021484375,
      "loss": 0.4177,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.562405586242676,
      "rewards/margins": 2.5362548828125,
      "rewards/rejected": -5.098660469055176,
      "step": 5480
    },
    {
      "epoch": 0.2707125893659173,
      "grad_norm": 1.1877930164337158,
      "learning_rate": 4.549369954715496e-05,
      "logits/chosen": 2.5333635807037354,
      "logits/rejected": 2.6362106800079346,
      "logps/chosen": -220.6451416015625,
      "logps/rejected": -248.6772003173828,
      "loss": 0.4905,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2660396099090576,
      "rewards/margins": 2.18807315826416,
      "rewards/rejected": -4.454112529754639,
      "step": 5500
    },
    {
      "epoch": 0.2716969987817934,
      "grad_norm": 2.0877487659454346,
      "learning_rate": 4.5477292117870974e-05,
      "logits/chosen": 2.6995081901550293,
      "logits/rejected": 2.9421920776367188,
      "logps/chosen": -266.6639709472656,
      "logps/rejected": -287.58489990234375,
      "loss": 0.5322,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.3575758934020996,
      "rewards/margins": 1.9334112405776978,
      "rewards/rejected": -4.290987491607666,
      "step": 5520
    },
    {
      "epoch": 0.2726814081976694,
      "grad_norm": 1.8478853702545166,
      "learning_rate": 4.5460884688587e-05,
      "logits/chosen": 2.589341402053833,
      "logits/rejected": 2.6920742988586426,
      "logps/chosen": -258.0606994628906,
      "logps/rejected": -305.01611328125,
      "loss": 0.5235,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.3092997074127197,
      "rewards/margins": 2.366241216659546,
      "rewards/rejected": -4.675539970397949,
      "step": 5540
    },
    {
      "epoch": 0.27366581761354547,
      "grad_norm": 1.592665195465088,
      "learning_rate": 4.5444477259303015e-05,
      "logits/chosen": 2.6958982944488525,
      "logits/rejected": 2.9316611289978027,
      "logps/chosen": -259.5805358886719,
      "logps/rejected": -256.86932373046875,
      "loss": 0.5238,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9316661357879639,
      "rewards/margins": 2.1739468574523926,
      "rewards/rejected": -4.105612754821777,
      "step": 5560
    },
    {
      "epoch": 0.27465022702942155,
      "grad_norm": 2.0272443294525146,
      "learning_rate": 4.542806983001903e-05,
      "logits/chosen": 2.5240261554718018,
      "logits/rejected": 2.8772904872894287,
      "logps/chosen": -264.3367004394531,
      "logps/rejected": -264.4194641113281,
      "loss": 0.3787,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.2498714923858643,
      "rewards/margins": 2.296290874481201,
      "rewards/rejected": -4.5461626052856445,
      "step": 5580
    },
    {
      "epoch": 0.2756346364452976,
      "grad_norm": 1.3607975244522095,
      "learning_rate": 4.5411662400735055e-05,
      "logits/chosen": 2.7108969688415527,
      "logits/rejected": 3.008924722671509,
      "logps/chosen": -273.5585021972656,
      "logps/rejected": -270.63665771484375,
      "loss": 0.401,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4672701358795166,
      "rewards/margins": 2.266603469848633,
      "rewards/rejected": -3.7338733673095703,
      "step": 5600
    },
    {
      "epoch": 0.27661904586117364,
      "grad_norm": 3.3115127086639404,
      "learning_rate": 4.539525497145107e-05,
      "logits/chosen": 2.802295207977295,
      "logits/rejected": 2.997713327407837,
      "logps/chosen": -263.33782958984375,
      "logps/rejected": -267.16046142578125,
      "loss": 0.5067,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.751408576965332,
      "rewards/margins": 2.503432273864746,
      "rewards/rejected": -4.254841327667236,
      "step": 5620
    },
    {
      "epoch": 0.2776034552770497,
      "grad_norm": 1.6525328159332275,
      "learning_rate": 4.5378847542167096e-05,
      "logits/chosen": 2.7586569786071777,
      "logits/rejected": 2.99749493598938,
      "logps/chosen": -265.67376708984375,
      "logps/rejected": -270.430908203125,
      "loss": 0.5847,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.8736705780029297,
      "rewards/margins": 1.9203836917877197,
      "rewards/rejected": -3.794053554534912,
      "step": 5640
    },
    {
      "epoch": 0.2785878646929258,
      "grad_norm": 6.647500038146973,
      "learning_rate": 4.536244011288311e-05,
      "logits/chosen": 2.6019742488861084,
      "logits/rejected": 2.851628065109253,
      "logps/chosen": -255.51687622070312,
      "logps/rejected": -266.2659606933594,
      "loss": 0.5494,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6576299667358398,
      "rewards/margins": 1.9814233779907227,
      "rewards/rejected": -3.6390533447265625,
      "step": 5660
    },
    {
      "epoch": 0.27957227410880187,
      "grad_norm": 1.8975929021835327,
      "learning_rate": 4.5346032683599136e-05,
      "logits/chosen": 2.766070604324341,
      "logits/rejected": 3.3936614990234375,
      "logps/chosen": -269.43402099609375,
      "logps/rejected": -266.49884033203125,
      "loss": 0.461,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6262975931167603,
      "rewards/margins": 2.6544411182403564,
      "rewards/rejected": -4.280738830566406,
      "step": 5680
    },
    {
      "epoch": 0.28055668352467794,
      "grad_norm": 5.458133220672607,
      "learning_rate": 4.532962525431515e-05,
      "logits/chosen": 2.704883098602295,
      "logits/rejected": 2.76969313621521,
      "logps/chosen": -282.1025390625,
      "logps/rejected": -313.71929931640625,
      "loss": 0.593,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.039731502532959,
      "rewards/margins": 2.2921321392059326,
      "rewards/rejected": -4.331863880157471,
      "step": 5700
    },
    {
      "epoch": 0.28154109294055396,
      "grad_norm": 1.468153953552246,
      "learning_rate": 4.5313217825031177e-05,
      "logits/chosen": 2.687809705734253,
      "logits/rejected": 3.041017532348633,
      "logps/chosen": -264.0646667480469,
      "logps/rejected": -289.1760559082031,
      "loss": 0.3655,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.220982074737549,
      "rewards/margins": 3.155125379562378,
      "rewards/rejected": -5.376107692718506,
      "step": 5720
    },
    {
      "epoch": 0.28252550235643004,
      "grad_norm": 1.3969789743423462,
      "learning_rate": 4.5296810395747193e-05,
      "logits/chosen": 2.645753860473633,
      "logits/rejected": 2.840886116027832,
      "logps/chosen": -280.5207824707031,
      "logps/rejected": -310.27301025390625,
      "loss": 0.7452,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.7347254753112793,
      "rewards/margins": 2.3056700229644775,
      "rewards/rejected": -5.040395736694336,
      "step": 5740
    },
    {
      "epoch": 0.2835099117723061,
      "grad_norm": 1.20014226436615,
      "learning_rate": 4.528040296646322e-05,
      "logits/chosen": 2.9208149909973145,
      "logits/rejected": 3.252574920654297,
      "logps/chosen": -280.9341735839844,
      "logps/rejected": -279.1548156738281,
      "loss": 0.3579,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.086369514465332,
      "rewards/margins": 2.780824899673462,
      "rewards/rejected": -4.867194175720215,
      "step": 5760
    },
    {
      "epoch": 0.2844943211881822,
      "grad_norm": 4.079502582550049,
      "learning_rate": 4.526399553717924e-05,
      "logits/chosen": 2.7207353115081787,
      "logits/rejected": 3.0591070652008057,
      "logps/chosen": -255.6107177734375,
      "logps/rejected": -268.1053771972656,
      "loss": 0.6473,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.7289527654647827,
      "rewards/margins": 1.7239030599594116,
      "rewards/rejected": -3.4528560638427734,
      "step": 5780
    },
    {
      "epoch": 0.2854787306040582,
      "grad_norm": 1.8083879947662354,
      "learning_rate": 4.524758810789526e-05,
      "logits/chosen": 2.8137502670288086,
      "logits/rejected": 2.9496982097625732,
      "logps/chosen": -242.96817016601562,
      "logps/rejected": -247.3957061767578,
      "loss": 0.6236,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.5946877002716064,
      "rewards/margins": 1.604162573814392,
      "rewards/rejected": -3.198850154876709,
      "step": 5800
    },
    {
      "epoch": 0.2864631400199343,
      "grad_norm": 0.518046498298645,
      "learning_rate": 4.523118067861128e-05,
      "logits/chosen": 3.043271541595459,
      "logits/rejected": 3.418332576751709,
      "logps/chosen": -253.86813354492188,
      "logps/rejected": -244.5006561279297,
      "loss": 0.5438,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9460606575012207,
      "rewards/margins": 2.0962724685668945,
      "rewards/rejected": -3.0423331260681152,
      "step": 5820
    },
    {
      "epoch": 0.28744754943581036,
      "grad_norm": 1.8208656311035156,
      "learning_rate": 4.52147732493273e-05,
      "logits/chosen": 2.8125433921813965,
      "logits/rejected": 3.121345043182373,
      "logps/chosen": -237.8603973388672,
      "logps/rejected": -244.746337890625,
      "loss": 0.4726,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2835941314697266,
      "rewards/margins": 1.8690929412841797,
      "rewards/rejected": -3.1526870727539062,
      "step": 5840
    },
    {
      "epoch": 0.28843195885168643,
      "grad_norm": 1.374565839767456,
      "learning_rate": 4.519836582004332e-05,
      "logits/chosen": 2.6528806686401367,
      "logits/rejected": 2.8231911659240723,
      "logps/chosen": -243.6230926513672,
      "logps/rejected": -252.4804229736328,
      "loss": 0.5482,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.1118662357330322,
      "rewards/margins": 2.2467215061187744,
      "rewards/rejected": -3.3585879802703857,
      "step": 5860
    },
    {
      "epoch": 0.28941636826756245,
      "grad_norm": 2.356158971786499,
      "learning_rate": 4.518195839075934e-05,
      "logits/chosen": 2.7486276626586914,
      "logits/rejected": 2.939563751220703,
      "logps/chosen": -267.2723083496094,
      "logps/rejected": -254.7738800048828,
      "loss": 0.5267,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.8076772689819336,
      "rewards/margins": 2.0451555252075195,
      "rewards/rejected": -3.852832794189453,
      "step": 5880
    },
    {
      "epoch": 0.2904007776834385,
      "grad_norm": 1.5483099222183228,
      "learning_rate": 4.5165550961475355e-05,
      "logits/chosen": 2.8077282905578613,
      "logits/rejected": 3.031550645828247,
      "logps/chosen": -246.2776336669922,
      "logps/rejected": -271.5143737792969,
      "loss": 0.4701,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.5324711799621582,
      "rewards/margins": 2.4425055980682373,
      "rewards/rejected": -3.9749767780303955,
      "step": 5900
    },
    {
      "epoch": 0.2913851870993146,
      "grad_norm": 4.812076568603516,
      "learning_rate": 4.514914353219138e-05,
      "logits/chosen": 2.6403300762176514,
      "logits/rejected": 2.751085042953491,
      "logps/chosen": -271.9637756347656,
      "logps/rejected": -289.1182556152344,
      "loss": 0.5793,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.158522367477417,
      "rewards/margins": 2.2361056804656982,
      "rewards/rejected": -4.394628524780273,
      "step": 5920
    },
    {
      "epoch": 0.2923695965151907,
      "grad_norm": 4.603996276855469,
      "learning_rate": 4.5132736102907396e-05,
      "logits/chosen": 2.637834310531616,
      "logits/rejected": 2.908496856689453,
      "logps/chosen": -232.4144287109375,
      "logps/rejected": -249.9583282470703,
      "loss": 0.7104,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8423891067504883,
      "rewards/margins": 1.9458589553833008,
      "rewards/rejected": -3.7882485389709473,
      "step": 5940
    },
    {
      "epoch": 0.29335400593106675,
      "grad_norm": 3.898214817047119,
      "learning_rate": 4.511632867362342e-05,
      "logits/chosen": 2.532057285308838,
      "logits/rejected": 2.6453442573547363,
      "logps/chosen": -252.35595703125,
      "logps/rejected": -252.40322875976562,
      "loss": 0.6867,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.7401043176651,
      "rewards/margins": 1.5896841287612915,
      "rewards/rejected": -3.3297886848449707,
      "step": 5960
    },
    {
      "epoch": 0.29433841534694277,
      "grad_norm": 2.3680660724639893,
      "learning_rate": 4.5099921244339436e-05,
      "logits/chosen": 2.699557065963745,
      "logits/rejected": 2.9132635593414307,
      "logps/chosen": -243.77664184570312,
      "logps/rejected": -273.3659362792969,
      "loss": 0.5655,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.5809837579727173,
      "rewards/margins": 1.8863966464996338,
      "rewards/rejected": -3.4673805236816406,
      "step": 5980
    },
    {
      "epoch": 0.29532282476281885,
      "grad_norm": 1.012650966644287,
      "learning_rate": 4.508351381505546e-05,
      "logits/chosen": 2.4270012378692627,
      "logits/rejected": 2.8870351314544678,
      "logps/chosen": -275.341796875,
      "logps/rejected": -278.2038879394531,
      "loss": 0.546,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.2886817455291748,
      "rewards/margins": 2.3759584426879883,
      "rewards/rejected": -3.664640426635742,
      "step": 6000
    },
    {
      "epoch": 0.2963072341786949,
      "grad_norm": 3.175963878631592,
      "learning_rate": 4.5067106385771477e-05,
      "logits/chosen": 2.852879285812378,
      "logits/rejected": 2.9579596519470215,
      "logps/chosen": -268.8714294433594,
      "logps/rejected": -283.7065124511719,
      "loss": 0.4053,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.6316827535629272,
      "rewards/margins": 2.0880532264709473,
      "rewards/rejected": -3.719735622406006,
      "step": 6020
    },
    {
      "epoch": 0.297291643594571,
      "grad_norm": 4.449084281921387,
      "learning_rate": 4.50506989564875e-05,
      "logits/chosen": 2.395656108856201,
      "logits/rejected": 2.7556121349334717,
      "logps/chosen": -247.23635864257812,
      "logps/rejected": -291.0061340332031,
      "loss": 0.5793,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.949824571609497,
      "rewards/margins": 1.6459518671035767,
      "rewards/rejected": -3.595776319503784,
      "step": 6040
    },
    {
      "epoch": 0.298276053010447,
      "grad_norm": 5.603615760803223,
      "learning_rate": 4.5034291527203524e-05,
      "logits/chosen": 2.3305716514587402,
      "logits/rejected": 2.8157427310943604,
      "logps/chosen": -262.52337646484375,
      "logps/rejected": -282.7818908691406,
      "loss": 0.5296,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.5303757190704346,
      "rewards/margins": 2.005174160003662,
      "rewards/rejected": -4.535550117492676,
      "step": 6060
    },
    {
      "epoch": 0.2992604624263231,
      "grad_norm": 3.0714290142059326,
      "learning_rate": 4.501788409791954e-05,
      "logits/chosen": 2.654764175415039,
      "logits/rejected": 2.8669180870056152,
      "logps/chosen": -250.89175415039062,
      "logps/rejected": -267.94647216796875,
      "loss": 0.5192,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.9789727926254272,
      "rewards/margins": 1.7368671894073486,
      "rewards/rejected": -3.7158398628234863,
      "step": 6080
    },
    {
      "epoch": 0.30024487184219917,
      "grad_norm": 5.916509628295898,
      "learning_rate": 4.5001476668635564e-05,
      "logits/chosen": 2.5176849365234375,
      "logits/rejected": 2.76580810546875,
      "logps/chosen": -260.8224792480469,
      "logps/rejected": -276.1700134277344,
      "loss": 0.4981,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.988172173500061,
      "rewards/margins": 2.2990424633026123,
      "rewards/rejected": -4.287214756011963,
      "step": 6100
    },
    {
      "epoch": 0.30122928125807524,
      "grad_norm": 2.4523062705993652,
      "learning_rate": 4.498506923935158e-05,
      "logits/chosen": 2.8372504711151123,
      "logits/rejected": 2.9801383018493652,
      "logps/chosen": -254.25198364257812,
      "logps/rejected": -257.83447265625,
      "loss": 0.6368,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.502485752105713,
      "rewards/margins": 1.546277642250061,
      "rewards/rejected": -4.048763751983643,
      "step": 6120
    },
    {
      "epoch": 0.3022136906739513,
      "grad_norm": 3.5035905838012695,
      "learning_rate": 4.4968661810067605e-05,
      "logits/chosen": 2.7031426429748535,
      "logits/rejected": 2.948758125305176,
      "logps/chosen": -271.7712097167969,
      "logps/rejected": -256.2470397949219,
      "loss": 0.4257,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0395100116729736,
      "rewards/margins": 1.8871281147003174,
      "rewards/rejected": -3.926638126373291,
      "step": 6140
    },
    {
      "epoch": 0.30319810008982734,
      "grad_norm": 10.766003608703613,
      "learning_rate": 4.495225438078362e-05,
      "logits/chosen": 2.707266092300415,
      "logits/rejected": 3.0228524208068848,
      "logps/chosen": -272.4481201171875,
      "logps/rejected": -235.73666381835938,
      "loss": 0.4231,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9072145223617554,
      "rewards/margins": 2.496220827102661,
      "rewards/rejected": -4.403434753417969,
      "step": 6160
    },
    {
      "epoch": 0.3041825095057034,
      "grad_norm": 0.6581427454948425,
      "learning_rate": 4.4935846951499645e-05,
      "logits/chosen": 2.655839204788208,
      "logits/rejected": 2.8966877460479736,
      "logps/chosen": -265.26458740234375,
      "logps/rejected": -272.4097900390625,
      "loss": 0.3839,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5520763397216797,
      "rewards/margins": 2.846020460128784,
      "rewards/rejected": -4.398097038269043,
      "step": 6180
    },
    {
      "epoch": 0.3051669189215795,
      "grad_norm": 3.3719043731689453,
      "learning_rate": 4.491943952221566e-05,
      "logits/chosen": 2.7620251178741455,
      "logits/rejected": 2.9259982109069824,
      "logps/chosen": -289.2167053222656,
      "logps/rejected": -300.685546875,
      "loss": 0.5502,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9875364303588867,
      "rewards/margins": 1.985884428024292,
      "rewards/rejected": -3.973421573638916,
      "step": 6200
    },
    {
      "epoch": 0.30615132833745556,
      "grad_norm": 4.016663551330566,
      "learning_rate": 4.490303209293168e-05,
      "logits/chosen": 2.9828991889953613,
      "logits/rejected": 3.109189510345459,
      "logps/chosen": -258.58892822265625,
      "logps/rejected": -264.6027526855469,
      "loss": 0.565,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9095500707626343,
      "rewards/margins": 1.869010329246521,
      "rewards/rejected": -3.7785611152648926,
      "step": 6220
    },
    {
      "epoch": 0.3071357377533316,
      "grad_norm": 3.622779130935669,
      "learning_rate": 4.48866246636477e-05,
      "logits/chosen": 3.244485378265381,
      "logits/rejected": 3.5587401390075684,
      "logps/chosen": -301.8114318847656,
      "logps/rejected": -313.1225891113281,
      "loss": 0.5553,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.143123149871826,
      "rewards/margins": 2.5357179641723633,
      "rewards/rejected": -4.678841590881348,
      "step": 6240
    },
    {
      "epoch": 0.30812014716920766,
      "grad_norm": 0.705336332321167,
      "learning_rate": 4.487021723436372e-05,
      "logits/chosen": 2.659106492996216,
      "logits/rejected": 2.7722764015197754,
      "logps/chosen": -254.19580078125,
      "logps/rejected": -256.6090393066406,
      "loss": 0.5761,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.8071743249893188,
      "rewards/margins": 2.1475844383239746,
      "rewards/rejected": -3.954758405685425,
      "step": 6260
    },
    {
      "epoch": 0.30910455658508373,
      "grad_norm": 3.8860528469085693,
      "learning_rate": 4.485380980507974e-05,
      "logits/chosen": 2.8609938621520996,
      "logits/rejected": 3.109135150909424,
      "logps/chosen": -269.8874206542969,
      "logps/rejected": -250.4751434326172,
      "loss": 0.581,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.2308852672576904,
      "rewards/margins": 1.732739806175232,
      "rewards/rejected": -3.963624954223633,
      "step": 6280
    },
    {
      "epoch": 0.3100889660009598,
      "grad_norm": 1.1654994487762451,
      "learning_rate": 4.483740237579576e-05,
      "logits/chosen": 2.7761385440826416,
      "logits/rejected": 2.9909002780914307,
      "logps/chosen": -232.791015625,
      "logps/rejected": -244.07363891601562,
      "loss": 0.5836,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3979333639144897,
      "rewards/margins": 1.758986473083496,
      "rewards/rejected": -3.1569199562072754,
      "step": 6300
    },
    {
      "epoch": 0.3110733754168359,
      "grad_norm": 6.110192775726318,
      "learning_rate": 4.482099494651178e-05,
      "logits/chosen": 2.797894239425659,
      "logits/rejected": 3.1224770545959473,
      "logps/chosen": -285.07489013671875,
      "logps/rejected": -281.48114013671875,
      "loss": 0.5414,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7024757862091064,
      "rewards/margins": 2.4243199825286865,
      "rewards/rejected": -4.126796245574951,
      "step": 6320
    },
    {
      "epoch": 0.3120577848327119,
      "grad_norm": 1.4399811029434204,
      "learning_rate": 4.48045875172278e-05,
      "logits/chosen": 3.0618908405303955,
      "logits/rejected": 3.251818895339966,
      "logps/chosen": -287.03668212890625,
      "logps/rejected": -278.66888427734375,
      "loss": 0.5163,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.0035531520843506,
      "rewards/margins": 1.604479193687439,
      "rewards/rejected": -2.6080322265625,
      "step": 6340
    },
    {
      "epoch": 0.313042194248588,
      "grad_norm": 3.6235530376434326,
      "learning_rate": 4.4788180087943824e-05,
      "logits/chosen": 2.9004878997802734,
      "logits/rejected": 2.9516854286193848,
      "logps/chosen": -246.81753540039062,
      "logps/rejected": -240.8434600830078,
      "loss": 0.3977,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.7236703038215637,
      "rewards/margins": 1.7935950756072998,
      "rewards/rejected": -2.5172653198242188,
      "step": 6360
    },
    {
      "epoch": 0.31402660366446405,
      "grad_norm": 2.24816632270813,
      "learning_rate": 4.477177265865985e-05,
      "logits/chosen": 2.877112865447998,
      "logits/rejected": 3.2879672050476074,
      "logps/chosen": -246.93075561523438,
      "logps/rejected": -239.11367797851562,
      "loss": 0.3971,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.2038376331329346,
      "rewards/margins": 1.871350884437561,
      "rewards/rejected": -3.075188398361206,
      "step": 6380
    },
    {
      "epoch": 0.31501101308034013,
      "grad_norm": 0.05676588416099548,
      "learning_rate": 4.4755365229375864e-05,
      "logits/chosen": 2.7742934226989746,
      "logits/rejected": 3.055048704147339,
      "logps/chosen": -256.9687805175781,
      "logps/rejected": -296.9956970214844,
      "loss": 0.5289,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4677261114120483,
      "rewards/margins": 2.69872784614563,
      "rewards/rejected": -4.166453838348389,
      "step": 6400
    },
    {
      "epoch": 0.31599542249621615,
      "grad_norm": 5.028689384460449,
      "learning_rate": 4.473895780009189e-05,
      "logits/chosen": 2.678133726119995,
      "logits/rejected": 2.827847957611084,
      "logps/chosen": -232.51296997070312,
      "logps/rejected": -269.9065856933594,
      "loss": 0.5071,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.6571201086044312,
      "rewards/margins": 2.3024685382843018,
      "rewards/rejected": -3.9595882892608643,
      "step": 6420
    },
    {
      "epoch": 0.3169798319120922,
      "grad_norm": 0.7952492237091064,
      "learning_rate": 4.4722550370807905e-05,
      "logits/chosen": 2.875145435333252,
      "logits/rejected": 2.990793228149414,
      "logps/chosen": -294.1397705078125,
      "logps/rejected": -305.0544738769531,
      "loss": 0.6778,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.2106986045837402,
      "rewards/margins": 2.3591954708099365,
      "rewards/rejected": -4.569893836975098,
      "step": 6440
    },
    {
      "epoch": 0.3179642413279683,
      "grad_norm": 7.43808126449585,
      "learning_rate": 4.470614294152393e-05,
      "logits/chosen": 2.6544768810272217,
      "logits/rejected": 2.932781219482422,
      "logps/chosen": -279.45928955078125,
      "logps/rejected": -304.06689453125,
      "loss": 0.5551,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.203964948654175,
      "rewards/margins": 2.2321107387542725,
      "rewards/rejected": -4.436075687408447,
      "step": 6460
    },
    {
      "epoch": 0.3189486507438444,
      "grad_norm": 7.685648441314697,
      "learning_rate": 4.4689735512239945e-05,
      "logits/chosen": 2.8323750495910645,
      "logits/rejected": 2.9252567291259766,
      "logps/chosen": -273.1502990722656,
      "logps/rejected": -261.19512939453125,
      "loss": 0.6939,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.9843190908432007,
      "rewards/margins": 1.6381012201309204,
      "rewards/rejected": -3.622420072555542,
      "step": 6480
    },
    {
      "epoch": 0.31993306015972045,
      "grad_norm": 3.7525434494018555,
      "learning_rate": 4.467332808295596e-05,
      "logits/chosen": 2.7962076663970947,
      "logits/rejected": 3.02065372467041,
      "logps/chosen": -265.1544189453125,
      "logps/rejected": -265.09222412109375,
      "loss": 0.4964,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5331552028656006,
      "rewards/margins": 1.964603066444397,
      "rewards/rejected": -3.497758388519287,
      "step": 6500
    },
    {
      "epoch": 0.32091746957559647,
      "grad_norm": 4.0199503898620605,
      "learning_rate": 4.4656920653671986e-05,
      "logits/chosen": 2.7487406730651855,
      "logits/rejected": 3.0974233150482178,
      "logps/chosen": -266.4001159667969,
      "logps/rejected": -260.13531494140625,
      "loss": 0.4299,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0200648307800293,
      "rewards/margins": 2.1878809928894043,
      "rewards/rejected": -4.207945823669434,
      "step": 6520
    },
    {
      "epoch": 0.32190187899147255,
      "grad_norm": 2.376396656036377,
      "learning_rate": 4.4640513224388e-05,
      "logits/chosen": 2.630777597427368,
      "logits/rejected": 2.9436378479003906,
      "logps/chosen": -255.3689727783203,
      "logps/rejected": -272.5231628417969,
      "loss": 0.5725,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.1525979042053223,
      "rewards/margins": 2.4101176261901855,
      "rewards/rejected": -4.56271505355835,
      "step": 6540
    },
    {
      "epoch": 0.3228862884073486,
      "grad_norm": 0.36446455121040344,
      "learning_rate": 4.4624105795104026e-05,
      "logits/chosen": 2.7371792793273926,
      "logits/rejected": 3.1477975845336914,
      "logps/chosen": -267.46649169921875,
      "logps/rejected": -251.5480499267578,
      "loss": 0.5504,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.8914995193481445,
      "rewards/margins": 2.1405014991760254,
      "rewards/rejected": -4.032000541687012,
      "step": 6560
    },
    {
      "epoch": 0.3238706978232247,
      "grad_norm": 1.298768162727356,
      "learning_rate": 4.460769836582004e-05,
      "logits/chosen": 2.8480536937713623,
      "logits/rejected": 3.110788106918335,
      "logps/chosen": -285.05926513671875,
      "logps/rejected": -295.50299072265625,
      "loss": 0.379,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7037503719329834,
      "rewards/margins": 2.367074728012085,
      "rewards/rejected": -4.070825099945068,
      "step": 6580
    },
    {
      "epoch": 0.3248551072391007,
      "grad_norm": 1.0623565912246704,
      "learning_rate": 4.4591290936536066e-05,
      "logits/chosen": 2.70204496383667,
      "logits/rejected": 3.038593292236328,
      "logps/chosen": -265.74322509765625,
      "logps/rejected": -275.90093994140625,
      "loss": 0.6309,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.6037769317626953,
      "rewards/margins": 1.9625990390777588,
      "rewards/rejected": -4.566375732421875,
      "step": 6600
    },
    {
      "epoch": 0.3258395166549768,
      "grad_norm": 1.3315335512161255,
      "learning_rate": 4.457488350725208e-05,
      "logits/chosen": 2.6250271797180176,
      "logits/rejected": 2.866650104522705,
      "logps/chosen": -277.9945983886719,
      "logps/rejected": -303.5171813964844,
      "loss": 0.4482,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.89481520652771,
      "rewards/margins": 2.66166090965271,
      "rewards/rejected": -4.55647611618042,
      "step": 6620
    },
    {
      "epoch": 0.32682392607085287,
      "grad_norm": 4.074191570281982,
      "learning_rate": 4.455847607796811e-05,
      "logits/chosen": 2.6982369422912598,
      "logits/rejected": 3.1529669761657715,
      "logps/chosen": -271.4862976074219,
      "logps/rejected": -270.8565368652344,
      "loss": 0.5347,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.0042431354522705,
      "rewards/margins": 1.7845255136489868,
      "rewards/rejected": -3.788769245147705,
      "step": 6640
    },
    {
      "epoch": 0.32780833548672894,
      "grad_norm": 1.3337990045547485,
      "learning_rate": 4.4542068648684124e-05,
      "logits/chosen": 2.8123767375946045,
      "logits/rejected": 3.014777898788452,
      "logps/chosen": -283.8089294433594,
      "logps/rejected": -292.6610107421875,
      "loss": 0.4228,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7789198160171509,
      "rewards/margins": 2.069056987762451,
      "rewards/rejected": -3.8479766845703125,
      "step": 6660
    },
    {
      "epoch": 0.328792744902605,
      "grad_norm": 0.40655717253685,
      "learning_rate": 4.452566121940015e-05,
      "logits/chosen": 2.6492743492126465,
      "logits/rejected": 3.030148983001709,
      "logps/chosen": -282.15997314453125,
      "logps/rejected": -282.30108642578125,
      "loss": 0.3657,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.8639147281646729,
      "rewards/margins": 2.6414413452148438,
      "rewards/rejected": -4.505356311798096,
      "step": 6680
    },
    {
      "epoch": 0.32977715431848104,
      "grad_norm": 1.1043075323104858,
      "learning_rate": 4.450925379011617e-05,
      "logits/chosen": 2.65641713142395,
      "logits/rejected": 2.784507989883423,
      "logps/chosen": -242.6179656982422,
      "logps/rejected": -252.72244262695312,
      "loss": 0.4095,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8745946884155273,
      "rewards/margins": 2.5169146060943604,
      "rewards/rejected": -4.391509056091309,
      "step": 6700
    },
    {
      "epoch": 0.3307615637343571,
      "grad_norm": 4.778198719024658,
      "learning_rate": 4.449284636083219e-05,
      "logits/chosen": 2.4453577995300293,
      "logits/rejected": 2.487672805786133,
      "logps/chosen": -254.7925262451172,
      "logps/rejected": -297.0152587890625,
      "loss": 0.6614,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.33958101272583,
      "rewards/margins": 2.1586689949035645,
      "rewards/rejected": -4.4982500076293945,
      "step": 6720
    },
    {
      "epoch": 0.3317459731502332,
      "grad_norm": 4.10339879989624,
      "learning_rate": 4.447643893154821e-05,
      "logits/chosen": 2.7125301361083984,
      "logits/rejected": 2.962939739227295,
      "logps/chosen": -253.05859375,
      "logps/rejected": -294.58929443359375,
      "loss": 0.538,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.106215238571167,
      "rewards/margins": 2.3149008750915527,
      "rewards/rejected": -4.421115875244141,
      "step": 6740
    },
    {
      "epoch": 0.33273038256610926,
      "grad_norm": 5.407823085784912,
      "learning_rate": 4.446003150226423e-05,
      "logits/chosen": 2.9383769035339355,
      "logits/rejected": 3.153292179107666,
      "logps/chosen": -255.78811645507812,
      "logps/rejected": -255.9033203125,
      "loss": 0.5055,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8157758712768555,
      "rewards/margins": 2.1546785831451416,
      "rewards/rejected": -3.970453977584839,
      "step": 6760
    },
    {
      "epoch": 0.3337147919819853,
      "grad_norm": 2.5723843574523926,
      "learning_rate": 4.444362407298025e-05,
      "logits/chosen": 2.852569580078125,
      "logits/rejected": 2.8700692653656006,
      "logps/chosen": -232.67691040039062,
      "logps/rejected": -255.0316619873047,
      "loss": 0.6522,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.1834776401519775,
      "rewards/margins": 1.8012416362762451,
      "rewards/rejected": -3.9847190380096436,
      "step": 6780
    },
    {
      "epoch": 0.33469920139786136,
      "grad_norm": 0.5167582631111145,
      "learning_rate": 4.442721664369627e-05,
      "logits/chosen": 2.7519209384918213,
      "logits/rejected": 3.0460386276245117,
      "logps/chosen": -277.64739990234375,
      "logps/rejected": -280.9656066894531,
      "loss": 0.6245,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8784143924713135,
      "rewards/margins": 1.6970651149749756,
      "rewards/rejected": -3.575479030609131,
      "step": 6800
    },
    {
      "epoch": 0.33568361081373743,
      "grad_norm": 7.066286563873291,
      "learning_rate": 4.4410809214412285e-05,
      "logits/chosen": 3.2184271812438965,
      "logits/rejected": 3.3003432750701904,
      "logps/chosen": -271.4791564941406,
      "logps/rejected": -291.6452331542969,
      "loss": 0.4959,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4304866790771484,
      "rewards/margins": 1.6590826511383057,
      "rewards/rejected": -3.089569330215454,
      "step": 6820
    },
    {
      "epoch": 0.3366680202296135,
      "grad_norm": 3.243960380554199,
      "learning_rate": 4.439440178512831e-05,
      "logits/chosen": 2.5715556144714355,
      "logits/rejected": 3.0269832611083984,
      "logps/chosen": -292.9185791015625,
      "logps/rejected": -275.4387512207031,
      "loss": 0.4124,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.094511866569519,
      "rewards/margins": 2.219829559326172,
      "rewards/rejected": -3.3143410682678223,
      "step": 6840
    },
    {
      "epoch": 0.3376524296454896,
      "grad_norm": 4.740694522857666,
      "learning_rate": 4.4377994355844326e-05,
      "logits/chosen": 2.615124225616455,
      "logits/rejected": 2.9987645149230957,
      "logps/chosen": -275.89678955078125,
      "logps/rejected": -279.34912109375,
      "loss": 0.5051,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8735477924346924,
      "rewards/margins": 1.9793037176132202,
      "rewards/rejected": -3.8528518676757812,
      "step": 6860
    },
    {
      "epoch": 0.3386368390613656,
      "grad_norm": 3.279529571533203,
      "learning_rate": 4.436158692656035e-05,
      "logits/chosen": 2.7842516899108887,
      "logits/rejected": 2.989255428314209,
      "logps/chosen": -251.3248291015625,
      "logps/rejected": -253.5217742919922,
      "loss": 0.4856,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5834805965423584,
      "rewards/margins": 2.0665266513824463,
      "rewards/rejected": -3.650007724761963,
      "step": 6880
    },
    {
      "epoch": 0.3396212484772417,
      "grad_norm": 2.477846384048462,
      "learning_rate": 4.4345179497276366e-05,
      "logits/chosen": 2.931100845336914,
      "logits/rejected": 3.1372671127319336,
      "logps/chosen": -267.68267822265625,
      "logps/rejected": -266.2176513671875,
      "loss": 0.4654,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.296260118484497,
      "rewards/margins": 1.76141357421875,
      "rewards/rejected": -3.057673931121826,
      "step": 6900
    },
    {
      "epoch": 0.34060565789311775,
      "grad_norm": 3.041628360748291,
      "learning_rate": 4.432877206799239e-05,
      "logits/chosen": 3.1077396869659424,
      "logits/rejected": 3.252847671508789,
      "logps/chosen": -278.0334167480469,
      "logps/rejected": -277.4228210449219,
      "loss": 0.573,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.8121684789657593,
      "rewards/margins": 1.5577986240386963,
      "rewards/rejected": -3.369966983795166,
      "step": 6920
    },
    {
      "epoch": 0.3415900673089938,
      "grad_norm": 1.253777027130127,
      "learning_rate": 4.431236463870841e-05,
      "logits/chosen": 2.740899085998535,
      "logits/rejected": 2.9860212802886963,
      "logps/chosen": -240.29470825195312,
      "logps/rejected": -255.45870971679688,
      "loss": 0.4843,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.610582709312439,
      "rewards/margins": 1.9365379810333252,
      "rewards/rejected": -3.5471205711364746,
      "step": 6940
    },
    {
      "epoch": 0.34257447672486985,
      "grad_norm": 6.3504743576049805,
      "learning_rate": 4.4295957209424424e-05,
      "logits/chosen": 3.0053603649139404,
      "logits/rejected": 3.0991368293762207,
      "logps/chosen": -259.66351318359375,
      "logps/rejected": -280.37353515625,
      "loss": 0.46,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7160303592681885,
      "rewards/margins": 1.8636925220489502,
      "rewards/rejected": -3.5797228813171387,
      "step": 6960
    },
    {
      "epoch": 0.3435588861407459,
      "grad_norm": 1.9829834699630737,
      "learning_rate": 4.427954978014045e-05,
      "logits/chosen": 2.6909093856811523,
      "logits/rejected": 2.758758544921875,
      "logps/chosen": -235.61575317382812,
      "logps/rejected": -248.1816864013672,
      "loss": 0.5363,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6188366413116455,
      "rewards/margins": 1.8165979385375977,
      "rewards/rejected": -3.435434341430664,
      "step": 6980
    },
    {
      "epoch": 0.344543295556622,
      "grad_norm": 1.573076844215393,
      "learning_rate": 4.426314235085647e-05,
      "logits/chosen": 2.3925423622131348,
      "logits/rejected": 2.8224685192108154,
      "logps/chosen": -283.8755187988281,
      "logps/rejected": -319.9624938964844,
      "loss": 0.4918,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.636357545852661,
      "rewards/margins": 2.7570297718048096,
      "rewards/rejected": -5.393387317657471,
      "step": 7000
    },
    {
      "epoch": 0.3455277049724981,
      "grad_norm": 2.0879900455474854,
      "learning_rate": 4.4246734921572494e-05,
      "logits/chosen": 2.60085391998291,
      "logits/rejected": 2.841473340988159,
      "logps/chosen": -261.6424865722656,
      "logps/rejected": -285.8551940917969,
      "loss": 0.3704,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8680570125579834,
      "rewards/margins": 2.727199077606201,
      "rewards/rejected": -4.5952558517456055,
      "step": 7020
    },
    {
      "epoch": 0.34651211438837415,
      "grad_norm": 2.699885606765747,
      "learning_rate": 4.423032749228851e-05,
      "logits/chosen": 2.7639245986938477,
      "logits/rejected": 3.0091753005981445,
      "logps/chosen": -285.77996826171875,
      "logps/rejected": -295.7724914550781,
      "loss": 0.5521,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.829664468765259,
      "rewards/margins": 2.281045436859131,
      "rewards/rejected": -5.110710144042969,
      "step": 7040
    },
    {
      "epoch": 0.34749652380425017,
      "grad_norm": 2.011746883392334,
      "learning_rate": 4.4213920063004535e-05,
      "logits/chosen": 2.944601535797119,
      "logits/rejected": 3.058234691619873,
      "logps/chosen": -277.5984191894531,
      "logps/rejected": -288.39434814453125,
      "loss": 0.3125,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.098949432373047,
      "rewards/margins": 2.86629581451416,
      "rewards/rejected": -4.965245246887207,
      "step": 7060
    },
    {
      "epoch": 0.34848093322012624,
      "grad_norm": 0.990038275718689,
      "learning_rate": 4.419751263372055e-05,
      "logits/chosen": 2.809288501739502,
      "logits/rejected": 2.83783221244812,
      "logps/chosen": -245.01904296875,
      "logps/rejected": -253.6934356689453,
      "loss": 0.7141,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.5186495780944824,
      "rewards/margins": 1.2157175540924072,
      "rewards/rejected": -3.7343673706054688,
      "step": 7080
    },
    {
      "epoch": 0.3494653426360023,
      "grad_norm": 4.425212860107422,
      "learning_rate": 4.4181105204436575e-05,
      "logits/chosen": 2.5841269493103027,
      "logits/rejected": 2.9599668979644775,
      "logps/chosen": -239.1602020263672,
      "logps/rejected": -263.51715087890625,
      "loss": 0.5314,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.080998182296753,
      "rewards/margins": 2.1515164375305176,
      "rewards/rejected": -4.232514381408691,
      "step": 7100
    },
    {
      "epoch": 0.3504497520518784,
      "grad_norm": 1.4528696537017822,
      "learning_rate": 4.416469777515259e-05,
      "logits/chosen": 2.3816590309143066,
      "logits/rejected": 2.5208497047424316,
      "logps/chosen": -239.44528198242188,
      "logps/rejected": -254.0281219482422,
      "loss": 0.5962,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.866981863975525,
      "rewards/margins": 2.002737045288086,
      "rewards/rejected": -3.8697190284729004,
      "step": 7120
    },
    {
      "epoch": 0.3514341614677544,
      "grad_norm": 2.4989981651306152,
      "learning_rate": 4.414829034586861e-05,
      "logits/chosen": 2.753361940383911,
      "logits/rejected": 2.7263851165771484,
      "logps/chosen": -269.03643798828125,
      "logps/rejected": -284.8096618652344,
      "loss": 0.6537,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.7342731952667236,
      "rewards/margins": 1.4734004735946655,
      "rewards/rejected": -3.2076735496520996,
      "step": 7140
    },
    {
      "epoch": 0.3524185708836305,
      "grad_norm": 2.519672155380249,
      "learning_rate": 4.413188291658463e-05,
      "logits/chosen": 2.5210657119750977,
      "logits/rejected": 2.8357510566711426,
      "logps/chosen": -239.86767578125,
      "logps/rejected": -243.93222045898438,
      "loss": 0.5183,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2892996072769165,
      "rewards/margins": 1.7008159160614014,
      "rewards/rejected": -2.990115165710449,
      "step": 7160
    },
    {
      "epoch": 0.35340298029950656,
      "grad_norm": 0.5702621936798096,
      "learning_rate": 4.411547548730065e-05,
      "logits/chosen": 2.6999897956848145,
      "logits/rejected": 2.9217207431793213,
      "logps/chosen": -265.072998046875,
      "logps/rejected": -271.007080078125,
      "loss": 0.393,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7348731756210327,
      "rewards/margins": 2.445835828781128,
      "rewards/rejected": -4.180708885192871,
      "step": 7180
    },
    {
      "epoch": 0.35438738971538264,
      "grad_norm": 0.9113279581069946,
      "learning_rate": 4.409906805801667e-05,
      "logits/chosen": 2.4914236068725586,
      "logits/rejected": 2.6094279289245605,
      "logps/chosen": -238.93350219726562,
      "logps/rejected": -291.1128845214844,
      "loss": 0.5348,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.2549062967300415,
      "rewards/margins": 2.553795337677002,
      "rewards/rejected": -3.808701753616333,
      "step": 7200
    },
    {
      "epoch": 0.3553717991312587,
      "grad_norm": 5.454126834869385,
      "learning_rate": 4.408266062873269e-05,
      "logits/chosen": 2.5820069313049316,
      "logits/rejected": 2.927469253540039,
      "logps/chosen": -274.07745361328125,
      "logps/rejected": -303.98504638671875,
      "loss": 0.4973,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8692957162857056,
      "rewards/margins": 2.6984665393829346,
      "rewards/rejected": -4.5677618980407715,
      "step": 7220
    },
    {
      "epoch": 0.35635620854713473,
      "grad_norm": 4.048349857330322,
      "learning_rate": 4.4066253199448714e-05,
      "logits/chosen": 2.6701416969299316,
      "logits/rejected": 2.9154133796691895,
      "logps/chosen": -264.1820068359375,
      "logps/rejected": -262.10809326171875,
      "loss": 0.6074,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.5861780643463135,
      "rewards/margins": 2.2109885215759277,
      "rewards/rejected": -3.797166109085083,
      "step": 7240
    },
    {
      "epoch": 0.3573406179630108,
      "grad_norm": 2.4997072219848633,
      "learning_rate": 4.404984577016473e-05,
      "logits/chosen": 2.8920726776123047,
      "logits/rejected": 2.9981637001037598,
      "logps/chosen": -238.8198699951172,
      "logps/rejected": -262.9375305175781,
      "loss": 0.4637,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7340856790542603,
      "rewards/margins": 2.2297282218933105,
      "rewards/rejected": -3.9638137817382812,
      "step": 7260
    },
    {
      "epoch": 0.3583250273788869,
      "grad_norm": 0.3806324303150177,
      "learning_rate": 4.403343834088075e-05,
      "logits/chosen": 2.59675931930542,
      "logits/rejected": 2.946930170059204,
      "logps/chosen": -256.76422119140625,
      "logps/rejected": -273.408203125,
      "loss": 0.4315,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8861322402954102,
      "rewards/margins": 2.2245192527770996,
      "rewards/rejected": -4.110651969909668,
      "step": 7280
    },
    {
      "epoch": 0.35930943679476296,
      "grad_norm": 1.2621748447418213,
      "learning_rate": 4.401703091159677e-05,
      "logits/chosen": 2.9210586547851562,
      "logits/rejected": 3.2021102905273438,
      "logps/chosen": -259.62188720703125,
      "logps/rejected": -272.4412841796875,
      "loss": 0.3932,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.101667881011963,
      "rewards/margins": 2.078770160675049,
      "rewards/rejected": -4.180438041687012,
      "step": 7300
    },
    {
      "epoch": 0.360293846210639,
      "grad_norm": 1.0875864028930664,
      "learning_rate": 4.4000623482312794e-05,
      "logits/chosen": 2.6796164512634277,
      "logits/rejected": 3.0127689838409424,
      "logps/chosen": -279.2728576660156,
      "logps/rejected": -279.62640380859375,
      "loss": 0.5054,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9468204975128174,
      "rewards/margins": 2.238659381866455,
      "rewards/rejected": -4.185480117797852,
      "step": 7320
    },
    {
      "epoch": 0.36127825562651505,
      "grad_norm": 5.770474910736084,
      "learning_rate": 4.398421605302882e-05,
      "logits/chosen": 2.68483304977417,
      "logits/rejected": 2.957515239715576,
      "logps/chosen": -273.82696533203125,
      "logps/rejected": -272.1775817871094,
      "loss": 0.6147,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9222233295440674,
      "rewards/margins": 1.9803903102874756,
      "rewards/rejected": -3.902613401412964,
      "step": 7340
    },
    {
      "epoch": 0.36226266504239113,
      "grad_norm": 1.6687288284301758,
      "learning_rate": 4.3967808623744835e-05,
      "logits/chosen": 2.8142001628875732,
      "logits/rejected": 2.9099926948547363,
      "logps/chosen": -260.59796142578125,
      "logps/rejected": -270.2603454589844,
      "loss": 0.3861,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4408791065216064,
      "rewards/margins": 2.219390392303467,
      "rewards/rejected": -3.6602694988250732,
      "step": 7360
    },
    {
      "epoch": 0.3632470744582672,
      "grad_norm": 1.1668243408203125,
      "learning_rate": 4.395140119446086e-05,
      "logits/chosen": 3.0562756061553955,
      "logits/rejected": 3.182091474533081,
      "logps/chosen": -267.5440368652344,
      "logps/rejected": -312.14154052734375,
      "loss": 0.4544,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.103893280029297,
      "rewards/margins": 2.802724838256836,
      "rewards/rejected": -4.906618118286133,
      "step": 7380
    },
    {
      "epoch": 0.3642314838741433,
      "grad_norm": 3.092134714126587,
      "learning_rate": 4.3934993765176875e-05,
      "logits/chosen": 3.0660221576690674,
      "logits/rejected": 3.3170535564422607,
      "logps/chosen": -263.2431335449219,
      "logps/rejected": -256.92218017578125,
      "loss": 0.476,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.3583462238311768,
      "rewards/margins": 2.151979684829712,
      "rewards/rejected": -4.510325908660889,
      "step": 7400
    },
    {
      "epoch": 0.3652158932900193,
      "grad_norm": 0.807424008846283,
      "learning_rate": 4.391858633589289e-05,
      "logits/chosen": 2.920760154724121,
      "logits/rejected": 2.989074230194092,
      "logps/chosen": -252.32217407226562,
      "logps/rejected": -280.16217041015625,
      "loss": 0.6502,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.317518711090088,
      "rewards/margins": 1.8740854263305664,
      "rewards/rejected": -4.191603660583496,
      "step": 7420
    },
    {
      "epoch": 0.3662003027058954,
      "grad_norm": 2.106663227081299,
      "learning_rate": 4.3902178906608916e-05,
      "logits/chosen": 2.755186080932617,
      "logits/rejected": 2.936166286468506,
      "logps/chosen": -240.0327606201172,
      "logps/rejected": -258.477783203125,
      "loss": 0.453,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.87490975856781,
      "rewards/margins": 2.267953395843506,
      "rewards/rejected": -4.1428632736206055,
      "step": 7440
    },
    {
      "epoch": 0.36718471212177145,
      "grad_norm": 1.4410158395767212,
      "learning_rate": 4.388577147732493e-05,
      "logits/chosen": 2.760016679763794,
      "logits/rejected": 3.1324949264526367,
      "logps/chosen": -266.75909423828125,
      "logps/rejected": -265.4830017089844,
      "loss": 0.3976,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.9978580474853516,
      "rewards/margins": 2.4234845638275146,
      "rewards/rejected": -4.421342849731445,
      "step": 7460
    },
    {
      "epoch": 0.3681691215376475,
      "grad_norm": 7.772514343261719,
      "learning_rate": 4.3869364048040956e-05,
      "logits/chosen": 2.7827260494232178,
      "logits/rejected": 3.0679283142089844,
      "logps/chosen": -280.644775390625,
      "logps/rejected": -296.90069580078125,
      "loss": 0.5099,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7674782276153564,
      "rewards/margins": 1.7509644031524658,
      "rewards/rejected": -3.518442153930664,
      "step": 7480
    },
    {
      "epoch": 0.36915353095352355,
      "grad_norm": 0.5951238870620728,
      "learning_rate": 4.385295661875697e-05,
      "logits/chosen": 2.887600898742676,
      "logits/rejected": 3.0823419094085693,
      "logps/chosen": -267.7447509765625,
      "logps/rejected": -282.490478515625,
      "loss": 0.4564,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.1561899185180664,
      "rewards/margins": 2.3979504108428955,
      "rewards/rejected": -4.554140090942383,
      "step": 7500
    },
    {
      "epoch": 0.3701379403693996,
      "grad_norm": 1.1355375051498413,
      "learning_rate": 4.3836549189473e-05,
      "logits/chosen": 2.935454845428467,
      "logits/rejected": 3.190671443939209,
      "logps/chosen": -267.52740478515625,
      "logps/rejected": -275.6647644042969,
      "loss": 0.336,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.925765037536621,
      "rewards/margins": 3.2887282371520996,
      "rewards/rejected": -5.214493751525879,
      "step": 7520
    },
    {
      "epoch": 0.3711223497852757,
      "grad_norm": 1.3519879579544067,
      "learning_rate": 4.3820141760189014e-05,
      "logits/chosen": 2.6670801639556885,
      "logits/rejected": 2.95082426071167,
      "logps/chosen": -265.0857849121094,
      "logps/rejected": -258.30877685546875,
      "loss": 0.6373,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.0605437755584717,
      "rewards/margins": 2.2123701572418213,
      "rewards/rejected": -4.272913932800293,
      "step": 7540
    },
    {
      "epoch": 0.37210675920115177,
      "grad_norm": 2.590859889984131,
      "learning_rate": 4.380373433090504e-05,
      "logits/chosen": 2.8449547290802,
      "logits/rejected": 3.2346649169921875,
      "logps/chosen": -254.8302764892578,
      "logps/rejected": -262.8879699707031,
      "loss": 0.4777,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.6515127420425415,
      "rewards/margins": 2.8228602409362793,
      "rewards/rejected": -4.474372863769531,
      "step": 7560
    },
    {
      "epoch": 0.37309116861702785,
      "grad_norm": 4.941651821136475,
      "learning_rate": 4.3787326901621054e-05,
      "logits/chosen": 3.1516504287719727,
      "logits/rejected": 3.2279582023620605,
      "logps/chosen": -251.0265350341797,
      "logps/rejected": -262.46307373046875,
      "loss": 0.5312,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.225832462310791,
      "rewards/margins": 2.1552743911743164,
      "rewards/rejected": -4.381106853485107,
      "step": 7580
    },
    {
      "epoch": 0.37407557803290387,
      "grad_norm": 0.17092005908489227,
      "learning_rate": 4.377091947233707e-05,
      "logits/chosen": 2.801300287246704,
      "logits/rejected": 3.097987413406372,
      "logps/chosen": -247.5294189453125,
      "logps/rejected": -276.47772216796875,
      "loss": 0.7624,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6028058528900146,
      "rewards/margins": 1.5439453125,
      "rewards/rejected": -3.1467509269714355,
      "step": 7600
    },
    {
      "epoch": 0.37505998744877994,
      "grad_norm": 2.919015407562256,
      "learning_rate": 4.3754512043053094e-05,
      "logits/chosen": 3.040708541870117,
      "logits/rejected": 2.987656354904175,
      "logps/chosen": -269.4347229003906,
      "logps/rejected": -281.90234375,
      "loss": 0.5978,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0325005054473877,
      "rewards/margins": 2.264488697052002,
      "rewards/rejected": -4.296988487243652,
      "step": 7620
    },
    {
      "epoch": 0.376044396864656,
      "grad_norm": 1.753340721130371,
      "learning_rate": 4.373810461376912e-05,
      "logits/chosen": 2.367008924484253,
      "logits/rejected": 2.6378040313720703,
      "logps/chosen": -246.7799835205078,
      "logps/rejected": -264.62298583984375,
      "loss": 0.5782,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7882039546966553,
      "rewards/margins": 2.1230626106262207,
      "rewards/rejected": -3.911266326904297,
      "step": 7640
    },
    {
      "epoch": 0.3770288062805321,
      "grad_norm": 2.663853168487549,
      "learning_rate": 4.372169718448514e-05,
      "logits/chosen": 3.0051398277282715,
      "logits/rejected": 3.2502124309539795,
      "logps/chosen": -258.3251037597656,
      "logps/rejected": -247.7973175048828,
      "loss": 0.566,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5597984790802002,
      "rewards/margins": 2.1350748538970947,
      "rewards/rejected": -3.694873332977295,
      "step": 7660
    },
    {
      "epoch": 0.3780132156964081,
      "grad_norm": 2.5983963012695312,
      "learning_rate": 4.370528975520116e-05,
      "logits/chosen": 2.6989331245422363,
      "logits/rejected": 2.9302122592926025,
      "logps/chosen": -231.75979614257812,
      "logps/rejected": -263.4096984863281,
      "loss": 0.591,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.5398328304290771,
      "rewards/margins": 1.5337637662887573,
      "rewards/rejected": -3.073596477508545,
      "step": 7680
    },
    {
      "epoch": 0.3789976251122842,
      "grad_norm": 1.0130808353424072,
      "learning_rate": 4.368888232591718e-05,
      "logits/chosen": 3.149237871170044,
      "logits/rejected": 3.3448143005371094,
      "logps/chosen": -261.51495361328125,
      "logps/rejected": -270.4013671875,
      "loss": 0.4501,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4767589569091797,
      "rewards/margins": 2.4310431480407715,
      "rewards/rejected": -3.907801866531372,
      "step": 7700
    },
    {
      "epoch": 0.37998203452816026,
      "grad_norm": 2.021233558654785,
      "learning_rate": 4.36724748966332e-05,
      "logits/chosen": 2.8345446586608887,
      "logits/rejected": 3.080801486968994,
      "logps/chosen": -267.691162109375,
      "logps/rejected": -255.9487762451172,
      "loss": 0.5426,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4352725744247437,
      "rewards/margins": 1.7141332626342773,
      "rewards/rejected": -3.1494057178497314,
      "step": 7720
    },
    {
      "epoch": 0.38096644394403634,
      "grad_norm": 1.4241715669631958,
      "learning_rate": 4.3656067467349216e-05,
      "logits/chosen": 2.917038679122925,
      "logits/rejected": 3.1454861164093018,
      "logps/chosen": -258.9171142578125,
      "logps/rejected": -285.52984619140625,
      "loss": 0.565,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.2797114849090576,
      "rewards/margins": 2.0286502838134766,
      "rewards/rejected": -3.308361768722534,
      "step": 7740
    },
    {
      "epoch": 0.3819508533599124,
      "grad_norm": 2.345186233520508,
      "learning_rate": 4.363966003806524e-05,
      "logits/chosen": 2.97465181350708,
      "logits/rejected": 3.2632784843444824,
      "logps/chosen": -249.2584686279297,
      "logps/rejected": -278.01068115234375,
      "loss": 0.3358,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.38852858543396,
      "rewards/margins": 2.520082473754883,
      "rewards/rejected": -3.9086108207702637,
      "step": 7760
    },
    {
      "epoch": 0.38293526277578843,
      "grad_norm": 2.9079346656799316,
      "learning_rate": 4.3623252608781256e-05,
      "logits/chosen": 2.8478221893310547,
      "logits/rejected": 3.0335521697998047,
      "logps/chosen": -269.32830810546875,
      "logps/rejected": -288.57208251953125,
      "loss": 0.4225,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3491194248199463,
      "rewards/margins": 2.45896577835083,
      "rewards/rejected": -3.8080856800079346,
      "step": 7780
    },
    {
      "epoch": 0.3839196721916645,
      "grad_norm": 4.6198625564575195,
      "learning_rate": 4.360684517949728e-05,
      "logits/chosen": 2.843919277191162,
      "logits/rejected": 3.1213431358337402,
      "logps/chosen": -244.8957977294922,
      "logps/rejected": -286.06805419921875,
      "loss": 0.4561,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5963798761367798,
      "rewards/margins": 2.6218533515930176,
      "rewards/rejected": -4.218233108520508,
      "step": 7800
    },
    {
      "epoch": 0.3849040816075406,
      "grad_norm": 4.285223960876465,
      "learning_rate": 4.35904377502133e-05,
      "logits/chosen": 2.8110008239746094,
      "logits/rejected": 3.0291852951049805,
      "logps/chosen": -224.18087768554688,
      "logps/rejected": -240.10842895507812,
      "loss": 0.6055,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.5218757390975952,
      "rewards/margins": 1.467892050743103,
      "rewards/rejected": -2.9897677898406982,
      "step": 7820
    },
    {
      "epoch": 0.38588849102341666,
      "grad_norm": 2.5492024421691895,
      "learning_rate": 4.357403032092932e-05,
      "logits/chosen": 2.7299861907958984,
      "logits/rejected": 3.125922679901123,
      "logps/chosen": -275.0205078125,
      "logps/rejected": -302.1222839355469,
      "loss": 0.5206,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.512697458267212,
      "rewards/margins": 2.6737449169158936,
      "rewards/rejected": -4.1864423751831055,
      "step": 7840
    },
    {
      "epoch": 0.3868729004392927,
      "grad_norm": 4.6212992668151855,
      "learning_rate": 4.355762289164534e-05,
      "logits/chosen": 2.8298871517181396,
      "logits/rejected": 2.8942630290985107,
      "logps/chosen": -267.60308837890625,
      "logps/rejected": -265.5650329589844,
      "loss": 0.6233,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6996078491210938,
      "rewards/margins": 2.1692185401916504,
      "rewards/rejected": -3.868826389312744,
      "step": 7860
    },
    {
      "epoch": 0.38785730985516875,
      "grad_norm": 1.5232869386672974,
      "learning_rate": 4.3541215462361354e-05,
      "logits/chosen": 2.68275785446167,
      "logits/rejected": 2.99178147315979,
      "logps/chosen": -278.4977722167969,
      "logps/rejected": -297.91668701171875,
      "loss": 0.5904,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9715923070907593,
      "rewards/margins": 2.2484803199768066,
      "rewards/rejected": -4.2200727462768555,
      "step": 7880
    },
    {
      "epoch": 0.38884171927104483,
      "grad_norm": 2.2809793949127197,
      "learning_rate": 4.352480803307738e-05,
      "logits/chosen": 2.7211499214172363,
      "logits/rejected": 2.9385275840759277,
      "logps/chosen": -266.7200927734375,
      "logps/rejected": -286.53497314453125,
      "loss": 0.5994,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.1432671546936035,
      "rewards/margins": 1.7774336338043213,
      "rewards/rejected": -3.920700788497925,
      "step": 7900
    },
    {
      "epoch": 0.3898261286869209,
      "grad_norm": 2.441835403442383,
      "learning_rate": 4.35084006037934e-05,
      "logits/chosen": 2.4548823833465576,
      "logits/rejected": 2.918942928314209,
      "logps/chosen": -283.364013671875,
      "logps/rejected": -306.8128967285156,
      "loss": 0.3932,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.002811908721924,
      "rewards/margins": 2.6456103324890137,
      "rewards/rejected": -4.648422718048096,
      "step": 7920
    },
    {
      "epoch": 0.390810538102797,
      "grad_norm": 2.6291720867156982,
      "learning_rate": 4.349199317450942e-05,
      "logits/chosen": 3.0240750312805176,
      "logits/rejected": 3.0654244422912598,
      "logps/chosen": -228.7930908203125,
      "logps/rejected": -269.5190734863281,
      "loss": 0.4779,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.533000111579895,
      "rewards/margins": 2.6137936115264893,
      "rewards/rejected": -4.146793842315674,
      "step": 7940
    },
    {
      "epoch": 0.391794947518673,
      "grad_norm": 2.5744388103485107,
      "learning_rate": 4.347558574522544e-05,
      "logits/chosen": 2.743701457977295,
      "logits/rejected": 2.9930601119995117,
      "logps/chosen": -266.24737548828125,
      "logps/rejected": -265.0289306640625,
      "loss": 0.4495,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9604368209838867,
      "rewards/margins": 2.2631962299346924,
      "rewards/rejected": -4.223633289337158,
      "step": 7960
    },
    {
      "epoch": 0.3927793569345491,
      "grad_norm": 0.7017626166343689,
      "learning_rate": 4.3459178315941465e-05,
      "logits/chosen": 2.6379504203796387,
      "logits/rejected": 2.9799437522888184,
      "logps/chosen": -284.6999816894531,
      "logps/rejected": -287.08917236328125,
      "loss": 0.3131,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7816095352172852,
      "rewards/margins": 2.6204657554626465,
      "rewards/rejected": -4.40207576751709,
      "step": 7980
    },
    {
      "epoch": 0.39376376635042515,
      "grad_norm": 4.125034332275391,
      "learning_rate": 4.344277088665748e-05,
      "logits/chosen": 2.6515140533447266,
      "logits/rejected": 2.914783477783203,
      "logps/chosen": -255.49911499023438,
      "logps/rejected": -250.8154754638672,
      "loss": 0.5829,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.0445635318756104,
      "rewards/margins": 2.121994972229004,
      "rewards/rejected": -4.166558265686035,
      "step": 8000
    },
    {
      "epoch": 0.3947481757663012,
      "grad_norm": 6.8514628410339355,
      "learning_rate": 4.3426363457373506e-05,
      "logits/chosen": 2.9435853958129883,
      "logits/rejected": 3.0754027366638184,
      "logps/chosen": -248.1304168701172,
      "logps/rejected": -251.64035034179688,
      "loss": 0.485,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4875212907791138,
      "rewards/margins": 2.2206413745880127,
      "rewards/rejected": -3.708162784576416,
      "step": 8020
    },
    {
      "epoch": 0.39573258518217724,
      "grad_norm": 3.899916410446167,
      "learning_rate": 4.340995602808952e-05,
      "logits/chosen": 3.0017476081848145,
      "logits/rejected": 3.237668991088867,
      "logps/chosen": -252.4458465576172,
      "logps/rejected": -267.1459655761719,
      "loss": 0.4662,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7904783487319946,
      "rewards/margins": 2.552215099334717,
      "rewards/rejected": -4.342693328857422,
      "step": 8040
    },
    {
      "epoch": 0.3967169945980533,
      "grad_norm": 4.657480716705322,
      "learning_rate": 4.339354859880554e-05,
      "logits/chosen": 2.965876579284668,
      "logits/rejected": 3.0752029418945312,
      "logps/chosen": -259.27081298828125,
      "logps/rejected": -248.4596405029297,
      "loss": 0.5502,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.9078121185302734,
      "rewards/margins": 2.1400222778320312,
      "rewards/rejected": -4.047834396362305,
      "step": 8060
    },
    {
      "epoch": 0.3977014040139294,
      "grad_norm": 1.4455894231796265,
      "learning_rate": 4.337714116952156e-05,
      "logits/chosen": 2.8524649143218994,
      "logits/rejected": 3.1424710750579834,
      "logps/chosen": -247.25765991210938,
      "logps/rejected": -238.56838989257812,
      "loss": 0.6049,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7531331777572632,
      "rewards/margins": 1.8729931116104126,
      "rewards/rejected": -3.626126527786255,
      "step": 8080
    },
    {
      "epoch": 0.39868581342980547,
      "grad_norm": 0.9508036375045776,
      "learning_rate": 4.336073374023758e-05,
      "logits/chosen": 2.532473087310791,
      "logits/rejected": 2.693845748901367,
      "logps/chosen": -232.62985229492188,
      "logps/rejected": -276.7513732910156,
      "loss": 0.4136,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.902235984802246,
      "rewards/margins": 2.8634581565856934,
      "rewards/rejected": -4.7656941413879395,
      "step": 8100
    },
    {
      "epoch": 0.39967022284568154,
      "grad_norm": 4.308849334716797,
      "learning_rate": 4.33443263109536e-05,
      "logits/chosen": 2.6368629932403564,
      "logits/rejected": 3.0171396732330322,
      "logps/chosen": -235.5747833251953,
      "logps/rejected": -280.87188720703125,
      "loss": 0.5533,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8088172674179077,
      "rewards/margins": 2.075737714767456,
      "rewards/rejected": -3.8845551013946533,
      "step": 8120
    },
    {
      "epoch": 0.40065463226155756,
      "grad_norm": 1.879665493965149,
      "learning_rate": 4.332791888166962e-05,
      "logits/chosen": 2.7652392387390137,
      "logits/rejected": 2.8604977130889893,
      "logps/chosen": -282.609375,
      "logps/rejected": -288.979736328125,
      "loss": 0.3417,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.632096529006958,
      "rewards/margins": 2.576688289642334,
      "rewards/rejected": -4.208784580230713,
      "step": 8140
    },
    {
      "epoch": 0.40163904167743364,
      "grad_norm": 1.3058124780654907,
      "learning_rate": 4.3311511452385644e-05,
      "logits/chosen": 2.448763847351074,
      "logits/rejected": 2.6543784141540527,
      "logps/chosen": -255.3648681640625,
      "logps/rejected": -269.6446838378906,
      "loss": 0.4112,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9110056161880493,
      "rewards/margins": 2.5160365104675293,
      "rewards/rejected": -4.427042007446289,
      "step": 8160
    },
    {
      "epoch": 0.4026234510933097,
      "grad_norm": 3.5250747203826904,
      "learning_rate": 4.329510402310166e-05,
      "logits/chosen": 2.538764715194702,
      "logits/rejected": 2.8137078285217285,
      "logps/chosen": -276.5500793457031,
      "logps/rejected": -284.24072265625,
      "loss": 0.5082,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.1478428840637207,
      "rewards/margins": 2.1537880897521973,
      "rewards/rejected": -4.301630973815918,
      "step": 8180
    },
    {
      "epoch": 0.4036078605091858,
      "grad_norm": 3.960930585861206,
      "learning_rate": 4.327869659381768e-05,
      "logits/chosen": 2.5191164016723633,
      "logits/rejected": 2.713263750076294,
      "logps/chosen": -256.5245666503906,
      "logps/rejected": -293.79486083984375,
      "loss": 0.3973,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6724897623062134,
      "rewards/margins": 2.1991946697235107,
      "rewards/rejected": -3.871685028076172,
      "step": 8200
    },
    {
      "epoch": 0.4045922699250618,
      "grad_norm": 3.430004835128784,
      "learning_rate": 4.32622891645337e-05,
      "logits/chosen": 2.7120938301086426,
      "logits/rejected": 3.0297515392303467,
      "logps/chosen": -282.7032165527344,
      "logps/rejected": -286.37518310546875,
      "loss": 0.4972,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.4741616249084473,
      "rewards/margins": 2.559394359588623,
      "rewards/rejected": -5.033555507659912,
      "step": 8220
    },
    {
      "epoch": 0.4055766793409379,
      "grad_norm": 1.7416425943374634,
      "learning_rate": 4.3245881735249725e-05,
      "logits/chosen": 2.792189598083496,
      "logits/rejected": 2.9897398948669434,
      "logps/chosen": -264.84783935546875,
      "logps/rejected": -313.4906005859375,
      "loss": 0.5034,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.5570876598358154,
      "rewards/margins": 2.804910182952881,
      "rewards/rejected": -5.361997604370117,
      "step": 8240
    },
    {
      "epoch": 0.40656108875681396,
      "grad_norm": 2.2403857707977295,
      "learning_rate": 4.322947430596574e-05,
      "logits/chosen": 2.598362445831299,
      "logits/rejected": 2.745723247528076,
      "logps/chosen": -257.7786865234375,
      "logps/rejected": -287.78729248046875,
      "loss": 0.4612,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.1477625370025635,
      "rewards/margins": 2.8231475353240967,
      "rewards/rejected": -4.97091007232666,
      "step": 8260
    },
    {
      "epoch": 0.40754549817269003,
      "grad_norm": 1.3173184394836426,
      "learning_rate": 4.3213066876681765e-05,
      "logits/chosen": 2.6534693241119385,
      "logits/rejected": 2.860987424850464,
      "logps/chosen": -259.5368957519531,
      "logps/rejected": -285.56890869140625,
      "loss": 0.5006,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9078264236450195,
      "rewards/margins": 2.426581621170044,
      "rewards/rejected": -4.334407806396484,
      "step": 8280
    },
    {
      "epoch": 0.4085299075885661,
      "grad_norm": 1.3221553564071655,
      "learning_rate": 4.319665944739779e-05,
      "logits/chosen": 2.7092859745025635,
      "logits/rejected": 2.9100916385650635,
      "logps/chosen": -273.88018798828125,
      "logps/rejected": -268.4090881347656,
      "loss": 0.6572,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.4790914058685303,
      "rewards/margins": 1.6546533107757568,
      "rewards/rejected": -4.133744239807129,
      "step": 8300
    },
    {
      "epoch": 0.40951431700444213,
      "grad_norm": 2.377056837081909,
      "learning_rate": 4.3180252018113806e-05,
      "logits/chosen": 2.889572858810425,
      "logits/rejected": 3.003819704055786,
      "logps/chosen": -231.7762451171875,
      "logps/rejected": -270.1121520996094,
      "loss": 0.5519,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.0765767097473145,
      "rewards/margins": 1.7483775615692139,
      "rewards/rejected": -3.8249542713165283,
      "step": 8320
    },
    {
      "epoch": 0.4104987264203182,
      "grad_norm": 1.5195258855819702,
      "learning_rate": 4.316384458882982e-05,
      "logits/chosen": 2.511174201965332,
      "logits/rejected": 2.7791926860809326,
      "logps/chosen": -267.83245849609375,
      "logps/rejected": -291.9610900878906,
      "loss": 0.6875,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.5844480991363525,
      "rewards/margins": 1.689352035522461,
      "rewards/rejected": -4.273799896240234,
      "step": 8340
    },
    {
      "epoch": 0.4114831358361943,
      "grad_norm": 0.7219486236572266,
      "learning_rate": 4.3147437159545846e-05,
      "logits/chosen": 2.6314735412597656,
      "logits/rejected": 2.913581132888794,
      "logps/chosen": -254.97201538085938,
      "logps/rejected": -296.50189208984375,
      "loss": 0.3944,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.697377920150757,
      "rewards/margins": 2.4153828620910645,
      "rewards/rejected": -5.1127610206604,
      "step": 8360
    },
    {
      "epoch": 0.41246754525207036,
      "grad_norm": 5.902717113494873,
      "learning_rate": 4.313102973026186e-05,
      "logits/chosen": 2.668867349624634,
      "logits/rejected": 2.8271384239196777,
      "logps/chosen": -271.5765686035156,
      "logps/rejected": -282.4339599609375,
      "loss": 0.3919,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.710732936859131,
      "rewards/margins": 2.546715021133423,
      "rewards/rejected": -5.257448196411133,
      "step": 8380
    },
    {
      "epoch": 0.4134519546679464,
      "grad_norm": 2.55597186088562,
      "learning_rate": 4.3114622300977887e-05,
      "logits/chosen": 2.438049077987671,
      "logits/rejected": 2.6689512729644775,
      "logps/chosen": -262.83648681640625,
      "logps/rejected": -295.9278564453125,
      "loss": 0.4152,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.7376599311828613,
      "rewards/margins": 2.8160839080810547,
      "rewards/rejected": -5.553743839263916,
      "step": 8400
    },
    {
      "epoch": 0.41443636408382245,
      "grad_norm": 1.511777400970459,
      "learning_rate": 4.30982148716939e-05,
      "logits/chosen": 2.5269129276275635,
      "logits/rejected": 2.6623477935791016,
      "logps/chosen": -252.58340454101562,
      "logps/rejected": -287.55596923828125,
      "loss": 0.4175,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.5181050300598145,
      "rewards/margins": 2.597628355026245,
      "rewards/rejected": -5.1157331466674805,
      "step": 8420
    },
    {
      "epoch": 0.4154207734996985,
      "grad_norm": 4.392457962036133,
      "learning_rate": 4.308180744240993e-05,
      "logits/chosen": 2.624011754989624,
      "logits/rejected": 2.6831295490264893,
      "logps/chosen": -267.8619384765625,
      "logps/rejected": -281.0054626464844,
      "loss": 0.4567,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.8085131645202637,
      "rewards/margins": 2.5161478519439697,
      "rewards/rejected": -5.3246612548828125,
      "step": 8440
    },
    {
      "epoch": 0.4164051829155746,
      "grad_norm": 1.223002552986145,
      "learning_rate": 4.3065400013125944e-05,
      "logits/chosen": 2.7854695320129395,
      "logits/rejected": 2.981919050216675,
      "logps/chosen": -288.0682678222656,
      "logps/rejected": -287.0045471191406,
      "loss": 0.5041,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.464071273803711,
      "rewards/margins": 2.5042872428894043,
      "rewards/rejected": -4.968358993530273,
      "step": 8460
    },
    {
      "epoch": 0.4173895923314507,
      "grad_norm": 7.525546550750732,
      "learning_rate": 4.304899258384197e-05,
      "logits/chosen": 2.5028536319732666,
      "logits/rejected": 2.7815284729003906,
      "logps/chosen": -256.74688720703125,
      "logps/rejected": -287.166015625,
      "loss": 0.5235,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -3.0898430347442627,
      "rewards/margins": 1.9041659832000732,
      "rewards/rejected": -4.994009017944336,
      "step": 8480
    },
    {
      "epoch": 0.4183740017473267,
      "grad_norm": 2.2149221897125244,
      "learning_rate": 4.3032585154557984e-05,
      "logits/chosen": 2.4457848072052,
      "logits/rejected": 2.7785675525665283,
      "logps/chosen": -280.08343505859375,
      "logps/rejected": -297.2209167480469,
      "loss": 0.6244,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -3.006459951400757,
      "rewards/margins": 2.186830520629883,
      "rewards/rejected": -5.193289756774902,
      "step": 8500
    },
    {
      "epoch": 0.41935841116320277,
      "grad_norm": 1.2633012533187866,
      "learning_rate": 4.3016177725274e-05,
      "logits/chosen": 2.7892820835113525,
      "logits/rejected": 3.0494072437286377,
      "logps/chosen": -271.04473876953125,
      "logps/rejected": -273.8157043457031,
      "loss": 0.582,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.5284576416015625,
      "rewards/margins": 2.1510558128356934,
      "rewards/rejected": -4.679513454437256,
      "step": 8520
    },
    {
      "epoch": 0.42034282057907885,
      "grad_norm": 1.0449368953704834,
      "learning_rate": 4.2999770295990025e-05,
      "logits/chosen": 2.873619318008423,
      "logits/rejected": 3.185323715209961,
      "logps/chosen": -260.8026123046875,
      "logps/rejected": -273.0561218261719,
      "loss": 0.3069,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.754787802696228,
      "rewards/margins": 3.1463847160339355,
      "rewards/rejected": -4.901172637939453,
      "step": 8540
    },
    {
      "epoch": 0.4213272299949549,
      "grad_norm": 4.75172233581543,
      "learning_rate": 4.298336286670605e-05,
      "logits/chosen": 2.962476968765259,
      "logits/rejected": 3.05509614944458,
      "logps/chosen": -256.9270935058594,
      "logps/rejected": -292.10272216796875,
      "loss": 0.5534,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.448516368865967,
      "rewards/margins": 2.1260745525360107,
      "rewards/rejected": -4.574590682983398,
      "step": 8560
    },
    {
      "epoch": 0.42231163941083094,
      "grad_norm": 3.084847927093506,
      "learning_rate": 4.2966955437422065e-05,
      "logits/chosen": 2.4112226963043213,
      "logits/rejected": 2.5241284370422363,
      "logps/chosen": -247.6161651611328,
      "logps/rejected": -286.72265625,
      "loss": 0.5332,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.4404287338256836,
      "rewards/margins": 2.421691417694092,
      "rewards/rejected": -4.862120151519775,
      "step": 8580
    },
    {
      "epoch": 0.423296048826707,
      "grad_norm": 3.028244733810425,
      "learning_rate": 4.295054800813809e-05,
      "logits/chosen": 2.593935489654541,
      "logits/rejected": 2.7522518634796143,
      "logps/chosen": -254.45693969726562,
      "logps/rejected": -274.16278076171875,
      "loss": 0.6554,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.5454764366149902,
      "rewards/margins": 1.132462501525879,
      "rewards/rejected": -3.677938938140869,
      "step": 8600
    },
    {
      "epoch": 0.4242804582425831,
      "grad_norm": 2.872694253921509,
      "learning_rate": 4.293414057885411e-05,
      "logits/chosen": 2.5431180000305176,
      "logits/rejected": 2.6999711990356445,
      "logps/chosen": -253.28305053710938,
      "logps/rejected": -297.20025634765625,
      "loss": 0.4534,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.450528621673584,
      "rewards/margins": 3.0059447288513184,
      "rewards/rejected": -5.456473350524902,
      "step": 8620
    },
    {
      "epoch": 0.42526486765845917,
      "grad_norm": 0.9202757477760315,
      "learning_rate": 4.291773314957013e-05,
      "logits/chosen": 2.5727498531341553,
      "logits/rejected": 2.8409974575042725,
      "logps/chosen": -284.52655029296875,
      "logps/rejected": -281.8761901855469,
      "loss": 0.5537,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.55683970451355,
      "rewards/margins": 2.5838305950164795,
      "rewards/rejected": -5.140669822692871,
      "step": 8640
    },
    {
      "epoch": 0.42624927707433524,
      "grad_norm": 11.45251750946045,
      "learning_rate": 4.2901325720286146e-05,
      "logits/chosen": 2.789689302444458,
      "logits/rejected": 3.083035945892334,
      "logps/chosen": -269.2749938964844,
      "logps/rejected": -269.99298095703125,
      "loss": 0.6512,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.424663543701172,
      "rewards/margins": 2.076341390609741,
      "rewards/rejected": -4.501004695892334,
      "step": 8660
    },
    {
      "epoch": 0.42723368649021126,
      "grad_norm": 3.6293838024139404,
      "learning_rate": 4.288491829100217e-05,
      "logits/chosen": 2.5273914337158203,
      "logits/rejected": 2.8427603244781494,
      "logps/chosen": -274.73541259765625,
      "logps/rejected": -286.68487548828125,
      "loss": 0.6191,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.1377110481262207,
      "rewards/margins": 2.648745059967041,
      "rewards/rejected": -4.786456108093262,
      "step": 8680
    },
    {
      "epoch": 0.42821809590608734,
      "grad_norm": 1.607992172241211,
      "learning_rate": 4.2868510861718186e-05,
      "logits/chosen": 2.976118564605713,
      "logits/rejected": 3.2514541149139404,
      "logps/chosen": -277.31787109375,
      "logps/rejected": -283.5945739746094,
      "loss": 0.5743,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2360482215881348,
      "rewards/margins": 2.024509906768799,
      "rewards/rejected": -4.260558128356934,
      "step": 8700
    },
    {
      "epoch": 0.4292025053219634,
      "grad_norm": 3.9720611572265625,
      "learning_rate": 4.285210343243421e-05,
      "logits/chosen": 2.8282876014709473,
      "logits/rejected": 2.828150987625122,
      "logps/chosen": -252.5951690673828,
      "logps/rejected": -254.7941131591797,
      "loss": 0.8114,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.342285633087158,
      "rewards/margins": 1.8924376964569092,
      "rewards/rejected": -4.234723091125488,
      "step": 8720
    },
    {
      "epoch": 0.4301869147378395,
      "grad_norm": 3.020658254623413,
      "learning_rate": 4.283569600315023e-05,
      "logits/chosen": 2.697828769683838,
      "logits/rejected": 2.8602137565612793,
      "logps/chosen": -277.77203369140625,
      "logps/rejected": -279.8143310546875,
      "loss": 0.6106,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.3268699645996094,
      "rewards/margins": 1.8575624227523804,
      "rewards/rejected": -4.184432029724121,
      "step": 8740
    },
    {
      "epoch": 0.4311713241537155,
      "grad_norm": 2.9000041484832764,
      "learning_rate": 4.281928857386625e-05,
      "logits/chosen": 2.821171760559082,
      "logits/rejected": 3.1038174629211426,
      "logps/chosen": -264.3285827636719,
      "logps/rejected": -300.03619384765625,
      "loss": 0.3554,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8883250951766968,
      "rewards/margins": 2.7317745685577393,
      "rewards/rejected": -4.620100021362305,
      "step": 8760
    },
    {
      "epoch": 0.4321557335695916,
      "grad_norm": 1.737545371055603,
      "learning_rate": 4.280288114458227e-05,
      "logits/chosen": 2.557981491088867,
      "logits/rejected": 2.610621213912964,
      "logps/chosen": -278.8607482910156,
      "logps/rejected": -301.8359680175781,
      "loss": 0.4906,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.0855906009674072,
      "rewards/margins": 2.2302138805389404,
      "rewards/rejected": -4.315804481506348,
      "step": 8780
    },
    {
      "epoch": 0.43314014298546766,
      "grad_norm": 4.560085296630859,
      "learning_rate": 4.2786473715298284e-05,
      "logits/chosen": 2.727739095687866,
      "logits/rejected": 3.0814671516418457,
      "logps/chosen": -265.93231201171875,
      "logps/rejected": -274.4959411621094,
      "loss": 0.3951,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6589291095733643,
      "rewards/margins": 2.2911736965179443,
      "rewards/rejected": -3.9501025676727295,
      "step": 8800
    },
    {
      "epoch": 0.43412455240134373,
      "grad_norm": 2.1568245887756348,
      "learning_rate": 4.277006628601431e-05,
      "logits/chosen": 2.6711316108703613,
      "logits/rejected": 2.999372959136963,
      "logps/chosen": -286.2334289550781,
      "logps/rejected": -305.37322998046875,
      "loss": 0.5216,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.3750829696655273,
      "rewards/margins": 2.3839709758758545,
      "rewards/rejected": -4.759053707122803,
      "step": 8820
    },
    {
      "epoch": 0.4351089618172198,
      "grad_norm": 0.5369257926940918,
      "learning_rate": 4.2753658856730325e-05,
      "logits/chosen": 2.946580410003662,
      "logits/rejected": 3.1607794761657715,
      "logps/chosen": -265.3640441894531,
      "logps/rejected": -259.05340576171875,
      "loss": 0.4322,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9445858001708984,
      "rewards/margins": 2.2280678749084473,
      "rewards/rejected": -4.172654151916504,
      "step": 8840
    },
    {
      "epoch": 0.43609337123309583,
      "grad_norm": 1.2732137441635132,
      "learning_rate": 4.273807179891055e-05,
      "logits/chosen": 2.5956099033355713,
      "logits/rejected": 2.7457127571105957,
      "logps/chosen": -269.6620178222656,
      "logps/rejected": -291.915283203125,
      "loss": 0.5438,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4569966793060303,
      "rewards/margins": 3.009934186935425,
      "rewards/rejected": -4.466930866241455,
      "step": 8860
    },
    {
      "epoch": 0.4370777806489719,
      "grad_norm": 8.766214370727539,
      "learning_rate": 4.272166436962657e-05,
      "logits/chosen": 2.7148334980010986,
      "logits/rejected": 2.9313673973083496,
      "logps/chosen": -266.5233154296875,
      "logps/rejected": -290.5625305175781,
      "loss": 0.4464,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5424597263336182,
      "rewards/margins": 2.852747678756714,
      "rewards/rejected": -4.39520788192749,
      "step": 8880
    },
    {
      "epoch": 0.438062190064848,
      "grad_norm": 0.5562940835952759,
      "learning_rate": 4.270525694034259e-05,
      "logits/chosen": 2.6793925762176514,
      "logits/rejected": 2.6956772804260254,
      "logps/chosen": -275.5362243652344,
      "logps/rejected": -272.10565185546875,
      "loss": 0.4382,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.17388916015625,
      "rewards/margins": 2.319999933242798,
      "rewards/rejected": -4.493889331817627,
      "step": 8900
    },
    {
      "epoch": 0.43904659948072405,
      "grad_norm": 1.4422545433044434,
      "learning_rate": 4.268884951105861e-05,
      "logits/chosen": 2.8907692432403564,
      "logits/rejected": 3.0852572917938232,
      "logps/chosen": -272.556640625,
      "logps/rejected": -279.7919006347656,
      "loss": 0.645,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.0364038944244385,
      "rewards/margins": 2.0733861923217773,
      "rewards/rejected": -4.109789848327637,
      "step": 8920
    },
    {
      "epoch": 0.4400310088966001,
      "grad_norm": 1.6896429061889648,
      "learning_rate": 4.267244208177463e-05,
      "logits/chosen": 2.814188241958618,
      "logits/rejected": 2.916316032409668,
      "logps/chosen": -269.54754638671875,
      "logps/rejected": -279.6426086425781,
      "loss": 0.4761,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.095214605331421,
      "rewards/margins": 2.1695666313171387,
      "rewards/rejected": -3.2647812366485596,
      "step": 8940
    },
    {
      "epoch": 0.44101541831247615,
      "grad_norm": 4.895583629608154,
      "learning_rate": 4.265603465249065e-05,
      "logits/chosen": 2.254234552383423,
      "logits/rejected": 2.4114303588867188,
      "logps/chosen": -249.605224609375,
      "logps/rejected": -270.5682067871094,
      "loss": 0.5047,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.582950234413147,
      "rewards/margins": 2.3410983085632324,
      "rewards/rejected": -3.924048662185669,
      "step": 8960
    },
    {
      "epoch": 0.4419998277283522,
      "grad_norm": 6.699903964996338,
      "learning_rate": 4.263962722320667e-05,
      "logits/chosen": 2.875337600708008,
      "logits/rejected": 3.0170321464538574,
      "logps/chosen": -274.8377990722656,
      "logps/rejected": -293.9153137207031,
      "loss": 0.5781,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0065035820007324,
      "rewards/margins": 2.200260639190674,
      "rewards/rejected": -4.2067646980285645,
      "step": 8980
    },
    {
      "epoch": 0.4429842371442283,
      "grad_norm": 1.9503788948059082,
      "learning_rate": 4.2623219793922695e-05,
      "logits/chosen": 2.3849031925201416,
      "logits/rejected": 2.780022144317627,
      "logps/chosen": -245.3660888671875,
      "logps/rejected": -262.4622497558594,
      "loss": 0.4395,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.351191997528076,
      "rewards/margins": 2.4727630615234375,
      "rewards/rejected": -4.8239545822143555,
      "step": 9000
    },
    {
      "epoch": 0.4439686465601044,
      "grad_norm": 4.860165596008301,
      "learning_rate": 4.260681236463871e-05,
      "logits/chosen": 2.5593209266662598,
      "logits/rejected": 2.7489726543426514,
      "logps/chosen": -265.44927978515625,
      "logps/rejected": -267.5726623535156,
      "loss": 0.4701,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.00353741645813,
      "rewards/margins": 2.599660634994507,
      "rewards/rejected": -4.6031975746154785,
      "step": 9020
    },
    {
      "epoch": 0.4449530559759804,
      "grad_norm": 3.8233866691589355,
      "learning_rate": 4.2590404935354735e-05,
      "logits/chosen": 2.5261361598968506,
      "logits/rejected": 2.836656093597412,
      "logps/chosen": -266.80755615234375,
      "logps/rejected": -285.455322265625,
      "loss": 0.5203,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.7314183712005615,
      "rewards/margins": 2.8499319553375244,
      "rewards/rejected": -5.581350803375244,
      "step": 9040
    },
    {
      "epoch": 0.44593746539185647,
      "grad_norm": 1.8008778095245361,
      "learning_rate": 4.257399750607075e-05,
      "logits/chosen": 2.6647298336029053,
      "logits/rejected": 2.89424467086792,
      "logps/chosen": -261.7373962402344,
      "logps/rejected": -281.5041809082031,
      "loss": 0.6141,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8272039890289307,
      "rewards/margins": 1.9215261936187744,
      "rewards/rejected": -3.748730182647705,
      "step": 9060
    },
    {
      "epoch": 0.44692187480773254,
      "grad_norm": 4.578163146972656,
      "learning_rate": 4.255759007678677e-05,
      "logits/chosen": 2.607837438583374,
      "logits/rejected": 2.8208847045898438,
      "logps/chosen": -262.02557373046875,
      "logps/rejected": -254.21054077148438,
      "loss": 0.4869,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9189773797988892,
      "rewards/margins": 2.0201592445373535,
      "rewards/rejected": -3.939136505126953,
      "step": 9080
    },
    {
      "epoch": 0.4479062842236086,
      "grad_norm": 8.379432678222656,
      "learning_rate": 4.254118264750279e-05,
      "logits/chosen": 2.800424337387085,
      "logits/rejected": 3.2836966514587402,
      "logps/chosen": -262.6653137207031,
      "logps/rejected": -272.009765625,
      "loss": 0.4687,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.1590728759765625,
      "rewards/margins": 2.7037501335144043,
      "rewards/rejected": -4.862823009490967,
      "step": 9100
    },
    {
      "epoch": 0.44889069363948464,
      "grad_norm": 1.9968457221984863,
      "learning_rate": 4.252477521821881e-05,
      "logits/chosen": 2.605586528778076,
      "logits/rejected": 2.9001235961914062,
      "logps/chosen": -273.32452392578125,
      "logps/rejected": -265.33489990234375,
      "loss": 0.5351,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.0517430305480957,
      "rewards/margins": 2.391592502593994,
      "rewards/rejected": -4.443336009979248,
      "step": 9120
    },
    {
      "epoch": 0.4498751030553607,
      "grad_norm": 3.256441116333008,
      "learning_rate": 4.250836778893483e-05,
      "logits/chosen": 2.8987040519714355,
      "logits/rejected": 3.1022751331329346,
      "logps/chosen": -263.2757873535156,
      "logps/rejected": -277.8409729003906,
      "loss": 0.5621,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.307532548904419,
      "rewards/margins": 2.5081050395965576,
      "rewards/rejected": -4.815638065338135,
      "step": 9140
    },
    {
      "epoch": 0.4508595124712368,
      "grad_norm": 0.56056809425354,
      "learning_rate": 4.249196035965085e-05,
      "logits/chosen": 2.342782497406006,
      "logits/rejected": 2.7036588191986084,
      "logps/chosen": -261.23468017578125,
      "logps/rejected": -297.3595886230469,
      "loss": 0.4254,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0362048149108887,
      "rewards/margins": 2.9259610176086426,
      "rewards/rejected": -4.962165832519531,
      "step": 9160
    },
    {
      "epoch": 0.45184392188711286,
      "grad_norm": 2.3788530826568604,
      "learning_rate": 4.247555293036687e-05,
      "logits/chosen": 2.807159900665283,
      "logits/rejected": 2.780754327774048,
      "logps/chosen": -254.7544708251953,
      "logps/rejected": -300.535888671875,
      "loss": 0.6497,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.107222557067871,
      "rewards/margins": 2.151958703994751,
      "rewards/rejected": -4.259181022644043,
      "step": 9180
    },
    {
      "epoch": 0.45282833130298894,
      "grad_norm": 2.358424425125122,
      "learning_rate": 4.245914550108289e-05,
      "logits/chosen": 2.4356236457824707,
      "logits/rejected": 2.621259927749634,
      "logps/chosen": -272.63043212890625,
      "logps/rejected": -281.9139709472656,
      "loss": 0.5315,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8120105266571045,
      "rewards/margins": 2.368375062942505,
      "rewards/rejected": -4.180385112762451,
      "step": 9200
    },
    {
      "epoch": 0.45381274071886496,
      "grad_norm": 0.7167635560035706,
      "learning_rate": 4.244273807179891e-05,
      "logits/chosen": 2.875394582748413,
      "logits/rejected": 3.087341785430908,
      "logps/chosen": -247.47659301757812,
      "logps/rejected": -250.093017578125,
      "loss": 0.6389,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5749890804290771,
      "rewards/margins": 1.935811996459961,
      "rewards/rejected": -3.510800838470459,
      "step": 9220
    },
    {
      "epoch": 0.45479715013474104,
      "grad_norm": 1.7007832527160645,
      "learning_rate": 4.242633064251493e-05,
      "logits/chosen": 2.8124101161956787,
      "logits/rejected": 2.7778289318084717,
      "logps/chosen": -257.56146240234375,
      "logps/rejected": -289.4492492675781,
      "loss": 0.4655,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6687761545181274,
      "rewards/margins": 2.147757053375244,
      "rewards/rejected": -3.816532850265503,
      "step": 9240
    },
    {
      "epoch": 0.4557815595506171,
      "grad_norm": 1.964820146560669,
      "learning_rate": 4.2409923213230954e-05,
      "logits/chosen": 2.8633179664611816,
      "logits/rejected": 3.2432987689971924,
      "logps/chosen": -244.25747680664062,
      "logps/rejected": -239.5396270751953,
      "loss": 0.4582,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5772018432617188,
      "rewards/margins": 2.382176637649536,
      "rewards/rejected": -3.9593780040740967,
      "step": 9260
    },
    {
      "epoch": 0.4567659689664932,
      "grad_norm": 2.3760619163513184,
      "learning_rate": 4.239351578394697e-05,
      "logits/chosen": 2.5176186561584473,
      "logits/rejected": 2.699028491973877,
      "logps/chosen": -269.26019287109375,
      "logps/rejected": -261.190673828125,
      "loss": 0.4133,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8406280279159546,
      "rewards/margins": 2.481969118118286,
      "rewards/rejected": -4.322596549987793,
      "step": 9280
    },
    {
      "epoch": 0.4577503783823692,
      "grad_norm": 1.1159886121749878,
      "learning_rate": 4.2377108354662995e-05,
      "logits/chosen": 2.775557279586792,
      "logits/rejected": 3.0656979084014893,
      "logps/chosen": -264.96307373046875,
      "logps/rejected": -274.5863952636719,
      "loss": 0.6243,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.235154867172241,
      "rewards/margins": 1.6718406677246094,
      "rewards/rejected": -3.9069952964782715,
      "step": 9300
    },
    {
      "epoch": 0.4587347877982453,
      "grad_norm": 0.62540203332901,
      "learning_rate": 4.236070092537902e-05,
      "logits/chosen": 2.6233127117156982,
      "logits/rejected": 2.9315805435180664,
      "logps/chosen": -262.2032165527344,
      "logps/rejected": -288.6009216308594,
      "loss": 0.4205,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7832491397857666,
      "rewards/margins": 2.8210930824279785,
      "rewards/rejected": -4.604341983795166,
      "step": 9320
    },
    {
      "epoch": 0.45971919721412136,
      "grad_norm": 1.38522469997406,
      "learning_rate": 4.2344293496095035e-05,
      "logits/chosen": 2.6940879821777344,
      "logits/rejected": 2.933899402618408,
      "logps/chosen": -275.2978210449219,
      "logps/rejected": -247.2162628173828,
      "loss": 0.6674,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.487940549850464,
      "rewards/margins": 1.1361712217330933,
      "rewards/rejected": -3.6241118907928467,
      "step": 9340
    },
    {
      "epoch": 0.46070360662999743,
      "grad_norm": 3.0153279304504395,
      "learning_rate": 4.232788606681106e-05,
      "logits/chosen": 2.299050807952881,
      "logits/rejected": 2.461205005645752,
      "logps/chosen": -258.7922058105469,
      "logps/rejected": -316.630126953125,
      "loss": 0.4702,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9866769313812256,
      "rewards/margins": 3.0432279109954834,
      "rewards/rejected": -5.029904842376709,
      "step": 9360
    },
    {
      "epoch": 0.4616880160458735,
      "grad_norm": 1.5010583400726318,
      "learning_rate": 4.2311478637527076e-05,
      "logits/chosen": 2.4980971813201904,
      "logits/rejected": 2.7292308807373047,
      "logps/chosen": -284.83038330078125,
      "logps/rejected": -290.44146728515625,
      "loss": 0.5197,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.0139880180358887,
      "rewards/margins": 1.925819754600525,
      "rewards/rejected": -3.939807891845703,
      "step": 9380
    },
    {
      "epoch": 0.4626724254617495,
      "grad_norm": 1.7591402530670166,
      "learning_rate": 4.229507120824309e-05,
      "logits/chosen": 2.6797142028808594,
      "logits/rejected": 2.9462499618530273,
      "logps/chosen": -225.960205078125,
      "logps/rejected": -259.07720947265625,
      "loss": 0.5644,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0689847469329834,
      "rewards/margins": 2.149566411972046,
      "rewards/rejected": -4.2185516357421875,
      "step": 9400
    },
    {
      "epoch": 0.4636568348776256,
      "grad_norm": 0.21843256056308746,
      "learning_rate": 4.2278663778959116e-05,
      "logits/chosen": 2.7531208992004395,
      "logits/rejected": 2.9433178901672363,
      "logps/chosen": -275.8055725097656,
      "logps/rejected": -279.23583984375,
      "loss": 0.4416,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.0041511058807373,
      "rewards/margins": 2.6036717891693115,
      "rewards/rejected": -4.607823371887207,
      "step": 9420
    },
    {
      "epoch": 0.4646412442935017,
      "grad_norm": 1.6173889636993408,
      "learning_rate": 4.226225634967513e-05,
      "logits/chosen": 2.8260366916656494,
      "logits/rejected": 3.117499828338623,
      "logps/chosen": -275.5247497558594,
      "logps/rejected": -275.9903564453125,
      "loss": 0.4309,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1718435287475586,
      "rewards/margins": 2.305286407470703,
      "rewards/rejected": -4.477129936218262,
      "step": 9440
    },
    {
      "epoch": 0.46562565370937775,
      "grad_norm": 0.846748411655426,
      "learning_rate": 4.2245848920391156e-05,
      "logits/chosen": 2.5775558948516846,
      "logits/rejected": 2.8857665061950684,
      "logps/chosen": -260.7857360839844,
      "logps/rejected": -276.0812683105469,
      "loss": 0.4598,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.358520269393921,
      "rewards/margins": 2.4921157360076904,
      "rewards/rejected": -3.8506362438201904,
      "step": 9460
    },
    {
      "epoch": 0.46661006312525377,
      "grad_norm": 1.384896993637085,
      "learning_rate": 4.222944149110717e-05,
      "logits/chosen": 2.6139426231384277,
      "logits/rejected": 2.861912965774536,
      "logps/chosen": -263.19244384765625,
      "logps/rejected": -265.81854248046875,
      "loss": 0.3987,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5437352657318115,
      "rewards/margins": 2.5476341247558594,
      "rewards/rejected": -4.09136962890625,
      "step": 9480
    },
    {
      "epoch": 0.46759447254112985,
      "grad_norm": 0.7766642570495605,
      "learning_rate": 4.22130340618232e-05,
      "logits/chosen": 2.383849620819092,
      "logits/rejected": 2.569014549255371,
      "logps/chosen": -274.7496032714844,
      "logps/rejected": -297.7185974121094,
      "loss": 0.4402,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2179856300354004,
      "rewards/margins": 2.3167452812194824,
      "rewards/rejected": -4.534731388092041,
      "step": 9500
    },
    {
      "epoch": 0.4685788819570059,
      "grad_norm": 4.52038049697876,
      "learning_rate": 4.2196626632539214e-05,
      "logits/chosen": 2.4271674156188965,
      "logits/rejected": 2.716662883758545,
      "logps/chosen": -267.35174560546875,
      "logps/rejected": -295.29364013671875,
      "loss": 0.4082,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.608151912689209,
      "rewards/margins": 2.6946918964385986,
      "rewards/rejected": -5.302844047546387,
      "step": 9520
    },
    {
      "epoch": 0.469563291372882,
      "grad_norm": 2.7160727977752686,
      "learning_rate": 4.218021920325523e-05,
      "logits/chosen": 2.138493776321411,
      "logits/rejected": 2.388507843017578,
      "logps/chosen": -235.28427124023438,
      "logps/rejected": -269.5101013183594,
      "loss": 0.4396,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.8072185516357422,
      "rewards/margins": 2.8456180095672607,
      "rewards/rejected": -4.652836322784424,
      "step": 9540
    },
    {
      "epoch": 0.47054770078875807,
      "grad_norm": 5.632421016693115,
      "learning_rate": 4.2163811773971254e-05,
      "logits/chosen": 2.8605682849884033,
      "logits/rejected": 3.039918899536133,
      "logps/chosen": -268.1609802246094,
      "logps/rejected": -266.7281494140625,
      "loss": 0.588,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.721736431121826,
      "rewards/margins": 2.6221203804016113,
      "rewards/rejected": -5.3438568115234375,
      "step": 9560
    },
    {
      "epoch": 0.4715321102046341,
      "grad_norm": 2.686537742614746,
      "learning_rate": 4.214740434468728e-05,
      "logits/chosen": 2.8060708045959473,
      "logits/rejected": 3.0801141262054443,
      "logps/chosen": -263.1944580078125,
      "logps/rejected": -255.7209014892578,
      "loss": 0.5424,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.3231863975524902,
      "rewards/margins": 2.132786273956299,
      "rewards/rejected": -4.455972671508789,
      "step": 9580
    },
    {
      "epoch": 0.47251651962051017,
      "grad_norm": 6.127219200134277,
      "learning_rate": 4.2130996915403295e-05,
      "logits/chosen": 2.7289376258850098,
      "logits/rejected": 3.0537707805633545,
      "logps/chosen": -285.6774597167969,
      "logps/rejected": -310.1622009277344,
      "loss": 0.469,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.002645492553711,
      "rewards/margins": 2.771141529083252,
      "rewards/rejected": -4.773787021636963,
      "step": 9600
    },
    {
      "epoch": 0.47350092903638624,
      "grad_norm": 0.30587348341941833,
      "learning_rate": 4.211458948611932e-05,
      "logits/chosen": 3.0435075759887695,
      "logits/rejected": 3.144728422164917,
      "logps/chosen": -246.74032592773438,
      "logps/rejected": -295.2457275390625,
      "loss": 0.5168,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.111395835876465,
      "rewards/margins": 2.1068570613861084,
      "rewards/rejected": -4.218253135681152,
      "step": 9620
    },
    {
      "epoch": 0.4744853384522623,
      "grad_norm": 4.9893012046813965,
      "learning_rate": 4.209818205683534e-05,
      "logits/chosen": 2.57177472114563,
      "logits/rejected": 2.8186962604522705,
      "logps/chosen": -267.0234680175781,
      "logps/rejected": -308.60028076171875,
      "loss": 0.4567,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7303903102874756,
      "rewards/margins": 2.4382951259613037,
      "rewards/rejected": -4.168685436248779,
      "step": 9640
    },
    {
      "epoch": 0.47546974786813834,
      "grad_norm": 2.0046632289886475,
      "learning_rate": 4.208177462755136e-05,
      "logits/chosen": 2.8895485401153564,
      "logits/rejected": 3.061039924621582,
      "logps/chosen": -258.81024169921875,
      "logps/rejected": -287.5414123535156,
      "loss": 0.4463,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.460803508758545,
      "rewards/margins": 2.9018843173980713,
      "rewards/rejected": -5.362688064575195,
      "step": 9660
    },
    {
      "epoch": 0.4764541572840144,
      "grad_norm": 1.472833275794983,
      "learning_rate": 4.2065367198267376e-05,
      "logits/chosen": 2.5743327140808105,
      "logits/rejected": 2.8861234188079834,
      "logps/chosen": -256.4364318847656,
      "logps/rejected": -282.3439636230469,
      "loss": 0.309,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2198538780212402,
      "rewards/margins": 3.3262436389923096,
      "rewards/rejected": -5.546097755432129,
      "step": 9680
    },
    {
      "epoch": 0.4774385666998905,
      "grad_norm": 3.692078113555908,
      "learning_rate": 4.20489597689834e-05,
      "logits/chosen": 2.56233286857605,
      "logits/rejected": 2.9594788551330566,
      "logps/chosen": -289.0985412597656,
      "logps/rejected": -281.12408447265625,
      "loss": 0.6594,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.8024322986602783,
      "rewards/margins": 2.3546206951141357,
      "rewards/rejected": -5.157052993774414,
      "step": 9700
    },
    {
      "epoch": 0.47842297611576656,
      "grad_norm": 4.732468605041504,
      "learning_rate": 4.2032552339699416e-05,
      "logits/chosen": 2.5839507579803467,
      "logits/rejected": 2.789073944091797,
      "logps/chosen": -256.8387451171875,
      "logps/rejected": -270.66595458984375,
      "loss": 0.5294,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.1893036365509033,
      "rewards/margins": 2.6206889152526855,
      "rewards/rejected": -4.80999231338501,
      "step": 9720
    },
    {
      "epoch": 0.4794073855316426,
      "grad_norm": 1.501609444618225,
      "learning_rate": 4.201614491041544e-05,
      "logits/chosen": 2.5939574241638184,
      "logits/rejected": 2.663872241973877,
      "logps/chosen": -286.8594665527344,
      "logps/rejected": -283.250732421875,
      "loss": 0.5489,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.8474864959716797,
      "rewards/margins": 2.0518429279327393,
      "rewards/rejected": -3.899329423904419,
      "step": 9740
    },
    {
      "epoch": 0.48039179494751866,
      "grad_norm": 1.7284876108169556,
      "learning_rate": 4.1999737481131456e-05,
      "logits/chosen": 2.4239487648010254,
      "logits/rejected": 2.785069465637207,
      "logps/chosen": -258.3748474121094,
      "logps/rejected": -286.63726806640625,
      "loss": 0.3412,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8682384490966797,
      "rewards/margins": 3.018277883529663,
      "rewards/rejected": -4.886516571044922,
      "step": 9760
    },
    {
      "epoch": 0.48137620436339473,
      "grad_norm": 11.609970092773438,
      "learning_rate": 4.198333005184748e-05,
      "logits/chosen": 2.875136375427246,
      "logits/rejected": 2.7425730228424072,
      "logps/chosen": -282.8055114746094,
      "logps/rejected": -292.1805725097656,
      "loss": 0.4415,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9208958148956299,
      "rewards/margins": 2.766530990600586,
      "rewards/rejected": -4.687426567077637,
      "step": 9780
    },
    {
      "epoch": 0.4823606137792708,
      "grad_norm": 1.4147175550460815,
      "learning_rate": 4.19669226225635e-05,
      "logits/chosen": 2.716292142868042,
      "logits/rejected": 2.7729015350341797,
      "logps/chosen": -254.81979370117188,
      "logps/rejected": -298.0594482421875,
      "loss": 0.5576,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8610109090805054,
      "rewards/margins": 2.5064499378204346,
      "rewards/rejected": -4.36746072769165,
      "step": 9800
    },
    {
      "epoch": 0.4833450231951469,
      "grad_norm": 5.7961201667785645,
      "learning_rate": 4.195051519327952e-05,
      "logits/chosen": 2.714722156524658,
      "logits/rejected": 2.9502177238464355,
      "logps/chosen": -273.1046447753906,
      "logps/rejected": -265.4563903808594,
      "loss": 0.4998,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.305798053741455,
      "rewards/margins": 2.2591519355773926,
      "rewards/rejected": -4.564949989318848,
      "step": 9820
    },
    {
      "epoch": 0.4843294326110229,
      "grad_norm": 5.421386241912842,
      "learning_rate": 4.193410776399554e-05,
      "logits/chosen": 2.639559268951416,
      "logits/rejected": 2.9414236545562744,
      "logps/chosen": -246.708251953125,
      "logps/rejected": -250.66293334960938,
      "loss": 0.4093,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9901832342147827,
      "rewards/margins": 2.428884983062744,
      "rewards/rejected": -4.419067859649658,
      "step": 9840
    },
    {
      "epoch": 0.485313842026899,
      "grad_norm": 1.1819738149642944,
      "learning_rate": 4.1917700334711554e-05,
      "logits/chosen": 2.739078998565674,
      "logits/rejected": 3.1076900959014893,
      "logps/chosen": -278.0373840332031,
      "logps/rejected": -276.5501403808594,
      "loss": 0.4559,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.038590908050537,
      "rewards/margins": 2.4483916759490967,
      "rewards/rejected": -4.486982822418213,
      "step": 9860
    },
    {
      "epoch": 0.48629825144277505,
      "grad_norm": 8.785249710083008,
      "learning_rate": 4.190129290542758e-05,
      "logits/chosen": 2.572474956512451,
      "logits/rejected": 2.934922695159912,
      "logps/chosen": -266.3714294433594,
      "logps/rejected": -304.13134765625,
      "loss": 0.3425,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8100664615631104,
      "rewards/margins": 3.48490571975708,
      "rewards/rejected": -5.2949724197387695,
      "step": 9880
    },
    {
      "epoch": 0.48728266085865113,
      "grad_norm": 0.6941534280776978,
      "learning_rate": 4.18848854761436e-05,
      "logits/chosen": 2.372650623321533,
      "logits/rejected": 2.7604401111602783,
      "logps/chosen": -320.18743896484375,
      "logps/rejected": -321.51898193359375,
      "loss": 0.4632,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.6471219062805176,
      "rewards/margins": 2.423668622970581,
      "rewards/rejected": -5.070790767669678,
      "step": 9900
    },
    {
      "epoch": 0.48826707027452715,
      "grad_norm": 5.773620128631592,
      "learning_rate": 4.186847804685962e-05,
      "logits/chosen": 2.6961312294006348,
      "logits/rejected": 2.827693462371826,
      "logps/chosen": -289.92022705078125,
      "logps/rejected": -271.79925537109375,
      "loss": 0.6723,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -3.051957845687866,
      "rewards/margins": 2.276257276535034,
      "rewards/rejected": -5.3282151222229,
      "step": 9920
    },
    {
      "epoch": 0.4892514796904032,
      "grad_norm": 3.0275840759277344,
      "learning_rate": 4.185207061757564e-05,
      "logits/chosen": 2.558727979660034,
      "logits/rejected": 2.7605700492858887,
      "logps/chosen": -253.07015991210938,
      "logps/rejected": -252.03125,
      "loss": 0.4891,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.227670907974243,
      "rewards/margins": 2.5857083797454834,
      "rewards/rejected": -4.813379287719727,
      "step": 9940
    },
    {
      "epoch": 0.4902358891062793,
      "grad_norm": 2.8119709491729736,
      "learning_rate": 4.1835663188291665e-05,
      "logits/chosen": 2.537987232208252,
      "logits/rejected": 2.7791106700897217,
      "logps/chosen": -280.32354736328125,
      "logps/rejected": -266.98504638671875,
      "loss": 0.5503,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.264855146408081,
      "rewards/margins": 2.73197865486145,
      "rewards/rejected": -4.996833801269531,
      "step": 9960
    },
    {
      "epoch": 0.4912202985221554,
      "grad_norm": 7.8867268562316895,
      "learning_rate": 4.181925575900768e-05,
      "logits/chosen": 2.7603564262390137,
      "logits/rejected": 3.0069339275360107,
      "logps/chosen": -262.5653991699219,
      "logps/rejected": -277.1330261230469,
      "loss": 0.4289,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.890531301498413,
      "rewards/margins": 2.766789197921753,
      "rewards/rejected": -4.657320976257324,
      "step": 9980
    },
    {
      "epoch": 0.49220470793803145,
      "grad_norm": 2.989910364151001,
      "learning_rate": 4.18028483297237e-05,
      "logits/chosen": 2.669870138168335,
      "logits/rejected": 2.805812358856201,
      "logps/chosen": -240.18026733398438,
      "logps/rejected": -319.5207214355469,
      "loss": 0.6619,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8974148035049438,
      "rewards/margins": 2.521052360534668,
      "rewards/rejected": -4.418467044830322,
      "step": 10000
    },
    {
      "epoch": 0.49220470793803145,
      "eval_logits/chosen": 3.2307000160217285,
      "eval_logits/rejected": 3.3689491748809814,
      "eval_logps/chosen": -390.4709777832031,
      "eval_logps/rejected": -352.98028564453125,
      "eval_loss": 0.6299328804016113,
      "eval_rewards/accuracies": 0.7491946816444397,
      "eval_rewards/chosen": -3.5889623165130615,
      "eval_rewards/margins": 2.0856523513793945,
      "eval_rewards/rejected": -5.674614429473877,
      "eval_runtime": 3533.3364,
      "eval_samples_per_second": 3.163,
      "eval_steps_per_second": 3.163,
      "step": 10000
    },
    {
      "epoch": 0.49318911735390747,
      "grad_norm": 1.2270575761795044,
      "learning_rate": 4.178644090043972e-05,
      "logits/chosen": 2.6240267753601074,
      "logits/rejected": 2.7924206256866455,
      "logps/chosen": -245.7616424560547,
      "logps/rejected": -264.0435791015625,
      "loss": 0.5358,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.7755250930786133,
      "rewards/margins": 2.121070384979248,
      "rewards/rejected": -3.8965961933135986,
      "step": 10020
    },
    {
      "epoch": 0.49417352676978354,
      "grad_norm": 4.2602434158325195,
      "learning_rate": 4.177003347115574e-05,
      "logits/chosen": 2.7323663234710693,
      "logits/rejected": 2.669203519821167,
      "logps/chosen": -260.2847900390625,
      "logps/rejected": -292.9620056152344,
      "loss": 0.4638,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9509642124176025,
      "rewards/margins": 2.664260149002075,
      "rewards/rejected": -4.6152238845825195,
      "step": 10040
    },
    {
      "epoch": 0.4951579361856596,
      "grad_norm": 1.6011278629302979,
      "learning_rate": 4.175362604187176e-05,
      "logits/chosen": 2.3611185550689697,
      "logits/rejected": 2.5586941242218018,
      "logps/chosen": -249.34005737304688,
      "logps/rejected": -257.8125,
      "loss": 0.3515,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.8873014450073242,
      "rewards/margins": 3.023559093475342,
      "rewards/rejected": -4.910860538482666,
      "step": 10060
    },
    {
      "epoch": 0.4961423456015357,
      "grad_norm": 2.9958295822143555,
      "learning_rate": 4.173721861258778e-05,
      "logits/chosen": 2.3725202083587646,
      "logits/rejected": 2.4363455772399902,
      "logps/chosen": -253.9608612060547,
      "logps/rejected": -271.01416015625,
      "loss": 0.5308,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.4235610961914062,
      "rewards/margins": 2.6027708053588867,
      "rewards/rejected": -5.026331901550293,
      "step": 10080
    },
    {
      "epoch": 0.4971267550174117,
      "grad_norm": 0.7678657174110413,
      "learning_rate": 4.1720811183303804e-05,
      "logits/chosen": 2.647662401199341,
      "logits/rejected": 2.878537178039551,
      "logps/chosen": -259.8066101074219,
      "logps/rejected": -292.35009765625,
      "loss": 0.5201,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -3.045987606048584,
      "rewards/margins": 2.6091058254241943,
      "rewards/rejected": -5.655093193054199,
      "step": 10100
    },
    {
      "epoch": 0.4981111644332878,
      "grad_norm": 2.034208059310913,
      "learning_rate": 4.170440375401982e-05,
      "logits/chosen": 2.0477046966552734,
      "logits/rejected": 2.3569302558898926,
      "logps/chosen": -240.93258666992188,
      "logps/rejected": -255.28945922851562,
      "loss": 0.5287,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9691135883331299,
      "rewards/margins": 2.529369831085205,
      "rewards/rejected": -4.498483180999756,
      "step": 10120
    },
    {
      "epoch": 0.49909557384916386,
      "grad_norm": 2.25409197807312,
      "learning_rate": 4.1687996324735844e-05,
      "logits/chosen": 2.528907299041748,
      "logits/rejected": 2.554405689239502,
      "logps/chosen": -236.8264617919922,
      "logps/rejected": -276.09332275390625,
      "loss": 0.3707,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.761659026145935,
      "rewards/margins": 2.817126750946045,
      "rewards/rejected": -4.5787858963012695,
      "step": 10140
    },
    {
      "epoch": 0.5000799832650399,
      "grad_norm": 0.14076237380504608,
      "learning_rate": 4.167158889545186e-05,
      "logits/chosen": 2.828916072845459,
      "logits/rejected": 3.0815203189849854,
      "logps/chosen": -274.80511474609375,
      "logps/rejected": -262.6591796875,
      "loss": 0.4468,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0957846641540527,
      "rewards/margins": 2.142322301864624,
      "rewards/rejected": -4.238106727600098,
      "step": 10160
    },
    {
      "epoch": 0.501064392680916,
      "grad_norm": 3.307957172393799,
      "learning_rate": 4.165518146616788e-05,
      "logits/chosen": 2.961974620819092,
      "logits/rejected": 3.0843758583068848,
      "logps/chosen": -274.63702392578125,
      "logps/rejected": -278.0751037597656,
      "loss": 0.5249,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5237476825714111,
      "rewards/margins": 2.772859573364258,
      "rewards/rejected": -4.29660701751709,
      "step": 10180
    },
    {
      "epoch": 0.502048802096792,
      "grad_norm": 2.184946298599243,
      "learning_rate": 4.16387740368839e-05,
      "logits/chosen": 2.7082295417785645,
      "logits/rejected": 2.971242666244507,
      "logps/chosen": -249.28219604492188,
      "logps/rejected": -252.25772094726562,
      "loss": 0.4566,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -0.9968135952949524,
      "rewards/margins": 2.105902910232544,
      "rewards/rejected": -3.1027169227600098,
      "step": 10200
    },
    {
      "epoch": 0.5030332115126681,
      "grad_norm": 0.16075924038887024,
      "learning_rate": 4.1622366607599925e-05,
      "logits/chosen": 2.455216646194458,
      "logits/rejected": 2.6948912143707275,
      "logps/chosen": -246.11502075195312,
      "logps/rejected": -263.585693359375,
      "loss": 0.4515,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6404311656951904,
      "rewards/margins": 1.9967777729034424,
      "rewards/rejected": -3.637209415435791,
      "step": 10220
    },
    {
      "epoch": 0.5040176209285442,
      "grad_norm": 7.907646656036377,
      "learning_rate": 4.160595917831595e-05,
      "logits/chosen": 2.6431949138641357,
      "logits/rejected": 2.9193122386932373,
      "logps/chosen": -274.57403564453125,
      "logps/rejected": -270.46429443359375,
      "loss": 0.6563,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.6011180877685547,
      "rewards/margins": 1.6375137567520142,
      "rewards/rejected": -3.2386314868927,
      "step": 10240
    },
    {
      "epoch": 0.5050020303444203,
      "grad_norm": 2.074242115020752,
      "learning_rate": 4.1589551749031965e-05,
      "logits/chosen": 2.500941038131714,
      "logits/rejected": 2.7406163215637207,
      "logps/chosen": -275.33001708984375,
      "logps/rejected": -280.02703857421875,
      "loss": 0.7161,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.2344772815704346,
      "rewards/margins": 1.7911508083343506,
      "rewards/rejected": -4.025628566741943,
      "step": 10260
    },
    {
      "epoch": 0.5059864397602963,
      "grad_norm": 0.9069291353225708,
      "learning_rate": 4.157314431974799e-05,
      "logits/chosen": 2.6709084510803223,
      "logits/rejected": 2.966693162918091,
      "logps/chosen": -290.1418762207031,
      "logps/rejected": -267.3299255371094,
      "loss": 0.3509,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3673079013824463,
      "rewards/margins": 2.6784212589263916,
      "rewards/rejected": -4.045729637145996,
      "step": 10280
    },
    {
      "epoch": 0.5069708491761724,
      "grad_norm": 1.304938793182373,
      "learning_rate": 4.1556736890464006e-05,
      "logits/chosen": 2.662322759628296,
      "logits/rejected": 3.071824789047241,
      "logps/chosen": -281.4659729003906,
      "logps/rejected": -284.8216247558594,
      "loss": 0.4602,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5947239398956299,
      "rewards/margins": 3.0511977672576904,
      "rewards/rejected": -4.6459221839904785,
      "step": 10300
    },
    {
      "epoch": 0.5079552585920485,
      "grad_norm": 1.4174669981002808,
      "learning_rate": 4.154032946118002e-05,
      "logits/chosen": 3.074324131011963,
      "logits/rejected": 3.1907315254211426,
      "logps/chosen": -250.0054168701172,
      "logps/rejected": -294.3397216796875,
      "loss": 0.6417,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.301551580429077,
      "rewards/margins": 1.8644506931304932,
      "rewards/rejected": -4.16600227355957,
      "step": 10320
    },
    {
      "epoch": 0.5089396680079245,
      "grad_norm": 5.673041343688965,
      "learning_rate": 4.1523922031896046e-05,
      "logits/chosen": 2.707643985748291,
      "logits/rejected": 2.846454620361328,
      "logps/chosen": -283.4462890625,
      "logps/rejected": -306.22296142578125,
      "loss": 0.5165,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.2846667766571045,
      "rewards/margins": 2.519139289855957,
      "rewards/rejected": -4.803806304931641,
      "step": 10340
    },
    {
      "epoch": 0.5099240774238005,
      "grad_norm": 0.512053906917572,
      "learning_rate": 4.150751460261206e-05,
      "logits/chosen": 2.8188271522521973,
      "logits/rejected": 2.8956081867218018,
      "logps/chosen": -279.79193115234375,
      "logps/rejected": -295.6383056640625,
      "loss": 0.4753,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.4863760471343994,
      "rewards/margins": 2.068223237991333,
      "rewards/rejected": -4.554598808288574,
      "step": 10360
    },
    {
      "epoch": 0.5109084868396766,
      "grad_norm": 2.382925033569336,
      "learning_rate": 4.149110717332809e-05,
      "logits/chosen": 2.6671032905578613,
      "logits/rejected": 2.925851821899414,
      "logps/chosen": -288.39202880859375,
      "logps/rejected": -281.11090087890625,
      "loss": 0.3684,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.87295663356781,
      "rewards/margins": 2.069242000579834,
      "rewards/rejected": -3.9421989917755127,
      "step": 10380
    },
    {
      "epoch": 0.5118928962555527,
      "grad_norm": 2.4668827056884766,
      "learning_rate": 4.1474699744044104e-05,
      "logits/chosen": 2.945265769958496,
      "logits/rejected": 3.144385814666748,
      "logps/chosen": -295.53948974609375,
      "logps/rejected": -304.48101806640625,
      "loss": 0.4426,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.763066291809082,
      "rewards/margins": 2.766303300857544,
      "rewards/rejected": -4.529369354248047,
      "step": 10400
    },
    {
      "epoch": 0.5128773056714288,
      "grad_norm": 4.660491466522217,
      "learning_rate": 4.145829231476013e-05,
      "logits/chosen": 2.5866641998291016,
      "logits/rejected": 2.6887450218200684,
      "logps/chosen": -261.252685546875,
      "logps/rejected": -264.1383972167969,
      "loss": 0.3075,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.635923147201538,
      "rewards/margins": 2.6438748836517334,
      "rewards/rejected": -4.2797980308532715,
      "step": 10420
    },
    {
      "epoch": 0.5138617150873048,
      "grad_norm": 3.6891987323760986,
      "learning_rate": 4.1441884885476144e-05,
      "logits/chosen": 2.766643762588501,
      "logits/rejected": 3.0443005561828613,
      "logps/chosen": -261.9582214355469,
      "logps/rejected": -258.99505615234375,
      "loss": 0.6798,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.2131707668304443,
      "rewards/margins": 2.630143880844116,
      "rewards/rejected": -4.843315124511719,
      "step": 10440
    },
    {
      "epoch": 0.5148461245031809,
      "grad_norm": 7.3927178382873535,
      "learning_rate": 4.142547745619216e-05,
      "logits/chosen": 2.6447415351867676,
      "logits/rejected": 2.70758056640625,
      "logps/chosen": -305.73834228515625,
      "logps/rejected": -342.8275451660156,
      "loss": 0.5905,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.348522901535034,
      "rewards/margins": 2.308678388595581,
      "rewards/rejected": -4.657201290130615,
      "step": 10460
    },
    {
      "epoch": 0.515830533919057,
      "grad_norm": 2.0915427207946777,
      "learning_rate": 4.1409070026908184e-05,
      "logits/chosen": 2.5604569911956787,
      "logits/rejected": 3.0267443656921387,
      "logps/chosen": -300.008544921875,
      "logps/rejected": -269.6700439453125,
      "loss": 0.3846,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.186613082885742,
      "rewards/margins": 2.7848362922668457,
      "rewards/rejected": -4.971449375152588,
      "step": 10480
    },
    {
      "epoch": 0.516814943334933,
      "grad_norm": 5.897282600402832,
      "learning_rate": 4.13926625976242e-05,
      "logits/chosen": 2.765427827835083,
      "logits/rejected": 2.910639524459839,
      "logps/chosen": -278.9759216308594,
      "logps/rejected": -289.42681884765625,
      "loss": 0.4962,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.862544298171997,
      "rewards/margins": 2.3432164192199707,
      "rewards/rejected": -4.205760478973389,
      "step": 10500
    },
    {
      "epoch": 0.517799352750809,
      "grad_norm": 6.507538795471191,
      "learning_rate": 4.1376255168340225e-05,
      "logits/chosen": 2.4646286964416504,
      "logits/rejected": 2.828610897064209,
      "logps/chosen": -237.3089141845703,
      "logps/rejected": -238.9277801513672,
      "loss": 0.4914,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.3435475826263428,
      "rewards/margins": 2.5387301445007324,
      "rewards/rejected": -4.882277488708496,
      "step": 10520
    },
    {
      "epoch": 0.5187837621666851,
      "grad_norm": 3.4511330127716064,
      "learning_rate": 4.135984773905625e-05,
      "logits/chosen": 2.6117641925811768,
      "logits/rejected": 2.759845018386841,
      "logps/chosen": -266.36724853515625,
      "logps/rejected": -286.38629150390625,
      "loss": 0.4933,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.3462438583374023,
      "rewards/margins": 2.4878392219543457,
      "rewards/rejected": -4.834083080291748,
      "step": 10540
    },
    {
      "epoch": 0.5197681715825612,
      "grad_norm": 1.4763548374176025,
      "learning_rate": 4.134344030977227e-05,
      "logits/chosen": 2.5619380474090576,
      "logits/rejected": 2.6381454467773438,
      "logps/chosen": -277.6824645996094,
      "logps/rejected": -268.45904541015625,
      "loss": 0.3185,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1684656143188477,
      "rewards/margins": 2.628185272216797,
      "rewards/rejected": -4.7966508865356445,
      "step": 10560
    },
    {
      "epoch": 0.5207525809984372,
      "grad_norm": 4.7337965965271,
      "learning_rate": 4.132703288048829e-05,
      "logits/chosen": 2.4501118659973145,
      "logits/rejected": 2.7010374069213867,
      "logps/chosen": -248.19100952148438,
      "logps/rejected": -284.88897705078125,
      "loss": 0.5469,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.498220443725586,
      "rewards/margins": 2.724687099456787,
      "rewards/rejected": -5.222907543182373,
      "step": 10580
    },
    {
      "epoch": 0.5217369904143133,
      "grad_norm": 2.1046910285949707,
      "learning_rate": 4.131062545120431e-05,
      "logits/chosen": 2.4554648399353027,
      "logits/rejected": 2.6047792434692383,
      "logps/chosen": -296.7896423339844,
      "logps/rejected": -319.0312194824219,
      "loss": 0.3238,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -2.5948195457458496,
      "rewards/margins": 2.789090633392334,
      "rewards/rejected": -5.383910179138184,
      "step": 10600
    },
    {
      "epoch": 0.5227213998301894,
      "grad_norm": 6.901193141937256,
      "learning_rate": 4.129421802192033e-05,
      "logits/chosen": 2.611863613128662,
      "logits/rejected": 2.9095523357391357,
      "logps/chosen": -279.1055603027344,
      "logps/rejected": -274.89898681640625,
      "loss": 0.6198,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.531528949737549,
      "rewards/margins": 2.3914852142333984,
      "rewards/rejected": -4.9230146408081055,
      "step": 10620
    },
    {
      "epoch": 0.5237058092460655,
      "grad_norm": 1.9284710884094238,
      "learning_rate": 4.1277810592636346e-05,
      "logits/chosen": 2.62251615524292,
      "logits/rejected": 2.9571914672851562,
      "logps/chosen": -265.0086975097656,
      "logps/rejected": -274.42425537109375,
      "loss": 0.4579,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.839317798614502,
      "rewards/margins": 2.7922682762145996,
      "rewards/rejected": -5.631585597991943,
      "step": 10640
    },
    {
      "epoch": 0.5246902186619415,
      "grad_norm": 0.7407469749450684,
      "learning_rate": 4.126140316335237e-05,
      "logits/chosen": 2.574974775314331,
      "logits/rejected": 3.037135362625122,
      "logps/chosen": -258.8783264160156,
      "logps/rejected": -253.5724639892578,
      "loss": 0.4687,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.896409034729004,
      "rewards/margins": 2.6551146507263184,
      "rewards/rejected": -5.551523685455322,
      "step": 10660
    },
    {
      "epoch": 0.5256746280778176,
      "grad_norm": 0.8391992449760437,
      "learning_rate": 4.124499573406839e-05,
      "logits/chosen": 2.916893482208252,
      "logits/rejected": 3.0776307582855225,
      "logps/chosen": -280.2530822753906,
      "logps/rejected": -289.69708251953125,
      "loss": 0.6134,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.719987154006958,
      "rewards/margins": 2.4912619590759277,
      "rewards/rejected": -5.211249351501465,
      "step": 10680
    },
    {
      "epoch": 0.5266590374936936,
      "grad_norm": 2.749664306640625,
      "learning_rate": 4.122858830478441e-05,
      "logits/chosen": 2.62591290473938,
      "logits/rejected": 2.9588747024536133,
      "logps/chosen": -269.056396484375,
      "logps/rejected": -276.533203125,
      "loss": 0.3421,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.37575101852417,
      "rewards/margins": 2.8724045753479004,
      "rewards/rejected": -5.24815559387207,
      "step": 10700
    },
    {
      "epoch": 0.5276434469095697,
      "grad_norm": 1.4268606901168823,
      "learning_rate": 4.121218087550043e-05,
      "logits/chosen": 2.3873484134674072,
      "logits/rejected": 2.809678554534912,
      "logps/chosen": -267.029052734375,
      "logps/rejected": -268.3454895019531,
      "loss": 0.4932,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.4513802528381348,
      "rewards/margins": 3.0735182762145996,
      "rewards/rejected": -5.524898529052734,
      "step": 10720
    },
    {
      "epoch": 0.5286278563254457,
      "grad_norm": 4.788084030151367,
      "learning_rate": 4.119577344621645e-05,
      "logits/chosen": 2.5182840824127197,
      "logits/rejected": 2.883422374725342,
      "logps/chosen": -275.626953125,
      "logps/rejected": -277.6941833496094,
      "loss": 0.6117,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.261220932006836,
      "rewards/margins": 2.4516806602478027,
      "rewards/rejected": -4.7129011154174805,
      "step": 10740
    },
    {
      "epoch": 0.5296122657413218,
      "grad_norm": 2.848585605621338,
      "learning_rate": 4.117936601693247e-05,
      "logits/chosen": 2.5696194171905518,
      "logits/rejected": 2.5880634784698486,
      "logps/chosen": -268.83685302734375,
      "logps/rejected": -273.03558349609375,
      "loss": 0.5161,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8969148397445679,
      "rewards/margins": 2.4154305458068848,
      "rewards/rejected": -4.312345027923584,
      "step": 10760
    },
    {
      "epoch": 0.5305966751571979,
      "grad_norm": 1.1957708597183228,
      "learning_rate": 4.1162958587648484e-05,
      "logits/chosen": 2.625068187713623,
      "logits/rejected": 2.8634417057037354,
      "logps/chosen": -309.41766357421875,
      "logps/rejected": -313.0762939453125,
      "loss": 0.4023,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8793652057647705,
      "rewards/margins": 3.248037815093994,
      "rewards/rejected": -5.127402305603027,
      "step": 10780
    },
    {
      "epoch": 0.531581084573074,
      "grad_norm": 2.587033987045288,
      "learning_rate": 4.114655115836451e-05,
      "logits/chosen": 2.564767360687256,
      "logits/rejected": 2.748929977416992,
      "logps/chosen": -260.9768371582031,
      "logps/rejected": -276.25311279296875,
      "loss": 0.5144,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.1963248252868652,
      "rewards/margins": 2.3906304836273193,
      "rewards/rejected": -4.5869550704956055,
      "step": 10800
    },
    {
      "epoch": 0.53256549398895,
      "grad_norm": 2.0523769855499268,
      "learning_rate": 4.1130143729080525e-05,
      "logits/chosen": 2.672731876373291,
      "logits/rejected": 2.8933143615722656,
      "logps/chosen": -253.36703491210938,
      "logps/rejected": -289.2445068359375,
      "loss": 0.5034,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8861172199249268,
      "rewards/margins": 2.381290912628174,
      "rewards/rejected": -4.26740837097168,
      "step": 10820
    },
    {
      "epoch": 0.5335499034048261,
      "grad_norm": 4.861220359802246,
      "learning_rate": 4.111373629979655e-05,
      "logits/chosen": 2.769948959350586,
      "logits/rejected": 2.8983123302459717,
      "logps/chosen": -304.4644470214844,
      "logps/rejected": -321.0390625,
      "loss": 0.5028,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.183350086212158,
      "rewards/margins": 1.8535712957382202,
      "rewards/rejected": -4.036921501159668,
      "step": 10840
    },
    {
      "epoch": 0.5345343128207022,
      "grad_norm": 2.510455369949341,
      "learning_rate": 4.109732887051257e-05,
      "logits/chosen": 2.6347603797912598,
      "logits/rejected": 2.983656644821167,
      "logps/chosen": -282.7123107910156,
      "logps/rejected": -296.33099365234375,
      "loss": 0.4292,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.055941581726074,
      "rewards/margins": 3.0534653663635254,
      "rewards/rejected": -5.109406471252441,
      "step": 10860
    },
    {
      "epoch": 0.5355187222365781,
      "grad_norm": 1.6211771965026855,
      "learning_rate": 4.1080921441228596e-05,
      "logits/chosen": 2.454763650894165,
      "logits/rejected": 2.858757972717285,
      "logps/chosen": -283.43499755859375,
      "logps/rejected": -265.5411071777344,
      "loss": 0.454,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.1809756755828857,
      "rewards/margins": 2.7345447540283203,
      "rewards/rejected": -4.915520668029785,
      "step": 10880
    },
    {
      "epoch": 0.5365031316524542,
      "grad_norm": 3.258518695831299,
      "learning_rate": 4.106451401194461e-05,
      "logits/chosen": 2.71639347076416,
      "logits/rejected": 3.1434340476989746,
      "logps/chosen": -277.54913330078125,
      "logps/rejected": -256.2738037109375,
      "loss": 0.4832,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.33171010017395,
      "rewards/margins": 2.103078842163086,
      "rewards/rejected": -4.434788703918457,
      "step": 10900
    },
    {
      "epoch": 0.5374875410683303,
      "grad_norm": 16.153207778930664,
      "learning_rate": 4.104810658266063e-05,
      "logits/chosen": 2.7280800342559814,
      "logits/rejected": 2.9063570499420166,
      "logps/chosen": -297.1661376953125,
      "logps/rejected": -302.1327819824219,
      "loss": 0.5175,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.15008282661438,
      "rewards/margins": 2.0018749237060547,
      "rewards/rejected": -4.1519575119018555,
      "step": 10920
    },
    {
      "epoch": 0.5384719504842064,
      "grad_norm": 1.8118315935134888,
      "learning_rate": 4.103169915337665e-05,
      "logits/chosen": 2.826869249343872,
      "logits/rejected": 3.012040615081787,
      "logps/chosen": -256.9591979980469,
      "logps/rejected": -291.2994689941406,
      "loss": 0.5297,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6987190246582031,
      "rewards/margins": 1.8511356115341187,
      "rewards/rejected": -3.5498547554016113,
      "step": 10940
    },
    {
      "epoch": 0.5394563599000824,
      "grad_norm": 0.8483715057373047,
      "learning_rate": 4.101529172409267e-05,
      "logits/chosen": 2.5182089805603027,
      "logits/rejected": 2.728991746902466,
      "logps/chosen": -255.57461547851562,
      "logps/rejected": -280.4023132324219,
      "loss": 0.5095,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0326499938964844,
      "rewards/margins": 2.045819044113159,
      "rewards/rejected": -4.078469276428223,
      "step": 10960
    },
    {
      "epoch": 0.5404407693159585,
      "grad_norm": 4.718937873840332,
      "learning_rate": 4.0998884294808693e-05,
      "logits/chosen": 2.754314422607422,
      "logits/rejected": 2.9398951530456543,
      "logps/chosen": -282.0653076171875,
      "logps/rejected": -276.74896240234375,
      "loss": 0.6498,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.5482475757598877,
      "rewards/margins": 2.121307373046875,
      "rewards/rejected": -4.669554710388184,
      "step": 10980
    },
    {
      "epoch": 0.5414251787318346,
      "grad_norm": 4.962639331817627,
      "learning_rate": 4.098247686552471e-05,
      "logits/chosen": 2.4870986938476562,
      "logits/rejected": 2.6957714557647705,
      "logps/chosen": -264.5473327636719,
      "logps/rejected": -296.54461669921875,
      "loss": 0.5989,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.395106792449951,
      "rewards/margins": 2.9246506690979004,
      "rewards/rejected": -5.31975793838501,
      "step": 11000
    },
    {
      "epoch": 0.5424095881477107,
      "grad_norm": 6.965230464935303,
      "learning_rate": 4.0966069436240734e-05,
      "logits/chosen": 2.546543598175049,
      "logits/rejected": 2.8328635692596436,
      "logps/chosen": -264.3038635253906,
      "logps/rejected": -276.7660217285156,
      "loss": 0.5162,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.1892597675323486,
      "rewards/margins": 2.169248342514038,
      "rewards/rejected": -4.358508110046387,
      "step": 11020
    },
    {
      "epoch": 0.5433939975635868,
      "grad_norm": 2.1812305450439453,
      "learning_rate": 4.094966200695675e-05,
      "logits/chosen": 2.730503797531128,
      "logits/rejected": 2.7931900024414062,
      "logps/chosen": -274.45074462890625,
      "logps/rejected": -277.50494384765625,
      "loss": 0.5567,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.86038076877594,
      "rewards/margins": 2.431948184967041,
      "rewards/rejected": -4.292328834533691,
      "step": 11040
    },
    {
      "epoch": 0.5443784069794627,
      "grad_norm": 0.6929173469543457,
      "learning_rate": 4.0933254577672774e-05,
      "logits/chosen": 2.5567049980163574,
      "logits/rejected": 2.922544002532959,
      "logps/chosen": -244.2121124267578,
      "logps/rejected": -256.9120788574219,
      "loss": 0.3641,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.742046594619751,
      "rewards/margins": 2.7083899974823,
      "rewards/rejected": -4.450436592102051,
      "step": 11060
    },
    {
      "epoch": 0.5453628163953388,
      "grad_norm": 0.7457565665245056,
      "learning_rate": 4.091684714838879e-05,
      "logits/chosen": 2.7112746238708496,
      "logits/rejected": 2.997755765914917,
      "logps/chosen": -280.528076171875,
      "logps/rejected": -279.5741882324219,
      "loss": 0.4844,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7545044422149658,
      "rewards/margins": 2.775679111480713,
      "rewards/rejected": -4.5301833152771,
      "step": 11080
    },
    {
      "epoch": 0.5463472258112149,
      "grad_norm": 6.269650936126709,
      "learning_rate": 4.090043971910481e-05,
      "logits/chosen": 2.4671683311462402,
      "logits/rejected": 2.7229533195495605,
      "logps/chosen": -279.44110107421875,
      "logps/rejected": -312.9090270996094,
      "loss": 0.4452,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9250364303588867,
      "rewards/margins": 2.3070318698883057,
      "rewards/rejected": -4.232068061828613,
      "step": 11100
    },
    {
      "epoch": 0.5473316352270909,
      "grad_norm": 3.0607688426971436,
      "learning_rate": 4.088403228982083e-05,
      "logits/chosen": 2.4808287620544434,
      "logits/rejected": 2.817948579788208,
      "logps/chosen": -244.3114013671875,
      "logps/rejected": -246.63827514648438,
      "loss": 0.4249,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6938221454620361,
      "rewards/margins": 2.5783708095550537,
      "rewards/rejected": -4.27219295501709,
      "step": 11120
    },
    {
      "epoch": 0.548316044642967,
      "grad_norm": 1.4845397472381592,
      "learning_rate": 4.086762486053685e-05,
      "logits/chosen": 2.590592861175537,
      "logits/rejected": 2.6758739948272705,
      "logps/chosen": -251.7832489013672,
      "logps/rejected": -247.92361450195312,
      "loss": 0.6117,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.2107815742492676,
      "rewards/margins": 1.8848426342010498,
      "rewards/rejected": -4.095623970031738,
      "step": 11140
    },
    {
      "epoch": 0.5493004540588431,
      "grad_norm": 1.377408504486084,
      "learning_rate": 4.085121743125287e-05,
      "logits/chosen": 2.5062947273254395,
      "logits/rejected": 2.707402229309082,
      "logps/chosen": -269.9819641113281,
      "logps/rejected": -263.9557800292969,
      "loss": 0.5812,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.3812267780303955,
      "rewards/margins": 1.8310019969940186,
      "rewards/rejected": -4.212229251861572,
      "step": 11160
    },
    {
      "epoch": 0.5502848634747192,
      "grad_norm": 4.569374084472656,
      "learning_rate": 4.0834810001968896e-05,
      "logits/chosen": 2.4977240562438965,
      "logits/rejected": 2.698068380355835,
      "logps/chosen": -255.52352905273438,
      "logps/rejected": -259.75201416015625,
      "loss": 0.4772,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8309335708618164,
      "rewards/margins": 2.5968666076660156,
      "rewards/rejected": -4.42780065536499,
      "step": 11180
    },
    {
      "epoch": 0.5512692728905952,
      "grad_norm": 2.4469287395477295,
      "learning_rate": 4.081840257268492e-05,
      "logits/chosen": 2.928514242172241,
      "logits/rejected": 3.127750873565674,
      "logps/chosen": -271.7622375488281,
      "logps/rejected": -303.6407775878906,
      "loss": 0.3946,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.150373935699463,
      "rewards/margins": 2.392798900604248,
      "rewards/rejected": -4.543173313140869,
      "step": 11200
    },
    {
      "epoch": 0.5522536823064713,
      "grad_norm": 1.7086901664733887,
      "learning_rate": 4.0801995143400936e-05,
      "logits/chosen": 2.5771751403808594,
      "logits/rejected": 2.7734267711639404,
      "logps/chosen": -247.3899383544922,
      "logps/rejected": -277.2937927246094,
      "loss": 0.4708,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.9653186798095703,
      "rewards/margins": 2.125836133956909,
      "rewards/rejected": -4.091155052185059,
      "step": 11220
    },
    {
      "epoch": 0.5532380917223473,
      "grad_norm": 3.281750440597534,
      "learning_rate": 4.078558771411695e-05,
      "logits/chosen": 2.7346973419189453,
      "logits/rejected": 2.855327606201172,
      "logps/chosen": -289.7152404785156,
      "logps/rejected": -300.0352783203125,
      "loss": 0.5849,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.709317684173584,
      "rewards/margins": 2.6293015480041504,
      "rewards/rejected": -5.338619232177734,
      "step": 11240
    },
    {
      "epoch": 0.5542225011382234,
      "grad_norm": 4.136171340942383,
      "learning_rate": 4.0769180284832977e-05,
      "logits/chosen": 2.594780445098877,
      "logits/rejected": 2.8420791625976562,
      "logps/chosen": -282.14691162109375,
      "logps/rejected": -283.76556396484375,
      "loss": 0.585,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.14599609375,
      "rewards/margins": 2.0003175735473633,
      "rewards/rejected": -4.1463141441345215,
      "step": 11260
    },
    {
      "epoch": 0.5552069105540994,
      "grad_norm": 3.6554319858551025,
      "learning_rate": 4.0752772855548993e-05,
      "logits/chosen": 2.5543665885925293,
      "logits/rejected": 2.80426025390625,
      "logps/chosen": -243.29995727539062,
      "logps/rejected": -279.67303466796875,
      "loss": 0.4843,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.399994134902954,
      "rewards/margins": 2.385667562484741,
      "rewards/rejected": -4.7856621742248535,
      "step": 11280
    },
    {
      "epoch": 0.5561913199699755,
      "grad_norm": 0.7913575172424316,
      "learning_rate": 4.073636542626502e-05,
      "logits/chosen": 2.5710062980651855,
      "logits/rejected": 2.9328835010528564,
      "logps/chosen": -263.757568359375,
      "logps/rejected": -270.890869140625,
      "loss": 0.4425,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.1997804641723633,
      "rewards/margins": 2.1970322132110596,
      "rewards/rejected": -4.396812438964844,
      "step": 11300
    },
    {
      "epoch": 0.5571757293858516,
      "grad_norm": 3.3212502002716064,
      "learning_rate": 4.0719957996981034e-05,
      "logits/chosen": 2.2398016452789307,
      "logits/rejected": 2.5158581733703613,
      "logps/chosen": -243.8412322998047,
      "logps/rejected": -244.08609008789062,
      "loss": 0.5563,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.7360856533050537,
      "rewards/margins": 1.9148792028427124,
      "rewards/rejected": -4.650965213775635,
      "step": 11320
    },
    {
      "epoch": 0.5581601388017277,
      "grad_norm": 2.9706103801727295,
      "learning_rate": 4.070355056769706e-05,
      "logits/chosen": 2.651679039001465,
      "logits/rejected": 2.806960105895996,
      "logps/chosen": -297.4730529785156,
      "logps/rejected": -296.73626708984375,
      "loss": 0.6902,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.7193031311035156,
      "rewards/margins": 1.8601070642471313,
      "rewards/rejected": -4.579410076141357,
      "step": 11340
    },
    {
      "epoch": 0.5591445482176037,
      "grad_norm": 0.11120012402534485,
      "learning_rate": 4.0687143138413074e-05,
      "logits/chosen": 2.613229274749756,
      "logits/rejected": 2.928053379058838,
      "logps/chosen": -284.4711608886719,
      "logps/rejected": -287.9352111816406,
      "loss": 0.3388,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.3261172771453857,
      "rewards/margins": 2.6143040657043457,
      "rewards/rejected": -4.940421104431152,
      "step": 11360
    },
    {
      "epoch": 0.5601289576334798,
      "grad_norm": 1.5006965398788452,
      "learning_rate": 4.067073570912909e-05,
      "logits/chosen": 2.2715039253234863,
      "logits/rejected": 2.515760898590088,
      "logps/chosen": -267.61090087890625,
      "logps/rejected": -267.7957458496094,
      "loss": 0.424,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.6474883556365967,
      "rewards/margins": 2.159653902053833,
      "rewards/rejected": -4.8071417808532715,
      "step": 11380
    },
    {
      "epoch": 0.5611133670493559,
      "grad_norm": 2.6214840412139893,
      "learning_rate": 4.0654328279845115e-05,
      "logits/chosen": 2.559390068054199,
      "logits/rejected": 2.7160959243774414,
      "logps/chosen": -265.3721618652344,
      "logps/rejected": -270.1139221191406,
      "loss": 0.4606,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.6796135902404785,
      "rewards/margins": 2.4591641426086426,
      "rewards/rejected": -5.138777732849121,
      "step": 11400
    },
    {
      "epoch": 0.5620977764652318,
      "grad_norm": 1.9133796691894531,
      "learning_rate": 4.063792085056113e-05,
      "logits/chosen": 2.5848939418792725,
      "logits/rejected": 2.698411226272583,
      "logps/chosen": -251.90774536132812,
      "logps/rejected": -288.9872131347656,
      "loss": 0.4022,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8599094152450562,
      "rewards/margins": 2.9899051189422607,
      "rewards/rejected": -4.849814414978027,
      "step": 11420
    },
    {
      "epoch": 0.5630821858811079,
      "grad_norm": 4.571882724761963,
      "learning_rate": 4.0621513421277155e-05,
      "logits/chosen": 2.52587628364563,
      "logits/rejected": 2.9083187580108643,
      "logps/chosen": -283.5042419433594,
      "logps/rejected": -268.8719177246094,
      "loss": 0.3839,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.240177631378174,
      "rewards/margins": 2.9241185188293457,
      "rewards/rejected": -5.1642961502075195,
      "step": 11440
    },
    {
      "epoch": 0.564066595296984,
      "grad_norm": 1.3741880655288696,
      "learning_rate": 4.060510599199317e-05,
      "logits/chosen": 2.6319382190704346,
      "logits/rejected": 2.8111319541931152,
      "logps/chosen": -246.99624633789062,
      "logps/rejected": -259.26934814453125,
      "loss": 0.4524,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.5618298053741455,
      "rewards/margins": 2.3257641792297363,
      "rewards/rejected": -4.887593746185303,
      "step": 11460
    },
    {
      "epoch": 0.5650510047128601,
      "grad_norm": 5.651872634887695,
      "learning_rate": 4.0588698562709196e-05,
      "logits/chosen": 2.5398898124694824,
      "logits/rejected": 2.7897586822509766,
      "logps/chosen": -257.90728759765625,
      "logps/rejected": -306.98583984375,
      "loss": 0.3865,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.512268543243408,
      "rewards/margins": 3.2311484813690186,
      "rewards/rejected": -5.743416786193848,
      "step": 11480
    },
    {
      "epoch": 0.5660354141287361,
      "grad_norm": 3.6002180576324463,
      "learning_rate": 4.057229113342522e-05,
      "logits/chosen": 2.4615321159362793,
      "logits/rejected": 2.851868152618408,
      "logps/chosen": -268.1731872558594,
      "logps/rejected": -262.5207214355469,
      "loss": 0.4301,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.121853828430176,
      "rewards/margins": 2.5423760414123535,
      "rewards/rejected": -4.664229869842529,
      "step": 11500
    },
    {
      "epoch": 0.5670198235446122,
      "grad_norm": 0.7109773755073547,
      "learning_rate": 4.055588370414124e-05,
      "logits/chosen": 2.686617136001587,
      "logits/rejected": 2.7922215461730957,
      "logps/chosen": -253.016845703125,
      "logps/rejected": -241.08151245117188,
      "loss": 0.7089,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -3.007849931716919,
      "rewards/margins": 1.8720413446426392,
      "rewards/rejected": -4.879891395568848,
      "step": 11520
    },
    {
      "epoch": 0.5680042329604883,
      "grad_norm": 8.550603866577148,
      "learning_rate": 4.053947627485726e-05,
      "logits/chosen": 2.6867668628692627,
      "logits/rejected": 3.026263475418091,
      "logps/chosen": -294.3108825683594,
      "logps/rejected": -293.71514892578125,
      "loss": 0.6072,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.543330669403076,
      "rewards/margins": 2.627082586288452,
      "rewards/rejected": -5.170413017272949,
      "step": 11540
    },
    {
      "epoch": 0.5689886423763644,
      "grad_norm": 3.8680052757263184,
      "learning_rate": 4.0523068845573277e-05,
      "logits/chosen": 2.570631504058838,
      "logits/rejected": 2.7463788986206055,
      "logps/chosen": -289.3570556640625,
      "logps/rejected": -316.7497863769531,
      "loss": 0.4723,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.2644667625427246,
      "rewards/margins": 2.165530204772949,
      "rewards/rejected": -4.429996967315674,
      "step": 11560
    },
    {
      "epoch": 0.5699730517922404,
      "grad_norm": 2.3509228229522705,
      "learning_rate": 4.05066614162893e-05,
      "logits/chosen": 2.8287134170532227,
      "logits/rejected": 2.8385252952575684,
      "logps/chosen": -284.3887634277344,
      "logps/rejected": -298.2532653808594,
      "loss": 0.4799,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.3843743801116943,
      "rewards/margins": 2.1533751487731934,
      "rewards/rejected": -4.537749767303467,
      "step": 11580
    },
    {
      "epoch": 0.5709574612081164,
      "grad_norm": 5.033230781555176,
      "learning_rate": 4.049025398700532e-05,
      "logits/chosen": 2.6464085578918457,
      "logits/rejected": 2.82342267036438,
      "logps/chosen": -255.82376098632812,
      "logps/rejected": -278.1092834472656,
      "loss": 0.5176,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.494947910308838,
      "rewards/margins": 2.1354379653930664,
      "rewards/rejected": -4.630385875701904,
      "step": 11600
    },
    {
      "epoch": 0.5719418706239925,
      "grad_norm": 1.1009653806686401,
      "learning_rate": 4.047384655772134e-05,
      "logits/chosen": 2.356696367263794,
      "logits/rejected": 2.8001608848571777,
      "logps/chosen": -275.0506591796875,
      "logps/rejected": -296.336181640625,
      "loss": 0.5053,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.8905616998672485,
      "rewards/margins": 2.8151652812957764,
      "rewards/rejected": -4.7057271003723145,
      "step": 11620
    },
    {
      "epoch": 0.5729262800398686,
      "grad_norm": 7.699037551879883,
      "learning_rate": 4.045743912843736e-05,
      "logits/chosen": 2.5224061012268066,
      "logits/rejected": 2.76117205619812,
      "logps/chosen": -249.53640747070312,
      "logps/rejected": -271.98297119140625,
      "loss": 0.7076,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.204810619354248,
      "rewards/margins": 1.884545087814331,
      "rewards/rejected": -4.08935546875,
      "step": 11640
    },
    {
      "epoch": 0.5739106894557446,
      "grad_norm": 3.2006773948669434,
      "learning_rate": 4.044103169915338e-05,
      "logits/chosen": 2.782370090484619,
      "logits/rejected": 3.0309255123138428,
      "logps/chosen": -278.56768798828125,
      "logps/rejected": -284.9919738769531,
      "loss": 0.4843,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.8485827445983887,
      "rewards/margins": 2.160155773162842,
      "rewards/rejected": -5.0087385177612305,
      "step": 11660
    },
    {
      "epoch": 0.5748950988716207,
      "grad_norm": 0.6044889092445374,
      "learning_rate": 4.04246242698694e-05,
      "logits/chosen": 2.2745907306671143,
      "logits/rejected": 2.4865448474884033,
      "logps/chosen": -268.19927978515625,
      "logps/rejected": -275.52435302734375,
      "loss": 0.6213,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9956880807876587,
      "rewards/margins": 2.1605989933013916,
      "rewards/rejected": -4.15628719329834,
      "step": 11680
    },
    {
      "epoch": 0.5758795082874968,
      "grad_norm": 2.9761908054351807,
      "learning_rate": 4.0408216840585415e-05,
      "logits/chosen": 2.471250534057617,
      "logits/rejected": 2.6502506732940674,
      "logps/chosen": -248.10610961914062,
      "logps/rejected": -256.6739807128906,
      "loss": 0.4963,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6455281972885132,
      "rewards/margins": 2.5329718589782715,
      "rewards/rejected": -4.178500175476074,
      "step": 11700
    },
    {
      "epoch": 0.5768639177033729,
      "grad_norm": 1.2496776580810547,
      "learning_rate": 4.039180941130144e-05,
      "logits/chosen": 2.4789936542510986,
      "logits/rejected": 2.7368760108947754,
      "logps/chosen": -261.087158203125,
      "logps/rejected": -252.3188018798828,
      "loss": 0.5789,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.1665666103363037,
      "rewards/margins": 2.006714344024658,
      "rewards/rejected": -4.173280715942383,
      "step": 11720
    },
    {
      "epoch": 0.5778483271192489,
      "grad_norm": 2.7371480464935303,
      "learning_rate": 4.0375401982017455e-05,
      "logits/chosen": 3.1373069286346436,
      "logits/rejected": 3.1263508796691895,
      "logps/chosen": -288.15997314453125,
      "logps/rejected": -304.1771240234375,
      "loss": 0.4093,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.567434549331665,
      "rewards/margins": 2.1089720726013184,
      "rewards/rejected": -3.6764063835144043,
      "step": 11740
    },
    {
      "epoch": 0.5788327365351249,
      "grad_norm": 1.3988549709320068,
      "learning_rate": 4.035899455273348e-05,
      "logits/chosen": 2.8690361976623535,
      "logits/rejected": 2.982262134552002,
      "logps/chosen": -264.9864196777344,
      "logps/rejected": -284.5517272949219,
      "loss": 0.3738,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.022310733795166,
      "rewards/margins": 2.427725315093994,
      "rewards/rejected": -4.45003604888916,
      "step": 11760
    },
    {
      "epoch": 0.579817145951001,
      "grad_norm": 4.597361087799072,
      "learning_rate": 4.0342587123449496e-05,
      "logits/chosen": 2.954941511154175,
      "logits/rejected": 3.0391807556152344,
      "logps/chosen": -256.2756042480469,
      "logps/rejected": -265.60430908203125,
      "loss": 0.5808,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.9839255809783936,
      "rewards/margins": 1.8647741079330444,
      "rewards/rejected": -3.8487000465393066,
      "step": 11780
    },
    {
      "epoch": 0.580801555366877,
      "grad_norm": 3.527700185775757,
      "learning_rate": 4.032617969416552e-05,
      "logits/chosen": 2.4870619773864746,
      "logits/rejected": 2.7887027263641357,
      "logps/chosen": -275.53021240234375,
      "logps/rejected": -293.44439697265625,
      "loss": 0.4251,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2169744968414307,
      "rewards/margins": 2.2490549087524414,
      "rewards/rejected": -4.466029167175293,
      "step": 11800
    },
    {
      "epoch": 0.5817859647827531,
      "grad_norm": 6.4392924308776855,
      "learning_rate": 4.030977226488154e-05,
      "logits/chosen": 2.6351535320281982,
      "logits/rejected": 2.719285249710083,
      "logps/chosen": -250.75033569335938,
      "logps/rejected": -290.5848693847656,
      "loss": 0.578,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.4475908279418945,
      "rewards/margins": 2.638502597808838,
      "rewards/rejected": -5.086093425750732,
      "step": 11820
    },
    {
      "epoch": 0.5827703741986292,
      "grad_norm": 1.130975365638733,
      "learning_rate": 4.029336483559756e-05,
      "logits/chosen": 2.3762526512145996,
      "logits/rejected": 2.597607374191284,
      "logps/chosen": -262.2193603515625,
      "logps/rejected": -281.8075866699219,
      "loss": 0.4198,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.7672687768936157,
      "rewards/margins": 2.752566337585449,
      "rewards/rejected": -4.519834995269775,
      "step": 11840
    },
    {
      "epoch": 0.5837547836145053,
      "grad_norm": 0.990044116973877,
      "learning_rate": 4.027695740631358e-05,
      "logits/chosen": 2.3364531993865967,
      "logits/rejected": 2.710833787918091,
      "logps/chosen": -247.65884399414062,
      "logps/rejected": -257.6033630371094,
      "loss": 0.4374,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.0690746307373047,
      "rewards/margins": 2.399745464324951,
      "rewards/rejected": -4.468820571899414,
      "step": 11860
    },
    {
      "epoch": 0.5847391930303814,
      "grad_norm": 3.8736917972564697,
      "learning_rate": 4.02605499770296e-05,
      "logits/chosen": 2.5414516925811768,
      "logits/rejected": 2.7409934997558594,
      "logps/chosen": -254.00772094726562,
      "logps/rejected": -286.5036926269531,
      "loss": 0.4355,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.8714573383331299,
      "rewards/margins": 2.2376389503479004,
      "rewards/rejected": -4.109096527099609,
      "step": 11880
    },
    {
      "epoch": 0.5857236024462574,
      "grad_norm": 1.9701640605926514,
      "learning_rate": 4.0244142547745624e-05,
      "logits/chosen": 2.6287636756896973,
      "logits/rejected": 2.959016799926758,
      "logps/chosen": -245.9458770751953,
      "logps/rejected": -254.3765106201172,
      "loss": 0.5617,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.412562847137451,
      "rewards/margins": 2.438917398452759,
      "rewards/rejected": -4.851480484008789,
      "step": 11900
    },
    {
      "epoch": 0.5867080118621335,
      "grad_norm": 4.386077880859375,
      "learning_rate": 4.022773511846164e-05,
      "logits/chosen": 2.615720272064209,
      "logits/rejected": 2.8731720447540283,
      "logps/chosen": -287.49322509765625,
      "logps/rejected": -324.416015625,
      "loss": 0.4733,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.1564953327178955,
      "rewards/margins": 2.944525718688965,
      "rewards/rejected": -5.101020812988281,
      "step": 11920
    },
    {
      "epoch": 0.5876924212780095,
      "grad_norm": 3.157855749130249,
      "learning_rate": 4.0211327689177664e-05,
      "logits/chosen": 2.6606082916259766,
      "logits/rejected": 2.9100914001464844,
      "logps/chosen": -266.7879943847656,
      "logps/rejected": -276.48919677734375,
      "loss": 0.5424,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.98468017578125,
      "rewards/margins": 2.585421085357666,
      "rewards/rejected": -4.5701003074646,
      "step": 11940
    },
    {
      "epoch": 0.5886768306938855,
      "grad_norm": 3.421513795852661,
      "learning_rate": 4.019492025989368e-05,
      "logits/chosen": 2.607072353363037,
      "logits/rejected": 2.755402088165283,
      "logps/chosen": -271.312744140625,
      "logps/rejected": -287.267822265625,
      "loss": 0.5057,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.2492451667785645,
      "rewards/margins": 2.6377193927764893,
      "rewards/rejected": -4.886963844299316,
      "step": 11960
    },
    {
      "epoch": 0.5896612401097616,
      "grad_norm": 1.8618264198303223,
      "learning_rate": 4.0178512830609705e-05,
      "logits/chosen": 2.542269229888916,
      "logits/rejected": 2.698960065841675,
      "logps/chosen": -249.88961791992188,
      "logps/rejected": -262.2260437011719,
      "loss": 0.6148,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.428737163543701,
      "rewards/margins": 2.184570550918579,
      "rewards/rejected": -4.613306999206543,
      "step": 11980
    },
    {
      "epoch": 0.5906456495256377,
      "grad_norm": 2.748168706893921,
      "learning_rate": 4.016210540132572e-05,
      "logits/chosen": 2.4458510875701904,
      "logits/rejected": 2.7562716007232666,
      "logps/chosen": -257.97760009765625,
      "logps/rejected": -289.0915832519531,
      "loss": 0.3579,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.40659499168396,
      "rewards/margins": 2.5992743968963623,
      "rewards/rejected": -4.005869388580322,
      "step": 12000
    },
    {
      "epoch": 0.5916300589415138,
      "grad_norm": 0.7550154328346252,
      "learning_rate": 4.014569797204174e-05,
      "logits/chosen": 2.5614981651306152,
      "logits/rejected": 2.604374885559082,
      "logps/chosen": -260.6418762207031,
      "logps/rejected": -279.343994140625,
      "loss": 0.9324,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.817786693572998,
      "rewards/margins": 1.5271965265274048,
      "rewards/rejected": -4.344983100891113,
      "step": 12020
    },
    {
      "epoch": 0.5926144683573898,
      "grad_norm": 2.9081332683563232,
      "learning_rate": 4.012929054275776e-05,
      "logits/chosen": 2.4330058097839355,
      "logits/rejected": 2.7563469409942627,
      "logps/chosen": -263.3586120605469,
      "logps/rejected": -260.3212890625,
      "loss": 0.5201,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0330452919006348,
      "rewards/margins": 2.5051074028015137,
      "rewards/rejected": -4.538152694702148,
      "step": 12040
    },
    {
      "epoch": 0.5935988777732659,
      "grad_norm": 2.4207167625427246,
      "learning_rate": 4.011288311347378e-05,
      "logits/chosen": 2.413393020629883,
      "logits/rejected": 2.6808836460113525,
      "logps/chosen": -271.086669921875,
      "logps/rejected": -280.89410400390625,
      "loss": 0.5114,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.6013755798339844,
      "rewards/margins": 1.9497292041778564,
      "rewards/rejected": -4.551104545593262,
      "step": 12060
    },
    {
      "epoch": 0.594583287189142,
      "grad_norm": 3.300788640975952,
      "learning_rate": 4.00964756841898e-05,
      "logits/chosen": 2.6032192707061768,
      "logits/rejected": 2.8860809803009033,
      "logps/chosen": -268.8815002441406,
      "logps/rejected": -300.0226745605469,
      "loss": 0.3828,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.206501007080078,
      "rewards/margins": 2.743340015411377,
      "rewards/rejected": -4.949841499328613,
      "step": 12080
    },
    {
      "epoch": 0.5955676966050181,
      "grad_norm": 3.649472236633301,
      "learning_rate": 4.0080068254905826e-05,
      "logits/chosen": 2.7223849296569824,
      "logits/rejected": 2.83937931060791,
      "logps/chosen": -271.75347900390625,
      "logps/rejected": -293.1022644042969,
      "loss": 0.4539,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.030770778656006,
      "rewards/margins": 2.7194876670837402,
      "rewards/rejected": -4.750257968902588,
      "step": 12100
    },
    {
      "epoch": 0.596552106020894,
      "grad_norm": 2.9167590141296387,
      "learning_rate": 4.006366082562184e-05,
      "logits/chosen": 2.322587490081787,
      "logits/rejected": 2.4654593467712402,
      "logps/chosen": -237.49771118164062,
      "logps/rejected": -273.66717529296875,
      "loss": 0.4355,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5109972953796387,
      "rewards/margins": 2.7899937629699707,
      "rewards/rejected": -4.300991535186768,
      "step": 12120
    },
    {
      "epoch": 0.5975365154367701,
      "grad_norm": 1.7257840633392334,
      "learning_rate": 4.0047253396337866e-05,
      "logits/chosen": 2.8051199913024902,
      "logits/rejected": 2.9232089519500732,
      "logps/chosen": -268.9447326660156,
      "logps/rejected": -275.9676208496094,
      "loss": 0.4253,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9982112646102905,
      "rewards/margins": 2.748523235321045,
      "rewards/rejected": -4.746735095977783,
      "step": 12140
    },
    {
      "epoch": 0.5985209248526462,
      "grad_norm": 3.5989744663238525,
      "learning_rate": 4.003084596705388e-05,
      "logits/chosen": 2.2372021675109863,
      "logits/rejected": 2.447390079498291,
      "logps/chosen": -247.6556396484375,
      "logps/rejected": -264.13226318359375,
      "loss": 0.418,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9234269857406616,
      "rewards/margins": 2.3218560218811035,
      "rewards/rejected": -4.245283603668213,
      "step": 12160
    },
    {
      "epoch": 0.5995053342685223,
      "grad_norm": 2.4669508934020996,
      "learning_rate": 4.001443853776991e-05,
      "logits/chosen": 2.369535207748413,
      "logits/rejected": 2.639167070388794,
      "logps/chosen": -269.3234558105469,
      "logps/rejected": -287.63763427734375,
      "loss": 0.6442,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.3878366947174072,
      "rewards/margins": 2.290269374847412,
      "rewards/rejected": -4.678106307983398,
      "step": 12180
    },
    {
      "epoch": 0.6004897436843983,
      "grad_norm": 0.22997801005840302,
      "learning_rate": 3.9998031108485924e-05,
      "logits/chosen": 2.6261701583862305,
      "logits/rejected": 2.873084545135498,
      "logps/chosen": -257.2069396972656,
      "logps/rejected": -303.80364990234375,
      "loss": 0.462,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.0396482944488525,
      "rewards/margins": 2.8074288368225098,
      "rewards/rejected": -4.847077369689941,
      "step": 12200
    },
    {
      "epoch": 0.6014741531002744,
      "grad_norm": 2.2119011878967285,
      "learning_rate": 3.998162367920195e-05,
      "logits/chosen": 2.6677324771881104,
      "logits/rejected": 2.8175265789031982,
      "logps/chosen": -282.5116271972656,
      "logps/rejected": -282.5773620605469,
      "loss": 0.612,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.7636034488677979,
      "rewards/margins": 2.203134059906006,
      "rewards/rejected": -3.9667372703552246,
      "step": 12220
    },
    {
      "epoch": 0.6024585625161505,
      "grad_norm": 1.3141930103302002,
      "learning_rate": 3.9965216249917964e-05,
      "logits/chosen": 2.7806553840637207,
      "logits/rejected": 2.8265557289123535,
      "logps/chosen": -278.36907958984375,
      "logps/rejected": -265.334716796875,
      "loss": 0.521,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.5051207542419434,
      "rewards/margins": 2.182190418243408,
      "rewards/rejected": -3.6873116493225098,
      "step": 12240
    },
    {
      "epoch": 0.6034429719320266,
      "grad_norm": 0.8930282592773438,
      "learning_rate": 3.994880882063399e-05,
      "logits/chosen": 2.5978188514709473,
      "logits/rejected": 2.538971185684204,
      "logps/chosen": -269.5330505371094,
      "logps/rejected": -288.5080261230469,
      "loss": 0.558,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4851323366165161,
      "rewards/margins": 1.9272487163543701,
      "rewards/rejected": -3.412381410598755,
      "step": 12260
    },
    {
      "epoch": 0.6044273813479026,
      "grad_norm": 1.281865119934082,
      "learning_rate": 3.9932401391350005e-05,
      "logits/chosen": 2.7126593589782715,
      "logits/rejected": 2.900369167327881,
      "logps/chosen": -290.3538818359375,
      "logps/rejected": -285.77911376953125,
      "loss": 0.3295,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.425072431564331,
      "rewards/margins": 2.25917387008667,
      "rewards/rejected": -3.684246778488159,
      "step": 12280
    },
    {
      "epoch": 0.6054117907637786,
      "grad_norm": 1.135982632637024,
      "learning_rate": 3.991599396206602e-05,
      "logits/chosen": 2.6935551166534424,
      "logits/rejected": 2.8760886192321777,
      "logps/chosen": -272.3716735839844,
      "logps/rejected": -283.43585205078125,
      "loss": 0.4691,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.2928062677383423,
      "rewards/margins": 2.8290019035339355,
      "rewards/rejected": -4.1218085289001465,
      "step": 12300
    },
    {
      "epoch": 0.6063962001796547,
      "grad_norm": 1.3676236867904663,
      "learning_rate": 3.9899586532782045e-05,
      "logits/chosen": 2.686814546585083,
      "logits/rejected": 2.8690783977508545,
      "logps/chosen": -267.57342529296875,
      "logps/rejected": -277.4516906738281,
      "loss": 0.4765,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.3675312995910645,
      "rewards/margins": 2.5465526580810547,
      "rewards/rejected": -4.914083957672119,
      "step": 12320
    },
    {
      "epoch": 0.6073806095955308,
      "grad_norm": 4.193396091461182,
      "learning_rate": 3.988317910349806e-05,
      "logits/chosen": 2.527759552001953,
      "logits/rejected": 2.9056897163391113,
      "logps/chosen": -267.76849365234375,
      "logps/rejected": -287.5159912109375,
      "loss": 0.4416,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8750293254852295,
      "rewards/margins": 2.4126455783843994,
      "rewards/rejected": -4.287674903869629,
      "step": 12340
    },
    {
      "epoch": 0.6083650190114068,
      "grad_norm": 4.096189022064209,
      "learning_rate": 3.9866771674214085e-05,
      "logits/chosen": 2.4840269088745117,
      "logits/rejected": 2.7726683616638184,
      "logps/chosen": -294.01068115234375,
      "logps/rejected": -313.34552001953125,
      "loss": 0.5815,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.019500494003296,
      "rewards/margins": 2.278573751449585,
      "rewards/rejected": -4.298074245452881,
      "step": 12360
    },
    {
      "epoch": 0.6093494284272829,
      "grad_norm": 2.7721757888793945,
      "learning_rate": 3.98503642449301e-05,
      "logits/chosen": 2.9180684089660645,
      "logits/rejected": 3.1233792304992676,
      "logps/chosen": -275.6666564941406,
      "logps/rejected": -306.29736328125,
      "loss": 0.35,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.015319347381592,
      "rewards/margins": 2.7809033393859863,
      "rewards/rejected": -4.796222686767578,
      "step": 12380
    },
    {
      "epoch": 0.610333837843159,
      "grad_norm": 7.840282917022705,
      "learning_rate": 3.9833956815646126e-05,
      "logits/chosen": 2.588283061981201,
      "logits/rejected": 2.7402164936065674,
      "logps/chosen": -268.9917297363281,
      "logps/rejected": -304.9256286621094,
      "loss": 0.5493,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.711418628692627,
      "rewards/margins": 2.1261019706726074,
      "rewards/rejected": -4.837520599365234,
      "step": 12400
    },
    {
      "epoch": 0.611318247259035,
      "grad_norm": 5.375072002410889,
      "learning_rate": 3.981754938636215e-05,
      "logits/chosen": 2.6547648906707764,
      "logits/rejected": 2.692586898803711,
      "logps/chosen": -237.9840850830078,
      "logps/rejected": -257.086181640625,
      "loss": 0.4927,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.27606201171875,
      "rewards/margins": 3.0395143032073975,
      "rewards/rejected": -5.315576553344727,
      "step": 12420
    },
    {
      "epoch": 0.6123026566749111,
      "grad_norm": 2.303957939147949,
      "learning_rate": 3.9801141957078166e-05,
      "logits/chosen": 2.460338592529297,
      "logits/rejected": 2.739797830581665,
      "logps/chosen": -266.646240234375,
      "logps/rejected": -293.3381652832031,
      "loss": 0.4046,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.638233184814453,
      "rewards/margins": 2.8265414237976074,
      "rewards/rejected": -5.464774131774902,
      "step": 12440
    },
    {
      "epoch": 0.6132870660907872,
      "grad_norm": 1.2510452270507812,
      "learning_rate": 3.978473452779419e-05,
      "logits/chosen": 2.463104009628296,
      "logits/rejected": 2.796830892562866,
      "logps/chosen": -253.19921875,
      "logps/rejected": -266.0909423828125,
      "loss": 0.5471,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.966905951499939,
      "rewards/margins": 2.2509853839874268,
      "rewards/rejected": -4.217891216278076,
      "step": 12460
    },
    {
      "epoch": 0.6142714755066632,
      "grad_norm": 2.239307403564453,
      "learning_rate": 3.976832709851021e-05,
      "logits/chosen": 2.9671287536621094,
      "logits/rejected": 3.123098850250244,
      "logps/chosen": -242.1826629638672,
      "logps/rejected": -257.2480773925781,
      "loss": 0.4912,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.373779296875,
      "rewards/margins": 2.5399816036224365,
      "rewards/rejected": -4.913761138916016,
      "step": 12480
    },
    {
      "epoch": 0.6152558849225392,
      "grad_norm": 5.006972789764404,
      "learning_rate": 3.975191966922623e-05,
      "logits/chosen": 2.5525312423706055,
      "logits/rejected": 2.7663512229919434,
      "logps/chosen": -275.1589660644531,
      "logps/rejected": -280.0295104980469,
      "loss": 0.4883,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.2725183963775635,
      "rewards/margins": 2.468735933303833,
      "rewards/rejected": -4.741254806518555,
      "step": 12500
    },
    {
      "epoch": 0.6162402943384153,
      "grad_norm": 0.6171839237213135,
      "learning_rate": 3.973551223994225e-05,
      "logits/chosen": 2.615121603012085,
      "logits/rejected": 2.809682607650757,
      "logps/chosen": -302.2325439453125,
      "logps/rejected": -279.9522399902344,
      "loss": 0.314,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.546168804168701,
      "rewards/margins": 2.9186623096466064,
      "rewards/rejected": -5.464831352233887,
      "step": 12520
    },
    {
      "epoch": 0.6172247037542914,
      "grad_norm": 3.234671115875244,
      "learning_rate": 3.971910481065827e-05,
      "logits/chosen": 2.469010829925537,
      "logits/rejected": 2.823051929473877,
      "logps/chosen": -271.0918884277344,
      "logps/rejected": -268.2142028808594,
      "loss": 0.5347,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.6308135986328125,
      "rewards/margins": 2.4455254077911377,
      "rewards/rejected": -5.076339244842529,
      "step": 12540
    },
    {
      "epoch": 0.6182091131701675,
      "grad_norm": 0.5538822412490845,
      "learning_rate": 3.970269738137429e-05,
      "logits/chosen": 2.7990334033966064,
      "logits/rejected": 3.0449557304382324,
      "logps/chosen": -261.4662170410156,
      "logps/rejected": -251.45755004882812,
      "loss": 0.4484,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8186641931533813,
      "rewards/margins": 2.8399734497070312,
      "rewards/rejected": -4.658637523651123,
      "step": 12560
    },
    {
      "epoch": 0.6191935225860435,
      "grad_norm": 5.154459476470947,
      "learning_rate": 3.968628995209031e-05,
      "logits/chosen": 2.7583813667297363,
      "logits/rejected": 2.8057749271392822,
      "logps/chosen": -239.2207794189453,
      "logps/rejected": -280.186767578125,
      "loss": 0.5501,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.1271557807922363,
      "rewards/margins": 2.007589817047119,
      "rewards/rejected": -4.1347455978393555,
      "step": 12580
    },
    {
      "epoch": 0.6201779320019196,
      "grad_norm": 0.8373851776123047,
      "learning_rate": 3.966988252280633e-05,
      "logits/chosen": 2.437553882598877,
      "logits/rejected": 2.7386109828948975,
      "logps/chosen": -250.1022186279297,
      "logps/rejected": -266.6519470214844,
      "loss": 0.6189,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.3730920553207397,
      "rewards/margins": 1.7267570495605469,
      "rewards/rejected": -3.099849224090576,
      "step": 12600
    },
    {
      "epoch": 0.6211623414177957,
      "grad_norm": 1.6995694637298584,
      "learning_rate": 3.9653475093522345e-05,
      "logits/chosen": 2.5565340518951416,
      "logits/rejected": 2.736985683441162,
      "logps/chosen": -254.4132537841797,
      "logps/rejected": -284.0806579589844,
      "loss": 0.4988,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9095840454101562,
      "rewards/margins": 2.4186878204345703,
      "rewards/rejected": -4.328271865844727,
      "step": 12620
    },
    {
      "epoch": 0.6221467508336718,
      "grad_norm": 1.8728232383728027,
      "learning_rate": 3.963706766423837e-05,
      "logits/chosen": 2.465745687484741,
      "logits/rejected": 2.606936454772949,
      "logps/chosen": -254.6449737548828,
      "logps/rejected": -281.21942138671875,
      "loss": 0.4065,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.808851957321167,
      "rewards/margins": 2.858957052230835,
      "rewards/rejected": -4.667808532714844,
      "step": 12640
    },
    {
      "epoch": 0.6231311602495477,
      "grad_norm": 0.6062004566192627,
      "learning_rate": 3.9620660234954385e-05,
      "logits/chosen": 2.662904739379883,
      "logits/rejected": 2.915393114089966,
      "logps/chosen": -260.4817199707031,
      "logps/rejected": -259.1235046386719,
      "loss": 0.5348,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7962491512298584,
      "rewards/margins": 2.257826805114746,
      "rewards/rejected": -4.054076194763184,
      "step": 12660
    },
    {
      "epoch": 0.6241155696654238,
      "grad_norm": 3.809988260269165,
      "learning_rate": 3.960425280567041e-05,
      "logits/chosen": 2.7913429737091064,
      "logits/rejected": 3.118424654006958,
      "logps/chosen": -273.08685302734375,
      "logps/rejected": -273.7010192871094,
      "loss": 0.3867,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8112119436264038,
      "rewards/margins": 2.4598071575164795,
      "rewards/rejected": -4.27101993560791,
      "step": 12680
    },
    {
      "epoch": 0.6250999790812999,
      "grad_norm": 1.4697877168655396,
      "learning_rate": 3.9587845376386426e-05,
      "logits/chosen": 2.4546923637390137,
      "logits/rejected": 2.3945987224578857,
      "logps/chosen": -269.57122802734375,
      "logps/rejected": -271.424560546875,
      "loss": 0.4979,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.84000563621521,
      "rewards/margins": 2.6914029121398926,
      "rewards/rejected": -4.531408786773682,
      "step": 12700
    },
    {
      "epoch": 0.626084388497176,
      "grad_norm": 1.6302450895309448,
      "learning_rate": 3.957143794710245e-05,
      "logits/chosen": 2.5027496814727783,
      "logits/rejected": 2.678349018096924,
      "logps/chosen": -262.3232421875,
      "logps/rejected": -280.34600830078125,
      "loss": 0.656,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.587779998779297,
      "rewards/margins": 2.381232738494873,
      "rewards/rejected": -4.969013214111328,
      "step": 12720
    },
    {
      "epoch": 0.627068797913052,
      "grad_norm": 3.885500431060791,
      "learning_rate": 3.955503051781847e-05,
      "logits/chosen": 2.313816547393799,
      "logits/rejected": 2.6701207160949707,
      "logps/chosen": -254.7333526611328,
      "logps/rejected": -286.80426025390625,
      "loss": 0.5773,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.6962149143218994,
      "rewards/margins": 2.633671760559082,
      "rewards/rejected": -4.329886436462402,
      "step": 12740
    },
    {
      "epoch": 0.6280532073289281,
      "grad_norm": 2.156317710876465,
      "learning_rate": 3.953862308853449e-05,
      "logits/chosen": 2.73722767829895,
      "logits/rejected": 2.821443557739258,
      "logps/chosen": -247.2190399169922,
      "logps/rejected": -256.8199768066406,
      "loss": 0.6539,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.2090132236480713,
      "rewards/margins": 1.7115402221679688,
      "rewards/rejected": -3.920553207397461,
      "step": 12760
    },
    {
      "epoch": 0.6290376167448042,
      "grad_norm": 1.2360267639160156,
      "learning_rate": 3.9522215659250514e-05,
      "logits/chosen": 2.6593785285949707,
      "logits/rejected": 2.8677783012390137,
      "logps/chosen": -254.61654663085938,
      "logps/rejected": -254.8738555908203,
      "loss": 0.4396,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.88667893409729,
      "rewards/margins": 2.4630067348480225,
      "rewards/rejected": -4.3496856689453125,
      "step": 12780
    },
    {
      "epoch": 0.6300220261606803,
      "grad_norm": 12.347277641296387,
      "learning_rate": 3.950580822996653e-05,
      "logits/chosen": 2.653923749923706,
      "logits/rejected": 3.1094393730163574,
      "logps/chosen": -247.0685577392578,
      "logps/rejected": -279.7607116699219,
      "loss": 0.4685,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6727501153945923,
      "rewards/margins": 2.7734344005584717,
      "rewards/rejected": -4.446184158325195,
      "step": 12800
    },
    {
      "epoch": 0.6310064355765563,
      "grad_norm": 9.2665376663208,
      "learning_rate": 3.9489400800682554e-05,
      "logits/chosen": 2.8067142963409424,
      "logits/rejected": 2.932020664215088,
      "logps/chosen": -259.9447021484375,
      "logps/rejected": -301.8472595214844,
      "loss": 0.4349,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8263814449310303,
      "rewards/margins": 2.6616244316101074,
      "rewards/rejected": -4.488005638122559,
      "step": 12820
    },
    {
      "epoch": 0.6319908449924323,
      "grad_norm": 1.0872949361801147,
      "learning_rate": 3.947299337139857e-05,
      "logits/chosen": 2.740217447280884,
      "logits/rejected": 3.045219659805298,
      "logps/chosen": -261.097900390625,
      "logps/rejected": -294.81317138671875,
      "loss": 0.4288,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7861502170562744,
      "rewards/margins": 2.54668927192688,
      "rewards/rejected": -4.332839012145996,
      "step": 12840
    },
    {
      "epoch": 0.6329752544083084,
      "grad_norm": 4.683445930480957,
      "learning_rate": 3.9456585942114594e-05,
      "logits/chosen": 3.1092684268951416,
      "logits/rejected": 3.235241651535034,
      "logps/chosen": -281.7209777832031,
      "logps/rejected": -274.54315185546875,
      "loss": 0.5066,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.175734758377075,
      "rewards/margins": 3.0275139808654785,
      "rewards/rejected": -5.203248500823975,
      "step": 12860
    },
    {
      "epoch": 0.6339596638241844,
      "grad_norm": 1.271791696548462,
      "learning_rate": 3.944017851283061e-05,
      "logits/chosen": 2.708547830581665,
      "logits/rejected": 2.993778944015503,
      "logps/chosen": -267.567626953125,
      "logps/rejected": -281.67974853515625,
      "loss": 0.5397,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.7666008472442627,
      "rewards/margins": 2.146122932434082,
      "rewards/rejected": -4.912724018096924,
      "step": 12880
    },
    {
      "epoch": 0.6349440732400605,
      "grad_norm": 4.671891689300537,
      "learning_rate": 3.9423771083546635e-05,
      "logits/chosen": 2.5223677158355713,
      "logits/rejected": 2.924694061279297,
      "logps/chosen": -288.3547058105469,
      "logps/rejected": -288.0673828125,
      "loss": 0.385,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.131563901901245,
      "rewards/margins": 2.7474586963653564,
      "rewards/rejected": -4.87902307510376,
      "step": 12900
    },
    {
      "epoch": 0.6359284826559366,
      "grad_norm": 2.7986698150634766,
      "learning_rate": 3.940736365426265e-05,
      "logits/chosen": 2.6172444820404053,
      "logits/rejected": 2.8329405784606934,
      "logps/chosen": -286.1448669433594,
      "logps/rejected": -307.95782470703125,
      "loss": 0.5641,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.2281479835510254,
      "rewards/margins": 2.6800363063812256,
      "rewards/rejected": -4.908184051513672,
      "step": 12920
    },
    {
      "epoch": 0.6369128920718127,
      "grad_norm": 1.4001259803771973,
      "learning_rate": 3.939095622497867e-05,
      "logits/chosen": 2.9485340118408203,
      "logits/rejected": 3.0194296836853027,
      "logps/chosen": -291.19989013671875,
      "logps/rejected": -267.5390625,
      "loss": 0.6699,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.579683780670166,
      "rewards/margins": 1.7556791305541992,
      "rewards/rejected": -4.335362911224365,
      "step": 12940
    },
    {
      "epoch": 0.6378973014876888,
      "grad_norm": 1.5286725759506226,
      "learning_rate": 3.937454879569469e-05,
      "logits/chosen": 2.872789144515991,
      "logits/rejected": 2.9252374172210693,
      "logps/chosen": -279.56903076171875,
      "logps/rejected": -294.69036865234375,
      "loss": 0.5529,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6318066120147705,
      "rewards/margins": 2.2918758392333984,
      "rewards/rejected": -3.923682451248169,
      "step": 12960
    },
    {
      "epoch": 0.6388817109035648,
      "grad_norm": 1.0799672603607178,
      "learning_rate": 3.935814136641071e-05,
      "logits/chosen": 2.388679265975952,
      "logits/rejected": 2.681148052215576,
      "logps/chosen": -257.27642822265625,
      "logps/rejected": -288.27093505859375,
      "loss": 0.3128,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.9113914966583252,
      "rewards/margins": 2.8969736099243164,
      "rewards/rejected": -4.808365345001221,
      "step": 12980
    },
    {
      "epoch": 0.6398661203194409,
      "grad_norm": 1.2467069625854492,
      "learning_rate": 3.934173393712673e-05,
      "logits/chosen": 2.6969895362854004,
      "logits/rejected": 2.8510918617248535,
      "logps/chosen": -281.1731872558594,
      "logps/rejected": -285.645263671875,
      "loss": 0.5226,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.2399752140045166,
      "rewards/margins": 1.8803703784942627,
      "rewards/rejected": -4.120345115661621,
      "step": 13000
    },
    {
      "epoch": 0.6408505297353169,
      "grad_norm": 3.104098081588745,
      "learning_rate": 3.932532650784275e-05,
      "logits/chosen": 2.6782898902893066,
      "logits/rejected": 2.9732227325439453,
      "logps/chosen": -271.41900634765625,
      "logps/rejected": -313.54425048828125,
      "loss": 0.6332,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.5227339267730713,
      "rewards/margins": 2.369889736175537,
      "rewards/rejected": -4.892622947692871,
      "step": 13020
    },
    {
      "epoch": 0.6418349391511929,
      "grad_norm": 0.5812941789627075,
      "learning_rate": 3.930891907855877e-05,
      "logits/chosen": 2.8594627380371094,
      "logits/rejected": 2.9574074745178223,
      "logps/chosen": -266.09039306640625,
      "logps/rejected": -305.0185546875,
      "loss": 0.4413,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1926159858703613,
      "rewards/margins": 2.981536388397217,
      "rewards/rejected": -5.174152374267578,
      "step": 13040
    },
    {
      "epoch": 0.642819348567069,
      "grad_norm": 1.6708999872207642,
      "learning_rate": 3.92925116492748e-05,
      "logits/chosen": 2.528991222381592,
      "logits/rejected": 2.9251387119293213,
      "logps/chosen": -264.46337890625,
      "logps/rejected": -289.9356994628906,
      "loss": 0.5115,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.061636447906494,
      "rewards/margins": 2.801647901535034,
      "rewards/rejected": -4.863285064697266,
      "step": 13060
    },
    {
      "epoch": 0.6438037579829451,
      "grad_norm": 2.528425455093384,
      "learning_rate": 3.9276104219990813e-05,
      "logits/chosen": 2.6416471004486084,
      "logits/rejected": 3.0201830863952637,
      "logps/chosen": -248.1992645263672,
      "logps/rejected": -245.6070556640625,
      "loss": 0.5708,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.7229259014129639,
      "rewards/margins": 1.948482871055603,
      "rewards/rejected": -3.6714088916778564,
      "step": 13080
    },
    {
      "epoch": 0.6447881673988212,
      "grad_norm": 3.995636224746704,
      "learning_rate": 3.925969679070684e-05,
      "logits/chosen": 2.73036527633667,
      "logits/rejected": 2.997471332550049,
      "logps/chosen": -273.38873291015625,
      "logps/rejected": -275.71783447265625,
      "loss": 0.4391,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8027031421661377,
      "rewards/margins": 3.087261915206909,
      "rewards/rejected": -4.889964580535889,
      "step": 13100
    },
    {
      "epoch": 0.6457725768146972,
      "grad_norm": 3.7826576232910156,
      "learning_rate": 3.9243289361422854e-05,
      "logits/chosen": 2.591681957244873,
      "logits/rejected": 2.7873740196228027,
      "logps/chosen": -286.6405334472656,
      "logps/rejected": -292.4107971191406,
      "loss": 0.6046,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.965934157371521,
      "rewards/margins": 1.9634437561035156,
      "rewards/rejected": -3.929378032684326,
      "step": 13120
    },
    {
      "epoch": 0.6467569862305733,
      "grad_norm": 0.7585161328315735,
      "learning_rate": 3.922688193213888e-05,
      "logits/chosen": 2.654120683670044,
      "logits/rejected": 2.8535640239715576,
      "logps/chosen": -253.9363250732422,
      "logps/rejected": -279.7166748046875,
      "loss": 0.5076,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.9052734375,
      "rewards/margins": 1.9934561252593994,
      "rewards/rejected": -3.8987293243408203,
      "step": 13140
    },
    {
      "epoch": 0.6477413956464494,
      "grad_norm": 4.4792890548706055,
      "learning_rate": 3.9210474502854894e-05,
      "logits/chosen": 3.022533655166626,
      "logits/rejected": 3.162823438644409,
      "logps/chosen": -285.6828918457031,
      "logps/rejected": -262.99200439453125,
      "loss": 0.4803,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.200648784637451,
      "rewards/margins": 2.4164061546325684,
      "rewards/rejected": -4.6170549392700195,
      "step": 13160
    },
    {
      "epoch": 0.6487258050623255,
      "grad_norm": 2.274033546447754,
      "learning_rate": 3.919406707357092e-05,
      "logits/chosen": 2.8532185554504395,
      "logits/rejected": 2.998345136642456,
      "logps/chosen": -256.4828796386719,
      "logps/rejected": -290.1071472167969,
      "loss": 0.5904,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0212514400482178,
      "rewards/margins": 2.287181854248047,
      "rewards/rejected": -4.308434009552002,
      "step": 13180
    },
    {
      "epoch": 0.6497102144782014,
      "grad_norm": 3.5659570693969727,
      "learning_rate": 3.9177659644286935e-05,
      "logits/chosen": 2.7686893939971924,
      "logits/rejected": 3.0387749671936035,
      "logps/chosen": -245.6992645263672,
      "logps/rejected": -239.85653686523438,
      "loss": 0.4427,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.555899739265442,
      "rewards/margins": 1.932329773902893,
      "rewards/rejected": -3.488229274749756,
      "step": 13200
    },
    {
      "epoch": 0.6506946238940775,
      "grad_norm": 2.278932809829712,
      "learning_rate": 3.916125221500295e-05,
      "logits/chosen": 2.855104923248291,
      "logits/rejected": 3.052612543106079,
      "logps/chosen": -269.7682800292969,
      "logps/rejected": -257.1123046875,
      "loss": 0.578,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -1.6948264837265015,
      "rewards/margins": 1.6583713293075562,
      "rewards/rejected": -3.3531975746154785,
      "step": 13220
    },
    {
      "epoch": 0.6516790333099536,
      "grad_norm": 3.930323362350464,
      "learning_rate": 3.9144844785718975e-05,
      "logits/chosen": 2.9971704483032227,
      "logits/rejected": 3.036512851715088,
      "logps/chosen": -266.80194091796875,
      "logps/rejected": -257.6959228515625,
      "loss": 0.6959,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.9198529720306396,
      "rewards/margins": 1.7013248205184937,
      "rewards/rejected": -3.6211776733398438,
      "step": 13240
    },
    {
      "epoch": 0.6526634427258297,
      "grad_norm": 1.3470346927642822,
      "learning_rate": 3.912843735643499e-05,
      "logits/chosen": 3.022113084793091,
      "logits/rejected": 3.232191562652588,
      "logps/chosen": -266.4309387207031,
      "logps/rejected": -273.599609375,
      "loss": 0.5037,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.3170948028564453,
      "rewards/margins": 2.466268301010132,
      "rewards/rejected": -3.7833633422851562,
      "step": 13260
    },
    {
      "epoch": 0.6536478521417057,
      "grad_norm": 0.9551032781600952,
      "learning_rate": 3.9112029927151016e-05,
      "logits/chosen": 2.931765079498291,
      "logits/rejected": 3.2751717567443848,
      "logps/chosen": -256.5714416503906,
      "logps/rejected": -246.6829833984375,
      "loss": 0.635,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.6455484628677368,
      "rewards/margins": 1.5033351182937622,
      "rewards/rejected": -3.14888334274292,
      "step": 13280
    },
    {
      "epoch": 0.6546322615575818,
      "grad_norm": 2.551542043685913,
      "learning_rate": 3.909562249786703e-05,
      "logits/chosen": 3.2316784858703613,
      "logits/rejected": 3.5188965797424316,
      "logps/chosen": -249.8926544189453,
      "logps/rejected": -243.067626953125,
      "loss": 0.4758,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.0643556118011475,
      "rewards/margins": 1.5768887996673584,
      "rewards/rejected": -2.641244411468506,
      "step": 13300
    },
    {
      "epoch": 0.6556166709734579,
      "grad_norm": 2.349839448928833,
      "learning_rate": 3.9079215068583056e-05,
      "logits/chosen": 3.0445358753204346,
      "logits/rejected": 3.3628780841827393,
      "logps/chosen": -239.70901489257812,
      "logps/rejected": -237.5197296142578,
      "loss": 0.5788,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6384414434432983,
      "rewards/margins": 1.7096455097198486,
      "rewards/rejected": -3.3480868339538574,
      "step": 13320
    },
    {
      "epoch": 0.656601080389334,
      "grad_norm": 5.646114826202393,
      "learning_rate": 3.906280763929907e-05,
      "logits/chosen": 3.0211644172668457,
      "logits/rejected": 3.170478343963623,
      "logps/chosen": -248.31051635742188,
      "logps/rejected": -270.4914245605469,
      "loss": 0.4436,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5852060317993164,
      "rewards/margins": 2.1127877235412598,
      "rewards/rejected": -3.6979942321777344,
      "step": 13340
    },
    {
      "epoch": 0.65758548980521,
      "grad_norm": 4.554261207580566,
      "learning_rate": 3.9046400210015097e-05,
      "logits/chosen": 2.871356725692749,
      "logits/rejected": 3.0527963638305664,
      "logps/chosen": -272.4373474121094,
      "logps/rejected": -268.5616149902344,
      "loss": 0.4475,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4904329776763916,
      "rewards/margins": 2.352630138397217,
      "rewards/rejected": -3.8430638313293457,
      "step": 13360
    },
    {
      "epoch": 0.658569899221086,
      "grad_norm": 0.3928069472312927,
      "learning_rate": 3.902999278073112e-05,
      "logits/chosen": 2.797976016998291,
      "logits/rejected": 3.036954879760742,
      "logps/chosen": -256.22479248046875,
      "logps/rejected": -250.4940948486328,
      "loss": 0.3835,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.3037933111190796,
      "rewards/margins": 2.5682151317596436,
      "rewards/rejected": -3.8720080852508545,
      "step": 13380
    },
    {
      "epoch": 0.6595543086369621,
      "grad_norm": 1.9294570684432983,
      "learning_rate": 3.901358535144714e-05,
      "logits/chosen": 3.0234062671661377,
      "logits/rejected": 3.021760940551758,
      "logps/chosen": -277.61907958984375,
      "logps/rejected": -328.9065246582031,
      "loss": 0.434,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.419156551361084,
      "rewards/margins": 2.3187689781188965,
      "rewards/rejected": -4.7379255294799805,
      "step": 13400
    },
    {
      "epoch": 0.6605387180528381,
      "grad_norm": 1.783673644065857,
      "learning_rate": 3.899717792216316e-05,
      "logits/chosen": 3.168452024459839,
      "logits/rejected": 3.3343634605407715,
      "logps/chosen": -256.2889709472656,
      "logps/rejected": -278.9024963378906,
      "loss": 0.5416,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.482006311416626,
      "rewards/margins": 2.575443744659424,
      "rewards/rejected": -5.057450294494629,
      "step": 13420
    },
    {
      "epoch": 0.6615231274687142,
      "grad_norm": 0.2139996886253357,
      "learning_rate": 3.898077049287918e-05,
      "logits/chosen": 3.2334353923797607,
      "logits/rejected": 3.366809129714966,
      "logps/chosen": -267.7038269042969,
      "logps/rejected": -258.04913330078125,
      "loss": 0.6861,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.9712669849395752,
      "rewards/margins": 2.0696747303009033,
      "rewards/rejected": -4.0409417152404785,
      "step": 13440
    },
    {
      "epoch": 0.6625075368845903,
      "grad_norm": 2.9712719917297363,
      "learning_rate": 3.89643630635952e-05,
      "logits/chosen": 3.24126935005188,
      "logits/rejected": 3.267282009124756,
      "logps/chosen": -298.16949462890625,
      "logps/rejected": -293.59259033203125,
      "loss": 0.5634,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.120086908340454,
      "rewards/margins": 2.2125561237335205,
      "rewards/rejected": -4.332643032073975,
      "step": 13460
    },
    {
      "epoch": 0.6634919463004664,
      "grad_norm": 1.1300320625305176,
      "learning_rate": 3.894795563431122e-05,
      "logits/chosen": 2.8373663425445557,
      "logits/rejected": 3.099133014678955,
      "logps/chosen": -261.05950927734375,
      "logps/rejected": -290.2504577636719,
      "loss": 0.4608,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.508388638496399,
      "rewards/margins": 2.4558167457580566,
      "rewards/rejected": -3.964205503463745,
      "step": 13480
    },
    {
      "epoch": 0.6644763557163424,
      "grad_norm": 1.9259905815124512,
      "learning_rate": 3.893154820502724e-05,
      "logits/chosen": 2.91347336769104,
      "logits/rejected": 3.0199577808380127,
      "logps/chosen": -220.79443359375,
      "logps/rejected": -244.46401977539062,
      "loss": 0.4886,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.3343758583068848,
      "rewards/margins": 2.018937587738037,
      "rewards/rejected": -3.353313446044922,
      "step": 13500
    },
    {
      "epoch": 0.6654607651322185,
      "grad_norm": 4.180617809295654,
      "learning_rate": 3.891514077574326e-05,
      "logits/chosen": 2.6681675910949707,
      "logits/rejected": 2.9505038261413574,
      "logps/chosen": -270.3739318847656,
      "logps/rejected": -283.7976989746094,
      "loss": 0.5173,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4958281517028809,
      "rewards/margins": 2.2256953716278076,
      "rewards/rejected": -3.7215232849121094,
      "step": 13520
    },
    {
      "epoch": 0.6664451745480946,
      "grad_norm": 0.5109612941741943,
      "learning_rate": 3.8898733346459275e-05,
      "logits/chosen": 2.502845287322998,
      "logits/rejected": 2.752833604812622,
      "logps/chosen": -275.5910339355469,
      "logps/rejected": -277.08538818359375,
      "loss": 0.432,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.156440019607544,
      "rewards/margins": 2.0215418338775635,
      "rewards/rejected": -4.177981853485107,
      "step": 13540
    },
    {
      "epoch": 0.6674295839639706,
      "grad_norm": 1.7277071475982666,
      "learning_rate": 3.88823259171753e-05,
      "logits/chosen": 2.6690568923950195,
      "logits/rejected": 2.9938793182373047,
      "logps/chosen": -265.8398742675781,
      "logps/rejected": -270.79937744140625,
      "loss": 0.3897,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.6820472478866577,
      "rewards/margins": 2.9146218299865723,
      "rewards/rejected": -4.5966691970825195,
      "step": 13560
    },
    {
      "epoch": 0.6684139933798466,
      "grad_norm": 7.2860798835754395,
      "learning_rate": 3.8865918487891316e-05,
      "logits/chosen": 2.885315179824829,
      "logits/rejected": 3.0652616024017334,
      "logps/chosen": -273.50732421875,
      "logps/rejected": -272.2204284667969,
      "loss": 0.3715,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5356497764587402,
      "rewards/margins": 2.777578830718994,
      "rewards/rejected": -4.313228607177734,
      "step": 13580
    },
    {
      "epoch": 0.6693984027957227,
      "grad_norm": 0.7478422522544861,
      "learning_rate": 3.884951105860734e-05,
      "logits/chosen": 2.5990116596221924,
      "logits/rejected": 2.7875983715057373,
      "logps/chosen": -252.07736206054688,
      "logps/rejected": -305.4432678222656,
      "loss": 0.4281,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.948803186416626,
      "rewards/margins": 3.3381354808807373,
      "rewards/rejected": -5.286938667297363,
      "step": 13600
    },
    {
      "epoch": 0.6703828122115988,
      "grad_norm": 1.1341302394866943,
      "learning_rate": 3.8833103629323356e-05,
      "logits/chosen": 2.5041470527648926,
      "logits/rejected": 2.8036394119262695,
      "logps/chosen": -223.79849243164062,
      "logps/rejected": -262.2901916503906,
      "loss": 0.5016,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7686388492584229,
      "rewards/margins": 2.758035898208618,
      "rewards/rejected": -4.526674747467041,
      "step": 13620
    },
    {
      "epoch": 0.6713672216274749,
      "grad_norm": 1.8250328302383423,
      "learning_rate": 3.881669620003938e-05,
      "logits/chosen": 2.40500545501709,
      "logits/rejected": 2.7388148307800293,
      "logps/chosen": -273.6684875488281,
      "logps/rejected": -264.0292053222656,
      "loss": 0.4834,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.4716506004333496,
      "rewards/margins": 2.943943500518799,
      "rewards/rejected": -5.415594577789307,
      "step": 13640
    },
    {
      "epoch": 0.6723516310433509,
      "grad_norm": 8.428571701049805,
      "learning_rate": 3.8800288770755397e-05,
      "logits/chosen": 2.8610968589782715,
      "logits/rejected": 3.0996906757354736,
      "logps/chosen": -252.47091674804688,
      "logps/rejected": -260.8023376464844,
      "loss": 0.5097,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.6248152256011963,
      "rewards/margins": 2.656402826309204,
      "rewards/rejected": -5.2812180519104,
      "step": 13660
    },
    {
      "epoch": 0.673336040459227,
      "grad_norm": 6.398179531097412,
      "learning_rate": 3.878388134147142e-05,
      "logits/chosen": 2.4899580478668213,
      "logits/rejected": 2.843867778778076,
      "logps/chosen": -262.17694091796875,
      "logps/rejected": -273.4400939941406,
      "loss": 0.4974,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.496777057647705,
      "rewards/margins": 3.102832794189453,
      "rewards/rejected": -5.599609851837158,
      "step": 13680
    },
    {
      "epoch": 0.6743204498751031,
      "grad_norm": 4.874876022338867,
      "learning_rate": 3.8767473912187444e-05,
      "logits/chosen": 2.506878137588501,
      "logits/rejected": 2.9640755653381348,
      "logps/chosen": -250.95291137695312,
      "logps/rejected": -267.5967712402344,
      "loss": 0.533,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.9450976848602295,
      "rewards/margins": 2.8775227069854736,
      "rewards/rejected": -5.822620391845703,
      "step": 13700
    },
    {
      "epoch": 0.6753048592909792,
      "grad_norm": 5.2340288162231445,
      "learning_rate": 3.875106648290346e-05,
      "logits/chosen": 2.8802998065948486,
      "logits/rejected": 2.975219249725342,
      "logps/chosen": -251.8772430419922,
      "logps/rejected": -284.8885498046875,
      "loss": 0.5011,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -3.0041704177856445,
      "rewards/margins": 2.5433826446533203,
      "rewards/rejected": -5.547553062438965,
      "step": 13720
    },
    {
      "epoch": 0.6762892687068551,
      "grad_norm": 4.00788688659668,
      "learning_rate": 3.8734659053619484e-05,
      "logits/chosen": 2.841488838195801,
      "logits/rejected": 3.3089072704315186,
      "logps/chosen": -276.6146545410156,
      "logps/rejected": -259.7701416015625,
      "loss": 0.6655,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -3.043506383895874,
      "rewards/margins": 2.361851215362549,
      "rewards/rejected": -5.405357837677002,
      "step": 13740
    },
    {
      "epoch": 0.6772736781227312,
      "grad_norm": 1.3611631393432617,
      "learning_rate": 3.87182516243355e-05,
      "logits/chosen": 2.9242026805877686,
      "logits/rejected": 3.224029064178467,
      "logps/chosen": -291.32635498046875,
      "logps/rejected": -294.0884094238281,
      "loss": 0.5366,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.979043483734131,
      "rewards/margins": 2.1473209857940674,
      "rewards/rejected": -5.126364231109619,
      "step": 13760
    },
    {
      "epoch": 0.6782580875386073,
      "grad_norm": 6.594446182250977,
      "learning_rate": 3.8701844195051525e-05,
      "logits/chosen": 2.7648863792419434,
      "logits/rejected": 3.0144529342651367,
      "logps/chosen": -258.51617431640625,
      "logps/rejected": -317.5171203613281,
      "loss": 0.4352,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.3740971088409424,
      "rewards/margins": 2.5546557903289795,
      "rewards/rejected": -4.92875337600708,
      "step": 13780
    },
    {
      "epoch": 0.6792424969544834,
      "grad_norm": 2.3911499977111816,
      "learning_rate": 3.868543676576754e-05,
      "logits/chosen": 2.811718702316284,
      "logits/rejected": 3.1930174827575684,
      "logps/chosen": -276.33966064453125,
      "logps/rejected": -302.9525146484375,
      "loss": 0.4205,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.515885353088379,
      "rewards/margins": 2.5446295738220215,
      "rewards/rejected": -5.0605149269104,
      "step": 13800
    },
    {
      "epoch": 0.6802269063703594,
      "grad_norm": 3.9168975353240967,
      "learning_rate": 3.8669029336483565e-05,
      "logits/chosen": 2.717252016067505,
      "logits/rejected": 2.9795453548431396,
      "logps/chosen": -263.8600769042969,
      "logps/rejected": -278.8155517578125,
      "loss": 0.4548,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.2619972229003906,
      "rewards/margins": 2.434926748275757,
      "rewards/rejected": -4.696923732757568,
      "step": 13820
    },
    {
      "epoch": 0.6812113157862355,
      "grad_norm": 2.827563762664795,
      "learning_rate": 3.865262190719958e-05,
      "logits/chosen": 2.837329387664795,
      "logits/rejected": 2.998317241668701,
      "logps/chosen": -276.4222412109375,
      "logps/rejected": -276.3081970214844,
      "loss": 0.4942,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.1880290508270264,
      "rewards/margins": 2.8841755390167236,
      "rewards/rejected": -6.072205066680908,
      "step": 13840
    },
    {
      "epoch": 0.6821957252021116,
      "grad_norm": 3.324526071548462,
      "learning_rate": 3.86362144779156e-05,
      "logits/chosen": 2.7295081615448,
      "logits/rejected": 2.9580166339874268,
      "logps/chosen": -300.65679931640625,
      "logps/rejected": -319.0636291503906,
      "loss": 0.5733,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.544851303100586,
      "rewards/margins": 3.2606658935546875,
      "rewards/rejected": -5.805517673492432,
      "step": 13860
    },
    {
      "epoch": 0.6831801346179877,
      "grad_norm": 5.0539631843566895,
      "learning_rate": 3.861980704863162e-05,
      "logits/chosen": 2.694326877593994,
      "logits/rejected": 2.9178662300109863,
      "logps/chosen": -290.2032775878906,
      "logps/rejected": -340.3641052246094,
      "loss": 0.3714,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.8946237564086914,
      "rewards/margins": 3.67596697807312,
      "rewards/rejected": -6.570590972900391,
      "step": 13880
    },
    {
      "epoch": 0.6841645440338637,
      "grad_norm": 0.5751727223396301,
      "learning_rate": 3.860339961934764e-05,
      "logits/chosen": 2.716857433319092,
      "logits/rejected": 2.8477630615234375,
      "logps/chosen": -275.261474609375,
      "logps/rejected": -286.8026428222656,
      "loss": 0.5371,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.7927136421203613,
      "rewards/margins": 2.5640218257904053,
      "rewards/rejected": -5.356735706329346,
      "step": 13900
    },
    {
      "epoch": 0.6851489534497397,
      "grad_norm": 2.3428452014923096,
      "learning_rate": 3.858699219006366e-05,
      "logits/chosen": 2.789389133453369,
      "logits/rejected": 3.051889657974243,
      "logps/chosen": -241.78536987304688,
      "logps/rejected": -233.8958740234375,
      "loss": 0.5721,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.3969242572784424,
      "rewards/margins": 1.7531156539916992,
      "rewards/rejected": -4.150040149688721,
      "step": 13920
    },
    {
      "epoch": 0.6861333628656158,
      "grad_norm": 1.7909084558486938,
      "learning_rate": 3.857058476077968e-05,
      "logits/chosen": 3.0872275829315186,
      "logits/rejected": 3.2649924755096436,
      "logps/chosen": -292.5624694824219,
      "logps/rejected": -281.0660095214844,
      "loss": 0.5452,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.6855177879333496,
      "rewards/margins": 2.701122760772705,
      "rewards/rejected": -5.386641025543213,
      "step": 13940
    },
    {
      "epoch": 0.6871177722814918,
      "grad_norm": 3.9162683486938477,
      "learning_rate": 3.85541773314957e-05,
      "logits/chosen": 3.069423198699951,
      "logits/rejected": 3.2348034381866455,
      "logps/chosen": -283.82843017578125,
      "logps/rejected": -285.88470458984375,
      "loss": 0.4965,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.528233528137207,
      "rewards/margins": 2.648703098297119,
      "rewards/rejected": -5.176936149597168,
      "step": 13960
    },
    {
      "epoch": 0.6881021816973679,
      "grad_norm": 1.4071214199066162,
      "learning_rate": 3.853776990221172e-05,
      "logits/chosen": 2.8534839153289795,
      "logits/rejected": 3.0702879428863525,
      "logps/chosen": -245.0069580078125,
      "logps/rejected": -268.724853515625,
      "loss": 0.5845,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.2594847679138184,
      "rewards/margins": 2.425273895263672,
      "rewards/rejected": -4.684758186340332,
      "step": 13980
    },
    {
      "epoch": 0.689086591113244,
      "grad_norm": 0.6190526485443115,
      "learning_rate": 3.8521362472927744e-05,
      "logits/chosen": 3.005673885345459,
      "logits/rejected": 3.070551633834839,
      "logps/chosen": -276.07489013671875,
      "logps/rejected": -281.21905517578125,
      "loss": 0.5191,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.3040101528167725,
      "rewards/margins": 2.305568218231201,
      "rewards/rejected": -4.6095781326293945,
      "step": 14000
    },
    {
      "epoch": 0.6900710005291201,
      "grad_norm": 2.3938002586364746,
      "learning_rate": 3.850495504364377e-05,
      "logits/chosen": 2.5281436443328857,
      "logits/rejected": 2.739701747894287,
      "logps/chosen": -256.495361328125,
      "logps/rejected": -261.81573486328125,
      "loss": 0.413,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.137155771255493,
      "rewards/margins": 2.4565234184265137,
      "rewards/rejected": -4.5936784744262695,
      "step": 14020
    },
    {
      "epoch": 0.6910554099449961,
      "grad_norm": 5.435007095336914,
      "learning_rate": 3.8488547614359784e-05,
      "logits/chosen": 2.704572916030884,
      "logits/rejected": 2.989356279373169,
      "logps/chosen": -299.4645690917969,
      "logps/rejected": -286.23248291015625,
      "loss": 0.4835,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.602541923522949,
      "rewards/margins": 2.7712814807891846,
      "rewards/rejected": -5.3738226890563965,
      "step": 14040
    },
    {
      "epoch": 0.6920398193608722,
      "grad_norm": 3.2016520500183105,
      "learning_rate": 3.847214018507581e-05,
      "logits/chosen": 2.8671371936798096,
      "logits/rejected": 3.1816649436950684,
      "logps/chosen": -226.77029418945312,
      "logps/rejected": -249.7066650390625,
      "loss": 0.5308,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.066474676132202,
      "rewards/margins": 3.0838160514831543,
      "rewards/rejected": -5.150290489196777,
      "step": 14060
    },
    {
      "epoch": 0.6930242287767483,
      "grad_norm": 3.5706634521484375,
      "learning_rate": 3.8455732755791825e-05,
      "logits/chosen": 2.7824501991271973,
      "logits/rejected": 2.893878936767578,
      "logps/chosen": -263.3230895996094,
      "logps/rejected": -283.14678955078125,
      "loss": 0.5044,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.0939836502075195,
      "rewards/margins": 2.029374122619629,
      "rewards/rejected": -4.12335729598999,
      "step": 14080
    },
    {
      "epoch": 0.6940086381926243,
      "grad_norm": 3.8278417587280273,
      "learning_rate": 3.843932532650785e-05,
      "logits/chosen": 2.838618040084839,
      "logits/rejected": 2.8171474933624268,
      "logps/chosen": -286.69842529296875,
      "logps/rejected": -282.1794128417969,
      "loss": 0.7458,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.175739049911499,
      "rewards/margins": 1.8556478023529053,
      "rewards/rejected": -4.031386375427246,
      "step": 14100
    },
    {
      "epoch": 0.6949930476085003,
      "grad_norm": 0.8023565411567688,
      "learning_rate": 3.8422917897223865e-05,
      "logits/chosen": 2.7439284324645996,
      "logits/rejected": 2.9464945793151855,
      "logps/chosen": -246.0240020751953,
      "logps/rejected": -258.9035339355469,
      "loss": 0.4828,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9448055028915405,
      "rewards/margins": 2.4742002487182617,
      "rewards/rejected": -4.419005870819092,
      "step": 14120
    },
    {
      "epoch": 0.6959774570243764,
      "grad_norm": 2.255840539932251,
      "learning_rate": 3.840651046793988e-05,
      "logits/chosen": 2.912797451019287,
      "logits/rejected": 2.9996337890625,
      "logps/chosen": -257.6463623046875,
      "logps/rejected": -300.07135009765625,
      "loss": 0.582,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6906802654266357,
      "rewards/margins": 2.029411792755127,
      "rewards/rejected": -3.7200920581817627,
      "step": 14140
    },
    {
      "epoch": 0.6969618664402525,
      "grad_norm": 3.152658462524414,
      "learning_rate": 3.8390103038655906e-05,
      "logits/chosen": 2.8692409992218018,
      "logits/rejected": 2.910919666290283,
      "logps/chosen": -250.17880249023438,
      "logps/rejected": -282.1105651855469,
      "loss": 0.4077,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5484923124313354,
      "rewards/margins": 2.7243781089782715,
      "rewards/rejected": -4.2728705406188965,
      "step": 14160
    },
    {
      "epoch": 0.6979462758561286,
      "grad_norm": 2.4490139484405518,
      "learning_rate": 3.837369560937192e-05,
      "logits/chosen": 2.437223434448242,
      "logits/rejected": 2.7123372554779053,
      "logps/chosen": -259.503662109375,
      "logps/rejected": -249.2456512451172,
      "loss": 0.4975,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.793988823890686,
      "rewards/margins": 2.099186658859253,
      "rewards/rejected": -3.8931756019592285,
      "step": 14180
    },
    {
      "epoch": 0.6989306852720046,
      "grad_norm": 1.2419439554214478,
      "learning_rate": 3.8357288180087946e-05,
      "logits/chosen": 3.106180191040039,
      "logits/rejected": 3.2912139892578125,
      "logps/chosen": -246.0151824951172,
      "logps/rejected": -262.4153747558594,
      "loss": 0.3642,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.2256598472595215,
      "rewards/margins": 3.006765604019165,
      "rewards/rejected": -5.232425212860107,
      "step": 14200
    },
    {
      "epoch": 0.6999150946878807,
      "grad_norm": 4.654540061950684,
      "learning_rate": 3.834088075080396e-05,
      "logits/chosen": 2.949908971786499,
      "logits/rejected": 3.13376784324646,
      "logps/chosen": -265.9791564941406,
      "logps/rejected": -263.8820495605469,
      "loss": 0.3375,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.3601057529449463,
      "rewards/margins": 2.9317104816436768,
      "rewards/rejected": -5.291815757751465,
      "step": 14220
    },
    {
      "epoch": 0.7008995041037568,
      "grad_norm": 1.217180609703064,
      "learning_rate": 3.8324473321519986e-05,
      "logits/chosen": 2.604666233062744,
      "logits/rejected": 2.8142077922821045,
      "logps/chosen": -255.3042755126953,
      "logps/rejected": -304.4220886230469,
      "loss": 0.4396,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.693129062652588,
      "rewards/margins": 3.019693374633789,
      "rewards/rejected": -5.712822437286377,
      "step": 14240
    },
    {
      "epoch": 0.7018839135196329,
      "grad_norm": 2.086035966873169,
      "learning_rate": 3.8308065892236e-05,
      "logits/chosen": 2.416290760040283,
      "logits/rejected": 2.668069362640381,
      "logps/chosen": -278.8875427246094,
      "logps/rejected": -290.8135986328125,
      "loss": 0.5272,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.69942307472229,
      "rewards/margins": 2.768763780593872,
      "rewards/rejected": -5.46818733215332,
      "step": 14260
    },
    {
      "epoch": 0.7028683229355088,
      "grad_norm": 0.950890302658081,
      "learning_rate": 3.829165846295203e-05,
      "logits/chosen": 2.626591205596924,
      "logits/rejected": 2.9985358715057373,
      "logps/chosen": -283.924072265625,
      "logps/rejected": -305.6534118652344,
      "loss": 0.6613,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.439131259918213,
      "rewards/margins": 2.459599018096924,
      "rewards/rejected": -4.898730278015137,
      "step": 14280
    },
    {
      "epoch": 0.7038527323513849,
      "grad_norm": 6.475663185119629,
      "learning_rate": 3.8275251033668044e-05,
      "logits/chosen": 2.5374107360839844,
      "logits/rejected": 2.695765733718872,
      "logps/chosen": -268.14007568359375,
      "logps/rejected": -282.07611083984375,
      "loss": 0.7717,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.216796875,
      "rewards/margins": 1.8326351642608643,
      "rewards/rejected": -4.049431800842285,
      "step": 14300
    },
    {
      "epoch": 0.704837141767261,
      "grad_norm": 4.585400104522705,
      "learning_rate": 3.825884360438407e-05,
      "logits/chosen": 2.653289318084717,
      "logits/rejected": 2.815415859222412,
      "logps/chosen": -258.6697998046875,
      "logps/rejected": -260.51776123046875,
      "loss": 0.5308,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.01833438873291,
      "rewards/margins": 1.7715225219726562,
      "rewards/rejected": -3.7898566722869873,
      "step": 14320
    },
    {
      "epoch": 0.705821551183137,
      "grad_norm": 3.394624710083008,
      "learning_rate": 3.824243617510009e-05,
      "logits/chosen": 2.4611105918884277,
      "logits/rejected": 2.7086756229400635,
      "logps/chosen": -259.9437561035156,
      "logps/rejected": -274.9537658691406,
      "loss": 0.449,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.903350830078125,
      "rewards/margins": 2.1832308769226074,
      "rewards/rejected": -4.086581707000732,
      "step": 14340
    },
    {
      "epoch": 0.7068059605990131,
      "grad_norm": 5.003801345825195,
      "learning_rate": 3.822602874581611e-05,
      "logits/chosen": 2.6146841049194336,
      "logits/rejected": 2.8034508228302,
      "logps/chosen": -298.0511779785156,
      "logps/rejected": -278.71044921875,
      "loss": 0.559,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.8815991878509521,
      "rewards/margins": 1.9874389171600342,
      "rewards/rejected": -3.8690383434295654,
      "step": 14360
    },
    {
      "epoch": 0.7077903700148892,
      "grad_norm": 2.3602123260498047,
      "learning_rate": 3.820962131653213e-05,
      "logits/chosen": 2.860410213470459,
      "logits/rejected": 2.8813350200653076,
      "logps/chosen": -264.8102722167969,
      "logps/rejected": -252.23574829101562,
      "loss": 0.5572,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9035346508026123,
      "rewards/margins": 1.9952290058135986,
      "rewards/rejected": -3.8987631797790527,
      "step": 14380
    },
    {
      "epoch": 0.7087747794307653,
      "grad_norm": 1.1570863723754883,
      "learning_rate": 3.819321388724815e-05,
      "logits/chosen": 2.7347912788391113,
      "logits/rejected": 2.8235340118408203,
      "logps/chosen": -251.0843963623047,
      "logps/rejected": -267.70184326171875,
      "loss": 0.5132,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5316123962402344,
      "rewards/margins": 2.222304344177246,
      "rewards/rejected": -3.7539162635803223,
      "step": 14400
    },
    {
      "epoch": 0.7097591888466414,
      "grad_norm": 1.0118458271026611,
      "learning_rate": 3.817680645796417e-05,
      "logits/chosen": 2.698845863342285,
      "logits/rejected": 3.054190158843994,
      "logps/chosen": -239.001708984375,
      "logps/rejected": -263.4767761230469,
      "loss": 0.4232,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.649920105934143,
      "rewards/margins": 2.5141241550445557,
      "rewards/rejected": -4.164044380187988,
      "step": 14420
    },
    {
      "epoch": 0.7107435982625174,
      "grad_norm": 7.9305596351623535,
      "learning_rate": 3.816039902868019e-05,
      "logits/chosen": 2.429790735244751,
      "logits/rejected": 2.615882396697998,
      "logps/chosen": -242.3623046875,
      "logps/rejected": -252.2212677001953,
      "loss": 0.6011,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.7094299793243408,
      "rewards/margins": 1.9909741878509521,
      "rewards/rejected": -3.700404405593872,
      "step": 14440
    },
    {
      "epoch": 0.7117280076783934,
      "grad_norm": 3.4827630519866943,
      "learning_rate": 3.8143991599396205e-05,
      "logits/chosen": 2.5903942584991455,
      "logits/rejected": 2.6751017570495605,
      "logps/chosen": -253.3821258544922,
      "logps/rejected": -267.2420654296875,
      "loss": 0.6362,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0023837089538574,
      "rewards/margins": 2.2325453758239746,
      "rewards/rejected": -4.234929084777832,
      "step": 14460
    },
    {
      "epoch": 0.7127124170942695,
      "grad_norm": 2.351313591003418,
      "learning_rate": 3.812758417011223e-05,
      "logits/chosen": 2.8372323513031006,
      "logits/rejected": 2.8655025959014893,
      "logps/chosen": -274.46112060546875,
      "logps/rejected": -276.098388671875,
      "loss": 0.3814,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.4203484058380127,
      "rewards/margins": 2.657979726791382,
      "rewards/rejected": -4.0783281326293945,
      "step": 14480
    },
    {
      "epoch": 0.7136968265101455,
      "grad_norm": 3.5661089420318604,
      "learning_rate": 3.8111176740828246e-05,
      "logits/chosen": 2.7820448875427246,
      "logits/rejected": 3.041095495223999,
      "logps/chosen": -253.7382354736328,
      "logps/rejected": -267.3102722167969,
      "loss": 0.4031,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5538303852081299,
      "rewards/margins": 2.4131293296813965,
      "rewards/rejected": -3.9669597148895264,
      "step": 14500
    },
    {
      "epoch": 0.7146812359260216,
      "grad_norm": 3.3894269466400146,
      "learning_rate": 3.809476931154427e-05,
      "logits/chosen": 2.717273712158203,
      "logits/rejected": 2.975615978240967,
      "logps/chosen": -278.41796875,
      "logps/rejected": -306.36016845703125,
      "loss": 0.4578,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8204925060272217,
      "rewards/margins": 2.4703023433685303,
      "rewards/rejected": -4.29079532623291,
      "step": 14520
    },
    {
      "epoch": 0.7156656453418977,
      "grad_norm": 3.2399628162384033,
      "learning_rate": 3.8078361882260286e-05,
      "logits/chosen": 2.68257212638855,
      "logits/rejected": 2.872464418411255,
      "logps/chosen": -299.3361511230469,
      "logps/rejected": -283.11065673828125,
      "loss": 0.4591,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.0444388389587402,
      "rewards/margins": 2.275923490524292,
      "rewards/rejected": -4.320362567901611,
      "step": 14540
    },
    {
      "epoch": 0.7166500547577738,
      "grad_norm": 4.4225263595581055,
      "learning_rate": 3.806195445297631e-05,
      "logits/chosen": 2.6157383918762207,
      "logits/rejected": 2.886115312576294,
      "logps/chosen": -230.3986358642578,
      "logps/rejected": -242.4092254638672,
      "loss": 0.4605,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.8703458309173584,
      "rewards/margins": 2.390197515487671,
      "rewards/rejected": -4.260542869567871,
      "step": 14560
    },
    {
      "epoch": 0.7176344641736498,
      "grad_norm": 3.1094861030578613,
      "learning_rate": 3.804554702369233e-05,
      "logits/chosen": 2.5395750999450684,
      "logits/rejected": 3.075780153274536,
      "logps/chosen": -289.858154296875,
      "logps/rejected": -331.7220153808594,
      "loss": 0.3224,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.2299740314483643,
      "rewards/margins": 3.367067813873291,
      "rewards/rejected": -5.597041130065918,
      "step": 14580
    },
    {
      "epoch": 0.7186188735895259,
      "grad_norm": 0.6295198798179626,
      "learning_rate": 3.802913959440835e-05,
      "logits/chosen": 2.3183071613311768,
      "logits/rejected": 2.7427303791046143,
      "logps/chosen": -261.35797119140625,
      "logps/rejected": -280.8729553222656,
      "loss": 0.3676,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.152039051055908,
      "rewards/margins": 2.793168306350708,
      "rewards/rejected": -4.945207118988037,
      "step": 14600
    },
    {
      "epoch": 0.719603283005402,
      "grad_norm": 2.0303008556365967,
      "learning_rate": 3.801273216512437e-05,
      "logits/chosen": 2.4740231037139893,
      "logits/rejected": 2.7386317253112793,
      "logps/chosen": -268.4482727050781,
      "logps/rejected": -265.4409484863281,
      "loss": 0.5193,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.4074790477752686,
      "rewards/margins": 2.389944553375244,
      "rewards/rejected": -4.797423839569092,
      "step": 14620
    },
    {
      "epoch": 0.720587692421278,
      "grad_norm": 3.6711502075195312,
      "learning_rate": 3.799632473584039e-05,
      "logits/chosen": 2.3588054180145264,
      "logits/rejected": 2.533684253692627,
      "logps/chosen": -257.9100036621094,
      "logps/rejected": -299.72698974609375,
      "loss": 0.5739,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.1088945865631104,
      "rewards/margins": 2.6381001472473145,
      "rewards/rejected": -4.746994972229004,
      "step": 14640
    },
    {
      "epoch": 0.721572101837154,
      "grad_norm": 1.020976185798645,
      "learning_rate": 3.7979917306556415e-05,
      "logits/chosen": 2.5645828247070312,
      "logits/rejected": 3.023699998855591,
      "logps/chosen": -273.09222412109375,
      "logps/rejected": -253.5192108154297,
      "loss": 0.429,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.4771473407745361,
      "rewards/margins": 2.871549129486084,
      "rewards/rejected": -4.348696708679199,
      "step": 14660
    },
    {
      "epoch": 0.7225565112530301,
      "grad_norm": 2.062861442565918,
      "learning_rate": 3.796350987727243e-05,
      "logits/chosen": 2.761864423751831,
      "logits/rejected": 2.8512091636657715,
      "logps/chosen": -242.12356567382812,
      "logps/rejected": -257.24200439453125,
      "loss": 0.3461,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4188768863677979,
      "rewards/margins": 2.5411155223846436,
      "rewards/rejected": -3.9599926471710205,
      "step": 14680
    },
    {
      "epoch": 0.7235409206689062,
      "grad_norm": 3.4980218410491943,
      "learning_rate": 3.7947102447988455e-05,
      "logits/chosen": 2.708862781524658,
      "logits/rejected": 2.9290528297424316,
      "logps/chosen": -256.0716857910156,
      "logps/rejected": -288.5441589355469,
      "loss": 0.5988,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.6412441730499268,
      "rewards/margins": 2.0590083599090576,
      "rewards/rejected": -3.7002525329589844,
      "step": 14700
    },
    {
      "epoch": 0.7245253300847823,
      "grad_norm": 3.772993326187134,
      "learning_rate": 3.793069501870447e-05,
      "logits/chosen": 2.8209807872772217,
      "logits/rejected": 2.9518799781799316,
      "logps/chosen": -244.3249053955078,
      "logps/rejected": -241.403076171875,
      "loss": 0.7782,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.234520673751831,
      "rewards/margins": 1.1817615032196045,
      "rewards/rejected": -3.4162821769714355,
      "step": 14720
    },
    {
      "epoch": 0.7255097395006583,
      "grad_norm": 1.2965861558914185,
      "learning_rate": 3.7914287589420495e-05,
      "logits/chosen": 2.4880788326263428,
      "logits/rejected": 2.748170852661133,
      "logps/chosen": -263.5808410644531,
      "logps/rejected": -262.279052734375,
      "loss": 0.5964,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5422502756118774,
      "rewards/margins": 2.228861093521118,
      "rewards/rejected": -3.771111249923706,
      "step": 14740
    },
    {
      "epoch": 0.7264941489165344,
      "grad_norm": 1.8693917989730835,
      "learning_rate": 3.789788016013651e-05,
      "logits/chosen": 2.7303199768066406,
      "logits/rejected": 2.9338488578796387,
      "logps/chosen": -268.34356689453125,
      "logps/rejected": -275.5627136230469,
      "loss": 0.5169,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.623110055923462,
      "rewards/margins": 1.996543288230896,
      "rewards/rejected": -3.6196532249450684,
      "step": 14760
    },
    {
      "epoch": 0.7274785583324105,
      "grad_norm": 1.8347936868667603,
      "learning_rate": 3.788147273085253e-05,
      "logits/chosen": 2.515298843383789,
      "logits/rejected": 2.7308526039123535,
      "logps/chosen": -286.45709228515625,
      "logps/rejected": -277.6018371582031,
      "loss": 0.4464,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.6568443775177002,
      "rewards/margins": 2.467825412750244,
      "rewards/rejected": -4.124669075012207,
      "step": 14780
    },
    {
      "epoch": 0.7284629677482866,
      "grad_norm": 5.806072235107422,
      "learning_rate": 3.786506530156855e-05,
      "logits/chosen": 2.601736307144165,
      "logits/rejected": 2.8174755573272705,
      "logps/chosen": -240.94970703125,
      "logps/rejected": -252.97915649414062,
      "loss": 0.5289,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.776653528213501,
      "rewards/margins": 2.3158793449401855,
      "rewards/rejected": -4.092532634735107,
      "step": 14800
    },
    {
      "epoch": 0.7294473771641625,
      "grad_norm": 2.9392282962799072,
      "learning_rate": 3.784865787228457e-05,
      "logits/chosen": 2.5111382007598877,
      "logits/rejected": 2.7116963863372803,
      "logps/chosen": -272.9493713378906,
      "logps/rejected": -284.27911376953125,
      "loss": 0.5273,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.718353033065796,
      "rewards/margins": 2.475276231765747,
      "rewards/rejected": -4.193629264831543,
      "step": 14820
    },
    {
      "epoch": 0.7304317865800386,
      "grad_norm": 5.461724281311035,
      "learning_rate": 3.783225044300059e-05,
      "logits/chosen": 2.901254177093506,
      "logits/rejected": 3.100339889526367,
      "logps/chosen": -277.10467529296875,
      "logps/rejected": -299.3042907714844,
      "loss": 0.4665,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.05250883102417,
      "rewards/margins": 2.3975539207458496,
      "rewards/rejected": -4.4500627517700195,
      "step": 14840
    },
    {
      "epoch": 0.7314161959959147,
      "grad_norm": 3.504931926727295,
      "learning_rate": 3.781584301371661e-05,
      "logits/chosen": 2.9067978858947754,
      "logits/rejected": 2.8845152854919434,
      "logps/chosen": -264.87738037109375,
      "logps/rejected": -283.2252502441406,
      "loss": 0.5957,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9293321371078491,
      "rewards/margins": 1.9769630432128906,
      "rewards/rejected": -3.9062952995300293,
      "step": 14860
    },
    {
      "epoch": 0.7324006054117908,
      "grad_norm": 2.8728702068328857,
      "learning_rate": 3.780025595589683e-05,
      "logits/chosen": 2.43149995803833,
      "logits/rejected": 2.6275482177734375,
      "logps/chosen": -257.55450439453125,
      "logps/rejected": -279.00531005859375,
      "loss": 0.5164,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7964063882827759,
      "rewards/margins": 2.0039331912994385,
      "rewards/rejected": -3.8003392219543457,
      "step": 14880
    },
    {
      "epoch": 0.7333850148276668,
      "grad_norm": 2.2054941654205322,
      "learning_rate": 3.778384852661285e-05,
      "logits/chosen": 2.5106310844421387,
      "logits/rejected": 2.7759807109832764,
      "logps/chosen": -244.4429168701172,
      "logps/rejected": -302.3607482910156,
      "loss": 0.4113,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6282011270523071,
      "rewards/margins": 3.3740546703338623,
      "rewards/rejected": -5.002255916595459,
      "step": 14900
    },
    {
      "epoch": 0.7343694242435429,
      "grad_norm": 3.942589282989502,
      "learning_rate": 3.776744109732887e-05,
      "logits/chosen": 2.60009503364563,
      "logits/rejected": 2.8167386054992676,
      "logps/chosen": -274.7919006347656,
      "logps/rejected": -286.56634521484375,
      "loss": 0.4322,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.477764368057251,
      "rewards/margins": 3.2264347076416016,
      "rewards/rejected": -4.704198837280273,
      "step": 14920
    },
    {
      "epoch": 0.735353833659419,
      "grad_norm": 4.648324489593506,
      "learning_rate": 3.775103366804489e-05,
      "logits/chosen": 2.522000312805176,
      "logits/rejected": 2.7172365188598633,
      "logps/chosen": -248.9720458984375,
      "logps/rejected": -244.31393432617188,
      "loss": 0.5802,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9122438430786133,
      "rewards/margins": 2.4181578159332275,
      "rewards/rejected": -4.330401420593262,
      "step": 14940
    },
    {
      "epoch": 0.736338243075295,
      "grad_norm": 3.153157949447632,
      "learning_rate": 3.773462623876091e-05,
      "logits/chosen": 2.8084957599639893,
      "logits/rejected": 2.832920551300049,
      "logps/chosen": -283.5921325683594,
      "logps/rejected": -304.39520263671875,
      "loss": 0.5389,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.9776312112808228,
      "rewards/margins": 2.5234971046447754,
      "rewards/rejected": -4.501128196716309,
      "step": 14960
    },
    {
      "epoch": 0.7373226524911711,
      "grad_norm": 7.9168291091918945,
      "learning_rate": 3.771821880947693e-05,
      "logits/chosen": 2.396768569946289,
      "logits/rejected": 2.603489637374878,
      "logps/chosen": -281.76971435546875,
      "logps/rejected": -271.0746765136719,
      "loss": 0.8616,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.2184078693389893,
      "rewards/margins": 1.832061529159546,
      "rewards/rejected": -4.050469398498535,
      "step": 14980
    },
    {
      "epoch": 0.7383070619070471,
      "grad_norm": 4.474634647369385,
      "learning_rate": 3.770181138019295e-05,
      "logits/chosen": 2.555694818496704,
      "logits/rejected": 2.853956699371338,
      "logps/chosen": -258.3180847167969,
      "logps/rejected": -255.76785278320312,
      "loss": 0.4663,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6702905893325806,
      "rewards/margins": 2.0549941062927246,
      "rewards/rejected": -3.725285053253174,
      "step": 15000
    },
    {
      "epoch": 0.7392914713229232,
      "grad_norm": 1.5122299194335938,
      "learning_rate": 3.768540395090897e-05,
      "logits/chosen": 2.9003231525421143,
      "logits/rejected": 3.1786906719207764,
      "logps/chosen": -263.2513122558594,
      "logps/rejected": -246.6077117919922,
      "loss": 0.5093,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4635648727416992,
      "rewards/margins": 1.8664886951446533,
      "rewards/rejected": -3.3300528526306152,
      "step": 15020
    },
    {
      "epoch": 0.7402758807387992,
      "grad_norm": 1.2245140075683594,
      "learning_rate": 3.7668996521625e-05,
      "logits/chosen": 2.8134398460388184,
      "logits/rejected": 3.033644199371338,
      "logps/chosen": -295.3100280761719,
      "logps/rejected": -319.3514404296875,
      "loss": 0.5462,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.9379371404647827,
      "rewards/margins": 2.3782219886779785,
      "rewards/rejected": -4.316159248352051,
      "step": 15040
    },
    {
      "epoch": 0.7412602901546753,
      "grad_norm": 3.071793556213379,
      "learning_rate": 3.7652589092341014e-05,
      "logits/chosen": 2.605437755584717,
      "logits/rejected": 2.7992119789123535,
      "logps/chosen": -267.57958984375,
      "logps/rejected": -255.84494018554688,
      "loss": 0.417,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.913849115371704,
      "rewards/margins": 2.471902370452881,
      "rewards/rejected": -4.385751247406006,
      "step": 15060
    },
    {
      "epoch": 0.7422446995705514,
      "grad_norm": 1.413204312324524,
      "learning_rate": 3.763618166305704e-05,
      "logits/chosen": 2.526580810546875,
      "logits/rejected": 2.700770616531372,
      "logps/chosen": -278.3785095214844,
      "logps/rejected": -291.7465515136719,
      "loss": 0.4196,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.941293716430664,
      "rewards/margins": 2.7478747367858887,
      "rewards/rejected": -4.689168453216553,
      "step": 15080
    },
    {
      "epoch": 0.7432291089864275,
      "grad_norm": 5.917830944061279,
      "learning_rate": 3.7619774233773054e-05,
      "logits/chosen": 2.480628490447998,
      "logits/rejected": 2.6529507637023926,
      "logps/chosen": -260.3484191894531,
      "logps/rejected": -280.56146240234375,
      "loss": 0.4838,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.423624038696289,
      "rewards/margins": 2.304546356201172,
      "rewards/rejected": -4.728170394897461,
      "step": 15100
    },
    {
      "epoch": 0.7442135184023035,
      "grad_norm": 5.8122124671936035,
      "learning_rate": 3.760336680448908e-05,
      "logits/chosen": 2.720503330230713,
      "logits/rejected": 2.858703374862671,
      "logps/chosen": -263.8725891113281,
      "logps/rejected": -245.3358917236328,
      "loss": 0.6848,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.8927189111709595,
      "rewards/margins": 1.9062764644622803,
      "rewards/rejected": -3.798994779586792,
      "step": 15120
    },
    {
      "epoch": 0.7451979278181796,
      "grad_norm": 1.1344656944274902,
      "learning_rate": 3.7586959375205095e-05,
      "logits/chosen": 2.4989447593688965,
      "logits/rejected": 2.8870677947998047,
      "logps/chosen": -253.94644165039062,
      "logps/rejected": -272.3868408203125,
      "loss": 0.6075,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0207877159118652,
      "rewards/margins": 2.049774408340454,
      "rewards/rejected": -4.07056188583374,
      "step": 15140
    },
    {
      "epoch": 0.7461823372340557,
      "grad_norm": 2.0138707160949707,
      "learning_rate": 3.757055194592112e-05,
      "logits/chosen": 2.9021553993225098,
      "logits/rejected": 3.0667691230773926,
      "logps/chosen": -253.71975708007812,
      "logps/rejected": -254.05117797851562,
      "loss": 0.4014,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5538461208343506,
      "rewards/margins": 2.522158145904541,
      "rewards/rejected": -4.076004981994629,
      "step": 15160
    },
    {
      "epoch": 0.7471667466499317,
      "grad_norm": 2.7541720867156982,
      "learning_rate": 3.7554144516637135e-05,
      "logits/chosen": 2.6613807678222656,
      "logits/rejected": 2.807579517364502,
      "logps/chosen": -272.41693115234375,
      "logps/rejected": -246.444091796875,
      "loss": 0.5207,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.5493108034133911,
      "rewards/margins": 1.9302380084991455,
      "rewards/rejected": -3.479548692703247,
      "step": 15180
    },
    {
      "epoch": 0.7481511560658077,
      "grad_norm": 5.798998832702637,
      "learning_rate": 3.753773708735315e-05,
      "logits/chosen": 2.5410068035125732,
      "logits/rejected": 2.5862555503845215,
      "logps/chosen": -269.55731201171875,
      "logps/rejected": -262.06512451171875,
      "loss": 0.6525,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.6388593912124634,
      "rewards/margins": 1.7756669521331787,
      "rewards/rejected": -3.4145264625549316,
      "step": 15200
    },
    {
      "epoch": 0.7491355654816838,
      "grad_norm": 1.1987133026123047,
      "learning_rate": 3.7521329658069176e-05,
      "logits/chosen": 2.6343510150909424,
      "logits/rejected": 2.890943765640259,
      "logps/chosen": -277.80120849609375,
      "logps/rejected": -292.28741455078125,
      "loss": 0.3056,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.5113537311553955,
      "rewards/margins": 2.912112236022949,
      "rewards/rejected": -4.423465728759766,
      "step": 15220
    },
    {
      "epoch": 0.7501199748975599,
      "grad_norm": 4.217841148376465,
      "learning_rate": 3.750492222878519e-05,
      "logits/chosen": 2.8715615272521973,
      "logits/rejected": 2.8322081565856934,
      "logps/chosen": -264.74957275390625,
      "logps/rejected": -277.47332763671875,
      "loss": 0.6053,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.9530261754989624,
      "rewards/margins": 1.942452073097229,
      "rewards/rejected": -3.8954784870147705,
      "step": 15240
    },
    {
      "epoch": 0.751104384313436,
      "grad_norm": 2.0293946266174316,
      "learning_rate": 3.7488514799501216e-05,
      "logits/chosen": 2.615636110305786,
      "logits/rejected": 2.8437659740448,
      "logps/chosen": -268.3143310546875,
      "logps/rejected": -268.27728271484375,
      "loss": 0.5503,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.775693655014038,
      "rewards/margins": 1.8650972843170166,
      "rewards/rejected": -3.640791416168213,
      "step": 15260
    },
    {
      "epoch": 0.752088793729312,
      "grad_norm": 4.329200267791748,
      "learning_rate": 3.747210737021723e-05,
      "logits/chosen": 2.635908842086792,
      "logits/rejected": 2.79524564743042,
      "logps/chosen": -279.96820068359375,
      "logps/rejected": -304.5728759765625,
      "loss": 0.3913,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.4090723991394043,
      "rewards/margins": 2.886657238006592,
      "rewards/rejected": -5.295729637145996,
      "step": 15280
    },
    {
      "epoch": 0.7530732031451881,
      "grad_norm": 0.6553032994270325,
      "learning_rate": 3.7455699940933256e-05,
      "logits/chosen": 2.4872825145721436,
      "logits/rejected": 2.5683953762054443,
      "logps/chosen": -244.4324188232422,
      "logps/rejected": -277.20941162109375,
      "loss": 0.5473,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.674753189086914,
      "rewards/margins": 2.1805152893066406,
      "rewards/rejected": -3.855268955230713,
      "step": 15300
    },
    {
      "epoch": 0.7540576125610642,
      "grad_norm": 3.332576274871826,
      "learning_rate": 3.743929251164927e-05,
      "logits/chosen": 2.258164882659912,
      "logits/rejected": 2.3876590728759766,
      "logps/chosen": -247.75076293945312,
      "logps/rejected": -263.7326354980469,
      "loss": 0.4595,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.081000566482544,
      "rewards/margins": 1.9381306171417236,
      "rewards/rejected": -4.019130706787109,
      "step": 15320
    },
    {
      "epoch": 0.7550420219769403,
      "grad_norm": 0.8940337300300598,
      "learning_rate": 3.74228850823653e-05,
      "logits/chosen": 2.544890880584717,
      "logits/rejected": 2.708609104156494,
      "logps/chosen": -253.5850830078125,
      "logps/rejected": -243.55996704101562,
      "loss": 0.6009,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.9768314361572266,
      "rewards/margins": 1.7394605875015259,
      "rewards/rejected": -3.716291904449463,
      "step": 15340
    },
    {
      "epoch": 0.7560264313928162,
      "grad_norm": 2.1114351749420166,
      "learning_rate": 3.740647765308132e-05,
      "logits/chosen": 2.682539224624634,
      "logits/rejected": 2.728861093521118,
      "logps/chosen": -252.08828735351562,
      "logps/rejected": -270.6251525878906,
      "loss": 0.4595,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5361579656600952,
      "rewards/margins": 2.177598714828491,
      "rewards/rejected": -3.713756561279297,
      "step": 15360
    },
    {
      "epoch": 0.7570108408086923,
      "grad_norm": 3.8172202110290527,
      "learning_rate": 3.739007022379734e-05,
      "logits/chosen": 2.5289714336395264,
      "logits/rejected": 2.5961196422576904,
      "logps/chosen": -228.34567260742188,
      "logps/rejected": -263.3091125488281,
      "loss": 0.636,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.398190975189209,
      "rewards/margins": 2.355241298675537,
      "rewards/rejected": -4.753432273864746,
      "step": 15380
    },
    {
      "epoch": 0.7579952502245684,
      "grad_norm": 4.498027324676514,
      "learning_rate": 3.737366279451336e-05,
      "logits/chosen": 2.6480228900909424,
      "logits/rejected": 2.765044689178467,
      "logps/chosen": -283.21240234375,
      "logps/rejected": -288.4017333984375,
      "loss": 0.4659,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.6223140954971313,
      "rewards/margins": 2.3506009578704834,
      "rewards/rejected": -3.9729151725769043,
      "step": 15400
    },
    {
      "epoch": 0.7589796596404444,
      "grad_norm": 2.193530797958374,
      "learning_rate": 3.735725536522938e-05,
      "logits/chosen": 2.4964308738708496,
      "logits/rejected": 2.692206859588623,
      "logps/chosen": -249.9369354248047,
      "logps/rejected": -278.78070068359375,
      "loss": 0.5952,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.792507529258728,
      "rewards/margins": 2.101837635040283,
      "rewards/rejected": -3.8943450450897217,
      "step": 15420
    },
    {
      "epoch": 0.7599640690563205,
      "grad_norm": 1.3879966735839844,
      "learning_rate": 3.73408479359454e-05,
      "logits/chosen": 2.6019082069396973,
      "logits/rejected": 2.7961039543151855,
      "logps/chosen": -288.06524658203125,
      "logps/rejected": -284.91815185546875,
      "loss": 0.5771,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.044598340988159,
      "rewards/margins": 1.5973398685455322,
      "rewards/rejected": -3.6419384479522705,
      "step": 15440
    },
    {
      "epoch": 0.7609484784721966,
      "grad_norm": 1.364526391029358,
      "learning_rate": 3.732444050666142e-05,
      "logits/chosen": 2.7741353511810303,
      "logits/rejected": 2.9746718406677246,
      "logps/chosen": -249.5883331298828,
      "logps/rejected": -267.2630920410156,
      "loss": 0.7211,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -2.035130023956299,
      "rewards/margins": 1.5475132465362549,
      "rewards/rejected": -3.582643508911133,
      "step": 15460
    },
    {
      "epoch": 0.7619328878880727,
      "grad_norm": 2.7915642261505127,
      "learning_rate": 3.7308033077377435e-05,
      "logits/chosen": 2.2889091968536377,
      "logits/rejected": 2.5258052349090576,
      "logps/chosen": -236.85183715820312,
      "logps/rejected": -281.0247802734375,
      "loss": 0.426,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2737500667572021,
      "rewards/margins": 2.8371455669403076,
      "rewards/rejected": -4.110896110534668,
      "step": 15480
    },
    {
      "epoch": 0.7629172973039487,
      "grad_norm": 1.5167628526687622,
      "learning_rate": 3.729162564809346e-05,
      "logits/chosen": 2.5680103302001953,
      "logits/rejected": 2.667590856552124,
      "logps/chosen": -265.17938232421875,
      "logps/rejected": -304.02935791015625,
      "loss": 0.5351,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4497443437576294,
      "rewards/margins": 1.8609867095947266,
      "rewards/rejected": -3.3107311725616455,
      "step": 15500
    },
    {
      "epoch": 0.7639017067198248,
      "grad_norm": 4.540196895599365,
      "learning_rate": 3.7275218218809475e-05,
      "logits/chosen": 2.76598858833313,
      "logits/rejected": 2.9513657093048096,
      "logps/chosen": -266.6698303222656,
      "logps/rejected": -279.36968994140625,
      "loss": 0.5307,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.637155532836914,
      "rewards/margins": 1.9429540634155273,
      "rewards/rejected": -3.5801093578338623,
      "step": 15520
    },
    {
      "epoch": 0.7648861161357008,
      "grad_norm": 4.984565734863281,
      "learning_rate": 3.72588107895255e-05,
      "logits/chosen": 2.681514263153076,
      "logits/rejected": 2.870007038116455,
      "logps/chosen": -252.9591827392578,
      "logps/rejected": -268.9974060058594,
      "loss": 0.5108,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3979482650756836,
      "rewards/margins": 1.9058030843734741,
      "rewards/rejected": -3.3037514686584473,
      "step": 15540
    },
    {
      "epoch": 0.7658705255515769,
      "grad_norm": 3.56253719329834,
      "learning_rate": 3.7242403360241516e-05,
      "logits/chosen": 2.5998482704162598,
      "logits/rejected": 2.9202351570129395,
      "logps/chosen": -234.2292022705078,
      "logps/rejected": -243.6722869873047,
      "loss": 0.4177,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.3612076044082642,
      "rewards/margins": 2.329051971435547,
      "rewards/rejected": -3.6902594566345215,
      "step": 15560
    },
    {
      "epoch": 0.7668549349674529,
      "grad_norm": 1.525580883026123,
      "learning_rate": 3.722599593095754e-05,
      "logits/chosen": 2.2836756706237793,
      "logits/rejected": 2.4937636852264404,
      "logps/chosen": -257.5011291503906,
      "logps/rejected": -289.5353088378906,
      "loss": 0.4746,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7696638107299805,
      "rewards/margins": 2.711022138595581,
      "rewards/rejected": -4.480686187744141,
      "step": 15580
    },
    {
      "epoch": 0.767839344383329,
      "grad_norm": 2.458695650100708,
      "learning_rate": 3.7209588501673556e-05,
      "logits/chosen": 2.8174822330474854,
      "logits/rejected": 2.801650285720825,
      "logps/chosen": -290.02569580078125,
      "logps/rejected": -293.92095947265625,
      "loss": 0.5823,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.1629319190979004,
      "rewards/margins": 2.0118143558502197,
      "rewards/rejected": -4.174746036529541,
      "step": 15600
    },
    {
      "epoch": 0.7688237537992051,
      "grad_norm": 4.146836280822754,
      "learning_rate": 3.719318107238958e-05,
      "logits/chosen": 2.788137197494507,
      "logits/rejected": 2.8943653106689453,
      "logps/chosen": -271.2330322265625,
      "logps/rejected": -276.37957763671875,
      "loss": 0.4131,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6522541046142578,
      "rewards/margins": 2.3896372318267822,
      "rewards/rejected": -4.041891098022461,
      "step": 15620
    },
    {
      "epoch": 0.7698081632150812,
      "grad_norm": 1.2004218101501465,
      "learning_rate": 3.71767736431056e-05,
      "logits/chosen": 2.724593162536621,
      "logits/rejected": 2.843212127685547,
      "logps/chosen": -281.41619873046875,
      "logps/rejected": -295.20501708984375,
      "loss": 0.5971,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.8523536920547485,
      "rewards/margins": 1.896222710609436,
      "rewards/rejected": -3.7485764026641846,
      "step": 15640
    },
    {
      "epoch": 0.7707925726309572,
      "grad_norm": 1.7912323474884033,
      "learning_rate": 3.716036621382162e-05,
      "logits/chosen": 2.6360692977905273,
      "logits/rejected": 2.856642961502075,
      "logps/chosen": -283.6529846191406,
      "logps/rejected": -245.7394561767578,
      "loss": 0.6109,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.7743009328842163,
      "rewards/margins": 1.7402098178863525,
      "rewards/rejected": -3.5145106315612793,
      "step": 15660
    },
    {
      "epoch": 0.7717769820468333,
      "grad_norm": 0.9693508148193359,
      "learning_rate": 3.7143958784537644e-05,
      "logits/chosen": 2.85550856590271,
      "logits/rejected": 3.0864675045013428,
      "logps/chosen": -268.765625,
      "logps/rejected": -267.6484375,
      "loss": 0.6387,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5112653970718384,
      "rewards/margins": 1.9721648693084717,
      "rewards/rejected": -3.4834301471710205,
      "step": 15680
    },
    {
      "epoch": 0.7727613914627094,
      "grad_norm": 3.932011127471924,
      "learning_rate": 3.712755135525366e-05,
      "logits/chosen": 2.576388359069824,
      "logits/rejected": 2.550528049468994,
      "logps/chosen": -264.6150207519531,
      "logps/rejected": -272.88177490234375,
      "loss": 0.5807,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.759764313697815,
      "rewards/margins": 1.4175148010253906,
      "rewards/rejected": -3.177278995513916,
      "step": 15700
    },
    {
      "epoch": 0.7737458008785854,
      "grad_norm": 2.56154727935791,
      "learning_rate": 3.7111143925969684e-05,
      "logits/chosen": 2.4845783710479736,
      "logits/rejected": 2.561579704284668,
      "logps/chosen": -245.4033966064453,
      "logps/rejected": -280.633544921875,
      "loss": 0.4344,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.6731951236724854,
      "rewards/margins": 2.665170192718506,
      "rewards/rejected": -4.338365077972412,
      "step": 15720
    },
    {
      "epoch": 0.7747302102944614,
      "grad_norm": 1.8627510070800781,
      "learning_rate": 3.70947364966857e-05,
      "logits/chosen": 2.6307151317596436,
      "logits/rejected": 2.646976947784424,
      "logps/chosen": -247.34683227539062,
      "logps/rejected": -277.4799499511719,
      "loss": 0.4362,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1446034908294678,
      "rewards/margins": 1.9274585247039795,
      "rewards/rejected": -4.072062015533447,
      "step": 15740
    },
    {
      "epoch": 0.7757146197103375,
      "grad_norm": 3.363114833831787,
      "learning_rate": 3.7078329067401725e-05,
      "logits/chosen": 2.6186091899871826,
      "logits/rejected": 2.8473265171051025,
      "logps/chosen": -280.87213134765625,
      "logps/rejected": -293.4970703125,
      "loss": 0.4666,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.1294758319854736,
      "rewards/margins": 2.4440343379974365,
      "rewards/rejected": -4.57351016998291,
      "step": 15760
    },
    {
      "epoch": 0.7766990291262136,
      "grad_norm": 5.9135847091674805,
      "learning_rate": 3.706192163811774e-05,
      "logits/chosen": 2.438676118850708,
      "logits/rejected": 2.6873042583465576,
      "logps/chosen": -279.8099365234375,
      "logps/rejected": -270.7684020996094,
      "loss": 0.7383,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.464663028717041,
      "rewards/margins": 1.63631272315979,
      "rewards/rejected": -4.10097599029541,
      "step": 15780
    },
    {
      "epoch": 0.7776834385420897,
      "grad_norm": 2.9549009799957275,
      "learning_rate": 3.704551420883376e-05,
      "logits/chosen": 2.598691701889038,
      "logits/rejected": 2.895550489425659,
      "logps/chosen": -247.97598266601562,
      "logps/rejected": -234.5032958984375,
      "loss": 0.4337,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.9608213901519775,
      "rewards/margins": 2.550086259841919,
      "rewards/rejected": -4.5109076499938965,
      "step": 15800
    },
    {
      "epoch": 0.7786678479579657,
      "grad_norm": 3.788856029510498,
      "learning_rate": 3.702910677954978e-05,
      "logits/chosen": 2.634981155395508,
      "logits/rejected": 2.571826457977295,
      "logps/chosen": -268.70025634765625,
      "logps/rejected": -275.7902526855469,
      "loss": 0.4624,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5134522914886475,
      "rewards/margins": 2.231219530105591,
      "rewards/rejected": -3.7446722984313965,
      "step": 15820
    },
    {
      "epoch": 0.7796522573738418,
      "grad_norm": 3.277904510498047,
      "learning_rate": 3.70126993502658e-05,
      "logits/chosen": 2.6529977321624756,
      "logits/rejected": 2.667153835296631,
      "logps/chosen": -252.0162353515625,
      "logps/rejected": -264.4518127441406,
      "loss": 0.5804,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -1.4145147800445557,
      "rewards/margins": 1.8165290355682373,
      "rewards/rejected": -3.231044054031372,
      "step": 15840
    },
    {
      "epoch": 0.7806366667897179,
      "grad_norm": 1.5869975090026855,
      "learning_rate": 3.699629192098182e-05,
      "logits/chosen": 2.6224913597106934,
      "logits/rejected": 2.8218719959259033,
      "logps/chosen": -246.8184051513672,
      "logps/rejected": -263.8486633300781,
      "loss": 0.4474,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.3683414459228516,
      "rewards/margins": 2.296642780303955,
      "rewards/rejected": -3.6649844646453857,
      "step": 15860
    },
    {
      "epoch": 0.781621076205594,
      "grad_norm": 2.4939467906951904,
      "learning_rate": 3.697988449169784e-05,
      "logits/chosen": 2.404036521911621,
      "logits/rejected": 2.623591661453247,
      "logps/chosen": -252.4598846435547,
      "logps/rejected": -277.71868896484375,
      "loss": 0.6359,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7411911487579346,
      "rewards/margins": 2.236422061920166,
      "rewards/rejected": -3.9776129722595215,
      "step": 15880
    },
    {
      "epoch": 0.7826054856214699,
      "grad_norm": 5.307072639465332,
      "learning_rate": 3.696347706241386e-05,
      "logits/chosen": 2.7696430683135986,
      "logits/rejected": 2.9044253826141357,
      "logps/chosen": -271.2637939453125,
      "logps/rejected": -285.6214904785156,
      "loss": 0.5336,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.8086583614349365,
      "rewards/margins": 2.28952956199646,
      "rewards/rejected": -4.0981879234313965,
      "step": 15900
    },
    {
      "epoch": 0.783589895037346,
      "grad_norm": 3.6394858360290527,
      "learning_rate": 3.694789000459408e-05,
      "logits/chosen": 2.4259777069091797,
      "logits/rejected": 2.683915853500366,
      "logps/chosen": -278.07720947265625,
      "logps/rejected": -298.97772216796875,
      "loss": 0.6004,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6843773126602173,
      "rewards/margins": 1.8192259073257446,
      "rewards/rejected": -3.503603458404541,
      "step": 15920
    },
    {
      "epoch": 0.7845743044532221,
      "grad_norm": 1.9371551275253296,
      "learning_rate": 3.69314825753101e-05,
      "logits/chosen": 2.7636516094207764,
      "logits/rejected": 2.9265551567077637,
      "logps/chosen": -244.92770385742188,
      "logps/rejected": -280.57659912109375,
      "loss": 0.4869,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.6932398080825806,
      "rewards/margins": 2.1476187705993652,
      "rewards/rejected": -3.8408589363098145,
      "step": 15940
    },
    {
      "epoch": 0.7855587138690981,
      "grad_norm": 1.6101597547531128,
      "learning_rate": 3.691507514602612e-05,
      "logits/chosen": 2.4436964988708496,
      "logits/rejected": 2.758197784423828,
      "logps/chosen": -264.2906494140625,
      "logps/rejected": -255.9755859375,
      "loss": 0.4211,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.27508544921875,
      "rewards/margins": 2.2130043506622314,
      "rewards/rejected": -3.4880897998809814,
      "step": 15960
    },
    {
      "epoch": 0.7865431232849742,
      "grad_norm": 1.4311612844467163,
      "learning_rate": 3.689866771674214e-05,
      "logits/chosen": 2.6448445320129395,
      "logits/rejected": 2.760159492492676,
      "logps/chosen": -234.1913604736328,
      "logps/rejected": -248.67788696289062,
      "loss": 0.7434,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -1.4372432231903076,
      "rewards/margins": 1.5525470972061157,
      "rewards/rejected": -2.989790201187134,
      "step": 15980
    },
    {
      "epoch": 0.7875275327008503,
      "grad_norm": 2.1599209308624268,
      "learning_rate": 3.688226028745816e-05,
      "logits/chosen": 2.6210150718688965,
      "logits/rejected": 2.986609935760498,
      "logps/chosen": -279.8674621582031,
      "logps/rejected": -282.1800537109375,
      "loss": 0.3997,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.9906328320503235,
      "rewards/margins": 2.3512566089630127,
      "rewards/rejected": -3.3418896198272705,
      "step": 16000
    },
    {
      "epoch": 0.7885119421167264,
      "grad_norm": 1.771780014038086,
      "learning_rate": 3.686585285817418e-05,
      "logits/chosen": 2.7058346271514893,
      "logits/rejected": 3.092273473739624,
      "logps/chosen": -269.4289855957031,
      "logps/rejected": -270.243896484375,
      "loss": 0.4084,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.4124259948730469,
      "rewards/margins": 2.4761366844177246,
      "rewards/rejected": -3.8885626792907715,
      "step": 16020
    },
    {
      "epoch": 0.7894963515326024,
      "grad_norm": 1.2024413347244263,
      "learning_rate": 3.68494454288902e-05,
      "logits/chosen": 2.580609083175659,
      "logits/rejected": 2.708512783050537,
      "logps/chosen": -276.1324462890625,
      "logps/rejected": -228.427734375,
      "loss": 0.7269,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7768577337265015,
      "rewards/margins": 1.992597222328186,
      "rewards/rejected": -3.7694549560546875,
      "step": 16040
    },
    {
      "epoch": 0.7904807609484785,
      "grad_norm": 4.89370584487915,
      "learning_rate": 3.6833037999606226e-05,
      "logits/chosen": 2.808572292327881,
      "logits/rejected": 3.087898015975952,
      "logps/chosen": -276.4488220214844,
      "logps/rejected": -282.6084289550781,
      "loss": 0.5369,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.5692112445831299,
      "rewards/margins": 2.305004119873047,
      "rewards/rejected": -3.8742153644561768,
      "step": 16060
    },
    {
      "epoch": 0.7914651703643545,
      "grad_norm": 0.8803796768188477,
      "learning_rate": 3.681663057032224e-05,
      "logits/chosen": 3.2464218139648438,
      "logits/rejected": 3.1885461807250977,
      "logps/chosen": -238.29135131835938,
      "logps/rejected": -241.6396484375,
      "loss": 0.5902,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.5748323202133179,
      "rewards/margins": 1.6620559692382812,
      "rewards/rejected": -3.2368881702423096,
      "step": 16080
    },
    {
      "epoch": 0.7924495797802306,
      "grad_norm": 0.7417648434638977,
      "learning_rate": 3.680022314103827e-05,
      "logits/chosen": 3.2741379737854004,
      "logits/rejected": 3.422799587249756,
      "logps/chosen": -269.8499450683594,
      "logps/rejected": -255.55514526367188,
      "loss": 0.4078,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.7474521994590759,
      "rewards/margins": 1.987579345703125,
      "rewards/rejected": -2.7350316047668457,
      "step": 16100
    },
    {
      "epoch": 0.7934339891961066,
      "grad_norm": 4.319652557373047,
      "learning_rate": 3.6783815711754284e-05,
      "logits/chosen": 2.9909186363220215,
      "logits/rejected": 3.1379547119140625,
      "logps/chosen": -274.09588623046875,
      "logps/rejected": -275.97393798828125,
      "loss": 0.6772,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.5996814966201782,
      "rewards/margins": 1.858232855796814,
      "rewards/rejected": -3.457914352416992,
      "step": 16120
    },
    {
      "epoch": 0.7944183986119827,
      "grad_norm": 2.9710404872894287,
      "learning_rate": 3.676740828247031e-05,
      "logits/chosen": 3.0677294731140137,
      "logits/rejected": 3.143326997756958,
      "logps/chosen": -284.054931640625,
      "logps/rejected": -284.4065856933594,
      "loss": 0.467,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.5929820537567139,
      "rewards/margins": 2.3516173362731934,
      "rewards/rejected": -3.944599151611328,
      "step": 16140
    },
    {
      "epoch": 0.7954028080278588,
      "grad_norm": 3.915403127670288,
      "learning_rate": 3.6751000853186324e-05,
      "logits/chosen": 2.877286195755005,
      "logits/rejected": 3.2071051597595215,
      "logps/chosen": -288.98077392578125,
      "logps/rejected": -276.7677917480469,
      "loss": 0.4853,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.5152256488800049,
      "rewards/margins": 2.4329159259796143,
      "rewards/rejected": -3.9481418132781982,
      "step": 16160
    },
    {
      "epoch": 0.7963872174437349,
      "grad_norm": 2.0168509483337402,
      "learning_rate": 3.673459342390235e-05,
      "logits/chosen": 2.780182361602783,
      "logits/rejected": 2.996662139892578,
      "logps/chosen": -296.7137145996094,
      "logps/rejected": -272.467041015625,
      "loss": 0.4048,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5012303590774536,
      "rewards/margins": 2.604645252227783,
      "rewards/rejected": -4.105875492095947,
      "step": 16180
    },
    {
      "epoch": 0.7973716268596109,
      "grad_norm": 8.613578796386719,
      "learning_rate": 3.6718185994618365e-05,
      "logits/chosen": 3.110704183578491,
      "logits/rejected": 3.2777657508850098,
      "logps/chosen": -239.03848266601562,
      "logps/rejected": -232.7664031982422,
      "loss": 0.492,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.0828158855438232,
      "rewards/margins": 1.5506755113601685,
      "rewards/rejected": -2.6334917545318604,
      "step": 16200
    },
    {
      "epoch": 0.798356036275487,
      "grad_norm": 2.7999892234802246,
      "learning_rate": 3.670177856533438e-05,
      "logits/chosen": 2.8400495052337646,
      "logits/rejected": 3.0372719764709473,
      "logps/chosen": -281.88751220703125,
      "logps/rejected": -276.7613830566406,
      "loss": 0.4017,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.1092870235443115,
      "rewards/margins": 2.572439670562744,
      "rewards/rejected": -4.681726932525635,
      "step": 16220
    },
    {
      "epoch": 0.7993404456913631,
      "grad_norm": 5.120355606079102,
      "learning_rate": 3.6685371136050405e-05,
      "logits/chosen": 2.956545352935791,
      "logits/rejected": 3.2144863605499268,
      "logps/chosen": -266.4501953125,
      "logps/rejected": -280.7679748535156,
      "loss": 0.4563,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.5881972312927246,
      "rewards/margins": 1.9884004592895508,
      "rewards/rejected": -3.5765979290008545,
      "step": 16240
    },
    {
      "epoch": 0.800324855107239,
      "grad_norm": 1.1669132709503174,
      "learning_rate": 3.666896370676642e-05,
      "logits/chosen": 3.033936023712158,
      "logits/rejected": 3.169053554534912,
      "logps/chosen": -286.66314697265625,
      "logps/rejected": -295.5419921875,
      "loss": 0.6839,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.0922789573669434,
      "rewards/margins": 1.5583603382110596,
      "rewards/rejected": -3.650639295578003,
      "step": 16260
    },
    {
      "epoch": 0.8013092645231151,
      "grad_norm": 3.5280730724334717,
      "learning_rate": 3.6652556277482445e-05,
      "logits/chosen": 2.8006672859191895,
      "logits/rejected": 3.05920147895813,
      "logps/chosen": -256.6082458496094,
      "logps/rejected": -254.1370086669922,
      "loss": 0.6609,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.5838191509246826,
      "rewards/margins": 1.9264214038848877,
      "rewards/rejected": -3.510240077972412,
      "step": 16280
    },
    {
      "epoch": 0.8022936739389912,
      "grad_norm": 6.588621139526367,
      "learning_rate": 3.663614884819846e-05,
      "logits/chosen": 2.8086676597595215,
      "logits/rejected": 3.063807964324951,
      "logps/chosen": -253.40194702148438,
      "logps/rejected": -289.4553527832031,
      "loss": 0.4995,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.3261497020721436,
      "rewards/margins": 2.1295878887176514,
      "rewards/rejected": -3.455737590789795,
      "step": 16300
    },
    {
      "epoch": 0.8032780833548673,
      "grad_norm": 0.8681040406227112,
      "learning_rate": 3.6619741418914486e-05,
      "logits/chosen": 2.773024320602417,
      "logits/rejected": 2.9630110263824463,
      "logps/chosen": -236.47128295898438,
      "logps/rejected": -286.77215576171875,
      "loss": 0.5758,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.6864006519317627,
      "rewards/margins": 2.4504661560058594,
      "rewards/rejected": -4.136866569519043,
      "step": 16320
    },
    {
      "epoch": 0.8042624927707434,
      "grad_norm": 3.5959529876708984,
      "learning_rate": 3.66033339896305e-05,
      "logits/chosen": 2.750070810317993,
      "logits/rejected": 3.0658628940582275,
      "logps/chosen": -267.7099609375,
      "logps/rejected": -278.8376159667969,
      "loss": 0.3673,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.359462857246399,
      "rewards/margins": 2.742049217224121,
      "rewards/rejected": -4.1015119552612305,
      "step": 16340
    },
    {
      "epoch": 0.8052469021866194,
      "grad_norm": 6.033932209014893,
      "learning_rate": 3.6586926560346526e-05,
      "logits/chosen": 2.8753607273101807,
      "logits/rejected": 2.9781527519226074,
      "logps/chosen": -263.49151611328125,
      "logps/rejected": -263.98712158203125,
      "loss": 0.4924,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.2708942890167236,
      "rewards/margins": 1.8004372119903564,
      "rewards/rejected": -4.071331977844238,
      "step": 16360
    },
    {
      "epoch": 0.8062313116024955,
      "grad_norm": 1.5905927419662476,
      "learning_rate": 3.657051913106255e-05,
      "logits/chosen": 2.6903765201568604,
      "logits/rejected": 2.8930230140686035,
      "logps/chosen": -257.3494873046875,
      "logps/rejected": -273.8577575683594,
      "loss": 0.3825,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7424652576446533,
      "rewards/margins": 2.331172466278076,
      "rewards/rejected": -4.07363748550415,
      "step": 16380
    },
    {
      "epoch": 0.8072157210183716,
      "grad_norm": 1.7553555965423584,
      "learning_rate": 3.655411170177857e-05,
      "logits/chosen": 2.956328868865967,
      "logits/rejected": 3.0141799449920654,
      "logps/chosen": -229.8308563232422,
      "logps/rejected": -244.27017211914062,
      "loss": 0.5354,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.2484822273254395,
      "rewards/margins": 2.117419719696045,
      "rewards/rejected": -4.365902423858643,
      "step": 16400
    },
    {
      "epoch": 0.8082001304342477,
      "grad_norm": 0.8073746562004089,
      "learning_rate": 3.653770427249459e-05,
      "logits/chosen": 2.776615858078003,
      "logits/rejected": 3.055802583694458,
      "logps/chosen": -256.04644775390625,
      "logps/rejected": -283.11865234375,
      "loss": 0.415,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.153578758239746,
      "rewards/margins": 2.271376848220825,
      "rewards/rejected": -4.424954891204834,
      "step": 16420
    },
    {
      "epoch": 0.8091845398501236,
      "grad_norm": 4.717316150665283,
      "learning_rate": 3.652129684321061e-05,
      "logits/chosen": 2.6867470741271973,
      "logits/rejected": 3.012814998626709,
      "logps/chosen": -273.8871154785156,
      "logps/rejected": -292.5967712402344,
      "loss": 0.5268,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.296452283859253,
      "rewards/margins": 2.2745585441589355,
      "rewards/rejected": -4.571011066436768,
      "step": 16440
    },
    {
      "epoch": 0.8101689492659997,
      "grad_norm": 1.3818904161453247,
      "learning_rate": 3.650488941392663e-05,
      "logits/chosen": 2.536224365234375,
      "logits/rejected": 2.8503212928771973,
      "logps/chosen": -271.50408935546875,
      "logps/rejected": -256.2688903808594,
      "loss": 0.4737,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.4229302406311035,
      "rewards/margins": 2.2717835903167725,
      "rewards/rejected": -4.694714069366455,
      "step": 16460
    },
    {
      "epoch": 0.8111533586818758,
      "grad_norm": 11.023242950439453,
      "learning_rate": 3.648848198464265e-05,
      "logits/chosen": 2.7379393577575684,
      "logits/rejected": 2.9758524894714355,
      "logps/chosen": -273.7212829589844,
      "logps/rejected": -286.2114562988281,
      "loss": 0.4687,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7495701313018799,
      "rewards/margins": 2.4052319526672363,
      "rewards/rejected": -4.154801845550537,
      "step": 16480
    },
    {
      "epoch": 0.8121377680977518,
      "grad_norm": 0.42307189106941223,
      "learning_rate": 3.647207455535867e-05,
      "logits/chosen": 3.073918342590332,
      "logits/rejected": 3.1582937240600586,
      "logps/chosen": -238.1826171875,
      "logps/rejected": -251.3061065673828,
      "loss": 0.5362,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.965711236000061,
      "rewards/margins": 2.677109956741333,
      "rewards/rejected": -4.642821311950684,
      "step": 16500
    },
    {
      "epoch": 0.8131221775136279,
      "grad_norm": 2.709190845489502,
      "learning_rate": 3.645566712607469e-05,
      "logits/chosen": 2.8547301292419434,
      "logits/rejected": 3.0852432250976562,
      "logps/chosen": -273.9220886230469,
      "logps/rejected": -282.25604248046875,
      "loss": 0.5298,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.1840994358062744,
      "rewards/margins": 2.265493869781494,
      "rewards/rejected": -4.4495930671691895,
      "step": 16520
    },
    {
      "epoch": 0.814106586929504,
      "grad_norm": 3.5288405418395996,
      "learning_rate": 3.6439259696790705e-05,
      "logits/chosen": 2.8780770301818848,
      "logits/rejected": 2.856943130493164,
      "logps/chosen": -268.91278076171875,
      "logps/rejected": -280.9228820800781,
      "loss": 0.4598,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0132832527160645,
      "rewards/margins": 2.5338594913482666,
      "rewards/rejected": -4.54714298248291,
      "step": 16540
    },
    {
      "epoch": 0.8150909963453801,
      "grad_norm": 4.35994815826416,
      "learning_rate": 3.642285226750673e-05,
      "logits/chosen": 2.5810844898223877,
      "logits/rejected": 2.817762851715088,
      "logps/chosen": -259.84173583984375,
      "logps/rejected": -292.53155517578125,
      "loss": 0.5523,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.330239772796631,
      "rewards/margins": 2.437713384628296,
      "rewards/rejected": -4.767952919006348,
      "step": 16560
    },
    {
      "epoch": 0.8160754057612561,
      "grad_norm": 4.863341808319092,
      "learning_rate": 3.6406444838222745e-05,
      "logits/chosen": 2.5931038856506348,
      "logits/rejected": 2.8217759132385254,
      "logps/chosen": -243.7905731201172,
      "logps/rejected": -272.9934997558594,
      "loss": 0.4036,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.747748613357544,
      "rewards/margins": 2.4111268520355225,
      "rewards/rejected": -4.158875465393066,
      "step": 16580
    },
    {
      "epoch": 0.8170598151771322,
      "grad_norm": 0.006192552391439676,
      "learning_rate": 3.639003740893877e-05,
      "logits/chosen": 2.518068790435791,
      "logits/rejected": 2.4400341510772705,
      "logps/chosen": -256.63671875,
      "logps/rejected": -296.20172119140625,
      "loss": 0.4104,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7038304805755615,
      "rewards/margins": 3.3353943824768066,
      "rewards/rejected": -5.039224624633789,
      "step": 16600
    },
    {
      "epoch": 0.8180442245930082,
      "grad_norm": 1.1915298700332642,
      "learning_rate": 3.6373629979654786e-05,
      "logits/chosen": 2.7403957843780518,
      "logits/rejected": 2.793839693069458,
      "logps/chosen": -260.1789855957031,
      "logps/rejected": -285.7505798339844,
      "loss": 0.5503,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.295727252960205,
      "rewards/margins": 2.1209940910339355,
      "rewards/rejected": -4.416721343994141,
      "step": 16620
    },
    {
      "epoch": 0.8190286340088843,
      "grad_norm": 3.928272247314453,
      "learning_rate": 3.635722255037081e-05,
      "logits/chosen": 2.501704454421997,
      "logits/rejected": 2.7909328937530518,
      "logps/chosen": -268.6929626464844,
      "logps/rejected": -271.07513427734375,
      "loss": 0.4266,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.121166944503784,
      "rewards/margins": 2.6028549671173096,
      "rewards/rejected": -4.724021911621094,
      "step": 16640
    },
    {
      "epoch": 0.8200130434247603,
      "grad_norm": 2.2918615341186523,
      "learning_rate": 3.634081512108683e-05,
      "logits/chosen": 2.7393949031829834,
      "logits/rejected": 2.9035706520080566,
      "logps/chosen": -274.34161376953125,
      "logps/rejected": -260.30963134765625,
      "loss": 0.4597,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.803506851196289,
      "rewards/margins": 2.060737371444702,
      "rewards/rejected": -3.864243745803833,
      "step": 16660
    },
    {
      "epoch": 0.8209974528406364,
      "grad_norm": 1.9093607664108276,
      "learning_rate": 3.632440769180285e-05,
      "logits/chosen": 2.76855731010437,
      "logits/rejected": 2.9197068214416504,
      "logps/chosen": -284.71356201171875,
      "logps/rejected": -310.9396667480469,
      "loss": 0.4717,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.6188290119171143,
      "rewards/margins": 2.852538585662842,
      "rewards/rejected": -5.471367835998535,
      "step": 16680
    },
    {
      "epoch": 0.8219818622565125,
      "grad_norm": 3.9135913848876953,
      "learning_rate": 3.6308000262518874e-05,
      "logits/chosen": 2.645658016204834,
      "logits/rejected": 2.7955641746520996,
      "logps/chosen": -270.88983154296875,
      "logps/rejected": -317.01483154296875,
      "loss": 0.3752,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8909488916397095,
      "rewards/margins": 3.4007086753845215,
      "rewards/rejected": -5.291657447814941,
      "step": 16700
    },
    {
      "epoch": 0.8229662716723886,
      "grad_norm": 2.9150924682617188,
      "learning_rate": 3.629159283323489e-05,
      "logits/chosen": 2.838066816329956,
      "logits/rejected": 3.0210514068603516,
      "logps/chosen": -280.0719909667969,
      "logps/rejected": -275.04412841796875,
      "loss": 0.6225,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.4813318252563477,
      "rewards/margins": 2.4983389377593994,
      "rewards/rejected": -4.979670524597168,
      "step": 16720
    },
    {
      "epoch": 0.8239506810882646,
      "grad_norm": 1.7597911357879639,
      "learning_rate": 3.6275185403950914e-05,
      "logits/chosen": 2.8971526622772217,
      "logits/rejected": 2.859058141708374,
      "logps/chosen": -251.54550170898438,
      "logps/rejected": -269.62628173828125,
      "loss": 0.3804,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.903728723526001,
      "rewards/margins": 2.976391553878784,
      "rewards/rejected": -4.880120277404785,
      "step": 16740
    },
    {
      "epoch": 0.8249350905041407,
      "grad_norm": 4.215928554534912,
      "learning_rate": 3.625877797466693e-05,
      "logits/chosen": 2.5003817081451416,
      "logits/rejected": 2.6439123153686523,
      "logps/chosen": -248.86123657226562,
      "logps/rejected": -267.45404052734375,
      "loss": 0.5879,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.4229636192321777,
      "rewards/margins": 1.9403693675994873,
      "rewards/rejected": -4.363332748413086,
      "step": 16760
    },
    {
      "epoch": 0.8259194999200168,
      "grad_norm": 0.5383965373039246,
      "learning_rate": 3.6242370545382954e-05,
      "logits/chosen": 2.730891227722168,
      "logits/rejected": 2.781177043914795,
      "logps/chosen": -258.5146179199219,
      "logps/rejected": -292.2905578613281,
      "loss": 0.5043,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.3072104454040527,
      "rewards/margins": 2.9681544303894043,
      "rewards/rejected": -5.275364398956299,
      "step": 16780
    },
    {
      "epoch": 0.8269039093358928,
      "grad_norm": 0.8999937176704407,
      "learning_rate": 3.622596311609897e-05,
      "logits/chosen": 2.513425588607788,
      "logits/rejected": 2.6655287742614746,
      "logps/chosen": -243.58615112304688,
      "logps/rejected": -253.89938354492188,
      "loss": 0.4494,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.6268978118896484,
      "rewards/margins": 2.266956329345703,
      "rewards/rejected": -3.8938536643981934,
      "step": 16800
    },
    {
      "epoch": 0.8278883187517688,
      "grad_norm": 2.8853132724761963,
      "learning_rate": 3.6209555686814995e-05,
      "logits/chosen": 2.5182063579559326,
      "logits/rejected": 2.8989205360412598,
      "logps/chosen": -274.0755615234375,
      "logps/rejected": -237.3590087890625,
      "loss": 0.4331,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.921766996383667,
      "rewards/margins": 2.6010172367095947,
      "rewards/rejected": -4.522784233093262,
      "step": 16820
    },
    {
      "epoch": 0.8288727281676449,
      "grad_norm": 1.0832490921020508,
      "learning_rate": 3.619314825753101e-05,
      "logits/chosen": 2.721808433532715,
      "logits/rejected": 2.878089189529419,
      "logps/chosen": -257.9288635253906,
      "logps/rejected": -253.0863800048828,
      "loss": 0.4203,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1179141998291016,
      "rewards/margins": 2.4879422187805176,
      "rewards/rejected": -4.605856895446777,
      "step": 16840
    },
    {
      "epoch": 0.829857137583521,
      "grad_norm": 2.433234691619873,
      "learning_rate": 3.617674082824703e-05,
      "logits/chosen": 2.4976768493652344,
      "logits/rejected": 2.714749813079834,
      "logps/chosen": -255.1080322265625,
      "logps/rejected": -257.9635314941406,
      "loss": 0.3965,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.241285800933838,
      "rewards/margins": 2.9061694145202637,
      "rewards/rejected": -5.147455215454102,
      "step": 16860
    },
    {
      "epoch": 0.830841546999397,
      "grad_norm": 0.6208771467208862,
      "learning_rate": 3.616033339896305e-05,
      "logits/chosen": 2.477724075317383,
      "logits/rejected": 2.677128314971924,
      "logps/chosen": -259.3382873535156,
      "logps/rejected": -292.69891357421875,
      "loss": 0.3785,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.069819927215576,
      "rewards/margins": 3.559619426727295,
      "rewards/rejected": -5.629439830780029,
      "step": 16880
    },
    {
      "epoch": 0.8318259564152731,
      "grad_norm": 1.7555296421051025,
      "learning_rate": 3.614392596967907e-05,
      "logits/chosen": 2.2742185592651367,
      "logits/rejected": 2.5627636909484863,
      "logps/chosen": -279.00970458984375,
      "logps/rejected": -282.998046875,
      "loss": 0.4061,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.339402914047241,
      "rewards/margins": 3.200890302658081,
      "rewards/rejected": -5.540292739868164,
      "step": 16900
    },
    {
      "epoch": 0.8328103658311492,
      "grad_norm": 2.1462459564208984,
      "learning_rate": 3.612751854039509e-05,
      "logits/chosen": 2.684755563735962,
      "logits/rejected": 2.840792179107666,
      "logps/chosen": -266.3282165527344,
      "logps/rejected": -273.36614990234375,
      "loss": 0.4824,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.5812010765075684,
      "rewards/margins": 2.576681613922119,
      "rewards/rejected": -5.157883167266846,
      "step": 16920
    },
    {
      "epoch": 0.8337947752470253,
      "grad_norm": 12.393446922302246,
      "learning_rate": 3.611111111111111e-05,
      "logits/chosen": 2.662121534347534,
      "logits/rejected": 2.816575050354004,
      "logps/chosen": -258.8154296875,
      "logps/rejected": -295.30242919921875,
      "loss": 0.3534,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.7421233654022217,
      "rewards/margins": 3.720309019088745,
      "rewards/rejected": -5.462432384490967,
      "step": 16940
    },
    {
      "epoch": 0.8347791846629014,
      "grad_norm": 2.9002606868743896,
      "learning_rate": 3.609470368182713e-05,
      "logits/chosen": 2.674664258956909,
      "logits/rejected": 2.8627519607543945,
      "logps/chosen": -270.9478454589844,
      "logps/rejected": -280.17352294921875,
      "loss": 0.4198,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.322937488555908,
      "rewards/margins": 2.8591980934143066,
      "rewards/rejected": -5.182135105133057,
      "step": 16960
    },
    {
      "epoch": 0.8357635940787773,
      "grad_norm": 6.96938943862915,
      "learning_rate": 3.607829625254316e-05,
      "logits/chosen": 2.642921209335327,
      "logits/rejected": 2.763361930847168,
      "logps/chosen": -243.8556671142578,
      "logps/rejected": -265.10595703125,
      "loss": 0.5644,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.099208116531372,
      "rewards/margins": 2.3682804107666016,
      "rewards/rejected": -4.4674882888793945,
      "step": 16980
    },
    {
      "epoch": 0.8367480034946534,
      "grad_norm": 4.250203609466553,
      "learning_rate": 3.6061888823259174e-05,
      "logits/chosen": 2.5928802490234375,
      "logits/rejected": 2.798666477203369,
      "logps/chosen": -258.9654541015625,
      "logps/rejected": -315.6954040527344,
      "loss": 0.4129,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.160679817199707,
      "rewards/margins": 3.748093843460083,
      "rewards/rejected": -5.908772945404053,
      "step": 17000
    },
    {
      "epoch": 0.8377324129105295,
      "grad_norm": 2.1070282459259033,
      "learning_rate": 3.60454813939752e-05,
      "logits/chosen": 2.1269659996032715,
      "logits/rejected": 2.2723946571350098,
      "logps/chosen": -270.98333740234375,
      "logps/rejected": -331.0690002441406,
      "loss": 0.3789,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.8095202445983887,
      "rewards/margins": 3.752800464630127,
      "rewards/rejected": -6.562320709228516,
      "step": 17020
    },
    {
      "epoch": 0.8387168223264055,
      "grad_norm": 6.282654762268066,
      "learning_rate": 3.6029073964691214e-05,
      "logits/chosen": 2.4583349227905273,
      "logits/rejected": 2.5730979442596436,
      "logps/chosen": -254.667236328125,
      "logps/rejected": -294.3324890136719,
      "loss": 0.4316,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.6435561180114746,
      "rewards/margins": 3.833796977996826,
      "rewards/rejected": -6.477353572845459,
      "step": 17040
    },
    {
      "epoch": 0.8397012317422816,
      "grad_norm": 4.474075794219971,
      "learning_rate": 3.601266653540724e-05,
      "logits/chosen": 2.486274242401123,
      "logits/rejected": 2.7873940467834473,
      "logps/chosen": -283.92919921875,
      "logps/rejected": -330.0198059082031,
      "loss": 0.3355,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.1052162647247314,
      "rewards/margins": 4.098734378814697,
      "rewards/rejected": -6.203949928283691,
      "step": 17060
    },
    {
      "epoch": 0.8406856411581577,
      "grad_norm": 1.157355785369873,
      "learning_rate": 3.5996259106123254e-05,
      "logits/chosen": 2.5311059951782227,
      "logits/rejected": 2.7537989616394043,
      "logps/chosen": -250.39163208007812,
      "logps/rejected": -272.3320007324219,
      "loss": 0.3997,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.7700295448303223,
      "rewards/margins": 3.1315369606018066,
      "rewards/rejected": -5.901566505432129,
      "step": 17080
    },
    {
      "epoch": 0.8416700505740338,
      "grad_norm": 4.336487770080566,
      "learning_rate": 3.597985167683928e-05,
      "logits/chosen": 2.86871600151062,
      "logits/rejected": 2.777196168899536,
      "logps/chosen": -261.3178405761719,
      "logps/rejected": -285.4337463378906,
      "loss": 0.7482,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.286210060119629,
      "rewards/margins": 1.5181047916412354,
      "rewards/rejected": -3.8043148517608643,
      "step": 17100
    },
    {
      "epoch": 0.8426544599899098,
      "grad_norm": 0.5596911907196045,
      "learning_rate": 3.5963444247555295e-05,
      "logits/chosen": 2.4997386932373047,
      "logits/rejected": 2.701141357421875,
      "logps/chosen": -262.1954040527344,
      "logps/rejected": -288.4052734375,
      "loss": 0.5012,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.9930312633514404,
      "rewards/margins": 3.1496989727020264,
      "rewards/rejected": -5.142730712890625,
      "step": 17120
    },
    {
      "epoch": 0.8436388694057859,
      "grad_norm": 2.0858747959136963,
      "learning_rate": 3.594703681827131e-05,
      "logits/chosen": 2.7321648597717285,
      "logits/rejected": 2.7605957984924316,
      "logps/chosen": -264.9071044921875,
      "logps/rejected": -273.95538330078125,
      "loss": 0.5481,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -1.704214334487915,
      "rewards/margins": 2.7016031742095947,
      "rewards/rejected": -4.405817985534668,
      "step": 17140
    },
    {
      "epoch": 0.8446232788216619,
      "grad_norm": 1.7194850444793701,
      "learning_rate": 3.5930629388987335e-05,
      "logits/chosen": 2.4385199546813965,
      "logits/rejected": 2.706435203552246,
      "logps/chosen": -264.5623779296875,
      "logps/rejected": -268.6004333496094,
      "loss": 0.3688,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7771358489990234,
      "rewards/margins": 2.9600820541381836,
      "rewards/rejected": -4.737217903137207,
      "step": 17160
    },
    {
      "epoch": 0.845607688237538,
      "grad_norm": 2.6565141677856445,
      "learning_rate": 3.591422195970335e-05,
      "logits/chosen": 2.584529161453247,
      "logits/rejected": 2.9125165939331055,
      "logps/chosen": -248.0327911376953,
      "logps/rejected": -283.7169189453125,
      "loss": 0.4107,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.417993187904358,
      "rewards/margins": 2.833618640899658,
      "rewards/rejected": -4.251611709594727,
      "step": 17180
    },
    {
      "epoch": 0.846592097653414,
      "grad_norm": 1.974002718925476,
      "learning_rate": 3.5897814530419376e-05,
      "logits/chosen": 2.7022483348846436,
      "logits/rejected": 3.0107345581054688,
      "logps/chosen": -237.35714721679688,
      "logps/rejected": -265.28839111328125,
      "loss": 0.4484,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.348456859588623,
      "rewards/margins": 2.745704412460327,
      "rewards/rejected": -5.094161033630371,
      "step": 17200
    },
    {
      "epoch": 0.8475765070692901,
      "grad_norm": 1.723704218864441,
      "learning_rate": 3.588140710113539e-05,
      "logits/chosen": 2.3687784671783447,
      "logits/rejected": 2.641263246536255,
      "logps/chosen": -262.30987548828125,
      "logps/rejected": -295.94061279296875,
      "loss": 0.5377,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.227006435394287,
      "rewards/margins": 2.527312994003296,
      "rewards/rejected": -4.754319667816162,
      "step": 17220
    },
    {
      "epoch": 0.8485609164851662,
      "grad_norm": 6.757002353668213,
      "learning_rate": 3.5864999671851416e-05,
      "logits/chosen": 2.6509242057800293,
      "logits/rejected": 2.885206460952759,
      "logps/chosen": -264.47503662109375,
      "logps/rejected": -277.83831787109375,
      "loss": 0.5722,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -3.037839412689209,
      "rewards/margins": 2.6802563667297363,
      "rewards/rejected": -5.718095302581787,
      "step": 17240
    },
    {
      "epoch": 0.8495453259010423,
      "grad_norm": 5.054065704345703,
      "learning_rate": 3.584859224256743e-05,
      "logits/chosen": 2.7205028533935547,
      "logits/rejected": 2.9151110649108887,
      "logps/chosen": -276.7974853515625,
      "logps/rejected": -290.75439453125,
      "loss": 0.4257,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.228001594543457,
      "rewards/margins": 2.7488903999328613,
      "rewards/rejected": -3.9768917560577393,
      "step": 17260
    },
    {
      "epoch": 0.8505297353169183,
      "grad_norm": 2.508359909057617,
      "learning_rate": 3.583218481328346e-05,
      "logits/chosen": 2.8091118335723877,
      "logits/rejected": 2.912261486053467,
      "logps/chosen": -277.35205078125,
      "logps/rejected": -295.7623596191406,
      "loss": 0.5431,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1986918449401855,
      "rewards/margins": 2.6732137203216553,
      "rewards/rejected": -4.871905326843262,
      "step": 17280
    },
    {
      "epoch": 0.8515141447327944,
      "grad_norm": 1.3400357961654663,
      "learning_rate": 3.581577738399948e-05,
      "logits/chosen": 2.9075047969818115,
      "logits/rejected": 3.0875678062438965,
      "logps/chosen": -271.17169189453125,
      "logps/rejected": -272.076171875,
      "loss": 0.4699,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.3698499202728271,
      "rewards/margins": 2.7408792972564697,
      "rewards/rejected": -4.110729217529297,
      "step": 17300
    },
    {
      "epoch": 0.8524985541486705,
      "grad_norm": 1.4733080863952637,
      "learning_rate": 3.57993699547155e-05,
      "logits/chosen": 2.7318484783172607,
      "logits/rejected": 2.9607093334198,
      "logps/chosen": -272.73675537109375,
      "logps/rejected": -288.3790283203125,
      "loss": 0.6829,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.4768550395965576,
      "rewards/margins": 2.0321974754333496,
      "rewards/rejected": -4.509052753448486,
      "step": 17320
    },
    {
      "epoch": 0.8534829635645464,
      "grad_norm": 4.301808834075928,
      "learning_rate": 3.578296252543152e-05,
      "logits/chosen": 2.7805564403533936,
      "logits/rejected": 3.1981825828552246,
      "logps/chosen": -280.01458740234375,
      "logps/rejected": -294.63140869140625,
      "loss": 0.4798,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.444824457168579,
      "rewards/margins": 2.5356016159057617,
      "rewards/rejected": -3.98042631149292,
      "step": 17340
    },
    {
      "epoch": 0.8544673729804225,
      "grad_norm": 1.324737310409546,
      "learning_rate": 3.576655509614754e-05,
      "logits/chosen": 2.4727911949157715,
      "logits/rejected": 2.747997760772705,
      "logps/chosen": -274.870361328125,
      "logps/rejected": -286.6504211425781,
      "loss": 0.4381,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.5947834253311157,
      "rewards/margins": 2.718557119369507,
      "rewards/rejected": -4.313340187072754,
      "step": 17360
    },
    {
      "epoch": 0.8554517823962986,
      "grad_norm": 1.6169523000717163,
      "learning_rate": 3.575014766686356e-05,
      "logits/chosen": 2.517444372177124,
      "logits/rejected": 2.6470181941986084,
      "logps/chosen": -264.19293212890625,
      "logps/rejected": -285.87432861328125,
      "loss": 0.5276,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7374553680419922,
      "rewards/margins": 2.6892189979553223,
      "rewards/rejected": -4.426673889160156,
      "step": 17380
    },
    {
      "epoch": 0.8564361918121747,
      "grad_norm": 3.695539712905884,
      "learning_rate": 3.573374023757958e-05,
      "logits/chosen": 2.7689008712768555,
      "logits/rejected": 3.0860424041748047,
      "logps/chosen": -261.1023254394531,
      "logps/rejected": -274.9486999511719,
      "loss": 0.4633,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.6362931728363037,
      "rewards/margins": 2.8227245807647705,
      "rewards/rejected": -4.459017753601074,
      "step": 17400
    },
    {
      "epoch": 0.8574206012280507,
      "grad_norm": 0.7182644009590149,
      "learning_rate": 3.57173328082956e-05,
      "logits/chosen": 2.682743549346924,
      "logits/rejected": 2.8603873252868652,
      "logps/chosen": -243.2378387451172,
      "logps/rejected": -271.62860107421875,
      "loss": 0.4579,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.578438639640808,
      "rewards/margins": 2.755835771560669,
      "rewards/rejected": -4.3342742919921875,
      "step": 17420
    },
    {
      "epoch": 0.8584050106439268,
      "grad_norm": 7.921550750732422,
      "learning_rate": 3.570092537901162e-05,
      "logits/chosen": 2.6131954193115234,
      "logits/rejected": 2.7605254650115967,
      "logps/chosen": -261.9692687988281,
      "logps/rejected": -283.85699462890625,
      "loss": 0.6565,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -2.117064952850342,
      "rewards/margins": 1.936131477355957,
      "rewards/rejected": -4.053196430206299,
      "step": 17440
    },
    {
      "epoch": 0.8593894200598029,
      "grad_norm": 0.888849139213562,
      "learning_rate": 3.5684517949727635e-05,
      "logits/chosen": 2.542634963989258,
      "logits/rejected": 2.6784534454345703,
      "logps/chosen": -257.69146728515625,
      "logps/rejected": -244.76089477539062,
      "loss": 0.4863,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.4777618646621704,
      "rewards/margins": 1.9855544567108154,
      "rewards/rejected": -3.4633164405822754,
      "step": 17460
    },
    {
      "epoch": 0.860373829475679,
      "grad_norm": 1.1150277853012085,
      "learning_rate": 3.566811052044366e-05,
      "logits/chosen": 2.6868515014648438,
      "logits/rejected": 2.8152871131896973,
      "logps/chosen": -265.52020263671875,
      "logps/rejected": -269.70391845703125,
      "loss": 0.4813,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.9454749822616577,
      "rewards/margins": 2.311720371246338,
      "rewards/rejected": -4.257195472717285,
      "step": 17480
    },
    {
      "epoch": 0.861358238891555,
      "grad_norm": 3.879488706588745,
      "learning_rate": 3.5651703091159676e-05,
      "logits/chosen": 2.6351494789123535,
      "logits/rejected": 2.861616849899292,
      "logps/chosen": -281.2568054199219,
      "logps/rejected": -306.72613525390625,
      "loss": 0.4872,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -2.00740122795105,
      "rewards/margins": 2.556527614593506,
      "rewards/rejected": -4.563928604125977,
      "step": 17500
    },
    {
      "epoch": 0.862342648307431,
      "grad_norm": 2.0966081619262695,
      "learning_rate": 3.56352956618757e-05,
      "logits/chosen": 2.409982204437256,
      "logits/rejected": 2.49275803565979,
      "logps/chosen": -295.67242431640625,
      "logps/rejected": -289.17626953125,
      "loss": 0.3668,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7880550622940063,
      "rewards/margins": 3.235609531402588,
      "rewards/rejected": -5.023664474487305,
      "step": 17520
    },
    {
      "epoch": 0.8633270577233071,
      "grad_norm": 3.1038706302642822,
      "learning_rate": 3.5618888232591716e-05,
      "logits/chosen": 2.4851937294006348,
      "logits/rejected": 2.5987472534179688,
      "logps/chosen": -243.864013671875,
      "logps/rejected": -280.0020751953125,
      "loss": 0.4737,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.1118197441101074,
      "rewards/margins": 2.6867175102233887,
      "rewards/rejected": -4.798537254333496,
      "step": 17540
    },
    {
      "epoch": 0.8643114671391832,
      "grad_norm": 3.4346163272857666,
      "learning_rate": 3.560248080330774e-05,
      "logits/chosen": 2.2078092098236084,
      "logits/rejected": 2.369779348373413,
      "logps/chosen": -222.59384155273438,
      "logps/rejected": -261.0206604003906,
      "loss": 0.4589,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7219429016113281,
      "rewards/margins": 2.8616766929626465,
      "rewards/rejected": -4.583619594573975,
      "step": 17560
    },
    {
      "epoch": 0.8652958765550592,
      "grad_norm": 3.9380578994750977,
      "learning_rate": 3.5586073374023757e-05,
      "logits/chosen": 2.443665027618408,
      "logits/rejected": 2.5112431049346924,
      "logps/chosen": -230.6083984375,
      "logps/rejected": -244.0526580810547,
      "loss": 0.5518,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.8123579025268555,
      "rewards/margins": 1.714057207107544,
      "rewards/rejected": -3.5264153480529785,
      "step": 17580
    },
    {
      "epoch": 0.8662802859709353,
      "grad_norm": 2.904322385787964,
      "learning_rate": 3.556966594473978e-05,
      "logits/chosen": 2.7531557083129883,
      "logits/rejected": 2.8577041625976562,
      "logps/chosen": -278.0243225097656,
      "logps/rejected": -277.1845397949219,
      "loss": 0.5725,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.143078327178955,
      "rewards/margins": 2.4563992023468018,
      "rewards/rejected": -4.599477767944336,
      "step": 17600
    },
    {
      "epoch": 0.8672646953868114,
      "grad_norm": 2.8546438217163086,
      "learning_rate": 3.5553258515455804e-05,
      "logits/chosen": 3.0807368755340576,
      "logits/rejected": 3.2082130908966064,
      "logps/chosen": -262.9140625,
      "logps/rejected": -300.50714111328125,
      "loss": 0.3506,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6185041666030884,
      "rewards/margins": 2.8159701824188232,
      "rewards/rejected": -4.434473991394043,
      "step": 17620
    },
    {
      "epoch": 0.8682491048026875,
      "grad_norm": 2.4997708797454834,
      "learning_rate": 3.553685108617182e-05,
      "logits/chosen": 2.5275118350982666,
      "logits/rejected": 2.6776747703552246,
      "logps/chosen": -287.16583251953125,
      "logps/rejected": -327.39996337890625,
      "loss": 0.4365,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.2563223838806152,
      "rewards/margins": 2.699038028717041,
      "rewards/rejected": -4.955360412597656,
      "step": 17640
    },
    {
      "epoch": 0.8692335142185635,
      "grad_norm": 1.1879165172576904,
      "learning_rate": 3.5520443656887844e-05,
      "logits/chosen": 2.4534878730773926,
      "logits/rejected": 2.622791051864624,
      "logps/chosen": -259.27740478515625,
      "logps/rejected": -248.73526000976562,
      "loss": 0.6099,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9866485595703125,
      "rewards/margins": 2.553518772125244,
      "rewards/rejected": -4.540167331695557,
      "step": 17660
    },
    {
      "epoch": 0.8702179236344396,
      "grad_norm": 5.353854179382324,
      "learning_rate": 3.550403622760386e-05,
      "logits/chosen": 2.7160425186157227,
      "logits/rejected": 2.646517515182495,
      "logps/chosen": -263.2185974121094,
      "logps/rejected": -259.7511291503906,
      "loss": 0.7418,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -2.1999447345733643,
      "rewards/margins": 1.7296043634414673,
      "rewards/rejected": -3.929548978805542,
      "step": 17680
    },
    {
      "epoch": 0.8712023330503156,
      "grad_norm": 0.6056061387062073,
      "learning_rate": 3.5487628798319885e-05,
      "logits/chosen": 2.3362812995910645,
      "logits/rejected": 2.6158580780029297,
      "logps/chosen": -259.3727722167969,
      "logps/rejected": -298.374755859375,
      "loss": 0.449,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.197979211807251,
      "rewards/margins": 2.8651235103607178,
      "rewards/rejected": -4.063102722167969,
      "step": 17700
    },
    {
      "epoch": 0.8721867424661917,
      "grad_norm": 2.5406148433685303,
      "learning_rate": 3.54712213690359e-05,
      "logits/chosen": 2.452301025390625,
      "logits/rejected": 2.6998038291931152,
      "logps/chosen": -249.676025390625,
      "logps/rejected": -258.05255126953125,
      "loss": 0.4865,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.304262638092041,
      "rewards/margins": 2.6532034873962402,
      "rewards/rejected": -3.9574661254882812,
      "step": 17720
    },
    {
      "epoch": 0.8731711518820677,
      "grad_norm": 1.307236671447754,
      "learning_rate": 3.5454813939751925e-05,
      "logits/chosen": 2.58481764793396,
      "logits/rejected": 2.740103244781494,
      "logps/chosen": -248.1825408935547,
      "logps/rejected": -286.6418762207031,
      "loss": 0.4115,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7006267309188843,
      "rewards/margins": 2.5103955268859863,
      "rewards/rejected": -4.21102237701416,
      "step": 17740
    },
    {
      "epoch": 0.8741555612979438,
      "grad_norm": 0.8031735420227051,
      "learning_rate": 3.543840651046794e-05,
      "logits/chosen": 2.3953628540039062,
      "logits/rejected": 2.6125106811523438,
      "logps/chosen": -245.4698486328125,
      "logps/rejected": -222.1780548095703,
      "loss": 0.3383,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.519853115081787,
      "rewards/margins": 2.870501756668091,
      "rewards/rejected": -4.390355110168457,
      "step": 17760
    },
    {
      "epoch": 0.8751399707138199,
      "grad_norm": 2.156182050704956,
      "learning_rate": 3.542199908118396e-05,
      "logits/chosen": 2.591217279434204,
      "logits/rejected": 2.7753188610076904,
      "logps/chosen": -265.1336364746094,
      "logps/rejected": -279.37939453125,
      "loss": 0.4702,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0968592166900635,
      "rewards/margins": 2.511425256729126,
      "rewards/rejected": -4.6082844734191895,
      "step": 17780
    },
    {
      "epoch": 0.876124380129696,
      "grad_norm": 1.740242600440979,
      "learning_rate": 3.540559165189998e-05,
      "logits/chosen": 2.6179308891296387,
      "logits/rejected": 2.692124843597412,
      "logps/chosen": -269.20123291015625,
      "logps/rejected": -285.90692138671875,
      "loss": 0.4543,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.831864595413208,
      "rewards/margins": 2.6503021717071533,
      "rewards/rejected": -4.482166290283203,
      "step": 17800
    },
    {
      "epoch": 0.877108789545572,
      "grad_norm": 2.06193208694458,
      "learning_rate": 3.5389184222616e-05,
      "logits/chosen": 2.5917258262634277,
      "logits/rejected": 2.8383445739746094,
      "logps/chosen": -298.9986572265625,
      "logps/rejected": -315.9997863769531,
      "loss": 0.3852,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.2841696739196777,
      "rewards/margins": 3.0203654766082764,
      "rewards/rejected": -5.304534912109375,
      "step": 17820
    },
    {
      "epoch": 0.8780931989614481,
      "grad_norm": 1.6371632814407349,
      "learning_rate": 3.537277679333202e-05,
      "logits/chosen": 2.679919481277466,
      "logits/rejected": 2.915137529373169,
      "logps/chosen": -270.92138671875,
      "logps/rejected": -283.29571533203125,
      "loss": 0.5843,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -1.4034841060638428,
      "rewards/margins": 2.232452154159546,
      "rewards/rejected": -3.6359362602233887,
      "step": 17840
    },
    {
      "epoch": 0.8790776083773242,
      "grad_norm": 2.7111923694610596,
      "learning_rate": 3.535636936404804e-05,
      "logits/chosen": 2.276796817779541,
      "logits/rejected": 2.5729355812072754,
      "logps/chosen": -227.7137908935547,
      "logps/rejected": -256.35687255859375,
      "loss": 0.3908,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0665717124938965,
      "rewards/margins": 2.865739345550537,
      "rewards/rejected": -4.932311058044434,
      "step": 17860
    },
    {
      "epoch": 0.8800620177932001,
      "grad_norm": 2.2918484210968018,
      "learning_rate": 3.533996193476406e-05,
      "logits/chosen": 2.2925963401794434,
      "logits/rejected": 2.5834827423095703,
      "logps/chosen": -257.76116943359375,
      "logps/rejected": -260.94537353515625,
      "loss": 0.292,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.7170116901397705,
      "rewards/margins": 3.2824013233184814,
      "rewards/rejected": -4.999413013458252,
      "step": 17880
    },
    {
      "epoch": 0.8810464272090762,
      "grad_norm": 1.3389945030212402,
      "learning_rate": 3.532355450548008e-05,
      "logits/chosen": 2.5711302757263184,
      "logits/rejected": 2.693525791168213,
      "logps/chosen": -281.9706726074219,
      "logps/rejected": -309.431640625,
      "loss": 0.2668,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -1.7958256006240845,
      "rewards/margins": 3.925898313522339,
      "rewards/rejected": -5.721724033355713,
      "step": 17900
    },
    {
      "epoch": 0.8820308366249523,
      "grad_norm": 6.039734840393066,
      "learning_rate": 3.5307147076196104e-05,
      "logits/chosen": 2.2159533500671387,
      "logits/rejected": 2.4855127334594727,
      "logps/chosen": -259.28106689453125,
      "logps/rejected": -308.8600158691406,
      "loss": 0.4543,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.879915475845337,
      "rewards/margins": 3.2959187030792236,
      "rewards/rejected": -6.175833702087402,
      "step": 17920
    },
    {
      "epoch": 0.8830152460408284,
      "grad_norm": 3.2966291904449463,
      "learning_rate": 3.529073964691213e-05,
      "logits/chosen": 2.3023598194122314,
      "logits/rejected": 2.4988481998443604,
      "logps/chosen": -283.64544677734375,
      "logps/rejected": -307.23089599609375,
      "loss": 0.641,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.944551944732666,
      "rewards/margins": 3.140153169631958,
      "rewards/rejected": -6.084705352783203,
      "step": 17940
    },
    {
      "epoch": 0.8839996554567044,
      "grad_norm": 2.553210496902466,
      "learning_rate": 3.5274332217628144e-05,
      "logits/chosen": 2.290804147720337,
      "logits/rejected": 2.4400908946990967,
      "logps/chosen": -289.20745849609375,
      "logps/rejected": -322.8547668457031,
      "loss": 0.6237,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.722041606903076,
      "rewards/margins": 3.148743152618408,
      "rewards/rejected": -5.870784759521484,
      "step": 17960
    },
    {
      "epoch": 0.8849840648725805,
      "grad_norm": 2.0200130939483643,
      "learning_rate": 3.525792478834417e-05,
      "logits/chosen": 2.50858736038208,
      "logits/rejected": 2.651559829711914,
      "logps/chosen": -268.87347412109375,
      "logps/rejected": -305.1802673339844,
      "loss": 0.6968,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.589151620864868,
      "rewards/margins": 2.5991828441619873,
      "rewards/rejected": -5.188333988189697,
      "step": 17980
    },
    {
      "epoch": 0.8859684742884566,
      "grad_norm": 12.124495506286621,
      "learning_rate": 3.5241517359060185e-05,
      "logits/chosen": 2.351435422897339,
      "logits/rejected": 2.5963356494903564,
      "logps/chosen": -253.0279541015625,
      "logps/rejected": -268.427734375,
      "loss": 0.757,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.6099836826324463,
      "rewards/margins": 2.091683864593506,
      "rewards/rejected": -4.701667785644531,
      "step": 18000
    },
    {
      "epoch": 0.8869528837043327,
      "grad_norm": 2.895387649536133,
      "learning_rate": 3.522510992977621e-05,
      "logits/chosen": 2.6685142517089844,
      "logits/rejected": 2.9849610328674316,
      "logps/chosen": -294.6398620605469,
      "logps/rejected": -280.71405029296875,
      "loss": 0.6133,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.8539726734161377,
      "rewards/margins": 2.17524790763855,
      "rewards/rejected": -4.029221057891846,
      "step": 18020
    },
    {
      "epoch": 0.8879372931202087,
      "grad_norm": 1.353604793548584,
      "learning_rate": 3.5208702500492225e-05,
      "logits/chosen": 2.740260362625122,
      "logits/rejected": 2.836489200592041,
      "logps/chosen": -255.6728515625,
      "logps/rejected": -290.55841064453125,
      "loss": 0.4088,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.6504840850830078,
      "rewards/margins": 2.6651954650878906,
      "rewards/rejected": -4.31567907333374,
      "step": 18040
    },
    {
      "epoch": 0.8889217025360847,
      "grad_norm": 5.24583101272583,
      "learning_rate": 3.519229507120824e-05,
      "logits/chosen": 2.610710620880127,
      "logits/rejected": 2.6283457279205322,
      "logps/chosen": -240.0519561767578,
      "logps/rejected": -246.07351684570312,
      "loss": 0.4083,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.1745973825454712,
      "rewards/margins": 2.517401933670044,
      "rewards/rejected": -3.6919994354248047,
      "step": 18060
    },
    {
      "epoch": 0.8899061119519608,
      "grad_norm": 1.5275981426239014,
      "learning_rate": 3.5175887641924266e-05,
      "logits/chosen": 2.8061716556549072,
      "logits/rejected": 2.9948313236236572,
      "logps/chosen": -254.6802520751953,
      "logps/rejected": -288.6783142089844,
      "loss": 0.4961,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7946827411651611,
      "rewards/margins": 2.7172975540161133,
      "rewards/rejected": -4.511980056762695,
      "step": 18080
    },
    {
      "epoch": 0.8908905213678369,
      "grad_norm": 2.181079626083374,
      "learning_rate": 3.515948021264028e-05,
      "logits/chosen": 2.6242194175720215,
      "logits/rejected": 2.660996437072754,
      "logps/chosen": -234.2058563232422,
      "logps/rejected": -244.5875701904297,
      "loss": 0.5159,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.086087703704834,
      "rewards/margins": 1.76850163936615,
      "rewards/rejected": -3.8545894622802734,
      "step": 18100
    },
    {
      "epoch": 0.8918749307837129,
      "grad_norm": 4.429276466369629,
      "learning_rate": 3.5143072783356306e-05,
      "logits/chosen": 2.6623191833496094,
      "logits/rejected": 2.84271240234375,
      "logps/chosen": -287.57305908203125,
      "logps/rejected": -278.42193603515625,
      "loss": 0.6241,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -2.1521499156951904,
      "rewards/margins": 2.1505255699157715,
      "rewards/rejected": -4.302675724029541,
      "step": 18120
    },
    {
      "epoch": 0.892859340199589,
      "grad_norm": 8.520204544067383,
      "learning_rate": 3.512666535407232e-05,
      "logits/chosen": 2.2475321292877197,
      "logits/rejected": 2.5573644638061523,
      "logps/chosen": -240.8190155029297,
      "logps/rejected": -259.88995361328125,
      "loss": 0.4885,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.1425838470458984,
      "rewards/margins": 2.2933220863342285,
      "rewards/rejected": -4.435905456542969,
      "step": 18140
    },
    {
      "epoch": 0.8938437496154651,
      "grad_norm": 1.9246803522109985,
      "learning_rate": 3.5110257924788346e-05,
      "logits/chosen": 2.4808483123779297,
      "logits/rejected": 2.709280490875244,
      "logps/chosen": -245.3497314453125,
      "logps/rejected": -258.1925354003906,
      "loss": 0.7053,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.0826001167297363,
      "rewards/margins": 1.8200886249542236,
      "rewards/rejected": -3.902688503265381,
      "step": 18160
    },
    {
      "epoch": 0.8948281590313412,
      "grad_norm": 6.871241092681885,
      "learning_rate": 3.509385049550436e-05,
      "logits/chosen": 2.5444774627685547,
      "logits/rejected": 2.674840211868286,
      "logps/chosen": -254.78762817382812,
      "logps/rejected": -298.2479248046875,
      "loss": 0.6209,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -2.408024311065674,
      "rewards/margins": 2.1874427795410156,
      "rewards/rejected": -4.595467567443848,
      "step": 18180
    },
    {
      "epoch": 0.8958125684472172,
      "grad_norm": 2.090853214263916,
      "learning_rate": 3.507744306622039e-05,
      "logits/chosen": 2.41084623336792,
      "logits/rejected": 2.6080665588378906,
      "logps/chosen": -278.2685852050781,
      "logps/rejected": -301.65948486328125,
      "loss": 0.6017,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.7571141719818115,
      "rewards/margins": 2.5609185695648193,
      "rewards/rejected": -5.318032264709473,
      "step": 18200
    },
    {
      "epoch": 0.8967969778630933,
      "grad_norm": 3.370913028717041,
      "learning_rate": 3.5061035636936404e-05,
      "logits/chosen": 2.398681640625,
      "logits/rejected": 2.4789648056030273,
      "logps/chosen": -270.08197021484375,
      "logps/rejected": -269.6436462402344,
      "loss": 0.4321,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.8014476299285889,
      "rewards/margins": 2.465216875076294,
      "rewards/rejected": -4.266664505004883,
      "step": 18220
    },
    {
      "epoch": 0.8977813872789693,
      "grad_norm": 2.4702847003936768,
      "learning_rate": 3.504462820765243e-05,
      "logits/chosen": 2.6827709674835205,
      "logits/rejected": 2.941206455230713,
      "logps/chosen": -282.1757507324219,
      "logps/rejected": -311.2469177246094,
      "loss": 0.5541,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.8997671604156494,
      "rewards/margins": 2.5098886489868164,
      "rewards/rejected": -4.409655570983887,
      "step": 18240
    },
    {
      "epoch": 0.8987657966948454,
      "grad_norm": 1.2327951192855835,
      "learning_rate": 3.502822077836845e-05,
      "logits/chosen": 2.526090145111084,
      "logits/rejected": 2.5933191776275635,
      "logps/chosen": -266.67547607421875,
      "logps/rejected": -290.0364685058594,
      "loss": 0.5363,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8083724975585938,
      "rewards/margins": 2.417875289916992,
      "rewards/rejected": -4.226247787475586,
      "step": 18260
    },
    {
      "epoch": 0.8997502061107214,
      "grad_norm": 5.032370090484619,
      "learning_rate": 3.501181334908447e-05,
      "logits/chosen": 2.630962610244751,
      "logits/rejected": 2.8756396770477295,
      "logps/chosen": -266.226318359375,
      "logps/rejected": -276.56640625,
      "loss": 0.4724,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.5177677869796753,
      "rewards/margins": 2.1626827716827393,
      "rewards/rejected": -3.680449962615967,
      "step": 18280
    },
    {
      "epoch": 0.9007346155265975,
      "grad_norm": 3.3452744483947754,
      "learning_rate": 3.499540591980049e-05,
      "logits/chosen": 2.646899700164795,
      "logits/rejected": 2.787309169769287,
      "logps/chosen": -261.4903259277344,
      "logps/rejected": -250.8380126953125,
      "loss": 0.5106,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.667586326599121,
      "rewards/margins": 1.8018782138824463,
      "rewards/rejected": -3.4694645404815674,
      "step": 18300
    },
    {
      "epoch": 0.9017190249424736,
      "grad_norm": 4.803933620452881,
      "learning_rate": 3.497899849051651e-05,
      "logits/chosen": 2.635622978210449,
      "logits/rejected": 2.861359119415283,
      "logps/chosen": -259.68048095703125,
      "logps/rejected": -274.03167724609375,
      "loss": 0.4828,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8240077495574951,
      "rewards/margins": 2.349520444869995,
      "rewards/rejected": -4.17352819442749,
      "step": 18320
    },
    {
      "epoch": 0.9027034343583497,
      "grad_norm": 1.6041510105133057,
      "learning_rate": 3.496259106123253e-05,
      "logits/chosen": 2.753880500793457,
      "logits/rejected": 2.8592369556427,
      "logps/chosen": -250.80734252929688,
      "logps/rejected": -254.03884887695312,
      "loss": 0.6799,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.8336527347564697,
      "rewards/margins": 1.806988000869751,
      "rewards/rejected": -3.6406409740448,
      "step": 18340
    },
    {
      "epoch": 0.9036878437742257,
      "grad_norm": 1.444320797920227,
      "learning_rate": 3.494618363194855e-05,
      "logits/chosen": 2.6537837982177734,
      "logits/rejected": 2.7194409370422363,
      "logps/chosen": -272.769287109375,
      "logps/rejected": -291.588134765625,
      "loss": 0.5335,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.620340347290039,
      "rewards/margins": 2.1968798637390137,
      "rewards/rejected": -3.8172202110290527,
      "step": 18360
    },
    {
      "epoch": 0.9046722531901018,
      "grad_norm": 2.7387771606445312,
      "learning_rate": 3.4929776202664566e-05,
      "logits/chosen": 2.484839677810669,
      "logits/rejected": 2.82100248336792,
      "logps/chosen": -250.03164672851562,
      "logps/rejected": -257.1274719238281,
      "loss": 0.4948,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.969464898109436,
      "rewards/margins": 2.1518492698669434,
      "rewards/rejected": -4.12131404876709,
      "step": 18380
    },
    {
      "epoch": 0.9056566626059779,
      "grad_norm": 1.790913701057434,
      "learning_rate": 3.491336877338059e-05,
      "logits/chosen": 2.5614707469940186,
      "logits/rejected": 2.767375946044922,
      "logps/chosen": -251.7299346923828,
      "logps/rejected": -267.3258361816406,
      "loss": 0.4762,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.2972707748413086,
      "rewards/margins": 1.9266927242279053,
      "rewards/rejected": -3.223963975906372,
      "step": 18400
    },
    {
      "epoch": 0.9066410720218538,
      "grad_norm": 2.287194013595581,
      "learning_rate": 3.4896961344096606e-05,
      "logits/chosen": 2.853299617767334,
      "logits/rejected": 3.0523743629455566,
      "logps/chosen": -279.338623046875,
      "logps/rejected": -277.3390197753906,
      "loss": 0.3304,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.5986502170562744,
      "rewards/margins": 3.046962022781372,
      "rewards/rejected": -4.645612716674805,
      "step": 18420
    },
    {
      "epoch": 0.9076254814377299,
      "grad_norm": 2.2304635047912598,
      "learning_rate": 3.488055391481263e-05,
      "logits/chosen": 2.456524610519409,
      "logits/rejected": 2.7617897987365723,
      "logps/chosen": -254.36154174804688,
      "logps/rejected": -257.06695556640625,
      "loss": 0.3846,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.25465989112854,
      "rewards/margins": 2.4263787269592285,
      "rewards/rejected": -3.6810386180877686,
      "step": 18440
    },
    {
      "epoch": 0.908609890853606,
      "grad_norm": 0.8630841970443726,
      "learning_rate": 3.4864146485528646e-05,
      "logits/chosen": 2.49372935295105,
      "logits/rejected": 2.717952013015747,
      "logps/chosen": -233.5165557861328,
      "logps/rejected": -303.86407470703125,
      "loss": 0.4773,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.7918932437896729,
      "rewards/margins": 2.2487432956695557,
      "rewards/rejected": -4.0406365394592285,
      "step": 18460
    },
    {
      "epoch": 0.9095943002694821,
      "grad_norm": 9.795790672302246,
      "learning_rate": 3.484773905624467e-05,
      "logits/chosen": 2.4000601768493652,
      "logits/rejected": 2.4867050647735596,
      "logps/chosen": -295.41510009765625,
      "logps/rejected": -291.27294921875,
      "loss": 0.4216,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.180755853652954,
      "rewards/margins": 2.0917131900787354,
      "rewards/rejected": -4.2724690437316895,
      "step": 18480
    },
    {
      "epoch": 0.9105787096853581,
      "grad_norm": 3.171243190765381,
      "learning_rate": 3.483215199842489e-05,
      "logits/chosen": 2.6441650390625,
      "logits/rejected": 2.809589385986328,
      "logps/chosen": -264.211181640625,
      "logps/rejected": -265.44000244140625,
      "loss": 0.3192,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.111246109008789,
      "rewards/margins": 2.7018685340881348,
      "rewards/rejected": -4.813115119934082,
      "step": 18500
    },
    {
      "epoch": 0.9115631191012342,
      "grad_norm": 4.459876537322998,
      "learning_rate": 3.4815744569140905e-05,
      "logits/chosen": 2.6036858558654785,
      "logits/rejected": 2.6402587890625,
      "logps/chosen": -257.1280822753906,
      "logps/rejected": -287.12750244140625,
      "loss": 0.5978,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.248918056488037,
      "rewards/margins": 2.405665397644043,
      "rewards/rejected": -4.654583930969238,
      "step": 18520
    },
    {
      "epoch": 0.9125475285171103,
      "grad_norm": 3.771138906478882,
      "learning_rate": 3.479933713985693e-05,
      "logits/chosen": 2.9465832710266113,
      "logits/rejected": 3.009157180786133,
      "logps/chosen": -266.494140625,
      "logps/rejected": -270.2781677246094,
      "loss": 0.4762,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.1633777618408203,
      "rewards/margins": 2.240295886993408,
      "rewards/rejected": -4.403674125671387,
      "step": 18540
    },
    {
      "epoch": 0.9135319379329864,
      "grad_norm": 3.0113399028778076,
      "learning_rate": 3.4782929710572946e-05,
      "logits/chosen": 2.7230985164642334,
      "logits/rejected": 2.824157238006592,
      "logps/chosen": -262.77093505859375,
      "logps/rejected": -280.87518310546875,
      "loss": 0.4162,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5832157135009766,
      "rewards/margins": 2.7370986938476562,
      "rewards/rejected": -4.320314407348633,
      "step": 18560
    },
    {
      "epoch": 0.9145163473488624,
      "grad_norm": 2.3712315559387207,
      "learning_rate": 3.476652228128897e-05,
      "logits/chosen": 2.6158313751220703,
      "logits/rejected": 2.9495997428894043,
      "logps/chosen": -252.0790557861328,
      "logps/rejected": -248.37124633789062,
      "loss": 0.508,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -1.865126371383667,
      "rewards/margins": 2.2593624591827393,
      "rewards/rejected": -4.124488830566406,
      "step": 18580
    },
    {
      "epoch": 0.9155007567647384,
      "grad_norm": 3.392427921295166,
      "learning_rate": 3.4750114852004986e-05,
      "logits/chosen": 2.2592263221740723,
      "logits/rejected": 2.383702516555786,
      "logps/chosen": -261.09259033203125,
      "logps/rejected": -260.9217529296875,
      "loss": 0.5595,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -1.942879319190979,
      "rewards/margins": 1.8997055292129517,
      "rewards/rejected": -3.8425846099853516,
      "step": 18600
    },
    {
      "epoch": 0.9164851661806145,
      "grad_norm": 2.4551138877868652,
      "learning_rate": 3.473370742272101e-05,
      "logits/chosen": 2.60123872756958,
      "logits/rejected": 2.7632102966308594,
      "logps/chosen": -266.13543701171875,
      "logps/rejected": -254.8997039794922,
      "loss": 0.305,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.035306215286255,
      "rewards/margins": 2.7643425464630127,
      "rewards/rejected": -4.799648761749268,
      "step": 18620
    },
    {
      "epoch": 0.9174695755964906,
      "grad_norm": 0.8747766017913818,
      "learning_rate": 3.471729999343703e-05,
      "logits/chosen": 2.7949490547180176,
      "logits/rejected": 2.968242883682251,
      "logps/chosen": -252.2857666015625,
      "logps/rejected": -269.9889831542969,
      "loss": 0.3173,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.682694435119629,
      "rewards/margins": 3.054291248321533,
      "rewards/rejected": -4.73698616027832,
      "step": 18640
    },
    {
      "epoch": 0.9184539850123666,
      "grad_norm": 2.8760435581207275,
      "learning_rate": 3.470089256415305e-05,
      "logits/chosen": 2.53707218170166,
      "logits/rejected": 2.8475451469421387,
      "logps/chosen": -285.4415588378906,
      "logps/rejected": -274.1592102050781,
      "loss": 0.3743,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.405599594116211,
      "rewards/margins": 3.5839176177978516,
      "rewards/rejected": -5.989517688751221,
      "step": 18660
    },
    {
      "epoch": 0.9194383944282427,
      "grad_norm": 4.923386573791504,
      "learning_rate": 3.4684485134869074e-05,
      "logits/chosen": 2.5415561199188232,
      "logits/rejected": 2.7607524394989014,
      "logps/chosen": -261.47918701171875,
      "logps/rejected": -265.3360900878906,
      "loss": 0.5613,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.040037155151367,
      "rewards/margins": 2.823235511779785,
      "rewards/rejected": -4.863272666931152,
      "step": 18680
    },
    {
      "epoch": 0.9204228038441188,
      "grad_norm": 2.4582087993621826,
      "learning_rate": 3.466807770558509e-05,
      "logits/chosen": 2.5747008323669434,
      "logits/rejected": 2.6712193489074707,
      "logps/chosen": -270.7317810058594,
      "logps/rejected": -287.9434814453125,
      "loss": 0.5981,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.966275930404663,
      "rewards/margins": 2.558060884475708,
      "rewards/rejected": -5.524336338043213,
      "step": 18700
    },
    {
      "epoch": 0.9214072132599949,
      "grad_norm": 3.699394941329956,
      "learning_rate": 3.4651670276301114e-05,
      "logits/chosen": 2.6148035526275635,
      "logits/rejected": 2.7360188961029053,
      "logps/chosen": -272.5691833496094,
      "logps/rejected": -294.22991943359375,
      "loss": 0.4881,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.4102132320404053,
      "rewards/margins": 2.821646213531494,
      "rewards/rejected": -5.231860160827637,
      "step": 18720
    },
    {
      "epoch": 0.9223916226758709,
      "grad_norm": 2.0634686946868896,
      "learning_rate": 3.463526284701713e-05,
      "logits/chosen": 2.7808289527893066,
      "logits/rejected": 2.9367470741271973,
      "logps/chosen": -289.780029296875,
      "logps/rejected": -263.05841064453125,
      "loss": 0.4968,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8051834106445312,
      "rewards/margins": 2.2228446006774902,
      "rewards/rejected": -4.0280280113220215,
      "step": 18740
    },
    {
      "epoch": 0.923376032091747,
      "grad_norm": 3.538616180419922,
      "learning_rate": 3.4618855417733155e-05,
      "logits/chosen": 2.788849353790283,
      "logits/rejected": 2.887589931488037,
      "logps/chosen": -276.7659606933594,
      "logps/rejected": -273.76104736328125,
      "loss": 0.4418,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.9522812366485596,
      "rewards/margins": 2.4218897819519043,
      "rewards/rejected": -4.374171257019043,
      "step": 18760
    },
    {
      "epoch": 0.924360441507623,
      "grad_norm": 3.937659502029419,
      "learning_rate": 3.460244798844917e-05,
      "logits/chosen": 2.4868083000183105,
      "logits/rejected": 2.5343987941741943,
      "logps/chosen": -279.7895202636719,
      "logps/rejected": -295.32440185546875,
      "loss": 0.4305,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.7556650638580322,
      "rewards/margins": 2.5150158405303955,
      "rewards/rejected": -4.270681381225586,
      "step": 18780
    },
    {
      "epoch": 0.925344850923499,
      "grad_norm": 1.526162028312683,
      "learning_rate": 3.458604055916519e-05,
      "logits/chosen": 2.80069637298584,
      "logits/rejected": 2.885171413421631,
      "logps/chosen": -238.91696166992188,
      "logps/rejected": -246.8394317626953,
      "loss": 0.3983,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.9490419626235962,
      "rewards/margins": 3.0096850395202637,
      "rewards/rejected": -4.958726406097412,
      "step": 18800
    },
    {
      "epoch": 0.9263292603393751,
      "grad_norm": 2.0726561546325684,
      "learning_rate": 3.456963312988121e-05,
      "logits/chosen": 2.707172393798828,
      "logits/rejected": 2.827932119369507,
      "logps/chosen": -257.8813171386719,
      "logps/rejected": -271.3477783203125,
      "loss": 0.5093,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.105546474456787,
      "rewards/margins": 2.5502421855926514,
      "rewards/rejected": -4.655788421630859,
      "step": 18820
    },
    {
      "epoch": 0.9273136697552512,
      "grad_norm": 3.5503506660461426,
      "learning_rate": 3.455322570059723e-05,
      "logits/chosen": 2.4714627265930176,
      "logits/rejected": 2.50738787651062,
      "logps/chosen": -220.77420043945312,
      "logps/rejected": -243.5322723388672,
      "loss": 0.4578,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5722789764404297,
      "rewards/margins": 2.4693617820739746,
      "rewards/rejected": -4.041640758514404,
      "step": 18840
    },
    {
      "epoch": 0.9282980791711273,
      "grad_norm": 1.4252748489379883,
      "learning_rate": 3.453681827131325e-05,
      "logits/chosen": 2.5894052982330322,
      "logits/rejected": 2.550844192504883,
      "logps/chosen": -256.8836364746094,
      "logps/rejected": -281.7620544433594,
      "loss": 0.4302,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.7741502523422241,
      "rewards/margins": 2.8826069831848145,
      "rewards/rejected": -4.656757354736328,
      "step": 18860
    },
    {
      "epoch": 0.9292824885870034,
      "grad_norm": 2.499760150909424,
      "learning_rate": 3.452041084202927e-05,
      "logits/chosen": 2.6735405921936035,
      "logits/rejected": 2.9051055908203125,
      "logps/chosen": -262.068115234375,
      "logps/rejected": -274.5615539550781,
      "loss": 0.4732,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.1074681282043457,
      "rewards/margins": 2.9236063957214355,
      "rewards/rejected": -5.031074047088623,
      "step": 18880
    },
    {
      "epoch": 0.9302668980028794,
      "grad_norm": 1.1272883415222168,
      "learning_rate": 3.450400341274529e-05,
      "logits/chosen": 2.617587089538574,
      "logits/rejected": 2.9726462364196777,
      "logps/chosen": -249.7194366455078,
      "logps/rejected": -272.0508117675781,
      "loss": 0.4856,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.8058130741119385,
      "rewards/margins": 3.224031448364258,
      "rewards/rejected": -5.029843807220459,
      "step": 18900
    },
    {
      "epoch": 0.9312513074187555,
      "grad_norm": 6.3418288230896,
      "learning_rate": 3.448759598346131e-05,
      "logits/chosen": 2.220160722732544,
      "logits/rejected": 2.7531650066375732,
      "logps/chosen": -258.25482177734375,
      "logps/rejected": -281.6504821777344,
      "loss": 0.5456,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.0999855995178223,
      "rewards/margins": 2.8961358070373535,
      "rewards/rejected": -4.996121883392334,
      "step": 18920
    },
    {
      "epoch": 0.9322357168346316,
      "grad_norm": 6.491754055023193,
      "learning_rate": 3.447118855417733e-05,
      "logits/chosen": 2.4315314292907715,
      "logits/rejected": 2.6965339183807373,
      "logps/chosen": -277.9995422363281,
      "logps/rejected": -305.2677001953125,
      "loss": 0.5771,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -1.8697582483291626,
      "rewards/margins": 2.886168956756592,
      "rewards/rejected": -4.755927085876465,
      "step": 18940
    },
    {
      "epoch": 0.9332201262505075,
      "grad_norm": 7.556081295013428,
      "learning_rate": 3.445478112489336e-05,
      "logits/chosen": 2.3789496421813965,
      "logits/rejected": 2.6142220497131348,
      "logps/chosen": -245.17324829101562,
      "logps/rejected": -258.66217041015625,
      "loss": 0.4601,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.036172866821289,
      "rewards/margins": 2.754464626312256,
      "rewards/rejected": -4.790637493133545,
      "step": 18960
    },
    {
      "epoch": 0.9342045356663836,
      "grad_norm": 1.4334036111831665,
      "learning_rate": 3.4438373695609374e-05,
      "logits/chosen": 2.355172634124756,
      "logits/rejected": 2.470019578933716,
      "logps/chosen": -244.8216094970703,
      "logps/rejected": -267.63494873046875,
      "loss": 0.4999,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -1.4736073017120361,
      "rewards/margins": 2.1456007957458496,
      "rewards/rejected": -3.6192080974578857,
      "step": 18980
    },
    {
      "epoch": 0.9351889450822597,
      "grad_norm": 2.548151731491089,
      "learning_rate": 3.44219662663254e-05,
      "logits/chosen": 2.246760606765747,
      "logits/rejected": 2.5175163745880127,
      "logps/chosen": -242.72103881835938,
      "logps/rejected": -271.38006591796875,
      "loss": 0.4019,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.3937448263168335,
      "rewards/margins": 2.592259407043457,
      "rewards/rejected": -3.986003875732422,
      "step": 19000
    },
    {
      "epoch": 0.9361733544981358,
      "grad_norm": 4.22709321975708,
      "learning_rate": 3.4405558837041414e-05,
      "logits/chosen": 2.6282572746276855,
      "logits/rejected": 2.8825488090515137,
      "logps/chosen": -269.63104248046875,
      "logps/rejected": -280.88385009765625,
      "loss": 0.4696,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.173490047454834,
      "rewards/margins": 2.5588877201080322,
      "rewards/rejected": -4.732378005981445,
      "step": 19020
    },
    {
      "epoch": 0.9371577639140118,
      "grad_norm": 0.6575531959533691,
      "learning_rate": 3.438915140775744e-05,
      "logits/chosen": 2.691570997238159,
      "logits/rejected": 2.940183162689209,
      "logps/chosen": -293.6067199707031,
      "logps/rejected": -300.3759765625,
      "loss": 0.4198,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.156310558319092,
      "rewards/margins": 2.736332416534424,
      "rewards/rejected": -4.892642974853516,
      "step": 19040
    },
    {
      "epoch": 0.9381421733298879,
      "grad_norm": 3.272843599319458,
      "learning_rate": 3.4372743978473455e-05,
      "logits/chosen": 2.8941397666931152,
      "logits/rejected": 2.976562738418579,
      "logps/chosen": -247.2921905517578,
      "logps/rejected": -257.5816345214844,
      "loss": 0.4994,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.6971124410629272,
      "rewards/margins": 2.8036439418792725,
      "rewards/rejected": -4.50075626373291,
      "step": 19060
    },
    {
      "epoch": 0.939126582745764,
      "grad_norm": 6.04261589050293,
      "learning_rate": 3.435633654918948e-05,
      "logits/chosen": 3.0454280376434326,
      "logits/rejected": 3.1848387718200684,
      "logps/chosen": -280.2130126953125,
      "logps/rejected": -295.4869079589844,
      "loss": 0.4847,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.0879297256469727,
      "rewards/margins": 2.3087573051452637,
      "rewards/rejected": -4.3966875076293945,
      "step": 19080
    },
    {
      "epoch": 0.9401109921616401,
      "grad_norm": 5.706531047821045,
      "learning_rate": 3.4339929119905495e-05,
      "logits/chosen": 2.7172322273254395,
      "logits/rejected": 2.7206344604492188,
      "logps/chosen": -256.33441162109375,
      "logps/rejected": -281.1887512207031,
      "loss": 0.3054,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.0167195796966553,
      "rewards/margins": 3.247466564178467,
      "rewards/rejected": -5.264185905456543,
      "step": 19100
    },
    {
      "epoch": 0.9410954015775161,
      "grad_norm": 1.6659799814224243,
      "learning_rate": 3.432352169062151e-05,
      "logits/chosen": 2.7346696853637695,
      "logits/rejected": 2.79022216796875,
      "logps/chosen": -270.1130065917969,
      "logps/rejected": -304.7659606933594,
      "loss": 0.5459,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -2.2912259101867676,
      "rewards/margins": 2.19498872756958,
      "rewards/rejected": -4.486214637756348,
      "step": 19120
    },
    {
      "epoch": 0.9420798109933921,
      "grad_norm": 0.8718059659004211,
      "learning_rate": 3.4307114261337536e-05,
      "logits/chosen": 2.618126392364502,
      "logits/rejected": 2.8320577144622803,
      "logps/chosen": -292.421875,
      "logps/rejected": -276.67413330078125,
      "loss": 0.5836,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.480933666229248,
      "rewards/margins": 2.3898797035217285,
      "rewards/rejected": -4.870813369750977,
      "step": 19140
    },
    {
      "epoch": 0.9430642204092682,
      "grad_norm": 0.32001376152038574,
      "learning_rate": 3.429070683205355e-05,
      "logits/chosen": 2.8020780086517334,
      "logits/rejected": 3.102661371231079,
      "logps/chosen": -279.45263671875,
      "logps/rejected": -303.52447509765625,
      "loss": 0.2971,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -2.375117063522339,
      "rewards/margins": 3.3033084869384766,
      "rewards/rejected": -5.6784257888793945,
      "step": 19160
    },
    {
      "epoch": 0.9440486298251443,
      "grad_norm": 3.6029932498931885,
      "learning_rate": 3.4274299402769576e-05,
      "logits/chosen": 2.346217632293701,
      "logits/rejected": 2.5511908531188965,
      "logps/chosen": -237.18130493164062,
      "logps/rejected": -248.62265014648438,
      "loss": 0.563,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.16861891746521,
      "rewards/margins": 2.3492865562438965,
      "rewards/rejected": -4.517905235290527,
      "step": 19180
    },
    {
      "epoch": 0.9450330392410203,
      "grad_norm": 0.7323289513587952,
      "learning_rate": 3.425789197348559e-05,
      "logits/chosen": 2.773921489715576,
      "logits/rejected": 2.6731977462768555,
      "logps/chosen": -271.3962097167969,
      "logps/rejected": -293.21612548828125,
      "loss": 0.8219,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -2.283189058303833,
      "rewards/margins": 1.1105859279632568,
      "rewards/rejected": -3.3937747478485107,
      "step": 19200
    },
    {
      "epoch": 0.9460174486568964,
      "grad_norm": 1.2385799884796143,
      "learning_rate": 3.4241484544201616e-05,
      "logits/chosen": 2.3976387977600098,
      "logits/rejected": 2.609138250350952,
      "logps/chosen": -272.3353576660156,
      "logps/rejected": -295.3125305175781,
      "loss": 0.4934,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.140934467315674,
      "rewards/margins": 2.7117292881011963,
      "rewards/rejected": -4.852663993835449,
      "step": 19220
    },
    {
      "epoch": 0.9470018580727725,
      "grad_norm": 0.11389584839344025,
      "learning_rate": 3.422507711491763e-05,
      "logits/chosen": 2.980681896209717,
      "logits/rejected": 3.19865083694458,
      "logps/chosen": -276.52886962890625,
      "logps/rejected": -279.6200866699219,
      "loss": 0.5797,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.9830436706542969,
      "rewards/margins": 2.417092800140381,
      "rewards/rejected": -4.400136470794678,
      "step": 19240
    },
    {
      "epoch": 0.9479862674886486,
      "grad_norm": 2.9571211338043213,
      "learning_rate": 3.420866968563366e-05,
      "logits/chosen": 2.7366557121276855,
      "logits/rejected": 2.7229251861572266,
      "logps/chosen": -242.57260131835938,
      "logps/rejected": -275.13507080078125,
      "loss": 0.5824,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.3419541120529175,
      "rewards/margins": 1.7373511791229248,
      "rewards/rejected": -3.079305410385132,
      "step": 19260
    },
    {
      "epoch": 0.9489706769045246,
      "grad_norm": 2.036862373352051,
      "learning_rate": 3.419226225634968e-05,
      "logits/chosen": 2.6617791652679443,
      "logits/rejected": 3.0099005699157715,
      "logps/chosen": -290.759033203125,
      "logps/rejected": -299.98382568359375,
      "loss": 0.506,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.5783976316452026,
      "rewards/margins": 2.3574419021606445,
      "rewards/rejected": -3.935839891433716,
      "step": 19280
    },
    {
      "epoch": 0.9499550863204007,
      "grad_norm": 4.224208354949951,
      "learning_rate": 3.41758548270657e-05,
      "logits/chosen": 2.650114059448242,
      "logits/rejected": 2.7953009605407715,
      "logps/chosen": -254.48046875,
      "logps/rejected": -268.15008544921875,
      "loss": 0.5281,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -2.5308213233947754,
      "rewards/margins": 2.4357025623321533,
      "rewards/rejected": -4.96652364730835,
      "step": 19300
    },
    {
      "epoch": 0.9509394957362767,
      "grad_norm": 1.0547219514846802,
      "learning_rate": 3.415944739778172e-05,
      "logits/chosen": 2.587649345397949,
      "logits/rejected": 2.8355095386505127,
      "logps/chosen": -264.98748779296875,
      "logps/rejected": -261.66949462890625,
      "loss": 0.3635,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.4848352670669556,
      "rewards/margins": 2.806694507598877,
      "rewards/rejected": -4.291529655456543,
      "step": 19320
    },
    {
      "epoch": 0.9519239051521527,
      "grad_norm": 2.235653877258301,
      "learning_rate": 3.414303996849774e-05,
      "logits/chosen": 2.7364118099212646,
      "logits/rejected": 2.9977691173553467,
      "logps/chosen": -252.1322784423828,
      "logps/rejected": -277.9189758300781,
      "loss": 0.489,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.1580970287323,
      "rewards/margins": 2.358933687210083,
      "rewards/rejected": -4.517030715942383,
      "step": 19340
    },
    {
      "epoch": 0.9529083145680288,
      "grad_norm": 0.20096704363822937,
      "learning_rate": 3.412663253921376e-05,
      "logits/chosen": 2.4798882007598877,
      "logits/rejected": 2.7636783123016357,
      "logps/chosen": -255.23031616210938,
      "logps/rejected": -255.83218383789062,
      "loss": 0.4333,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5364141464233398,
      "rewards/margins": 2.0451979637145996,
      "rewards/rejected": -3.5816121101379395,
      "step": 19360
    },
    {
      "epoch": 0.9538927239839049,
      "grad_norm": 0.16009891033172607,
      "learning_rate": 3.411022510992978e-05,
      "logits/chosen": 2.604814291000366,
      "logits/rejected": 2.8714940547943115,
      "logps/chosen": -256.0582580566406,
      "logps/rejected": -261.7436218261719,
      "loss": 0.267,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -1.1676652431488037,
      "rewards/margins": 3.1664559841156006,
      "rewards/rejected": -4.334121227264404,
      "step": 19380
    },
    {
      "epoch": 0.954877133399781,
      "grad_norm": 1.5750818252563477,
      "learning_rate": 3.4093817680645795e-05,
      "logits/chosen": 2.512261390686035,
      "logits/rejected": 2.5802369117736816,
      "logps/chosen": -254.5013427734375,
      "logps/rejected": -275.146484375,
      "loss": 0.542,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.18479061126709,
      "rewards/margins": 2.2772374153137207,
      "rewards/rejected": -4.462028503417969,
      "step": 19400
    },
    {
      "epoch": 0.955861542815657,
      "grad_norm": 4.193398952484131,
      "learning_rate": 3.407741025136182e-05,
      "logits/chosen": 2.9078621864318848,
      "logits/rejected": 3.1174471378326416,
      "logps/chosen": -263.5072326660156,
      "logps/rejected": -289.726318359375,
      "loss": 0.6776,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -1.91357421875,
      "rewards/margins": 1.6620960235595703,
      "rewards/rejected": -3.575669765472412,
      "step": 19420
    },
    {
      "epoch": 0.9568459522315331,
      "grad_norm": 2.90102219581604,
      "learning_rate": 3.4061002822077835e-05,
      "logits/chosen": 2.6655616760253906,
      "logits/rejected": 2.6685237884521484,
      "logps/chosen": -244.37283325195312,
      "logps/rejected": -254.28250122070312,
      "loss": 0.5896,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.8021732568740845,
      "rewards/margins": 1.784430742263794,
      "rewards/rejected": -3.586604356765747,
      "step": 19440
    },
    {
      "epoch": 0.9578303616474092,
      "grad_norm": 1.5982842445373535,
      "learning_rate": 3.404459539279386e-05,
      "logits/chosen": 2.8935484886169434,
      "logits/rejected": 3.0683510303497314,
      "logps/chosen": -257.00048828125,
      "logps/rejected": -259.27728271484375,
      "loss": 0.3525,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.5117264986038208,
      "rewards/margins": 2.2267396450042725,
      "rewards/rejected": -3.738466262817383,
      "step": 19460
    },
    {
      "epoch": 0.9588147710632852,
      "grad_norm": 4.38400936126709,
      "learning_rate": 3.4028187963509876e-05,
      "logits/chosen": 2.625807285308838,
      "logits/rejected": 2.9084601402282715,
      "logps/chosen": -274.03948974609375,
      "logps/rejected": -298.30706787109375,
      "loss": 0.469,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.7182562351226807,
      "rewards/margins": 2.4008750915527344,
      "rewards/rejected": -4.119131565093994,
      "step": 19480
    },
    {
      "epoch": 0.9597991804791612,
      "grad_norm": 3.69130802154541,
      "learning_rate": 3.40117805342259e-05,
      "logits/chosen": 2.941443681716919,
      "logits/rejected": 3.2247910499572754,
      "logps/chosen": -308.3272399902344,
      "logps/rejected": -251.09579467773438,
      "loss": 0.5187,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -2.0328924655914307,
      "rewards/margins": 2.746589183807373,
      "rewards/rejected": -4.779481410980225,
      "step": 19500
    },
    {
      "epoch": 0.9607835898950373,
      "grad_norm": 2.431384325027466,
      "learning_rate": 3.3995373104941916e-05,
      "logits/chosen": 2.9038000106811523,
      "logits/rejected": 2.9927773475646973,
      "logps/chosen": -254.5740203857422,
      "logps/rejected": -273.4964294433594,
      "loss": 0.346,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.270660400390625,
      "rewards/margins": 3.2461025714874268,
      "rewards/rejected": -4.516762733459473,
      "step": 19520
    },
    {
      "epoch": 0.9617679993109134,
      "grad_norm": 1.6652884483337402,
      "learning_rate": 3.397896567565794e-05,
      "logits/chosen": 2.7615466117858887,
      "logits/rejected": 2.9848601818084717,
      "logps/chosen": -242.8813934326172,
      "logps/rejected": -271.1859436035156,
      "loss": 0.3373,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0725804567337036,
      "rewards/margins": 2.657597303390503,
      "rewards/rejected": -3.730177640914917,
      "step": 19540
    },
    {
      "epoch": 0.9627524087267895,
      "grad_norm": 5.327178001403809,
      "learning_rate": 3.396255824637396e-05,
      "logits/chosen": 3.0141615867614746,
      "logits/rejected": 3.247952938079834,
      "logps/chosen": -248.5539093017578,
      "logps/rejected": -250.7808074951172,
      "loss": 0.4396,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.4430763721466064,
      "rewards/margins": 2.606261730194092,
      "rewards/rejected": -4.049337863922119,
      "step": 19560
    },
    {
      "epoch": 0.9637368181426655,
      "grad_norm": 2.220404863357544,
      "learning_rate": 3.394615081708998e-05,
      "logits/chosen": 2.9522109031677246,
      "logits/rejected": 3.0851070880889893,
      "logps/chosen": -269.0969543457031,
      "logps/rejected": -270.4322204589844,
      "loss": 0.5969,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.352752685546875,
      "rewards/margins": 2.2519209384918213,
      "rewards/rejected": -4.604673862457275,
      "step": 19580
    },
    {
      "epoch": 0.9647212275585416,
      "grad_norm": 1.9724516868591309,
      "learning_rate": 3.3929743387806004e-05,
      "logits/chosen": 2.8670260906219482,
      "logits/rejected": 3.072446584701538,
      "logps/chosen": -258.3946533203125,
      "logps/rejected": -268.30230712890625,
      "loss": 0.4883,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.743767499923706,
      "rewards/margins": 2.730195999145508,
      "rewards/rejected": -4.473963260650635,
      "step": 19600
    },
    {
      "epoch": 0.9657056369744177,
      "grad_norm": 1.346852421760559,
      "learning_rate": 3.391333595852202e-05,
      "logits/chosen": 3.032086133956909,
      "logits/rejected": 3.1553704738616943,
      "logps/chosen": -298.34100341796875,
      "logps/rejected": -261.6247863769531,
      "loss": 0.4523,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.7784106731414795,
      "rewards/margins": 2.528104543685913,
      "rewards/rejected": -4.306515216827393,
      "step": 19620
    },
    {
      "epoch": 0.9666900463902938,
      "grad_norm": 0.5610674023628235,
      "learning_rate": 3.3896928529238044e-05,
      "logits/chosen": 2.829240322113037,
      "logits/rejected": 2.899972915649414,
      "logps/chosen": -268.54486083984375,
      "logps/rejected": -285.1858825683594,
      "loss": 0.6043,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -1.913487195968628,
      "rewards/margins": 2.3456549644470215,
      "rewards/rejected": -4.2591423988342285,
      "step": 19640
    },
    {
      "epoch": 0.9676744558061697,
      "grad_norm": 8.652148246765137,
      "learning_rate": 3.388052109995406e-05,
      "logits/chosen": 2.879875898361206,
      "logits/rejected": 2.9972453117370605,
      "logps/chosen": -260.3899841308594,
      "logps/rejected": -260.7587585449219,
      "loss": 0.4738,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -1.922125220298767,
      "rewards/margins": 2.1186394691467285,
      "rewards/rejected": -4.040764808654785,
      "step": 19660
    },
    {
      "epoch": 0.9686588652220458,
      "grad_norm": 1.7738903760910034,
      "learning_rate": 3.3864113670670085e-05,
      "logits/chosen": 2.9678499698638916,
      "logits/rejected": 2.961071252822876,
      "logps/chosen": -269.2601318359375,
      "logps/rejected": -252.5314178466797,
      "loss": 0.6252,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -2.2733042240142822,
      "rewards/margins": 1.8664706945419312,
      "rewards/rejected": -4.139775276184082,
      "step": 19680
    },
    {
      "epoch": 0.9696432746379219,
      "grad_norm": 1.9747849702835083,
      "learning_rate": 3.38477062413861e-05,
      "logits/chosen": 2.9159350395202637,
      "logits/rejected": 3.2178280353546143,
      "logps/chosen": -285.00848388671875,
      "logps/rejected": -280.86492919921875,
      "loss": 0.2933,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.508448839187622,
      "rewards/margins": 2.90077543258667,
      "rewards/rejected": -4.409224033355713,
      "step": 19700
    },
    {
      "epoch": 0.970627684053798,
      "grad_norm": 1.6755164861679077,
      "learning_rate": 3.383129881210212e-05,
      "logits/chosen": 2.837284564971924,
      "logits/rejected": 3.0047712326049805,
      "logps/chosen": -251.45358276367188,
      "logps/rejected": -272.49639892578125,
      "loss": 0.6047,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.7268619537353516,
      "rewards/margins": 2.385033130645752,
      "rewards/rejected": -4.1118950843811035,
      "step": 19720
    },
    {
      "epoch": 0.971612093469674,
      "grad_norm": 1.9227548837661743,
      "learning_rate": 3.381489138281814e-05,
      "logits/chosen": 2.887525796890259,
      "logits/rejected": 2.9485318660736084,
      "logps/chosen": -286.05242919921875,
      "logps/rejected": -286.3552551269531,
      "loss": 0.5239,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.679823637008667,
      "rewards/margins": 2.1907401084899902,
      "rewards/rejected": -3.8705639839172363,
      "step": 19740
    },
    {
      "epoch": 0.9725965028855501,
      "grad_norm": 1.5657575130462646,
      "learning_rate": 3.379848395353416e-05,
      "logits/chosen": 2.845376968383789,
      "logits/rejected": 2.9505510330200195,
      "logps/chosen": -252.80874633789062,
      "logps/rejected": -261.7606506347656,
      "loss": 0.3958,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -1.9105689525604248,
      "rewards/margins": 2.4900991916656494,
      "rewards/rejected": -4.400668144226074,
      "step": 19760
    },
    {
      "epoch": 0.9735809123014262,
      "grad_norm": 1.2030832767486572,
      "learning_rate": 3.378207652425018e-05,
      "logits/chosen": 2.6679627895355225,
      "logits/rejected": 3.057471752166748,
      "logps/chosen": -270.9091491699219,
      "logps/rejected": -271.54193115234375,
      "loss": 0.4793,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.4199378490447998,
      "rewards/margins": 3.0465047359466553,
      "rewards/rejected": -4.466442584991455,
      "step": 19780
    },
    {
      "epoch": 0.9745653217173023,
      "grad_norm": 3.907722234725952,
      "learning_rate": 3.37656690949662e-05,
      "logits/chosen": 2.7696781158447266,
      "logits/rejected": 3.061856269836426,
      "logps/chosen": -294.796630859375,
      "logps/rejected": -299.12835693359375,
      "loss": 0.3585,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.0555052757263184,
      "rewards/margins": 2.771282911300659,
      "rewards/rejected": -4.826787948608398,
      "step": 19800
    },
    {
      "epoch": 0.9755497311331783,
      "grad_norm": 1.4061400890350342,
      "learning_rate": 3.374926166568222e-05,
      "logits/chosen": 2.674612522125244,
      "logits/rejected": 2.973604202270508,
      "logps/chosen": -282.0682678222656,
      "logps/rejected": -258.83612060546875,
      "loss": 0.4262,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -1.5392565727233887,
      "rewards/margins": 2.9923291206359863,
      "rewards/rejected": -4.531585693359375,
      "step": 19820
    },
    {
      "epoch": 0.9765341405490543,
      "grad_norm": 1.522696614265442,
      "learning_rate": 3.373285423639824e-05,
      "logits/chosen": 2.9430766105651855,
      "logits/rejected": 3.104776382446289,
      "logps/chosen": -244.345458984375,
      "logps/rejected": -299.843505859375,
      "loss": 0.3833,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -2.228394031524658,
      "rewards/margins": 2.668370485305786,
      "rewards/rejected": -4.896763801574707,
      "step": 19840
    },
    {
      "epoch": 0.9775185499649304,
      "grad_norm": 4.394012928009033,
      "learning_rate": 3.3716446807114264e-05,
      "logits/chosen": 2.7555079460144043,
      "logits/rejected": 2.8319830894470215,
      "logps/chosen": -263.79083251953125,
      "logps/rejected": -278.12933349609375,
      "loss": 0.455,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -1.6157478094100952,
      "rewards/margins": 2.7259328365325928,
      "rewards/rejected": -4.341681003570557,
      "step": 19860
    },
    {
      "epoch": 0.9785029593808064,
      "grad_norm": 4.914345741271973,
      "learning_rate": 3.370003937783028e-05,
      "logits/chosen": 2.6803689002990723,
      "logits/rejected": 2.9597697257995605,
      "logps/chosen": -251.12368774414062,
      "logps/rejected": -288.5434265136719,
      "loss": 0.4582,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1621577739715576,
      "rewards/margins": 2.3736445903778076,
      "rewards/rejected": -4.535802364349365,
      "step": 19880
    },
    {
      "epoch": 0.9794873687966825,
      "grad_norm": 6.771846294403076,
      "learning_rate": 3.3683631948546304e-05,
      "logits/chosen": 2.738739490509033,
      "logits/rejected": 2.969444990158081,
      "logps/chosen": -266.4725036621094,
      "logps/rejected": -295.4224548339844,
      "loss": 0.3424,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -2.0253467559814453,
      "rewards/margins": 2.8754959106445312,
      "rewards/rejected": -4.900843143463135,
      "step": 19900
    },
    {
      "epoch": 0.9804717782125586,
      "grad_norm": 11.420331954956055,
      "learning_rate": 3.366722451926233e-05,
      "logits/chosen": 2.5438857078552246,
      "logits/rejected": 2.7602248191833496,
      "logps/chosen": -268.7850341796875,
      "logps/rejected": -293.27252197265625,
      "loss": 0.4153,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -2.0610995292663574,
      "rewards/margins": 3.0602328777313232,
      "rewards/rejected": -5.12133264541626,
      "step": 19920
    },
    {
      "epoch": 0.9814561876284347,
      "grad_norm": 0.6475497484207153,
      "learning_rate": 3.3650817089978344e-05,
      "logits/chosen": 2.6926097869873047,
      "logits/rejected": 2.8677055835723877,
      "logps/chosen": -256.87738037109375,
      "logps/rejected": -258.0762939453125,
      "loss": 0.6223,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -2.5861735343933105,
      "rewards/margins": 2.2965023517608643,
      "rewards/rejected": -4.882676124572754,
      "step": 19940
    },
    {
      "epoch": 0.9824405970443107,
      "grad_norm": 0.9717075228691101,
      "learning_rate": 3.363440966069437e-05,
      "logits/chosen": 2.5207836627960205,
      "logits/rejected": 2.709747552871704,
      "logps/chosen": -253.4453887939453,
      "logps/rejected": -285.87969970703125,
      "loss": 0.3711,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -1.8222614526748657,
      "rewards/margins": 3.858126401901245,
      "rewards/rejected": -5.6803879737854,
      "step": 19960
    },
    {
      "epoch": 0.9834250064601868,
      "grad_norm": 0.7594213485717773,
      "learning_rate": 3.3618002231410385e-05,
      "logits/chosen": 2.813093900680542,
      "logits/rejected": 3.0756099224090576,
      "logps/chosen": -297.18389892578125,
      "logps/rejected": -287.0049743652344,
      "loss": 0.6333,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -2.6426830291748047,
      "rewards/margins": 2.44317626953125,
      "rewards/rejected": -5.085859775543213,
      "step": 19980
    },
    {
      "epoch": 0.9844094158760629,
      "grad_norm": 13.506938934326172,
      "learning_rate": 3.360159480212641e-05,
      "logits/chosen": 2.5434775352478027,
      "logits/rejected": 2.824963092803955,
      "logps/chosen": -258.7874755859375,
      "logps/rejected": -282.3102111816406,
      "loss": 0.5615,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -2.178030490875244,
      "rewards/margins": 2.7950055599212646,
      "rewards/rejected": -4.97303581237793,
      "step": 20000
    },
    {
      "epoch": 0.9844094158760629,
      "eval_logits/chosen": 3.3568007946014404,
      "eval_logits/rejected": 3.479260206222534,
      "eval_logps/chosen": -398.0038146972656,
      "eval_logps/rejected": -364.98065185546875,
      "eval_loss": 0.6243801116943359,
      "eval_rewards/accuracies": 0.7547423243522644,
      "eval_rewards/chosen": -4.34224796295166,
      "eval_rewards/margins": 2.532402515411377,
      "eval_rewards/rejected": -6.874650955200195,
      "eval_runtime": 3532.7384,
      "eval_samples_per_second": 3.164,
      "eval_steps_per_second": 3.164,
      "step": 20000
    }
  ],
  "logging_steps": 20,
  "max_steps": 60948,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 10000,
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
